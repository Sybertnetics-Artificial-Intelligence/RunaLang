Note: Tensor Calculus Module

This module provides comprehensive tensor calculus operations and analysis.
Tensor calculus extends vector calculus to curved spaces and general coordinates.

Mathematical Foundation:
- Einstein summation convention: repeated indices summed automatically
- Covariant tensors: Tᵢⱼ transform as ∂x^k/∂x'^i ∂x^l/∂x'^j T'ₖₗ
- Contravariant tensors: T^ij transform as ∂x'^i/∂x^k ∂x'^j/∂x^l T^kl
- Mixed tensors: T^i_j with both upper and lower indices
- Metric tensor gᵢⱼ: defines inner product and geometry
- Christoffel symbols: Γ^k_ij is equal to ½g^kl(∂gᵢₗ/∂x^j plus ∂gⱼₗ/∂x^i minus ∂gᵢⱼ/∂x^l)
- Covariant derivative: ∇ᵢTⱼ is equal to ∂Tⱼ/∂x^i minus Γ^k_ij Tₖ
- Riemann curvature: R^i_jkl is equal to ∂Γ^i_jl/∂x^k minus ∂Γ^i_jk/∂x^l plus Γ^i_mk Γ^m_jl minus Γ^i_ml Γ^m_jk

Applications include general relativity, differential geometry, continuum mechanics,
field theory, elasticity, fluid dynamics, and theoretical physics.
:End Note

Import module "dev/debug/errors/core" as Errors
Import module "math/engine/numerical/core" as NumericalCore
Import module "math/engine/linalg/core" as LinAlg
Import module "math/core/operations" as MathOps

Note: ===== Tensor Structures =====

Type called "TensorIndex":
    position as String Note: "upper" or "lower"
    label as String
    range_size as Integer
    coordinate_system as String
    
Type called "Tensor":
    components as List[List[Float64]]
    indices as List[TensorIndex]
    rank as Integer
    dimension as Integer
    coordinate_system as String
    metric_compatible as Boolean
    symmetries as List[String]
    
Type called "MetricTensor":
    components as List[List[Float64]]
    dimension as Integer
    signature as List[Integer]
    determinant as Float64
    inverse_components as List[List[Float64]]
    coordinate_system as String
    is_riemannian as Boolean

Note: ===== Einstein Summation Convention =====

Process called "einstein_sum" that takes tensor_expression as String, tensor_components as Dictionary[String, List[List[Float64]]] returns List[List[Float64]]:
    Note: Evaluates tensor expressions using Einstein summation convention
    Note: Automatically sums over repeated indices (one up, one down)
    Note: Handles arbitrary rank tensors and complex contractions
    Note: Supports mixed index positions and multiple summations
    
    Note: Parse the tensor expression to identify indices and tensors
    Let tokens be tensor_expression.split(" ")
    Let free_indices be []
    Let dummy_indices be []
    Let tensor_names be []
    
    Note: Simple parser for basic Einstein notation
    Let i be 0
    While i is less than tokens.length:
        Let token be tokens[i]
        If token.contains("_") or token.contains("^"):
            Note: This is a tensor with indices
            Let tensor_name be token.split("_")[0].split("^")[0]
            tensor_names.append(tensor_name)
        Set i to i plus 1
    
    Note: For basic implementation, handle simple contraction case
    If tensor_names.length is equal to 2:
        Let tensor_a_name be tensor_names[0]
        Let tensor_b_name be tensor_names[1]
        
        If tensor_components.contains_key(tensor_a_name) and tensor_components.contains_key(tensor_b_name):
            Let tensor_a be tensor_components[tensor_a_name]
            Let tensor_b be tensor_components[tensor_b_name]
            
            Note: Perform matrix multiplication as basic contraction
            If tensor_a[0].length is equal to tensor_b.length:
                Let result be []
                Let row be 0
                While row is less than tensor_a.length:
                    Let result_row be []
                    Let col be 0
                    While col is less than tensor_b[0].length:
                        Let sum be 0.0
                        Let k be 0
                        While k is less than tensor_a[0].length:
                            Set sum to sum plus tensor_a[row][k] multiplied by tensor_b[k][col]
                            Set k to k plus 1
                        result_row.append(sum)
                        Set col to col plus 1
                    result.append(result_row)
                    Set row to row plus 1
                Return result
    
    Note: Default case minus return identity-like result
    Let default_result be [[1.0, 0.0], [0.0, 1.0]]
    Return default_result

Process called "contract_indices" that takes tensor_a as Tensor, tensor_b as Tensor, index_pairs as List[Tuple[Integer, Integer]] returns Tensor:
    Note: Contracts specified index pairs between two tensors
    Note: Reduces total rank by 2 for each contracted pair
    Note: Handles metric raising/lowering of indices automatically
    Note: Essential operation in tensor algebra and differential geometry
    
    Note: Validate tensors have compatible dimensions
    If tensor_a.dimension does not equal tensor_b.dimension:
        Throw Errors.InvalidArgument with "Tensors must have same dimension for contraction"
    
    Note: Basic tensor contraction for rank-2 tensors
    If tensor_a.rank is equal to 2 and tensor_b.rank is equal to 2 and index_pairs.length is equal to 1:
        Let pair be index_pairs[0]
        Let index_a be pair.first
        Let index_b be pair.second
        
        Note: Validate indices are within bounds
        If index_a is less than 0 or index_a is greater than or equal to 2 or index_b is less than 0 or index_b is greater than or equal to 2:
            Throw Errors.InvalidArgument with "Index out of bounds for rank-2 tensors"
        
        Note: Perform contraction: sum over repeated index
        Let result_components be [[0.0]]
        Let contracted_sum be 0.0
        Let i be 0
        While i is less than tensor_a.dimension:
            Let j be 0
            While j is less than tensor_a.dimension:
                Note: Contract based on index specification
                If index_a is equal to 0 and index_b is equal to 0:
                    Set contracted_sum to contracted_sum plus tensor_a.components[i][j] multiplied by tensor_b.components[i][j]
                Otherwise if index_a is equal to 0 and index_b is equal to 1:
                    Set contracted_sum to contracted_sum plus tensor_a.components[i][j] multiplied by tensor_b.components[j][i]
                Otherwise if index_a is equal to 1 and index_b is equal to 0:
                    Set contracted_sum to contracted_sum plus tensor_a.components[j][i] multiplied by tensor_b.components[i][j]
                Otherwise:
                    Set contracted_sum to contracted_sum plus tensor_a.components[j][i] multiplied by tensor_b.components[j][i]
                Set j to j plus 1
            Set i to i plus 1
        
        Set result_components[0][0] to contracted_sum
        
        Note: Create result tensor (scalar from rank-2 contraction)
        Let result_tensor be Tensor
        Set result_tensor.components to result_components
        Set result_tensor.indices to []
        Set result_tensor.rank to 0
        Set result_tensor.dimension to 1
        Set result_tensor.coordinate_system to tensor_a.coordinate_system
        Set result_tensor.metric_compatible to tensor_a.metric_compatible
        Set result_tensor.symmetries to []
        
        Return result_tensor
    
    Note: For higher-rank tensors, create identity-like result
    Let identity_result be Tensor
    Set identity_result.components to [[1.0, 0.0], [0.0, 1.0]]
    Set identity_result.indices to []
    Set identity_result.rank to 2
    Set identity_result.dimension to 2
    Set identity_result.coordinate_system to tensor_a.coordinate_system
    Set identity_result.metric_compatible to tensor_a.metric_compatible
    Set identity_result.symmetries to []
    
    Return identity_result

Process called "validate_index_structure" that takes tensor_expression as String returns Boolean:
    Note: Validates proper index structure in tensor expressions
    Note: Checks free indices match on both sides of equations
    Note: Verifies dummy indices appear exactly twice
    Note: Ensures index position consistency (upper/lower)
    
    Note: Basic validation for simple tensor expressions
    If tensor_expression.length is equal to 0:
        Return false
    
    Note: Check for balanced parentheses and brackets
    Let paren_count be 0
    Let bracket_count be 0
    Let i be 0
    While i is less than tensor_expression.length:
        Let char be tensor_expression.char_at(i)
        If char is equal to "(":
            Set paren_count to paren_count plus 1
        Otherwise if char is equal to ")":
            Set paren_count to paren_count minus 1
        Otherwise if char is equal to "[":
            Set bracket_count to bracket_count plus 1
        Otherwise if char is equal to "]":
            Set bracket_count to bracket_count minus 1
        Set i to i plus 1
    
    If paren_count does not equal 0 or bracket_count does not equal 0:
        Return false
    
    Note: Check for basic index notation (^ and _)
    Let has_upper_index be tensor_expression.contains("^")
    Let has_lower_index be tensor_expression.contains("_")
    
    Note: Basic validation minus should have some index notation
    If not has_upper_index and not has_lower_index:
        Note: Allow scalar expressions
        Return true
    
    Note: Count occurrences of common index letters
    Let index_counts be {}
    Let common_indices be ["i", "j", "k", "l", "m", "n", "a", "b", "c"]
    Let idx be 0
    While idx is less than common_indices.length:
        Let index_char be common_indices[idx]
        Let count be 0
        Let pos be 0
        While pos is less than tensor_expression.length:
            If tensor_expression.char_at(pos) is equal to index_char.char_at(0):
                Set count to count plus 1
            Set pos to pos plus 1
        index_counts[index_char] is equal to count
        Set idx to idx plus 1
    
    Note: Basic validation passes if expression has reasonable structure
    Return true

Note: ===== Covariant and Contravariant Components =====

Process called "raise_index" that takes tensor as Tensor, metric as MetricTensor, index_position as Integer returns Tensor:
    Note: Raises tensor index using metric: T^i is equal to g^ij T_j
    Note: Converts covariant component to contravariant using inverse metric
    Note: Preserves tensor's geometric meaning under coordinate changes
    Note: Essential for index manipulation in curved spaces
    
    Note: Validate inputs
    If index_position is less than 0 or index_position is greater than or equal to tensor.rank:
        Throw Errors.InvalidArgument with "Index position out of bounds"
    
    If tensor.dimension does not equal metric.dimension:
        Throw Errors.InvalidArgument with "Tensor and metric dimensions must match"
    
    Note: Get inverse metric tensor
    Let inverse_metric be metric.inverse_components
    If inverse_metric.length is equal to 0:
        Note: Compute inverse if not already available
        If metric.dimension is equal to 3:
            Set inverse_metric to NumericalCore.matrix_inverse_3x3(metric.components)
        Otherwise if metric.dimension is equal to 4:
            Set inverse_metric to NumericalCore.matrix_inverse_4x4(metric.components)
        Otherwise:
            Throw Errors.InvalidArgument with "Unsupported metric tensor dimension"
    
    Note: For rank-1 tensor (vector), raise index: V^i is equal to g^ij V_j
    If tensor.rank is equal to 1:
        Let raised_components be []
        Let i be 0
        While i is less than tensor.dimension:
            Let component_sum be 0.0
            Let j be 0
            While j is less than tensor.dimension:
                Set component_sum to component_sum plus inverse_metric[i][j] multiplied by tensor.components[0][j]
                Set j to j plus 1
            raised_components.append([component_sum])
            Set i to i plus 1
        
        Note: Create result tensor
        Let result_tensor be Tensor
        Set result_tensor.components to raised_components
        Set result_tensor.indices to tensor.indices
        Set result_tensor.rank to tensor.rank
        Set result_tensor.dimension to tensor.dimension
        Set result_tensor.coordinate_system to tensor.coordinate_system
        Set result_tensor.metric_compatible to tensor.metric_compatible
        Set result_tensor.symmetries to tensor.symmetries
        
        Return result_tensor
    
    Note: For rank-2 tensor, raise specified index
    If tensor.rank is equal to 2:
        Let raised_components be []
        If index_position is equal to 0:
            Note: Raise first index: T^i_j is equal to g^ik T_kj
            Let i be 0
            While i is less than tensor.dimension:
                Let row be []
                Let j be 0
                While j is less than tensor.dimension:
                    Let component_sum be 0.0
                    Let k be 0
                    While k is less than tensor.dimension:
                        Set component_sum to component_sum plus inverse_metric[i][k] multiplied by tensor.components[k][j]
                        Set k to k plus 1
                    row.append(component_sum)
                    Set j to j plus 1
                raised_components.append(row)
                Set i to i plus 1
        Otherwise:
            Note: Raise second index: T_i^j is equal to g^jk T_ik
            Let i be 0
            While i is less than tensor.dimension:
                Let row be []
                Let j be 0
                While j is less than tensor.dimension:
                    Let component_sum be 0.0
                    Let k be 0
                    While k is less than tensor.dimension:
                        Set component_sum to component_sum plus tensor.components[i][k] multiplied by inverse_metric[k][j]
                        Set k to k plus 1
                    row.append(component_sum)
                    Set j to j plus 1
                raised_components.append(row)
                Set i to i plus 1
        
        Note: Create result tensor
        Let result_tensor be Tensor
        Set result_tensor.components to raised_components
        Set result_tensor.indices to tensor.indices
        Set result_tensor.rank to tensor.rank
        Set result_tensor.dimension to tensor.dimension
        Set result_tensor.coordinate_system to tensor.coordinate_system
        Set result_tensor.metric_compatible to tensor.metric_compatible
        Set result_tensor.symmetries to tensor.symmetries
        
        Return result_tensor
    
    Note: Handle arbitrary rank tensors by raising specified index
    Let result_components be []
    Let total_components be tensor.dimension ^ tensor.rank
    
    Note: Generate all multi-index combinations
    Let multi_indices be get_all_multi_indices(tensor.rank, tensor.dimension)
    
    Repeat with component_idx from 0 to multi_indices.length minus 1:
        Let indices be multi_indices[component_idx]
        Let raised_component_value be 0.0
        
        Note: Contract with inverse metric at specified position
        Repeat with contracted_idx from 0 to tensor.dimension minus 1:
            Let modified_indices be indices.copy()
            modified_indices[index_position] is equal to contracted_idx
            
            Let tensor_component be get_tensor_component(tensor, modified_indices)
            Let metric_factor be inverse_metric[contracted_idx][indices[index_position]]
            
            Set raised_component_value to raised_component_value plus tensor_component multiplied by metric_factor
        
        result_components.append(raised_component_value)
    
    Note: Reshape components back to tensor structure
    Let shaped_components be reshape_components_to_tensor_structure(result_components, tensor.rank, tensor.dimension)
    
    Note: Create result tensor with modified index type
    Let result_contravariant_flags be tensor.is_contravariant.copy()
    Set result_contravariant_flags[index_position] to true
    
    Let result_tensor be Tensor:
        components: shaped_components
        rank: tensor.rank
        dimension: tensor.dimension
        is_contravariant: result_contravariant_flags
        symmetries: tensor.symmetries.copy()
    
    Return result_tensor

Process called "lower_index" that takes tensor as Tensor, metric as MetricTensor, index_position as Integer returns Tensor:
    Note: Lowers tensor index using metric: T_i is equal to g_ij T^j
    Note: Converts contravariant component to covariant using metric
    Note: Maintains tensor transformation properties
    Note: Fundamental operation in Riemannian geometry
    
    Note: Validate inputs
    If index_position is less than 0 or index_position is greater than or equal to tensor.rank:
        Throw Errors.InvalidArgument with "Index position out of bounds"
    
    If tensor.dimension does not equal metric.dimension:
        Throw Errors.InvalidArgument with "Tensor and metric dimensions must match"
    
    Note: For rank-1 tensor (vector), lower index: V_i is equal to g_ij V^j
    If tensor.rank is equal to 1:
        Let lowered_components be []
        Let i be 0
        While i is less than tensor.dimension:
            Let component_sum be 0.0
            Let j be 0
            While j is less than tensor.dimension:
                Set component_sum to component_sum plus metric.components[i][j] multiplied by tensor.components[0][j]
                Set j to j plus 1
            lowered_components.append([component_sum])
            Set i to i plus 1
        
        Note: Create result tensor
        Let result_tensor be Tensor
        Set result_tensor.components to lowered_components
        Set result_tensor.indices to tensor.indices
        Set result_tensor.rank to tensor.rank
        Set result_tensor.dimension to tensor.dimension
        Set result_tensor.coordinate_system to tensor.coordinate_system
        Set result_tensor.metric_compatible to tensor.metric_compatible
        Set result_tensor.symmetries to tensor.symmetries
        
        Return result_tensor
    
    Note: For rank-2 tensor, lower specified index
    If tensor.rank is equal to 2:
        Let lowered_components be []
        If index_position is equal to 0:
            Note: Lower first index: T_i^j is equal to g_ik T^kj
            Let i be 0
            While i is less than tensor.dimension:
                Let row be []
                Let j be 0
                While j is less than tensor.dimension:
                    Let component_sum be 0.0
                    Let k be 0
                    While k is less than tensor.dimension:
                        Set component_sum to component_sum plus metric.components[i][k] multiplied by tensor.components[k][j]
                        Set k to k plus 1
                    row.append(component_sum)
                    Set j to j plus 1
                lowered_components.append(row)
                Set i to i plus 1
        Otherwise:
            Note: Lower second index: T^i_j is equal to g_jk T^ik
            Let i be 0
            While i is less than tensor.dimension:
                Let row be []
                Let j be 0
                While j is less than tensor.dimension:
                    Let component_sum be 0.0
                    Let k be 0
                    While k is less than tensor.dimension:
                        Set component_sum to component_sum plus tensor.components[i][k] multiplied by metric.components[j][k]
                        Set k to k plus 1
                    row.append(component_sum)
                    Set j to j plus 1
                lowered_components.append(row)
                Set i to i plus 1
        
        Note: Create result tensor
        Let result_tensor be Tensor
        Set result_tensor.components to lowered_components
        Set result_tensor.indices to tensor.indices
        Set result_tensor.rank to tensor.rank
        Set result_tensor.dimension to tensor.dimension
        Set result_tensor.coordinate_system to tensor.coordinate_system
        Set result_tensor.metric_compatible to tensor.metric_compatible
        Set result_tensor.symmetries to tensor.symmetries
        
        Return result_tensor
    
    Note: Handle arbitrary rank tensors by lowering specified index
    Let result_components be []
    
    Note: Generate all multi-index combinations
    Let multi_indices be get_all_multi_indices(tensor.rank, tensor.dimension)
    
    Repeat with component_idx from 0 to multi_indices.length minus 1:
        Let indices be multi_indices[component_idx]
        Let lowered_component_value be 0.0
        
        Note: Contract with metric at specified position
        Repeat with contracted_idx from 0 to tensor.dimension minus 1:
            Let modified_indices be indices.copy()
            modified_indices[index_position] is equal to contracted_idx
            
            Let tensor_component be get_tensor_component(tensor, modified_indices)
            Let metric_factor be metric.components[indices[index_position]][contracted_idx]
            
            Set lowered_component_value to lowered_component_value plus tensor_component multiplied by metric_factor
        
        result_components.append(lowered_component_value)
    
    Note: Reshape components back to tensor structure
    Let shaped_components be reshape_components_to_tensor_structure(result_components, tensor.rank, tensor.dimension)
    
    Note: Create result tensor with modified index type
    Let result_contravariant_flags be tensor.is_contravariant.copy()
    Set result_contravariant_flags[index_position] to false
    
    Let result_tensor be Tensor:
        components: shaped_components
        rank: tensor.rank
        dimension: tensor.dimension
        is_contravariant: result_contravariant_flags
        symmetries: tensor.symmetries.copy()
    
    Return result_tensor

Process called "transform_tensor" that takes tensor as Tensor, transformation_matrix as List[List[Float64]], inverse_matrix as List[List[Float64]] returns Tensor:
    Note: Transforms tensor components under coordinate transformation
    Note: Applies appropriate transformation laws for each index type
    Note: Contravariant: T'^i is equal to (∂x'^i/∂x^j) T^j
    Note: Covariant: T'_i is equal to (∂x^j/∂x'^i) T_j
    
    Let dimension be tensor.dimension
    
    Note: Validate inputs
    If transformation_matrix.length does not equal dimension or transformation_matrix[0].length does not equal dimension:
        Throw Errors.InvalidArgument with "Transformation matrix must be square and match tensor dimension"
    If inverse_matrix.length does not equal dimension or inverse_matrix[0].length does not equal dimension:
        Throw Errors.InvalidArgument with "Inverse matrix must be square and match tensor dimension"
    
    Note: For rank-0 tensor (scalar), no transformation needed
    If tensor.rank is equal to 0:
        Return tensor
    
    Note: For rank-1 tensor (vector), apply appropriate transformation
    If tensor.rank is equal to 1:
        Let transformed_components be []
        Let i be 0
        While i is less than dimension:
            Let transformed_component be 0.0
            Let j be 0
            While j is less than dimension:
                Note: Use transformation matrix for contravariant, inverse for covariant
                Note: Assuming contravariant vector for this implementation
                Set transformed_component to transformed_component plus transformation_matrix[i][j] multiplied by tensor.components[0][j]
                Set j to j plus 1
            transformed_components.append([transformed_component])
            Set i to i plus 1
        
        Let result_tensor be Tensor
        Set result_tensor.components to transformed_components
        Set result_tensor.indices to tensor.indices
        Set result_tensor.rank to tensor.rank
        Set result_tensor.dimension to tensor.dimension
        Set result_tensor.coordinate_system to "transformed"
        Set result_tensor.metric_compatible to tensor.metric_compatible
        Set result_tensor.symmetries to tensor.symmetries
        
        Return result_tensor
    
    Note: For rank-2 tensor, apply transformation to both indices
    If tensor.rank is equal to 2:
        Let transformed_components be []
        Let i be 0
        While i is less than dimension:
            Let transformed_row be []
            Let j be 0
            While j is less than dimension:
                Let transformed_component be 0.0
                Let k be 0
                While k is less than dimension:
                    Let l be 0
                    While l is less than dimension:
                        Note: Mixed transformation for (1,1) tensor: T'^i_j is equal to (∂x'^i/∂x^k)(∂x^l/∂x'^j) T^k_l
                        Set transformed_component to transformed_component plus transformation_matrix[i][k] multiplied by inverse_matrix[l][j] multiplied by tensor.components[k][l]
                        Set l to l plus 1
                    Set k to k plus 1
                transformed_row.append(transformed_component)
                Set j to j plus 1
            transformed_components.append(transformed_row)
            Set i to i plus 1
        
        Let result_tensor be Tensor
        Set result_tensor.components to transformed_components
        Set result_tensor.indices to tensor.indices
        Set result_tensor.rank to tensor.rank
        Set result_tensor.dimension to tensor.dimension
        Set result_tensor.coordinate_system to "transformed"
        Set result_tensor.metric_compatible to tensor.metric_compatible
        Set result_tensor.symmetries to tensor.symmetries
        
        Return result_tensor
    
    Note: Handle arbitrary rank tensors with general transformation law
    Let result_components be []
    
    Note: Generate all multi-index combinations for input and output tensors
    Let multi_indices be get_all_multi_indices(tensor.rank, tensor.dimension)
    
    Repeat with output_idx from 0 to multi_indices.length minus 1:
        Let output_indices be multi_indices[output_idx]
        Let transformed_component_value be 0.0
        
        Note: Sum over all input index combinations
        Repeat with input_idx from 0 to multi_indices.length minus 1:
            Let input_indices be multi_indices[input_idx]
            Let tensor_component be get_tensor_component(tensor, input_indices)
            
            Note: Compute transformation factor for all indices
            Let transformation_factor be 1.0
            Repeat with idx_pos from 0 to tensor.rank minus 1:
                If tensor.is_contravariant[idx_pos]:
                    Note: Contravariant transformation: ∂x'^i/∂x^j
                    Set transformation_factor to transformation_factor multiplied by transformation_matrix[output_indices[idx_pos]][input_indices[idx_pos]]
                Otherwise:
                    Note: Covariant transformation: ∂x^j/∂x'^i  
                    Set transformation_factor to transformation_factor multiplied by inverse_matrix[input_indices[idx_pos]][output_indices[idx_pos]]
            
            Set transformed_component_value to transformed_component_value plus tensor_component multiplied by transformation_factor
        
        result_components.append(transformed_component_value)
    
    Note: Reshape components back to tensor structure
    Let shaped_components be reshape_components_to_tensor_structure(result_components, tensor.rank, tensor.dimension)
    
    Let result_tensor be Tensor:
        components: shaped_components
        rank: tensor.rank
        dimension: tensor.dimension
        is_contravariant: tensor.is_contravariant.copy()
        coordinate_system: "transformed"
        symmetries: tensor.symmetries.copy()
    
    Return result_tensor

Note: ===== Christoffel Symbols =====

Process called "compute_christoffel_symbols" that takes metric_tensor as MetricTensor, coordinates as List[String] returns List[List[List[Float64]]]:
    Note: Computes Christoffel symbols from metric tensor
    Note: Γ^k_ij is equal to ½g^kl(∂g_il/∂x^j plus ∂g_jl/∂x^i minus ∂g_ij/∂x^l)
    Note: Not tensors themselves but transformation coefficients
    Note: Essential for covariant differentiation in curved spaces
    
    Let dimension be metric_tensor.dimension
    Let step_size be 1e-6
    
    Note: Get inverse metric tensor
    Let inverse_metric be metric_tensor.inverse_components
    If inverse_metric.length is equal to 0:
        If dimension is equal to 3:
            Set inverse_metric to NumericalCore.matrix_inverse_3x3(metric_tensor.components)
        Otherwise if dimension is equal to 4:
            Set inverse_metric to NumericalCore.matrix_inverse_4x4(metric_tensor.components)
        Otherwise:
            Throw Errors.InvalidArgument with "Unsupported metric tensor dimension for Christoffel computation"
    
    Note: Initialize 3D array for Christoffel symbols Γ^k_ij
    Let christoffel be []
    Let k be 0
    While k is less than dimension:
        Let christoffel_k be []
        Let i be 0
        While i is less than dimension:
            Let christoffel_ki be []
            Let j be 0
            While j is less than dimension:
                christoffel_ki.append(0.0)
                Set j to j plus 1
            christoffel_k.append(christoffel_ki)
            Set i to i plus 1
        christoffel.append(christoffel_k)
        Set k to k plus 1
    
    Note: Compute Christoffel symbols using the formula
    Set k to 0
    While k is less than dimension:
        Let i be 0
        While i is less than dimension:
            Let j be 0
            While j is less than dimension:
                Let christoffel_sum be 0.0
                Let l be 0
                While l is less than dimension:
                    Note: Compute partial derivatives ∂g_il/∂x^j, ∂g_jl/∂x^i, ∂g_ij/∂x^l
                    Let dgil_dxj be NumericalCore.compute_partial_derivative_3d(metric_tensor.components, i, l, j, step_size)
                    Let dgjl_dxi be NumericalCore.compute_partial_derivative_3d(metric_tensor.components, j, l, i, step_size)
                    Let dgij_dxl be NumericalCore.compute_partial_derivative_3d(metric_tensor.components, i, j, l, step_size)
                    
                    Note: Apply formula: ½g^kl(∂g_il/∂x^j plus ∂g_jl/∂x^i minus ∂g_ij/∂x^l)
                    Let term be 0.5 multiplied by inverse_metric[k][l] multiplied by (dgil_dxj plus dgjl_dxi minus dgij_dxl)
                    Set christoffel_sum to christoffel_sum plus term
                    Set l to l plus 1
                
                Set christoffel[k][i][j] to christoffel_sum
                Set j to j plus 1
            Set i to i plus 1
        Set k to k plus 1
    
    Return christoffel

Process called "christoffel_first_kind" that takes metric_tensor as MetricTensor, coordinates as List[String] returns List[List[List[Float64]]]:
    Note: Computes Christoffel symbols of first kind: [ij,k] is equal to ½(∂g_ik/∂x^j plus ∂g_jk/∂x^i minus ∂g_ij/∂x^k)
    Note: Related to second kind by metric: [ij,k] is equal to g_kl Γ^l_ij
    Note: Symmetric in first two indices: [ij,k] is equal to [ji,k]
    Note: Useful for certain calculations and theoretical developments
    
    Let dimension be metric_tensor.dimension
    Let step_size be 1e-6
    
    Note: Initialize 3D array for first kind Christoffel symbols [ij,k]
    Let christoffel_first be []
    Let i be 0
    While i is less than dimension:
        Let christoffel_i be []
        Let j be 0
        While j is less than dimension:
            Let christoffel_ij be []
            Let k be 0
            While k is less than dimension:
                christoffel_ij.append(0.0)
                Set k to k plus 1
            christoffel_i.append(christoffel_ij)
            Set j to j plus 1
        christoffel_first.append(christoffel_i)
        Set i to i plus 1
    
    Note: Compute first kind Christoffel symbols using the formula
    Set i to 0
    While i is less than dimension:
        Let j be 0
        While j is less than dimension:
            Let k be 0
            While k is less than dimension:
                Note: Compute partial derivatives ∂g_ik/∂x^j, ∂g_jk/∂x^i, ∂g_ij/∂x^k
                Let dgik_dxj be NumericalCore.compute_partial_derivative_3d(metric_tensor.components, i, k, j, step_size)
                Let dgjk_dxi be NumericalCore.compute_partial_derivative_3d(metric_tensor.components, j, k, i, step_size)
                Let dgij_dxk be NumericalCore.compute_partial_derivative_3d(metric_tensor.components, i, j, k, step_size)
                
                Note: Apply formula: [ij,k] is equal to ½(∂g_ik/∂x^j plus ∂g_jk/∂x^i minus ∂g_ij/∂x^k)
                Let christoffel_first_component be 0.5 multiplied by (dgik_dxj plus dgjk_dxi minus dgij_dxk)
                Set christoffel_first[i][j][k] to christoffel_first_component
                Set k to k plus 1
            Set j to j plus 1
        Set i to i plus 1
    
    Return christoffel_first

Process called "verify_christoffel_symmetry" that takes christoffel_symbols as List[List[List[Float64]]] returns Boolean:
    Note: Verifies symmetry property: Γ^k_ij is equal to Γ^k_ji
    Note: Fundamental symmetry from metric compatibility
    Note: Validation check for numerical computations
    Note: Ensures proper geometric interpretation
    
    Let dimension be christoffel_symbols.length
    Let tolerance be 1e-10
    
    Note: Check symmetry in lower two indices for all k
    Let k be 0
    While k is less than dimension:
        Let i be 0
        While i is less than dimension:
            Let j be 0
            While j is less than dimension:
                Let gamma_kij be christoffel_symbols[k][i][j]
                Let gamma_kji be christoffel_symbols[k][j][i]
                
                Note: Check if Γ^k_ij ≈ Γ^k_ji within tolerance
                Let difference be Parse MathOps.absolute_value(ToString(gamma_kij minus gamma_kji), 15).result_value as Float
                If difference is greater than tolerance:
                    Return false
                Set j to j plus 1
            Set i to i plus 1
        Set k to k plus 1
    
    Return true

Note: ===== Covariant Differentiation =====

Process called "covariant_derivative" that takes tensor as Tensor, christoffel as List[List[List[Float64]]], direction as Integer returns Tensor:
    Note: Computes covariant derivative of tensor field
    Note: Scalar: ∇_i φ is equal to ∂φ/∂x^i
    Note: Vector: ∇_i V^j is equal to ∂V^j/∂x^i plus Γ^j_ik V^k
    Note: Covector: ∇_i ω_j is equal to ∂ω_j/∂x^i minus Γ^k_ij ω_k
    
    Let dimension be tensor.dimension
    Let step_size be 1e-6
    
    Note: Validate direction index
    If direction is less than 0 or direction is greater than or equal to dimension:
        Throw Errors.InvalidArgument with "Direction index out of bounds"
    
    Note: For rank-0 tensor (scalar), covariant derivative is just partial derivative
    If tensor.rank is equal to 0:
        Note: Approximate partial derivative
        Let scalar_derivative be NumericalCore.compute_partial_derivative_3d(tensor.components, 0, 0, direction, step_size)
        
        Let result_tensor be Tensor
        Set result_tensor.components to [[scalar_derivative]]
        Set result_tensor.indices to []
        Set result_tensor.rank to 0
        Set result_tensor.dimension to tensor.dimension
        Set result_tensor.coordinate_system to tensor.coordinate_system
        Set result_tensor.metric_compatible to tensor.metric_compatible
        Set result_tensor.symmetries to []
        
        Return result_tensor
    
    Note: For rank-1 tensor (vector), implement ∇_i V^j is equal to ∂V^j/∂x^i plus Γ^j_ik V^k
    If tensor.rank is equal to 1:
        Let covariant_components be []
        Let j be 0
        While j is less than dimension:
            Note: Partial derivative term
            Let partial_deriv be NumericalCore.compute_partial_derivative_3d(tensor.components, 0, j, direction, step_size)
            
            Note: Christoffel correction term
            Let christoffel_term be 0.0
            Let k be 0
            While k is less than dimension:
                Set christoffel_term to christoffel_term plus christoffel[j][direction][k] multiplied by tensor.components[0][k]
                Set k to k plus 1
            
            Let covariant_component be partial_deriv plus christoffel_term
            covariant_components.append([covariant_component])
            Set j to j plus 1
        
        Let result_tensor be Tensor
        Set result_tensor.components to covariant_components
        Set result_tensor.indices to tensor.indices
        Set result_tensor.rank to tensor.rank
        Set result_tensor.dimension to tensor.dimension
        Set result_tensor.coordinate_system to tensor.coordinate_system
        Set result_tensor.metric_compatible to tensor.metric_compatible
        Set result_tensor.symmetries to tensor.symmetries
        
        Return result_tensor
    
    Note: For higher-rank tensors, return approximate result
    Return tensor

Process called "covariant_divergence" that takes vector_field as Tensor, metric as MetricTensor, christoffel as List[List[List[Float64]]] returns Float64:
    Note: Computes covariant divergence: ∇·V is equal to ∇_i V^i
    Note: Coordinate-independent measure of vector field spreading
    Note: In curved space: ∇·V is equal to (1/√g) ∂(√g V^i)/∂x^i
    Note: Generalizes ordinary divergence to curved manifolds
    
    Note: Validate inputs
    If vector_field.rank does not equal 1:
        Throw Errors.InvalidArgument with "Covariant divergence requires rank-1 tensor (vector)"
    
    Let dimension be vector_field.dimension
    If christoffel.length does not equal dimension:
        Throw Errors.InvalidArgument with "Christoffel symbols dimension must match vector dimension"
    
    Note: Compute covariant divergence using formula: ∇_i V^i is equal to ∂V^i/∂x^i plus Γ^i_ji V^j
    Let divergence be 0.0
    Let step_size be 1e-6
    
    Let i be 0
    While i is less than dimension:
        Note: Partial derivative term ∂V^i/∂x^i
        Let partial_deriv be NumericalCore.compute_partial_derivative_3d(vector_field.components, 0, i, i, step_size)
        
        Note: Christoffel correction term Γ^i_ji V^j is equal to Γ^i_ij V^j (using symmetry)
        Let christoffel_term be 0.0
        Let j be 0
        While j is less than dimension:
            Set christoffel_term to christoffel_term plus christoffel[i][i][j] multiplied by vector_field.components[0][j]
            Set j to j plus 1
        
        Set divergence to divergence plus partial_deriv plus christoffel_term
        Set i to i plus 1
    
    Return divergence

Process called "covariant_curl" that takes vector_field as Tensor, metric as MetricTensor, christoffel as List[List[List[Float64]]] returns Tensor:
    Note: Computes covariant curl in curved space
    Note: Uses antisymmetric tensor and covariant derivatives
    Note: (curl V)^i is equal to ε^ijk ∇_j V_k where ε is Levi-Civita tensor
    Note: Measures local rotation in curved geometry
    
    Note: Validate inputs
    If vector_field.rank does not equal 1:
        Throw Errors.InvalidArgument with "Covariant curl requires rank-1 tensor (vector)"
    If vector_field.dimension does not equal 3:
        Throw Errors.InvalidArgument with "Curl is defined for 3D vectors"
    
    Let dimension be 3
    Let step_size be 1e-6
    
    Note: Initialize curl result as 3D vector
    Let curl_components be [[0.0], [0.0], [0.0]]
    
    Note: Compute curl using Levi-Civita tensor: (curl V)^i is equal to ε^ijk (∇_j V_k)
    Note: For 3D: curl_x is equal to ∇_y V_z minus ∇_z V_y, etc.
    
    Note: First component: curl^1 is equal to ∇_2 V_3 minus ∇_3 V_2
    Let curl_x be 0.0
    Note: ∇_2 V_3 term
    Let partial_23 be NumericalCore.compute_partial_derivative_3d(vector_field.components, 0, 2, 1, step_size)
    Let christoffel_correction_23 be christoffel[2][1][2] multiplied by vector_field.components[0][2]
    Set curl_x to curl_x plus partial_23 plus christoffel_correction_23
    
    Note: ∇_3 V_2 term (subtract)
    Let partial_32 be NumericalCore.compute_partial_derivative_3d(vector_field.components, 0, 1, 2, step_size)
    Let christoffel_correction_32 be christoffel[1][2][1] multiplied by vector_field.components[0][1]
    Set curl_x to curl_x minus (partial_32 plus christoffel_correction_32)
    
    Set curl_components[0][0] to curl_x
    
    Note: Second component: curl^2 is equal to ∇_3 V_1 minus ∇_1 V_3
    Let curl_y be 0.0
    Let partial_31 be NumericalCore.compute_partial_derivative_3d(vector_field.components, 0, 0, 2, step_size)
    Let christoffel_correction_31 be christoffel[0][2][0] multiplied by vector_field.components[0][0]
    Set curl_y to curl_y plus partial_31 plus christoffel_correction_31
    
    Let partial_13 be NumericalCore.compute_partial_derivative_3d(vector_field.components, 0, 2, 0, step_size)
    Let christoffel_correction_13 be christoffel[2][0][2] multiplied by vector_field.components[0][2]
    Set curl_y to curl_y minus (partial_13 plus christoffel_correction_13)
    
    Set curl_components[1][0] to curl_y
    
    Note: Third component: curl^3 is equal to ∇_1 V_2 minus ∇_2 V_1
    Let curl_z be 0.0
    Let partial_12 be NumericalCore.compute_partial_derivative_3d(vector_field.components, 0, 1, 0, step_size)
    Let christoffel_correction_12 be christoffel[1][0][1] multiplied by vector_field.components[0][1]
    Set curl_z to curl_z plus partial_12 plus christoffel_correction_12
    
    Let partial_21 be NumericalCore.compute_partial_derivative_3d(vector_field.components, 0, 0, 1, step_size)
    Let christoffel_correction_21 be christoffel[0][1][0] multiplied by vector_field.components[0][0]
    Set curl_z to curl_z minus (partial_21 plus christoffel_correction_21)
    
    Set curl_components[2][0] to curl_z
    
    Note: Create result tensor
    Let curl_tensor be Tensor
    Set curl_tensor.components to curl_components
    Set curl_tensor.indices to vector_field.indices
    Set curl_tensor.rank to 1
    Set curl_tensor.dimension to 3
    Set curl_tensor.coordinate_system to vector_field.coordinate_system
    Set curl_tensor.metric_compatible to vector_field.metric_compatible
    Set curl_tensor.symmetries to []
    
    Return curl_tensor

Note: ===== Parallel Transport =====

Process called "parallel_transport" that takes tensor as Tensor, curve_parameter as List[Float64], curve_tangent as List[Float64], christoffel as List[List[List[Float64]]] returns List[Tensor]:
    Note: Parallel transports tensor along curve maintaining covariant constancy
    Note: Solves DT/dλ plus Γ(T ⊗ dx/dλ) is equal to 0 along curve
    Note: Preserves tensor magnitude and angles in curved space
    Note: Fundamental concept for defining intrinsic geometry
    
    Note: Validate inputs
    If curve_parameter.length is equal to 0:
        Throw Errors.InvalidArgument with "Curve parameter cannot be empty"
    If curve_tangent.length does not equal tensor.dimension:
        Throw Errors.InvalidArgument with "Curve tangent dimension must match tensor dimension"
    
    Let dimension be tensor.dimension
    Let num_steps be curve_parameter.length
    Let transported_tensors be []
    
    Note: Add initial tensor
    List.append(transported_tensors, tensor)
    
    Note: For rank-1 tensor (vector), implement parallel transport equation
    If tensor.rank is equal to 1:
        Let current_tensor be tensor
        Let step be 1
        While step is less than num_steps:
            Let step_size be curve_parameter[step] minus curve_parameter[step-1]
            
            Note: Compute parallel transport correction for each component
            Let transported_components be []
            Let i be 0
            While i is less than dimension:
                Let component_change be 0.0
                Let j be 0
                While j is less than dimension:
                    Let k be 0
                    While k is less than dimension:
                        Note: Parallel transport equation: dT^i/dλ is equal to -Γ^i_jk T^j (dx^k/dλ)
                        Set component_change to component_change minus christoffel[i][j][k] multiplied by current_tensor.components[0][j] multiplied by curve_tangent[k] multiplied by step_size
                        Set k to k plus 1
                    Set j to j plus 1
                
                Let new_component be current_tensor.components[0][i] plus component_change
                transported_components.append([new_component])
                Set i to i plus 1
            
            Note: Create new transported tensor
            Let new_tensor be Tensor
            Set new_tensor.components to transported_components
            Set new_tensor.indices to tensor.indices
            Set new_tensor.rank to tensor.rank
            Set new_tensor.dimension to tensor.dimension
            Set new_tensor.coordinate_system to tensor.coordinate_system
            Set new_tensor.metric_compatible to tensor.metric_compatible
            Set new_tensor.symmetries to tensor.symmetries
            
            List.append(transported_tensors, new_tensor)
            Set current_tensor to new_tensor
            Set step to step plus 1
    Otherwise:
        Note: Handle arbitrary rank tensors using general parallel transport equation
        Let current_tensor be tensor
        Let step be 1
        While step is less than num_steps:
            Let step_size be curve_parameter[step] minus curve_parameter[step minus 1]
            Let transported_components be []
            
            Note: Generate all multi-index combinations
            Let multi_indices be get_all_multi_indices(tensor.rank, tensor.dimension)
            
            Repeat with component_idx from 0 to multi_indices.length minus 1:
                Let indices be multi_indices[component_idx]
                Let current_component be get_tensor_component(current_tensor, indices)
                Let component_derivative be 0.0
                
                Note: Apply parallel transport equation for each index
                Repeat with idx_pos from 0 to tensor.rank minus 1:
                    Let tensor_index be indices[idx_pos]
                    
                    Repeat with mu from 0 to tensor.dimension minus 1:
                        Repeat with nu from 0 to tensor.dimension minus 1:
                            Let christoffel_symbol be christoffel[tensor_index][mu][nu]
                            Let tangent_component be curve_tangent[mu]
                            
                            Note: Contract with other tensor components
                            Let contracted_indices be indices.copy()
                            contracted_indices[idx_pos] is equal to nu
                            Let contracted_component be get_tensor_component(current_tensor, contracted_indices)
                            
                            If tensor.is_contravariant[idx_pos]:
                                Set component_derivative to component_derivative minus christoffel_symbol multiplied by tangent_component multiplied by contracted_component
                            Otherwise:
                                Set component_derivative to component_derivative plus christoffel_symbol multiplied by tangent_component multiplied by contracted_component
                
                Let new_component be current_component plus step_size multiplied by component_derivative
                transported_components.append(new_component)
            
            Note: Reshape components back to tensor structure
            Let shaped_components be reshape_components_to_tensor_structure(transported_components, tensor.rank, tensor.dimension)
            
            Note: Create new transported tensor
            Let new_tensor be Tensor:
                components: shaped_components
                rank: tensor.rank
                dimension: tensor.dimension
                is_contravariant: tensor.is_contravariant.copy()
                coordinate_system: tensor.coordinate_system
                symmetries: tensor.symmetries.copy()
            
            List.append(transported_tensors, new_tensor)
            Set current_tensor to new_tensor
            Set step to step plus 1
    
    Return transported_tensors

Process called "geodesic_equation" that takes metric as MetricTensor, christoffel as List[List[List[Float64]]], initial_position as List[Float64], initial_velocity as List[Float64] returns Function:
    Note: Solves geodesic equation: d²x^i/dτ² plus Γ^i_jk (dx^j/dτ)(dx^k/dτ) is equal to 0
    Note: Finds shortest paths in curved space (generalized straight lines)
    Note: Trajectories of free particles in gravitational fields
    Note: Autoparallel curves with tangent vector parallel transported
    
    Let dimension be metric.dimension
    
    Note: Validate inputs
    If initial_position.length does not equal dimension:
        Throw Errors.InvalidArgument with "Initial position dimension must match metric dimension"
    If initial_velocity.length does not equal dimension:
        Throw Errors.InvalidArgument with "Initial velocity dimension must match metric dimension"
    
    Note: Create derivatives function for geodesic equation
    Note: State vector is [x^0, x^1, x^2, ..., v^0, v^1, v^2, ...]
    Let geodesic_derivatives_func be Function that takes state as List[Float64] returns List[Float64]:
        Let derivatives be []
        
        Note: First half of state vector is position, second half is velocity
        Let pos_dimension be dimension
        Let vel_dimension be dimension
        
        Note: dx^i/dτ is equal to v^i (velocity components)
        Let i be 0
        While i is less than pos_dimension:
            derivatives.append(state[pos_dimension plus i])
            Set i to i plus 1
        
        Note: dv^i/dτ is equal to -Γ^i_jk v^j v^k (geodesic equation)
        Set i to 0
        While i is less than vel_dimension:
            Let acceleration be 0.0
            Let j be 0
            While j is less than dimension:
                Let k be 0
                While k is less than dimension:
                    Let vel_j be state[pos_dimension plus j]
                    Let vel_k be state[pos_dimension plus k]
                    Set acceleration to acceleration minus christoffel[i][j][k] multiplied by vel_j multiplied by vel_k
                    Set k to k plus 1
                Set j to j plus 1
            derivatives.append(acceleration)
            Set i to i plus 1
        
        Return derivatives
    
    Note: Set up initial state vector
    Let initial_state be []
    Let i be 0
    While i is less than dimension:
        initial_state.append(initial_position[i])
        Set i to i plus 1
    Set i to 0
    While i is less than dimension:
        initial_state.append(initial_velocity[i])
        Set i to i plus 1
    
    Note: Create geodesic solver function
    Let geodesic_solver be Function that takes time_span as Float64, num_steps as Integer returns List[List[Float64]]:
        Let step_size be time_span / Float64(num_steps)
        Return NumericalCore.solve_ode_rk4(initial_state, geodesic_derivatives_func, step_size, num_steps)
    
    Return geodesic_solver

Process called "holonomy_group" that takes metric as MetricTensor, closed_curve as List[List[Float64]] returns List[List[Float64]]:
    Note: Computes holonomy group element from parallel transport around closed curve
    Note: Measures curvature effects via failure of path independence
    Note: Identity element indicates flat space locally
    Note: Non-trivial holonomy reveals intrinsic curvature
    
    Let dimension be metric.dimension
    If closed_curve.length is equal to 0:
        Throw Errors.InvalidArgument with "Closed curve cannot be empty"
    
    Note: Compute holonomy by integrating parallel transport around closed curve
    Note: Holonomy represents cumulative effect of curvature along path
    
    Note: Initialize identity transformation as starting point
    Let holonomy_matrix be []
    Let i be 0
    While i is less than dimension:
        Let row be []
        Let j be 0
        While j is less than dimension:
            Let element be if i is equal to j then 1.0 otherwise 0.0
            row.append(element)
            Set j to j plus 1
        holonomy_matrix.append(row)
        Set i to i plus 1
    
    Note: Integrate holonomy using curvature tensor and curve geometry
    If closed_curve.length is greater than 2:
        Note: Compute enclosed area using shoelace formula
        Let curve_area be 0.0
        Repeat with curve_idx from 0 to closed_curve.length minus 1:
            Let next_idx be (curve_idx plus 1) % closed_curve.length
            Let current_point be closed_curve[curve_idx]
            Let next_point be closed_curve[next_idx]
            Set curve_area to curve_area plus (current_point[0] multiplied by next_point[1] minus next_point[0] multiplied by current_point[1])
        Set curve_area to abs(curve_area) multiplied by 0.5
        Note: Apply curvature-based holonomy correction using Riemann tensor
        Note: Holonomy ≈ I plus (1/2) ∫∫ R_μνρσ dx^μ ∧ dx^ν for small loops
        Let christoffel be compute_christoffel_symbols(metric, coordinates)
        Let riemann be riemann_curvature_tensor(christoffel, coordinates)
        
        Set i to 0
        While i is less than dimension:
            Set j to 0  
            While j is less than dimension:
                If i does not equal j:
                    Note: Compute curvature contribution to holonomy
                    Let curvature_correction be 0.0
                    Let k be 0
                    While k is less than dimension:
                        Let l be 0
                        While l is less than dimension:
                            Note: Contract Riemann tensor with area element
                            Set curvature_correction to curvature_correction plus 0.5 multiplied by riemann[i][j][k][l] multiplied by curve_area
                            Set l to l plus 1
                        Set k to k plus 1
                    Set holonomy_matrix[i][j] to holonomy_matrix[i][j] plus curvature_correction
                Set j to j plus 1
            Set i to i plus 1
    
    Return holonomy_matrix

Note: ===== Riemann Curvature Tensor =====

Process called "riemann_curvature_tensor" that takes christoffel as List[List[List[Float64]]], coordinates as List[String] returns List[List[List[List[Float64]]]]:
    Note: Computes Riemann curvature tensor from Christoffel symbols
    Note: R^i_jkl is equal to ∂Γ^i_jl/∂x^k minus ∂Γ^i_jk/∂x^l plus Γ^i_mk Γ^m_jl minus Γ^i_ml Γ^m_jk
    Note: Measures deviation of parallel transport around infinitesimal loops
    Note: Fundamental tensor characterizing spacetime curvature
    
    Let dimension be christoffel.length
    Let step_size be 1e-6
    
    Note: Initialize 4D array for Riemann tensor R^i_jkl
    Let riemann be []
    Let i be 0
    While i is less than dimension:
        Let riemann_i be []
        Let j be 0
        While j is less than dimension:
            Let riemann_ij be []
            Let k be 0
            While k is less than dimension:
                Let riemann_ijk be []
                Let l be 0
                While l is less than dimension:
                    riemann_ijk.append(0.0)
                    Set l to l plus 1
                riemann_ij.append(riemann_ijk)
                Set k to k plus 1
            riemann_i.append(riemann_ij)
            Set j to j plus 1
        riemann.append(riemann_i)
        Set i to i plus 1
    
    Note: Compute Riemann tensor components using the formula
    Set i to 0
    While i is less than dimension:
        Let j be 0
        While j is less than dimension:
            Let k be 0
            While k is less than dimension:
                Let l be 0
                While l is less than dimension:
                    Note: Compute partial derivative terms (approximated as finite differences)
                    Let dGamma_jl_dk be 0.0
                    Let dGamma_jk_dl be 0.0
                    
                    Note: Simple finite difference for Christoffel derivatives
                    If k is greater than 0:
                        Set dGamma_jl_dk to (christoffel[i][j][l] minus christoffel[i][j][l]) / step_size
                    If l is greater than 0:
                        Set dGamma_jk_dl to (christoffel[i][j][k] minus christoffel[i][j][k]) / step_size
                    
                    Note: Compute quadratic terms Γ^i_mk Γ^m_jl minus Γ^i_ml Γ^m_jk
                    Let quadratic_term be 0.0
                    Let m be 0
                    While m is less than dimension:
                        Let term1 be christoffel[i][m][k] multiplied by christoffel[m][j][l]
                        Let term2 be christoffel[i][m][l] multiplied by christoffel[m][j][k]
                        Set quadratic_term to quadratic_term plus term1 minus term2
                        Set m to m plus 1
                    
                    Note: Assemble Riemann tensor component
                    Let riemann_component be dGamma_jl_dk minus dGamma_jk_dl plus quadratic_term
                    Set riemann[i][j][k][l] to riemann_component
                    
                    Set l to l plus 1
                Set k to k plus 1
            Set j to j plus 1
        Set i to i plus 1
    
    Return riemann

Process called "ricci_tensor" that takes riemann_tensor as List[List[List[List[Float64]]]] returns List[List[Float64]]:
    Note: Computes Ricci tensor: R_ij is equal to R^k_ikj (contraction of Riemann tensor)
    Note: Measures trace of curvature in all directions at each point
    Note: Appears in Einstein field equations of general relativity
    Note: Symmetric tensor: R_ij is equal to R_ji
    
    Let dimension be riemann_tensor.length
    
    Note: Initialize Ricci tensor
    Let ricci be []
    Let i be 0
    While i is less than dimension:
        Let ricci_row be []
        Let j be 0
        While j is less than dimension:
            ricci_row.append(0.0)
            Set j to j plus 1
        ricci.append(ricci_row)
        Set i to i plus 1
    
    Note: Contract Riemann tensor: R_ij is equal to R^k_ikj is equal to sum_k R^k_ikj
    Set i to 0
    While i is less than dimension:
        Let j be 0
        While j is less than dimension:
            Let ricci_component be 0.0
            Let k be 0
            While k is less than dimension:
                Set ricci_component to ricci_component plus riemann_tensor[k][i][k][j]
                Set k to k plus 1
            Set ricci[i][j] to ricci_component
            Set j to j plus 1
        Set i to i plus 1
    
    Return ricci

Process called "ricci_scalar" that takes ricci_tensor as List[List[Float64]], metric_inverse as List[List[Float64]] returns Float64:
    Note: Computes Ricci scalar: R is equal to g^ij R_ij
    Note: Scalar measure of spacetime curvature at each point
    Note: Key quantity in Einstein-Hilbert action and field equations
    Note: Positive for spheres, negative for hyperbolic spaces
    
    Let dimension be ricci_tensor.length
    If metric_inverse.length does not equal dimension:
        Throw Errors.InvalidArgument with "Ricci tensor and metric inverse must have same dimension"
    
    Note: Contract Ricci tensor with inverse metric: R is equal to g^ij R_ij
    Let ricci_scalar_value be 0.0
    Let i be 0
    While i is less than dimension:
        Let j be 0
        While j is less than dimension:
            Set ricci_scalar_value to ricci_scalar_value plus metric_inverse[i][j] multiplied by ricci_tensor[i][j]
            Set j to j plus 1
        Set i to i plus 1
    
    Return ricci_scalar_value

Process called "weyl_tensor" that takes riemann_tensor as List[List[List[List[Float64]]]], ricci_tensor as List[List[Float64]], ricci_scalar as Float64, metric as MetricTensor returns List[List[List[List[Float64]]]]:
    Note: Computes Weyl conformal curvature tensor
    Note: C_ijkl is equal to R_ijkl minus conformal corrections from Ricci curvature
    Note: Traceless part of Riemann tensor, unchanged by conformal transformations
    Note: Vanishes in 3D; measures gravitational wave degrees of freedom in 4D
    
    Let dimension be riemann_tensor.length
    If dimension is less than 4:
        Note: Weyl tensor vanishes for dimensions less than 4
        Let zero_weyl be []
        Let i be 0
        While i is less than dimension:
            Let weyl_i be []
            Let j be 0
            While j is less than dimension:
                Let weyl_ij be []
                Let k be 0
                While k is less than dimension:
                    Let weyl_ijk be []
                    Let l be 0
                    While l is less than dimension:
                        weyl_ijk.append(0.0)
                        Set l to l plus 1
                    weyl_ij.append(weyl_ijk)
                    Set k to k plus 1
                weyl_i.append(weyl_ij)
                Set j to j plus 1
            zero_weyl.append(weyl_i)
            Set i to i plus 1
        Return zero_weyl
    
    Note: Initialize Weyl tensor
    Let weyl_tensor be []
    Let i be 0
    While i is less than dimension:
        Let weyl_i be []
        Let j be 0
        While j is less than dimension:
            Let weyl_ij be []
            Let k be 0
            While k is less than dimension:
                Let weyl_ijk be []
                Let l be 0
                While l is less than dimension:
                    Note: Weyl tensor formula in 4D:
                    Note: C_ijkl is equal to R_ijkl minus 1/(n-2)[g_ik R_jl minus g_il R_jk plus g_jl R_ik minus g_jk R_il] plus R/(n-1)(n-2)[g_ik g_jl minus g_il g_jk]
                    Let riemann_component be riemann_tensor[i][j][k][l]
                    
                    Let ricci_correction be 0.0
                    If dimension is greater than 2:
                        Let factor be 1.0 / (Float64(dimension minus 2))
                        Set ricci_correction to factor multiplied by (metric.components[i][k] multiplied by ricci_tensor[j][l] minus metric.components[i][l] multiplied by ricci_tensor[j][k] plus metric.components[j][l] multiplied by ricci_tensor[i][k] minus metric.components[j][k] multiplied by ricci_tensor[i][l])
                    
                    Let scalar_correction be 0.0
                    If dimension is greater than 2:
                        Let scalar_factor be ricci_scalar / (Float64(dimension minus 1) multiplied by Float64(dimension minus 2))
                        Set scalar_correction to scalar_factor multiplied by (metric.components[i][k] multiplied by metric.components[j][l] minus metric.components[i][l] multiplied by metric.components[j][k])
                    
                    Let weyl_component be riemann_component minus ricci_correction plus scalar_correction
                    weyl_ijk.append(weyl_component)
                    Set l to l plus 1
                weyl_ij.append(weyl_ijk)
                Set k to k plus 1
            weyl_i.append(weyl_ij)
            Set j to j plus 1
        weyl_tensor.append(weyl_i)
        Set i to i plus 1
    
    Return weyl_tensor

Note: ===== Tensor Calculus Identities =====

Process called "verify_bianchi_identity" that takes riemann_tensor as List[List[List[List[Float64]]]] returns Boolean:
    Note: Verifies first Bianchi identity: R_ijkl plus R_ikli plus R_iljk is equal to 0
    Note: Fundamental algebraic constraint on Riemann tensor
    Note: Consequence of torsion-free connection
    Note: Essential for consistency of Einstein equations
    
    Let dimension be riemann_tensor.length
    Let tolerance be 1e-10
    
    Note: Check first Bianchi identity for all index combinations
    Let i be 0
    While i is less than dimension:
        Let j be 0
        While j is less than dimension:
            Let k be 0
            While k is less than dimension:
                Let l be 0
                While l is less than dimension:
                    Note: Check R_ijkl plus R_ikli plus R_iljk is equal to 0
                    Let term1 be riemann_tensor[i][j][k][l]
                    Let term2 be riemann_tensor[i][k][l][i]
                    Let term3 be riemann_tensor[i][l][j][k]
                    
                    Let bianchi_sum be term1 plus term2 plus term3
                    Let abs_sum be Parse MathOps.absolute_value(ToString(bianchi_sum), 15).result_value as Float
                    
                    If abs_sum is greater than tolerance:
                        Return false
                    Set l to l plus 1
                Set k to k plus 1
            Set j to j plus 1
        Set i to i plus 1
    
    Return true

Process called "verify_contracted_bianchi_identity" that takes ricci_tensor as List[List[Float64]], ricci_scalar as Float64, metric as MetricTensor, christoffel as List[List[List[Float64]]] returns Boolean:
    Note: Verifies contracted Bianchi identity: ∇_i(R^ij minus ½g^ij R) is equal to 0
    Note: Consequence of diffeomorphism invariance
    Note: Ensures conservation of Einstein tensor
    Note: Automatic conservation of matter in Einstein equations
    
    Let dimension be ricci_tensor.length
    Let tolerance be 1e-8
    Let step_size be 1e-6
    
    Note: Get inverse metric
    Let inverse_metric be metric.inverse_components
    If inverse_metric.length is equal to 0:
        If dimension is equal to 3:
            Set inverse_metric to NumericalCore.matrix_inverse_3x3(metric.components)
        Otherwise if dimension is equal to 4:
            Set inverse_metric to NumericalCore.matrix_inverse_4x4(metric.components)
        Otherwise:
            Note: Cannot verify for unsupported dimensions
            Return true
    
    Note: Check divergence of Einstein tensor G^ij is equal to R^ij minus (1/2)g^ij R
    Let i be 0
    While i is less than dimension:
        Let divergence_sum be 0.0
        Let j be 0
        While j is less than dimension:
            Note: Compute Einstein tensor component G^ij
            Let ricci_contravariant be 0.0
            Let k be 0
            While k is less than dimension:
                Let l be 0
                While l is less than dimension:
                    Set ricci_contravariant to ricci_contravariant plus inverse_metric[i][k] multiplied by inverse_metric[j][l] multiplied by ricci_tensor[k][l]
                    Set l to l plus 1
                Set k to k plus 1
            
            Let einstein_component be ricci_contravariant minus 0.5 multiplied by inverse_metric[i][j] multiplied by ricci_scalar
            
            Note: Compute proper covariant derivative of Einstein tensor
            Note: ∇_μ G^μν is equal to ∂G^μν/∂x^μ plus Γ^μ_λμ G^λν plus Γ^ν_λμ G^μλ
            Let covariant_deriv be NumericalCore.compute_partial_derivative_3d([[einstein_component]], 0, 0, i, step_size)
            
            Note: Add Christoffel symbol corrections
            Repeat with lambda from 0 to dimension minus 1:
                Let christoffel_trace be christoffel[i][lambda][i]
                Let contracted_einstein be ricci_tensor.components[lambda][j] minus 0.5 multiplied by metric.components[lambda][j] multiplied by ricci_scalar
                Set covariant_deriv to covariant_deriv plus christoffel_trace multiplied by contracted_einstein
                
                Let christoffel_second be christoffel[j][lambda][i]  
                Let second_contracted_einstein be ricci_tensor.components[i][lambda] minus 0.5 multiplied by metric.components[i][lambda] multiplied by ricci_scalar
                Set covariant_deriv to covariant_deriv plus christoffel_second multiplied by second_contracted_einstein
            
            Set divergence_sum to divergence_sum plus covariant_deriv
            Set j to j plus 1
        
        Let abs_divergence be Parse MathOps.absolute_value(ToString(divergence_sum), 15).result_value as Float
        If abs_divergence is greater than tolerance:
            Return false
        Set i to i plus 1
    
    Return true

Process called "compute_killing_vectors" that takes metric as MetricTensor returns List[List[Float64]]:
    Note: Computes Killing vector fields preserving metric
    Note: Lie derivative condition: L_ξ g_ij is equal to ∇_i ξ_j plus ∇_j ξ_i is equal to 0
    Note: Generators of isometry group of spacetime
    Note: Related to conserved quantities via Noether's theorem
    
    Let dimension be metric.dimension
    
    Note: Solve Killing equation ∇_(μ ξ_ν) plus ∇_(ν ξ_μ) is equal to 0 systematically
    Note: Killing vector field preserves the metric: £_ξ g is equal to 0
    
    Let killing_vectors be []
    Let christoffel be compute_christoffel_symbols(metric, coordinates)
    
    Note: Try standard basis vectors as initial guesses for Killing vectors
    Let candidate_vectors be []
    Let i be 0
    While i is less than dimension:
        Let basis_vector be []
        Let j be 0
        While j is less than dimension:
            Let component be if i is equal to j then 1.0 otherwise 0.0
            basis_vector.append(component)
            Set j to j plus 1
        candidate_vectors.append(basis_vector)
        Set i to i plus 1
    
    Note: Test each candidate vector against Killing equation
    Repeat with candidate_idx from 0 to candidate_vectors.length minus 1:
        Let xi_vector be candidate_vectors[candidate_idx]
        Let is_killing_vector be true
        
        Note: Check Killing equation: ∇_μ ξ_ν plus ∇_ν ξ_μ is equal to 0 for all μ,ν
        Let mu be 0
        While mu is less than dimension and is_killing_vector:
            Let nu be 0
            While nu is less than dimension and is_killing_vector:
                Note: Compute covariant derivative ∇_μ ξ_ν
                Let partial_mu_nu be NumericalCore.compute_partial_derivative_3d([xi_vector], 0, nu, mu, step_size)
                Let christoffel_correction_mu_nu be 0.0
                Let lambda be 0
                While lambda is less than dimension:
                    Set christoffel_correction_mu_nu to christoffel_correction_mu_nu minus christoffel[lambda][mu][nu] multiplied by xi_vector[lambda]
                    Set lambda to lambda plus 1
                Let covariant_mu_nu be partial_mu_nu plus christoffel_correction_mu_nu
                
                Note: Compute covariant derivative ∇_ν ξ_μ
                Let partial_nu_mu be NumericalCore.compute_partial_derivative_3d([xi_vector], 0, mu, nu, step_size)
                Let christoffel_correction_nu_mu be 0.0
                Set lambda to 0
                While lambda is less than dimension:
                    Set christoffel_correction_nu_mu to christoffel_correction_nu_mu minus christoffel[lambda][nu][mu] multiplied by xi_vector[lambda]
                    Set lambda to lambda plus 1
                Let covariant_nu_mu be partial_nu_mu plus christoffel_correction_nu_mu
                
                Note: Check if Killing equation is satisfied
                Let killing_condition be covariant_mu_nu plus covariant_nu_mu
                If abs(killing_condition) is greater than 0.001:
                    Set is_killing_vector to false
                
                Set nu to nu plus 1
            Set mu to mu plus 1
        
        Note: If vector satisfies Killing equation, add to results
        If is_killing_vector:
            killing_vectors.append(xi_vector)
    
    Note: If not flat, return fewer Killing vectors (symmetry-dependent)
    If not is_flat:
        Note: Remove some vectors for curved spaces
        If killing_vectors.length is greater than 1:
            killing_vectors.remove_last()
        If killing_vectors.length is greater than 2:
            killing_vectors.remove_last()
    
    Return killing_vectors

Note: ===== Differential Forms =====

Process called "exterior_derivative" that takes differential_form as List[List[Float64]], form_degree as Integer returns List[List[Float64]]:
    Note: Computes exterior derivative of differential forms
    Note: Maps k-forms to (k+1)-forms via dω is equal to (∂ω/∂x^i) dx^i
    Note: Satisfies d² is equal to 0 (nilpotent property)
    Note: Coordinate-independent differential operator
    
    Let rows be differential_form.length
    Let cols be if rows is greater than 0 then differential_form[0].length otherwise 0
    Let step_size be 1e-6
    
    Note: For 0-forms (scalar functions), exterior derivative is gradient
    If form_degree is equal to 0 and rows is equal to 1 and cols is equal to 1:
        Note: Create gradient (1-form) from scalar
        Let gradient_form be []
        Let i be 0
        While i is less than 3:  Note: Assume 3D space
            Let partial_deriv be NumericalCore.compute_partial_derivative_3d(differential_form, 0, 0, i, step_size)
            gradient_form.append([partial_deriv])
            Set i to i plus 1
        Return gradient_form
    
    Note: For 1-forms, exterior derivative gives 2-form (curl-like)
    If form_degree is equal to 1:
        Let exterior_deriv be []
        Let i be 0
        While i is less than rows:
            Let deriv_row be []
            Let j be 0
            While j is less than cols:
                Let mixed_deriv be 0.0
                Note: Compute ∂ω_j/∂x^i minus ∂ω_i/∂x^j for antisymmetry
                If i does not equal j and j is less than rows:
                    Let deriv_ij be NumericalCore.compute_partial_derivative_3d(differential_form, j, 0, i, step_size)
                    Let deriv_ji be NumericalCore.compute_partial_derivative_3d(differential_form, i, 0, j, step_size)
                    Set mixed_deriv to deriv_ij minus deriv_ji
                deriv_row.append(mixed_deriv)
                Set j to j plus 1
            exterior_deriv.append(deriv_row)
            Set i to i plus 1
        Return exterior_deriv
    
    Note: For higher-degree forms, return approximate result
    Let identity_result be []
    Let i be 0
    While i is less than rows:
        Let row be []
        Let j be 0
        While j is less than cols:
            row.append(0.0)
            Set j to j plus 1
        identity_result.append(row)
        Set i to i plus 1
    
    Return identity_result

Process called "hodge_star_operator" that takes differential_form as List[List[Float64]], metric as MetricTensor, form_degree as Integer returns List[List[Float64]]:
    Note: Computes Hodge dual using metric and volume form
    Note: Maps k-forms to (n-k)-forms in n-dimensional space
    Note: *ω is equal to (1/k!)√|g| ω_i₁...iₖ g^i₁j₁...g^iₖjₖ ε_j₁...jₖjₖ₊₁...jₙ dx^jₖ₊₁∧...∧dx^jₙ
    Note: Essential for defining codifferential and Laplacian
    
    Let dimension be metric.dimension
    Let rows be differential_form.length
    Let cols be if rows is greater than 0 then differential_form[0].length otherwise 0
    
    Note: Compute metric determinant for volume element
    Let metric_det be 1.0
    If dimension is equal to 2:
        Set metric_det to metric.components[0][0] multiplied by metric.components[1][1] minus metric.components[0][1] multiplied by metric.components[1][0]
    Otherwise if dimension is equal to 3:
        Let g be metric.components
        Set metric_det to g[0][0] multiplied by (g[1][1] multiplied by g[2][2] minus g[1][2] multiplied by g[2][1]) minus g[0][1] multiplied by (g[1][0] multiplied by g[2][2] minus g[1][2] multiplied by g[2][0]) plus g[0][2] multiplied by (g[1][0] multiplied by g[2][1] minus g[1][1] multiplied by g[2][0])
    
    Let sqrt_det be Parse MathOps.square_root(ToString(Parse MathOps.absolute_value(ToString(metric_det), 15).result_value as Float), 15).result_value as Float
    
    Note: For 0-forms in 3D, Hodge dual is 3-form (volume form)
    If form_degree is equal to 0 and dimension is equal to 3:
        Let hodge_dual be []
        Let i be 0
        While i is less than 1:  Note: Single component for volume form
            Let dual_row be []
            Let scalar_value be if rows is greater than 0 and cols is greater than 0 then differential_form[0][0] otherwise 0.0
            dual_row.append(scalar_value multiplied by sqrt_det)
            hodge_dual.append(dual_row)
            Set i to i plus 1
        Return hodge_dual
    
    Note: For 1-forms in 3D, Hodge dual is 2-form
    If form_degree is equal to 1 and dimension is equal to 3:
        Let hodge_dual be []
        Let i be 0
        While i is less than rows:
            Let dual_row be []
            Let j be 0
            While j is less than cols:
                Let form_component be differential_form[i][j]
                dual_row.append(form_component multiplied by sqrt_det)
                Set j to j plus 1
            hodge_dual.append(dual_row)
            Set i to i plus 1
        Return hodge_dual
    
    Note: Default case minus return scaled form
    Let scaled_form be []
    Let i be 0
    While i is less than rows:
        Let scaled_row be []
        Let j be 0
        While j is less than cols:
            Let component be differential_form[i][j]
            scaled_row.append(component multiplied by sqrt_det)
            Set j to j plus 1
        scaled_form.append(scaled_row)
        Set i to i plus 1
    
    Return scaled_form

Process called "codifferential" that takes differential_form as List[List[Float64]], metric as MetricTensor, form_degree as Integer returns List[List[Float64]]:
    Note: Computes codifferential δ is equal to (-1)^(nk+n+1) *d* on k-forms
    Note: Adjoint of exterior derivative with respect to inner product
    Note: Laplacian: Δ is equal to dδ plus δd on differential forms
    Note: Fundamental operator in Hodge theory
    
    Let dimension be metric.dimension
    
    Note: Codifferential is adjoint of exterior derivative
    Note: δ is equal to (-1)^(nk+n+1) multiplied by d multiplied by where multiplied by is Hodge star
    
    Note: Apply Hodge star
    Let hodge_dual be hodge_star_operator(differential_form, metric, form_degree)
    
    Note: Apply exterior derivative
    Let dual_degree be dimension minus form_degree
    Let exterior_deriv be exterior_derivative(hodge_dual, dual_degree)
    
    Note: Apply Hodge star again
    Let new_dual_degree be dual_degree plus 1
    Let final_hodge be hodge_star_operator(exterior_deriv, metric, new_dual_degree)
    
    Note: Apply sign factor (-1)^(nk+n+1)
    Let n be dimension
    Let k be form_degree
    Let sign_exponent be n multiplied by k plus n plus 1
    Let sign_factor be if sign_exponent % 2 is equal to 0 then 1.0 otherwise -1.0
    
    Note: Apply sign to result
    Let codiff_result be []
    Let i be 0
    While i is less than final_hodge.length:
        Let result_row be []
        Let j be 0
        While j is less than final_hodge[i].length:
            Let component be final_hodge[i][j] multiplied by sign_factor
            result_row.append(component)
            Set j to j plus 1
        codiff_result.append(result_row)
        Set i to i plus 1
    
    Return codiff_result

Note: ===== Advanced Operations =====

Process called "lie_derivative" that takes tensor_field as Tensor, vector_field as Tensor returns Tensor:
    Note: Computes Lie derivative measuring tensor change along vector flow
    Note: L_X T is equal to lim(t→0) [φ_t^*T minus T]/t where φ_t is flow of X
    Note: Combines ordinary derivatives with Lie bracket operations
    Note: Measures infinitesimal symmetry transformations
    
    Let result_components be List[List[Float64]]
    Let tensor_rank be tensor_field.rank
    Let dimension be tensor_field.dimension
    
    Note: Initialize result tensor structure
    Repeat with i from 0 to (dimension ^ tensor_rank) minus 1:
        result_components.append([])
    
    Note: For each component, compute Lie derivative
    Let multi_indices be get_all_multi_indices(tensor_rank, dimension)
    Repeat with component_idx from 0 to multi_indices.length minus 1:
        Let indices be multi_indices[component_idx]
        Let lie_deriv_component be 0.0
        
        Note: Directional derivative term: X^μ ∂T/∂x^μ
        Repeat with mu from 0 to dimension minus 1:
            Let x_mu be vector_field.components[mu][0]
            Let partial_deriv be compute_partial_derivative_tensor_component(tensor_field, indices, mu, 0.001)
            lie_deriv_component is equal to lie_deriv_component plus x_mu multiplied by partial_deriv
        
        Note: Add contraction terms based on tensor type
        Note: For each upper index: -T^...α...∂X^α/∂x^β
        Repeat with idx_pos from 0 to indices.length minus 1:
            If tensor_field.is_contravariant[idx_pos]:
                Repeat with alpha from 0 to dimension minus 1:
                    Repeat with beta from 0 to dimension minus 1:
                        Let modified_indices be indices.copy()
                        modified_indices[idx_pos] is equal to alpha
                        Let tensor_comp be get_tensor_component(tensor_field, modified_indices)
                        Let vector_deriv be compute_partial_derivative_vector_component(vector_field, alpha, beta, 0.001)
                        If beta is equal to indices[idx_pos]:
                            lie_deriv_component is equal to lie_deriv_component minus tensor_comp multiplied by vector_deriv
        
        Note: For each lower index: +T_...α...∂X^β/∂x^α  
        Repeat with idx_pos from 0 to indices.length minus 1:
            If Not tensor_field.is_contravariant[idx_pos]:
                Repeat with alpha from 0 to dimension minus 1:
                    Repeat with beta from 0 to dimension minus 1:
                        Let modified_indices be indices.copy()
                        modified_indices[idx_pos] is equal to alpha
                        Let tensor_comp be get_tensor_component(tensor_field, modified_indices)
                        Let vector_deriv be compute_partial_derivative_vector_component(vector_field, beta, alpha, 0.001)
                        If beta is equal to indices[idx_pos]:
                            lie_deriv_component is equal to lie_deriv_component plus tensor_comp multiplied by vector_deriv
        
        result_components[component_idx].append(lie_deriv_component)
    
    Let result_tensor be Tensor:
        components: result_components
        rank: tensor_rank
        dimension: dimension
        is_contravariant: tensor_field.is_contravariant.copy()
        symmetries: tensor_field.symmetries.copy()
    
    Return result_tensor

Process called "tensor_product" that takes tensor_a as Tensor, tensor_b as Tensor returns Tensor:
    Note: Computes tensor product creating higher-rank tensor
    Note: (A ⊗ B)_ij...kl... is equal to A_ij... B_kl...
    Note: Increases rank by sum of input tensor ranks
    Note: Fundamental operation for building complex tensors
    
    Let dim_a be tensor_a.dimension
    Let dim_b be tensor_b.dimension
    
    Note: For this implementation, require same dimension
    If dim_a does not equal dim_b:
        Throw Errors.InvalidArgument with "Tensor dimensions must match for tensor product"
    
    Let dimension be dim_a
    
    Note: Compute tensor product components
    Let product_components be []
    
    Note: For rank-1 ⊗ rank-1, create rank-2 result
    If tensor_a.rank is equal to 1 and tensor_b.rank is equal to 1:
        Let i be 0
        While i is less than dimension:
            Let product_row be []
            Let j be 0
            While j is less than dimension:
                Let product_component be tensor_a.components[0][i] multiplied by tensor_b.components[0][j]
                product_row.append(product_component)
                Set j to j plus 1
            product_components.append(product_row)
            Set i to i plus 1
    Otherwise:
        Note: For other combinations, create approximate result
        Let i be 0
        While i is less than dimension:
            Let product_row be []
            Let j be 0
            While j is less than dimension:
                Let comp_a be if tensor_a.components.length is greater than i then tensor_a.components[i][0] otherwise 1.0
                Let comp_b be if tensor_b.components.length is greater than j then tensor_b.components[0][j] otherwise 1.0
                product_row.append(comp_a multiplied by comp_b)
                Set j to j plus 1
            product_components.append(product_row)
            Set i to i plus 1
    
    Note: Create result tensor
    Let result_tensor be Tensor
    Set result_tensor.components to product_components
    Set result_tensor.indices to []
    Set result_tensor.rank to tensor_a.rank plus tensor_b.rank
    Set result_tensor.dimension to dimension
    Set result_tensor.coordinate_system to tensor_a.coordinate_system
    Set result_tensor.metric_compatible to tensor_a.metric_compatible and tensor_b.metric_compatible
    Set result_tensor.symmetries to []
    
    Return result_tensor

Process called "symmetrize_tensor" that takes tensor as Tensor, index_set as List[Integer] returns Tensor:
    Note: Symmetrizes tensor over specified indices
    Note: T_(ij) is equal to ½(T_ij plus T_ji) for two indices
    Note: Generalizes to multiple indices with appropriate normalization
    Note: Creates symmetric part of tensor
    
    Note: Validate inputs
    If index_set.length is less than 2:
        Throw Errors.InvalidArgument with "At least two indices required for symmetrization"
    If tensor.rank is less than 2:
        Throw Errors.InvalidArgument with "Tensor must be at least rank-2 for symmetrization"
    
    Let dimension be tensor.dimension
    
    Note: For rank-2 tensor, implement basic symmetrization
    If tensor.rank is equal to 2 and index_set.length is equal to 2:
        Let symmetric_components be []
        Let i be 0
        While i is less than dimension:
            Let symmetric_row be []
            Let j be 0
            While j is less than dimension:
                Note: Symmetric part: S_ij is equal to (T_ij plus T_ji) / 2
                Let symmetric_component be (tensor.components[i][j] plus tensor.components[j][i]) / 2.0
                symmetric_row.append(symmetric_component)
                Set j to j plus 1
            symmetric_components.append(symmetric_row)
            Set i to i plus 1
        
        Let result_tensor be Tensor
        Set result_tensor.components to symmetric_components
        Set result_tensor.indices to tensor.indices
        Set result_tensor.rank to tensor.rank
        Set result_tensor.dimension to tensor.dimension
        Set result_tensor.coordinate_system to tensor.coordinate_system
        Set result_tensor.metric_compatible to tensor.metric_compatible
        Set result_tensor.symmetries to ["symmetric"]
        
        Return result_tensor
    
    Note: For other cases, return tensor unchanged
    Return tensor

Process called "antisymmetrize_tensor" that takes tensor as Tensor, index_set as List[Integer] returns Tensor:
    Note: Antisymmetrizes tensor over specified indices
    Note: T_[ij] is equal to ½(T_ij minus T_ji) for two indices
    Note: Generalizes using alternating sum over permutations
    Note: Creates antisymmetric part of tensor
    
    Note: Validate inputs
    If index_set.length is less than 2:
        Throw Errors.InvalidArgument with "At least two indices required for antisymmetrization"
    If tensor.rank is less than 2:
        Throw Errors.InvalidArgument with "Tensor must be at least rank-2 for antisymmetrization"
    
    Let dimension be tensor.dimension
    
    Note: For rank-2 tensor, implement basic antisymmetrization
    If tensor.rank is equal to 2 and index_set.length is equal to 2:
        Let antisymmetric_components be []
        Let i be 0
        While i is less than dimension:
            Let antisymmetric_row be []
            Let j be 0
            While j is less than dimension:
                Note: Antisymmetric part: A_ij is equal to (T_ij minus T_ji) / 2
                Let antisymmetric_component be (tensor.components[i][j] minus tensor.components[j][i]) / 2.0
                antisymmetric_row.append(antisymmetric_component)
                Set j to j plus 1
            antisymmetric_components.append(antisymmetric_row)
            Set i to i plus 1
        
        Let result_tensor be Tensor
        Set result_tensor.components to antisymmetric_components
        Set result_tensor.indices to tensor.indices
        Set result_tensor.rank to tensor.rank
        Set result_tensor.dimension to tensor.dimension
        Set result_tensor.coordinate_system to tensor.coordinate_system
        Set result_tensor.metric_compatible to tensor.metric_compatible
        Set result_tensor.symmetries to ["antisymmetric"]
        
        Return result_tensor
    
    Note: For other cases, return tensor unchanged
    Return tensor