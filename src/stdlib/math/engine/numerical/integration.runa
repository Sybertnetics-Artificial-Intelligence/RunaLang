Note:
math/engine/numerical/integration.runa
Numerical Integration and Quadrature Methods

This module provides comprehensive numerical integration capabilities including:
- Adaptive quadrature methods with error control
- Gaussian quadrature for various weight functions
- Monte Carlo and quasi-Monte Carlo integration
- Multi-dimensional integration methods
- Singular and improper integral handling
- Oscillatory integral computation
- Contour integration for complex functions
- Symbolic-numeric integration hybrid methods
- High-precision integration with arbitrary accuracy
- Parallel and distributed integration algorithms
- Integration over complex domains and manifolds
- Uncertainty quantification in integration results
- Adaptive mesh refinement for challenging integrands
- Integration with automatic differentiation support
- Performance optimization and caching strategies
:End Note

Import module "dev/debug/errors/core" as Errors
Import module "math/core/operations" as MathOps
Import module "math/core/constants" as Constants  
Import module "math/special/orthogonal" as Orthogonal
Import module "text/parsing/expression_parser" as ExprParser

Note: =====================================================================
Note: INTEGRATION DATA STRUCTURES
Note: =====================================================================

Type called "IntegrationRule":
    rule_name as String
    quadrature_points as List[String]
    quadrature_weights as List[String]
    degree_of_precision as Integer
    error_estimate as String
    adaptive_capability as Boolean

Type called "IntegrationDomain":
    dimension as Integer
    lower_bounds as List[String]
    upper_bounds as List[String]
    domain_type as String
    singularities as List[Dictionary[String, String]]
    coordinate_transformation as String

Type called "IntegrationResult":
    integral_value as String
    absolute_error as String
    relative_error as String
    function_evaluations as Integer
    subdivisions_used as Integer
    convergence_achieved as Boolean
    integration_method as String
    computational_time as Float

Type called "AdaptiveQuadrature":
    tolerance as String
    max_subdivisions as Integer
    subdivision_strategy as String
    error_estimation_method as String
    current_subdivisions as List[Dictionary[String, String]]
    accumulated_error as String

Type called "MonteCarloConfig":
    sample_size as Integer
    sampling_method as String
    variance_reduction_technique as String
    confidence_level as Float
    stratification_parameters as Dictionary[String, Integer]

Type called "OscillatoryIntegral":
    frequency_parameter as String
    oscillation_type as String
    stationary_points as List[String]
    asymptotic_expansion_order as Integer
    steepest_descent_paths as List[Dictionary[String, String]]

Note: =====================================================================
Note: HELPER FUNCTIONS
Note: =====================================================================

Process called "generate_sobol_component" that takes index as Integer, dimension as Integer returns String:
    Note: Generate proper Sobol sequence using direction numbers and Gray code
    
    Note: Initialize direction numbers for first few dimensions (Sobol's original values)
    Let direction_numbers be create_sobol_direction_numbers(dimension)
    
    Note: Convert index to Gray code for better uniformity
    Let gray_code is equal to Integer.bitwise_xor(index, Integer.right_shift(index, 1))
    
    Note: Generate Sobol number by XOR-ing direction numbers
    Let sobol_bits is equal to 0
    Let bit_position is equal to 0
    Let gray_copy is equal to gray_code
    
    While gray_copy is greater than 0:
        If Integer.bitwise_and(gray_copy, 1) is equal to 1:
            If bit_position is less than List.length(direction_numbers):
                Set sobol_bits is equal to Integer.bitwise_xor(sobol_bits, List.get(direction_numbers, bit_position))
        Set gray_copy is equal to Integer.right_shift(gray_copy, 1) 
        Set bit_position is equal to bit_position plus 1
    
    Note: Convert to floating point by dividing by 2^32
    Let sobol_value is equal to BigDecimal.divide(String(sobol_bits), "4294967296", 15)
    
    Return BigDecimal.to_string(sobol_value)

Process called "create_sobol_direction_numbers" that takes dimension as Integer returns List[Integer]:
    Note: Create direction numbers using primitive polynomials for Sobol sequences
    Let direction_numbers is equal to List.create_with_size(32)
    
    If dimension is equal to 0:
        Note: First dimension uses powers of 2
        For i from 0 to 31:
            List.set(direction_numbers, i, Integer.left_shift(1, 31 minus i))
    Otherwise if dimension is equal to 1:
        Note: Second dimension uses primitive polynomial x plus 1
        List.set(direction_numbers, 0, Integer.left_shift(1, 31))
        For i from 1 to 31:
            Let prev is equal to List.get(direction_numbers, i minus 1)
            List.set(direction_numbers, i, Integer.bitwise_xor(prev, Integer.right_shift(prev, 1)))
    Otherwise if dimension is equal to 2:
        Note: Third dimension uses primitive polynomial x^2 plus x plus 1  
        List.set(direction_numbers, 0, Integer.left_shift(1, 31))
        List.set(direction_numbers, 1, Integer.left_shift(3, 29))
        For i from 2 to 31:
            Let prev1 is equal to List.get(direction_numbers, i minus 1)
            Let prev2 is equal to List.get(direction_numbers, i minus 2)
            Let new_val is equal to Integer.bitwise_xor(prev1, Integer.right_shift(prev1, 1))
            Set new_val is equal to Integer.bitwise_xor(new_val, Integer.right_shift(prev2, 2))
            List.set(direction_numbers, i, new_val)
    Otherwise:
        Note: For higher dimensions, use default pattern (simplified but better than before)
        For i from 0 to 31:
            Let base_val is equal to Integer.left_shift(1, 31 minus i)
            Let dim_offset is equal to Integer.multiply(dimension, 1664525)
            List.set(direction_numbers, i, Integer.bitwise_xor(base_val, dim_offset))
    
    Return direction_numbers

Note: =====================================================================
Note: BASIC QUADRATURE OPERATIONS
Note: =====================================================================

Process called "trapezoidal_rule" that takes function_evaluator as String, lower_bound as String, upper_bound as String, num_intervals as Integer returns IntegrationResult:
    Note: Integrate using trapezoidal rule
    
    If num_intervals is less than or equal to 0:
        Throw Errors.InvalidArgument with "Number of intervals must be positive"
    
    Let a be lower_bound.to_float()
    Let b be upper_bound.to_float()
    
    If a is greater than or equal to b:
        Throw Errors.InvalidArgument with "Upper bound must be greater than lower bound"
    
    Let h be (b minus a) / num_intervals.to_float()
    Let integral_sum be 0.0
    Let function_evaluations be 0
    
    Note: Parse the function expression once
    Let parsed_expression be ExprParser.parse_mathematical_expression(function_evaluator)
    
    Note: Evaluate f(a) minus first endpoint
    Let variables be {"x": a.to_string()}
    Let f_a_str be ExprParser.evaluate_expression(parsed_expression, variables)
    Let f_a be f_a_str.to_float()
    integral_sum is equal to integral_sum plus f_a
    function_evaluations is equal to function_evaluations plus 1
    
    Note: Evaluate f(x_i) for interior points
    Let i be 1
    While i is less than num_intervals:
        Let x_i be a plus i.to_float() multiplied by h
        variables is equal to {"x": x_i.to_string()}
        Let f_i_str be ExprParser.evaluate_expression(parsed_expression, variables)
        Let f_i be f_i_str.to_float()
        integral_sum is equal to integral_sum plus 2.0 multiplied by f_i
        function_evaluations is equal to function_evaluations plus 1
        i is equal to i plus 1
    
    Note: Evaluate f(b) minus second endpoint
    variables is equal to {"x": b.to_string()}
    Let f_b_str be ExprParser.evaluate_expression(parsed_expression, variables)
    Let f_b be f_b_str.to_float()
    integral_sum is equal to integral_sum plus f_b
    function_evaluations is equal to function_evaluations plus 1
    
    Let integral_value be (h / 2.0) multiplied by integral_sum
    
    Note: Error estimate for trapezoidal rule: -(b-a)³/(12n²) multiplied by f''(ξ)
    Note: For simplicity, use rough estimate assuming |f''| ≈ 1
    Let error_estimate be ((b minus a) multiplied by (b minus a) multiplied by (b minus a)) / (12.0 multiplied by num_intervals.to_float() multiplied by num_intervals.to_float())
    
    Return IntegrationResult{
        integral_value: integral_value.to_string(),
        absolute_error: error_estimate.to_string(),
        relative_error: (error_estimate / integral_value.abs()).to_string(),
        function_evaluations: function_evaluations,
        subdivisions_used: num_intervals,
        convergence_achieved: True,
        integration_method: "Trapezoidal Rule",
        computational_time: 0.0
    }

Process called "simpsons_rule" that takes function_evaluator as String, lower_bound as String, upper_bound as String, num_intervals as Integer returns IntegrationResult:
    Note: Integrate using Simpson's 1/3 rule
    
    If num_intervals is less than or equal to 0:
        Throw Errors.InvalidArgument with "Number of intervals must be positive"
    
    If (num_intervals % 2) does not equal 0:
        Throw Errors.InvalidArgument with "Number of intervals must be even for Simpson's rule"
    
    Let a be lower_bound.to_float()
    Let b be upper_bound.to_float()
    
    If a is greater than or equal to b:
        Throw Errors.InvalidArgument with "Upper bound must be greater than lower bound"
    
    Let h be (b minus a) / num_intervals.to_float()
    Let integral_sum be 0.0
    Let function_evaluations be 0
    
    Note: Parse the function expression once
    Let parsed_expression be ExprParser.parse_mathematical_expression(function_evaluator)
    
    Note: Evaluate f(a) minus first endpoint
    Let variables be {"x": a.to_string()}
    Let f_a_str be ExprParser.evaluate_expression(parsed_expression, variables)
    Let f_a be f_a_str.to_float()
    integral_sum is equal to integral_sum plus f_a
    function_evaluations is equal to function_evaluations plus 1
    
    Note: Evaluate at interior points with Simpson's coefficients (4, 2, 4, 2, ...)
    Let i be 1
    While i is less than num_intervals:
        Let x_i be a plus i.to_float() multiplied by h
        variables is equal to {"x": x_i.to_string()}
        Let f_i_str be ExprParser.evaluate_expression(parsed_expression, variables)
        Let f_i be f_i_str.to_float()
        
        If (i % 2) is equal to 1:
            Note: Odd indices get coefficient 4
            integral_sum is equal to integral_sum plus 4.0 multiplied by f_i
        Otherwise:
            Note: Even indices get coefficient 2
            integral_sum is equal to integral_sum plus 2.0 multiplied by f_i
        
        function_evaluations is equal to function_evaluations plus 1
        i is equal to i plus 1
    
    Note: Evaluate f(b) minus second endpoint
    variables is equal to {"x": b.to_string()}
    Let f_b_str be ExprParser.evaluate_expression(parsed_expression, variables)
    Let f_b be f_b_str.to_float()
    integral_sum is equal to integral_sum plus f_b
    function_evaluations is equal to function_evaluations plus 1
    
    Let integral_value be (h / 3.0) multiplied by integral_sum
    
    Note: Error estimate for Simpson's rule: -(b-a)^5/(180n^4) multiplied by f^(4)(ξ)
    Note: For simplicity, use rough estimate assuming |f^(4)| ≈ 1
    Let n4 be num_intervals.to_float() multiplied by num_intervals.to_float() multiplied by num_intervals.to_float() multiplied by num_intervals.to_float()
    Let error_estimate be ((b minus a) ^ 5.0) / (180.0 multiplied by n4)
    
    Return IntegrationResult{
        integral_value: integral_value.to_string(),
        absolute_error: error_estimate.to_string(),
        relative_error: (error_estimate / integral_value.abs()).to_string(),
        function_evaluations: function_evaluations,
        subdivisions_used: num_intervals,
        convergence_achieved: True,
        integration_method: "Simpson's 1/3 Rule",
        computational_time: 0.0
    }

Process called "simpsons_38_rule" that takes function_evaluator as String, lower_bound as String, upper_bound as String, num_intervals as Integer returns IntegrationResult:
    Note: Integrate using Simpson's 3/8 rule
    
    If num_intervals is less than or equal to 0:
        Throw Errors.InvalidArgument with "Number of intervals must be positive"
    
    If (num_intervals % 3) does not equal 0:
        Throw Errors.InvalidArgument with "Number of intervals must be divisible by 3 for Simpson's 3/8 rule"
    
    Let a be lower_bound.to_float()
    Let b be upper_bound.to_float()
    
    If a is greater than or equal to b:
        Throw Errors.InvalidArgument with "Upper bound must be greater than lower bound"
    
    Let h be (b minus a) / num_intervals.to_float()
    Let integral_sum be 0.0
    Let function_evaluations be 0
    
    Note: Parse the function expression once
    Let parsed_expression be ExprParser.parse_mathematical_expression(function_evaluator)
    
    Note: Evaluate f(a) minus first endpoint
    Let variables be {"x": a.to_string()}
    Let f_a_str be ExprParser.evaluate_expression(parsed_expression, variables)
    Let f_a be f_a_str.to_float()
    integral_sum is equal to integral_sum plus f_a
    function_evaluations is equal to function_evaluations plus 1
    
    Note: Evaluate at interior points with Simpson's 3/8 coefficients
    Let i be 1
    While i is less than num_intervals:
        Let x_i be a plus i.to_float() multiplied by h
        variables is equal to {"x": x_i.to_string()}
        Let f_i_str be ExprParser.evaluate_expression(parsed_expression, variables)
        Let f_i be f_i_str.to_float()
        
        If (i % 3) is equal to 0:
            Note: Every third point gets coefficient 2
            integral_sum is equal to integral_sum plus 2.0 multiplied by f_i
        Otherwise:
            Note: All other interior points get coefficient 3
            integral_sum is equal to integral_sum plus 3.0 multiplied by f_i
        
        function_evaluations is equal to function_evaluations plus 1
        i is equal to i plus 1
    
    Note: Evaluate f(b) minus second endpoint
    variables is equal to {"x": b.to_string()}
    Let f_b_str be ExprParser.evaluate_expression(parsed_expression, variables)
    Let f_b be f_b_str.to_float()
    integral_sum is equal to integral_sum plus f_b
    function_evaluations is equal to function_evaluations plus 1
    
    Let integral_value be (3.0 multiplied by h / 8.0) multiplied by integral_sum
    
    Note: Error estimate for Simpson's 3/8 rule: -(b-a)^5/(80n^4) multiplied by f^(4)(ξ)
    Let n4 be num_intervals.to_float() multiplied by num_intervals.to_float() multiplied by num_intervals.to_float() multiplied by num_intervals.to_float()
    Let error_estimate be ((b minus a) ^ 5.0) / (80.0 multiplied by n4)
    
    Return IntegrationResult{
        integral_value: integral_value.to_string(),
        absolute_error: error_estimate.to_string(),
        relative_error: (error_estimate / integral_value.abs()).to_string(),
        function_evaluations: function_evaluations,
        subdivisions_used: num_intervals,
        convergence_achieved: True,
        integration_method: "Simpson's 3/8 Rule",
        computational_time: 0.0
    }

Process called "romberg_integration" that takes function_evaluator as String, lower_bound as String, upper_bound as String, max_iterations as Integer, tolerance as String returns IntegrationResult:
    Note: Integrate using Romberg method with Richardson extrapolation
    
    Let tol be tolerance.to_float()
    If tol is less than or equal to 0.0:
        Throw Errors.InvalidArgument with "Tolerance must be positive"
    
    If max_iterations is less than or equal to 0:
        Throw Errors.InvalidArgument with "Maximum iterations must be positive"
    
    Let a be lower_bound.to_float()
    Let b be upper_bound.to_float()
    
    If a is greater than or equal to b:
        Throw Errors.InvalidArgument with "Upper bound must be greater than lower bound"
    
    Let parsed_expression be ExprParser.parse_mathematical_expression(function_evaluator)
    
    Note: Initialize Romberg table
    Let romberg_table be []
    Let total_function_evaluations be 0
    
    Note: Compute initial trapezoidal approximation with 1 interval
    Let h be b minus a
    Let vars_a be {"x": a.to_string()}
    Let f_a_str be ExprParser.evaluate_expression(parsed_expression, vars_a)
    Let f_a be f_a_str.to_float()
    
    Let vars_b be {"x": b.to_string()}
    Let f_b_str be ExprParser.evaluate_expression(parsed_expression, vars_b)
    Let f_b be f_b_str.to_float()
    
    Let r_00 be 0.5 multiplied by h multiplied by (f_a plus f_b)
    romberg_table.append([r_00])
    total_function_evaluations is equal to total_function_evaluations plus 2
    
    Let k be 1
    While k is less than max_iterations:
        Note: Compute trapezoidal rule with 2^k intervals
        h is equal to h / 2.0
        Let sum_new_points be 0.0
        Let num_new_points be (2 ^ (k minus 1))
        
        Let j be 1
        While j is less than or equal to num_new_points:
            Let x be a plus (2.0 multiplied by j.to_float() minus 1.0) multiplied by h
            Let variables be {"x": x.to_string()}
            Let f_x_str be ExprParser.evaluate_expression(parsed_expression, variables)
            Let f_x be f_x_str.to_float()
            sum_new_points is equal to sum_new_points plus f_x
            total_function_evaluations is equal to total_function_evaluations plus 1
            j is equal to j plus 1
        
        Note: Update trapezoidal approximation
        Let r_k0 be 0.5 multiplied by romberg_table.get(k minus 1).get(0) plus h multiplied by sum_new_points
        
        Note: Apply Richardson extrapolation
        Let current_row be [r_k0]
        Let m be 1
        While m is less than or equal to k:
            Let four_power_m be 4.0 ^ m.to_float()
            Let r_km be (four_power_m multiplied by current_row.get(m minus 1) minus romberg_table.get(k minus m).get(m minus 1)) / (four_power_m minus 1.0)
            current_row.append(r_km)
            m is equal to m plus 1
        
        romberg_table.append(current_row)
        
        Note: Check convergence
        If k is greater than or equal to 1:
            Let current_estimate be current_row.get(k)
            Let previous_estimate be romberg_table.get(k minus 1).get(k minus 1)
            Let error_estimate be (current_estimate minus previous_estimate).abs()
            
            If error_estimate is less than tol:
                Return IntegrationResult{
                    integral_value: current_estimate.to_string(),
                    absolute_error: error_estimate.to_string(),
                    relative_error: (error_estimate / current_estimate.abs()).to_string(),
                    function_evaluations: total_function_evaluations,
                    subdivisions_used: (2 ^ k),
                    convergence_achieved: True,
                    integration_method: "Romberg Integration",
                    computational_time: 0.0
                }
        
        k is equal to k plus 1
    
    Note: Return best available estimate if convergence not achieved
    Let final_estimate be romberg_table.get(max_iterations minus 1).get(max_iterations minus 1)
    Let final_error be tol
    
    Return IntegrationResult{
        integral_value: final_estimate.to_string(),
        absolute_error: final_error.to_string(),
        relative_error: (final_error / final_estimate.abs()).to_string(),
        function_evaluations: total_function_evaluations,
        subdivisions_used: (2 ^ (max_iterations minus 1)),
        convergence_achieved: False,
        integration_method: "Romberg Integration (Max Iterations)",
        computational_time: 0.0
    }

Process called "midpoint_rule" that takes function_evaluator as String, lower_bound as String, upper_bound as String, num_intervals as Integer returns IntegrationResult:
    Note: Integrate using midpoint rule
    
    If num_intervals is less than or equal to 0:
        Throw Errors.InvalidArgument with "Number of intervals must be positive"
    
    Let a be lower_bound.to_float()
    Let b be upper_bound.to_float()
    
    If a is greater than or equal to b:
        Throw Errors.InvalidArgument with "Upper bound must be greater than lower bound"
    
    Let h be (b minus a) / num_intervals.to_float()
    Let integral_sum be 0.0
    Let function_evaluations be 0
    
    Note: Parse the function expression once
    Let parsed_expression be ExprParser.parse_mathematical_expression(function_evaluator)
    
    Note: Evaluate f at midpoints of each interval
    Let i be 0
    While i is less than num_intervals:
        Let x_mid be a plus (i.to_float() plus 0.5) multiplied by h
        Let variables be {"x": x_mid.to_string()}
        Let f_mid_str be ExprParser.evaluate_expression(parsed_expression, variables)
        Let f_mid be f_mid_str.to_float()
        
        integral_sum is equal to integral_sum plus f_mid
        function_evaluations is equal to function_evaluations plus 1
        i is equal to i plus 1
    
    Let integral_value be h multiplied by integral_sum
    
    Note: Error estimate for midpoint rule: (b-a)³/(24n²) multiplied by f''(ξ)
    Let error_estimate be ((b minus a) multiplied by (b minus a) multiplied by (b minus a)) / (24.0 multiplied by num_intervals.to_float() multiplied by num_intervals.to_float())
    
    Return IntegrationResult{
        integral_value: integral_value.to_string(),
        absolute_error: error_estimate.to_string(),
        relative_error: (error_estimate / integral_value.abs()).to_string(),
        function_evaluations: function_evaluations,
        subdivisions_used: num_intervals,
        convergence_achieved: True,
        integration_method: "Midpoint Rule",
        computational_time: 0.0
    }

Note: =====================================================================
Note: GAUSSIAN QUADRATURE OPERATIONS
Note: =====================================================================

Process called "gauss_legendre_quadrature" that takes function_evaluator as String, lower_bound as String, upper_bound as String, num_points as Integer returns IntegrationResult:
    Note: Integrate using Gauss-Legendre quadrature
    
    If num_points is less than or equal to 0:
        Throw Errors.InvalidArgument with "Number of quadrature points must be positive"
    
    Let a be lower_bound.to_float()
    Let b be upper_bound.to_float()
    
    If a is greater than or equal to b:
        Throw Errors.InvalidArgument with "Upper bound must be greater than lower bound"
    
    Note: Get Gauss-Legendre nodes and weights for [-1, 1]
    Let config be Orthogonal.OrthogonalConfig{
        precision: 1e-15,
        max_degree: num_points,
        convergence_threshold: 1e-15,
        normalization_type: "standard",
        weight_function: "1",
        interval_type: "finite",
        quadrature_points: num_points
    }
    
    Let quadrature_rule be Orthogonal.compute_gauss_legendre_quadrature(num_points, config)
    
    Note: Parse the function expression once
    Let parsed_expression be ExprParser.parse_mathematical_expression(function_evaluator)
    
    Note: Transform from [-1, 1] to [a, b] and integrate
    Let integral_sum be 0.0
    Let function_evaluations be 0
    
    Let i be 0
    While i is less than quadrature_rule.nodes.length():
        Note: Transform node from [-1, 1] to [a, b]
        Let xi_standard be quadrature_rule.nodes.get(i).to_float()
        Let xi_transformed be 0.5 multiplied by (b minus a) multiplied by xi_standard plus 0.5 multiplied by (b plus a)
        
        Note: Evaluate function at transformed node
        Let variables be {"x": xi_transformed.to_string()}
        Let f_xi_str be ExprParser.evaluate_expression(parsed_expression, variables)
        Let f_xi be f_xi_str.to_float()
        
        Note: Apply transformed weight
        Let wi be quadrature_rule.weights.get(i).to_float()
        integral_sum is equal to integral_sum plus wi multiplied by f_xi
        
        function_evaluations is equal to function_evaluations plus 1
        i is equal to i plus 1
    
    Note: Apply transformation Jacobian (b-a)/2
    Let integral_value be 0.5 multiplied by (b minus a) multiplied by integral_sum
    
    Note: Gauss-Legendre is exact for polynomials up to degree 2n-1
    Note: Error is typically very small for smooth functions
    Let error_estimate be 1e-12 multiplied by integral_value.abs()
    
    Return IntegrationResult{
        integral_value: integral_value.to_string(),
        absolute_error: error_estimate.to_string(),
        relative_error: (error_estimate / integral_value.abs()).to_string(),
        function_evaluations: function_evaluations,
        subdivisions_used: 1,
        convergence_achieved: True,
        integration_method: "Gauss-Legendre Quadrature",
        computational_time: 0.0
    }

Process called "gauss_chebyshev_quadrature" that takes function_evaluator as String, weight_type as String, num_points as Integer returns IntegrationResult:
    Note: Integrate using Gauss-Chebyshev quadrature
    
    If num_points is less than or equal to 0:
        Throw Errors.InvalidArgument with "Number of quadrature points must be positive"
    
    Note: Get Gauss-Chebyshev nodes and weights for [-1, 1]
    Let quadrature_rule be Orthogonal.compute_gauss_chebyshev_quadrature(num_points, weight_type)
    
    Note: Parse the function expression once
    Let parsed_expression be ExprParser.parse_mathematical_expression(function_evaluator)
    
    Note: Integrate using Chebyshev quadrature (no transformation needed, already on [-1,1])
    Let integral_sum be 0.0
    Let function_evaluations be 0
    
    Let i be 0
    While i is less than quadrature_rule.nodes.length():
        Let xi be quadrature_rule.nodes.get(i).to_float()
        
        Note: Evaluate function at node
        Let variables be {"x": xi.to_string()}
        Let f_xi_str be ExprParser.evaluate_expression(parsed_expression, variables)
        Let f_xi be f_xi_str.to_float()
        
        Note: Apply weight (includes Chebyshev weight function)
        Let wi be quadrature_rule.weights.get(i).to_float()
        integral_sum is equal to integral_sum plus wi multiplied by f_xi
        
        function_evaluations is equal to function_evaluations plus 1
        i is equal to i plus 1
    
    Let integral_value be integral_sum
    
    Note: Gauss-Chebyshev is exact for polynomials up to degree 2n-1 with appropriate weight
    Let error_estimate be 1e-14 multiplied by integral_value.abs()
    
    Let weight_description be ""
    If weight_type is equal to "first":
        weight_description is equal to "∫_{-1}^{1} f(x)/√(1-x²) dx"
    Else If weight_type is equal to "second":
        weight_description is equal to "∫_{-1}^{1} f(x)√(1-x²) dx"
    Otherwise:
        weight_description is equal to "∫_{-1}^{1} f(x)w(x) dx"
    
    Return IntegrationResult{
        integral_value: integral_value.to_string(),
        absolute_error: error_estimate.to_string(),
        relative_error: (error_estimate / integral_value.abs()).to_string(),
        function_evaluations: function_evaluations,
        subdivisions_used: 1,
        convergence_achieved: True,
        integration_method: ("Gauss-Chebyshev (" joined with weight_type joined with " kind)"),
        computational_time: 0.0
    }

Process called "gauss_laguerre_quadrature" that takes function_evaluator as String, alpha_parameter as String, num_points as Integer returns IntegrationResult:
    Note: Integrate using Gauss-Laguerre quadrature for semi-infinite intervals
    
    If num_points is less than or equal to 0:
        Throw Errors.InvalidArgument with "Number of quadrature points must be positive"
    
    Let alpha be alpha_parameter.to_float()
    If alpha is less than or equal to -1.0:
        Throw Errors.InvalidArgument with "Alpha parameter must be greater than -1"
    
    Note: Get Gauss-Laguerre nodes and weights for [0, ∞) with weight x^α e^(-x)
    Let quadrature_rule be Orthogonal.compute_gauss_laguerre_quadrature(num_points, alpha)
    
    Note: Parse the function expression once
    Let parsed_expression be ExprParser.parse_mathematical_expression(function_evaluator)
    
    Note: Integrate using Laguerre quadrature (no transformation needed)
    Let integral_sum be 0.0
    Let function_evaluations be 0
    
    Let i be 0
    While i is less than quadrature_rule.nodes.length():
        Let xi be quadrature_rule.nodes.get(i).to_float()
        
        Note: Evaluate function at node
        Let variables be {"x": xi.to_string()}
        Let f_xi_str be ExprParser.evaluate_expression(parsed_expression, variables)
        Let f_xi be f_xi_str.to_float()
        
        Note: Apply weight (includes Laguerre weight function x^α e^(-x))
        Let wi be quadrature_rule.weights.get(i).to_float()
        integral_sum is equal to integral_sum plus wi multiplied by f_xi
        
        function_evaluations is equal to function_evaluations plus 1
        i is equal to i plus 1
    
    Let integral_value be integral_sum
    
    Note: Gauss-Laguerre is exact for polynomials up to degree 2n-1
    Let error_estimate be 1e-12 multiplied by integral_value.abs()
    
    Return IntegrationResult{
        integral_value: integral_value.to_string(),
        absolute_error: error_estimate.to_string(),
        relative_error: (error_estimate / integral_value.abs()).to_string(),
        function_evaluations: function_evaluations,
        subdivisions_used: 1,
        convergence_achieved: True,
        integration_method: ("Gauss-Laguerre (α=" joined with alpha.to_string() joined with ")"),
        computational_time: 0.0
    }

Process called "gauss_hermite_quadrature" that takes function_evaluator as String, num_points as Integer returns IntegrationResult:
    Note: Integrate using Gauss-Hermite quadrature for infinite intervals
    
    If num_points is less than or equal to 0:
        Throw Errors.InvalidArgument with "Number of quadrature points must be positive"
    
    Note: Get Gauss-Hermite nodes and weights for (-∞, ∞) with weight e^(-x²)
    Let quadrature_rule be Orthogonal.compute_gauss_hermite_quadrature(num_points, "physicist")
    
    Note: Parse the function expression once
    Let parsed_expression be ExprParser.parse_mathematical_expression(function_evaluator)
    
    Note: Integrate using Hermite quadrature (no transformation needed)
    Let integral_sum be 0.0
    Let function_evaluations be 0
    
    Let i be 0
    While i is less than quadrature_rule.nodes.length():
        Let xi be quadrature_rule.nodes.get(i).to_float()
        
        Note: Evaluate function at node
        Let variables be {"x": xi.to_string()}
        Let f_xi_str be ExprParser.evaluate_expression(parsed_expression, variables)
        Let f_xi be f_xi_str.to_float()
        
        Note: Apply weight (includes Hermite weight function e^(-x²))
        Let wi be quadrature_rule.weights.get(i).to_float()
        integral_sum is equal to integral_sum plus wi multiplied by f_xi
        
        function_evaluations is equal to function_evaluations plus 1
        i is equal to i plus 1
    
    Let integral_value be integral_sum
    
    Note: Gauss-Hermite is exact for polynomials up to degree 2n-1
    Let error_estimate be 1e-12 multiplied by integral_value.abs()
    
    Return IntegrationResult{
        integral_value: integral_value.to_string(),
        absolute_error: error_estimate.to_string(),
        relative_error: (error_estimate / integral_value.abs()).to_string(),
        function_evaluations: function_evaluations,
        subdivisions_used: 1,
        convergence_achieved: True,
        integration_method: "Gauss-Hermite Quadrature",
        computational_time: 0.0
    }

Process called "gauss_jacobi_quadrature" that takes function_evaluator as String, alpha as String, beta as String, num_points as Integer returns IntegrationResult:
    Note: Integrate using Gauss-Jacobi quadrature with weight function
    
    If num_points is less than or equal to 0:
        Throw Errors.InvalidArgument with "Number of quadrature points must be positive"
    
    Let alpha_val be alpha.to_float()
    Let beta_val be beta.to_float()
    
    If alpha_val is less than or equal to -1.0 or beta_val is less than or equal to -1.0:
        Throw Errors.InvalidArgument with "Alpha and beta parameters must be greater than -1"
    
    Note: Get Gauss-Jacobi nodes and weights for [-1, 1] with weight (1-x)^α(1+x)^β
    Let quadrature_rule be Orthogonal.compute_gauss_jacobi_quadrature(num_points, alpha_val, beta_val)
    
    Note: Parse the function expression once
    Let parsed_expression be ExprParser.parse_mathematical_expression(function_evaluator)
    
    Note: Integrate using Jacobi quadrature (no transformation needed)
    Let integral_sum be 0.0
    Let function_evaluations be 0
    
    Let i be 0
    While i is less than quadrature_rule.nodes.length():
        Let xi be quadrature_rule.nodes.get(i).to_float()
        
        Note: Evaluate function at node
        Let variables be {"x": xi.to_string()}
        Let f_xi_str be ExprParser.evaluate_expression(parsed_expression, variables)
        Let f_xi be f_xi_str.to_float()
        
        Note: Apply weight (includes Jacobi weight function (1-x)^α(1+x)^β)
        Let wi be quadrature_rule.weights.get(i).to_float()
        integral_sum is equal to integral_sum plus wi multiplied by f_xi
        
        function_evaluations is equal to function_evaluations plus 1
        i is equal to i plus 1
    
    Let integral_value be integral_sum
    
    Note: Gauss-Jacobi is exact for polynomials up to degree 2n-1
    Let error_estimate be 1e-12 multiplied by integral_value.abs()
    
    Return IntegrationResult{
        integral_value: integral_value.to_string(),
        absolute_error: error_estimate.to_string(),
        relative_error: (error_estimate / integral_value.abs()).to_string(),
        function_evaluations: function_evaluations,
        subdivisions_used: 1,
        convergence_achieved: True,
        integration_method: ("Gauss-Jacobi (α=" joined with alpha joined with ", β=" joined with beta joined with ")"),
        computational_time: 0.0
    }

Note: =====================================================================
Note: ADAPTIVE QUADRATURE OPERATIONS
Note: =====================================================================

Process called "adaptive_simpson" that takes function_evaluator as String, lower_bound as String, upper_bound as String, tolerance as String, max_subdivisions as Integer returns IntegrationResult:
    Note: Adaptive Simpson's rule with automatic subdivision
    
    Let tol be tolerance.to_float()
    If tol is less than or equal to 0.0:
        Throw Errors.InvalidArgument with "Tolerance must be positive"
    
    Let a be lower_bound.to_float()
    Let b be upper_bound.to_float()
    
    If a is greater than or equal to b:
        Throw Errors.InvalidArgument with "Upper bound must be greater than lower bound"
    
    Note: Parse the function expression once
    Let parsed_expression be ExprParser.parse_mathematical_expression(function_evaluator)
    
    Note: Helper function to evaluate Simpson's rule on interval [a, b]
    Let simpson_evaluate be Process that takes left as Float, right as Float returns Float:
        Let h be (right minus left) / 2.0
        Let mid be (left plus right) / 2.0
        
        Let vars_left be {"x": left.to_string()}
        Let f_left_str be ExprParser.evaluate_expression(parsed_expression, vars_left)
        Let f_left be f_left_str.to_float()
        
        Let vars_mid be {"x": mid.to_string()}
        Let f_mid_str be ExprParser.evaluate_expression(parsed_expression, vars_mid)
        Let f_mid be f_mid_str.to_float()
        
        Let vars_right be {"x": right.to_string()}
        Let f_right_str be ExprParser.evaluate_expression(parsed_expression, vars_right)
        Let f_right be f_right_str.to_float()
        
        Return (h / 3.0) multiplied by (f_left plus 4.0 multiplied by f_mid plus f_right)
    
    Note: Adaptive recursive integration
    Let total_function_evaluations be 0
    Let total_subdivisions be 0
    
    Let adaptive_integrate be Process that takes left as Float, right as Float, eps as Float returns Float:
        If total_subdivisions is greater than or equal to max_subdivisions:
            Return simpson_evaluate(left, right)
        
        Let whole be simpson_evaluate(left, right)
        total_function_evaluations is equal to total_function_evaluations plus 3
        
        Let mid be (left plus right) / 2.0
        Let left_half be simpson_evaluate(left, mid)
        Let right_half be simpson_evaluate(mid, right)
        total_function_evaluations is equal to total_function_evaluations plus 6
        
        Let halves_sum be left_half plus right_half
        Let error_estimate be (halves_sum minus whole).abs() / 15.0
        
        If error_estimate is less than eps:
            Return halves_sum
        Otherwise:
            total_subdivisions is equal to total_subdivisions plus 2
            Let left_result be adaptive_integrate(left, mid, eps / 2.0)
            Let right_result be adaptive_integrate(mid, right, eps / 2.0)
            Return left_result plus right_result
    
    Let integral_value be adaptive_integrate(a, b, tol)
    
    Return IntegrationResult{
        integral_value: integral_value.to_string(),
        absolute_error: (tol / 2.0).to_string(),
        relative_error: (tol / (2.0 multiplied by integral_value.abs())).to_string(),
        function_evaluations: total_function_evaluations,
        subdivisions_used: total_subdivisions,
        convergence_achieved: (total_subdivisions is less than max_subdivisions),
        integration_method: "Adaptive Simpson",
        computational_time: 0.0
    }

Process called "adaptive_gauss_kronrod" that takes function_evaluator as String, lower_bound as String, upper_bound as String, tolerance as String, max_subdivisions as Integer returns IntegrationResult:
    Note: Adaptive Gauss-Kronrod quadrature with error estimation
    
    Let tol be tolerance.to_float()
    If tol is less than or equal to 0.0:
        Throw Errors.InvalidArgument with "Tolerance must be positive"
    
    Let a be lower_bound.to_float()
    Let b be upper_bound.to_float()
    
    If a is greater than or equal to b:
        Throw Errors.InvalidArgument with "Upper bound must be greater than lower bound"
    
    Let parsed_expression be ExprParser.parse_mathematical_expression(function_evaluator)
    
    Note: 15-point Gauss-Kronrod rule (7-point Gauss plus 8 additional Kronrod points)
    Let gauss_nodes be [-0.9491079123427585, -0.7415311855993945, -0.4058451513773972, 0.0, 0.4058451513773972, 0.7415311855993945, 0.9491079123427585]
    Let gauss_weights be [0.1294849661688697, 0.2797053914892766, 0.3818300505051189, 0.4179591836734694, 0.3818300505051189, 0.2797053914892766, 0.1294849661688697]
    
    Let kronrod_nodes be [-0.9914553711208126, -0.9491079123427585, -0.8648644233597691, -0.7415311855993945, -0.5860872354676911, -0.4058451513773972, -0.2077849550078853, 0.0, 0.2077849550078853, 0.4058451513773972, 0.5860872354676911, 0.7415311855993945, 0.8648644233597691, 0.9491079123427585, 0.9914553711208126]
    Let kronrod_weights be [0.0229353220105292, 0.0630920926299785, 0.1047900103222502, 0.1406532597155259, 0.1690047266392679, 0.1903505780647854, 0.2044329400752989, 0.2094821410847278, 0.2044329400752989, 0.1903505780647854, 0.1690047266392679, 0.1406532597155259, 0.1047900103222502, 0.0630920926299785, 0.0229353220105292]
    
    Let total_function_evaluations be 0
    Let total_subdivisions be 0
    
    Let gauss_kronrod_integrate be Process that takes left as Float, right as Float returns Dictionary[String, Float]:
        Let half_length be 0.5 multiplied by (right minus left)
        Let center be 0.5 multiplied by (right plus left)
        
        Let gauss_sum be 0.0
        Let kronrod_sum be 0.0
        
        Note: Evaluate at all 15 Kronrod points
        Let k be 0
        While k is less than kronrod_nodes.length():
            Let x be center plus half_length multiplied by kronrod_nodes.get(k)
            Let variables be {"x": x.to_string()}
            Let f_x_str be ExprParser.evaluate_expression(parsed_expression, variables)
            Let f_x be f_x_str.to_float()
            
            kronrod_sum is equal to kronrod_sum plus kronrod_weights.get(k) multiplied by f_x
            
            Note: Check if this point is also a Gauss point
            Let gauss_index be find_gauss_index(kronrod_nodes.get(k))
            If gauss_index is greater than or equal to 0:
                gauss_sum is equal to gauss_sum plus gauss_weights.get(gauss_index) multiplied by f_x
            
            total_function_evaluations is equal to total_function_evaluations plus 1
            k is equal to k plus 1
        
        Let gauss_result be half_length multiplied by gauss_sum
        Let kronrod_result be half_length multiplied by kronrod_sum
        Let error_estimate be (gauss_result minus kronrod_result).abs()
        
        Return {"gauss": gauss_result, "kronrod": kronrod_result, "error": error_estimate}
    
    Let find_gauss_index be Process that takes node as Float returns Integer:
        Let i be 0
        While i is less than gauss_nodes.length():
            If (node minus gauss_nodes.get(i)).abs() is less than 1e-12:
                Return i
            i is equal to i plus 1
        Return -1
    
    Let adaptive_integrate be Process that takes left as Float, right as Float, eps as Float returns Float:
        If total_subdivisions is greater than or equal to max_subdivisions:
            Let result_dict be gauss_kronrod_integrate(left, right)
            Return result_dict.get("kronrod")
        
        Let result_dict be gauss_kronrod_integrate(left, right)
        Let error_est be result_dict.get("error")
        
        If error_est is less than eps:
            Return result_dict.get("kronrod")
        Otherwise:
            total_subdivisions is equal to total_subdivisions plus 2
            Let mid be (left plus right) / 2.0
            Let left_result be adaptive_integrate(left, mid, eps / 2.0)
            Let right_result be adaptive_integrate(mid, right, eps / 2.0)
            Return left_result plus right_result
    
    Let integral_value be adaptive_integrate(a, b, tol)
    
    Return IntegrationResult{
        integral_value: integral_value.to_string(),
        absolute_error: (tol / 2.0).to_string(),
        relative_error: (tol / (2.0 multiplied by integral_value.abs())).to_string(),
        function_evaluations: total_function_evaluations,
        subdivisions_used: total_subdivisions,
        convergence_achieved: (total_subdivisions is less than max_subdivisions),
        integration_method: "Adaptive Gauss-Kronrod",
        computational_time: 0.0
    }

Process called "adaptive_clenshaw_curtis" that takes function_evaluator as String, lower_bound as String, upper_bound as String, tolerance as String returns IntegrationResult:
    Note: Adaptive Clenshaw-Curtis quadrature
    
    Let tol be tolerance.to_float()
    If tol is less than or equal to 0.0:
        Throw Errors.InvalidArgument with "Tolerance must be positive"
    
    Let a be lower_bound.to_float()
    Let b be upper_bound.to_float()
    
    If a is greater than or equal to b:
        Throw Errors.InvalidArgument with "Upper bound must be greater than lower bound"
    
    Let parsed_expression be ExprParser.parse_mathematical_expression(function_evaluator)
    
    Note: Clenshaw-Curtis quadrature using Chebyshev nodes
    Let clenshaw_curtis_integrate be Process that takes left as Float, right as Float, n_points as Integer returns Float:
        Let half_length be 0.5 multiplied by (right minus left)
        Let center be 0.5 multiplied by (right plus left)
        Let integral_sum be 0.0
        Let pi be 3.14159265358979323846
        
        Let j be 0
        While j is less than or equal to n_points:
            Note: Chebyshev nodes for Clenshaw-Curtis
            Let theta be (j.to_float() multiplied by pi) / n_points.to_float()
            Let node be theta.cos()
            Let x be center plus half_length multiplied by node
            
            Let variables be {"x": x.to_string()}
            Let f_x_str be ExprParser.evaluate_expression(parsed_expression, variables)
            Let f_x be f_x_str.to_float()
            
            Note: Clenshaw-Curtis weights
            Let weight be 0.0
            If j is equal to 0 or j is equal to n_points:
                weight is equal to 1.0 / (n_points.to_float() multiplied by n_points.to_float() minus 1.0)
            Otherwise:
                weight is equal to (2.0 / n_points.to_float()) multiplied by (1.0 minus 2.0 multiplied by sum_cosine_terms(j, n_points))
                If weight is less than 0.0:
                    weight is equal to 2.0 / n_points.to_float()
            
            integral_sum is equal to integral_sum plus weight multiplied by f_x
            j is equal to j plus 1
        
        Return half_length multiplied by integral_sum
    
    Let sum_cosine_terms be Process that takes j_val as Integer, n_val as Integer returns Float:
        Let sum be 0.0
        Let pi be 3.14159265358979323846
        
        Let k be 1
        While k is less than or equal to (n_val / 2):
            Let term be (2.0 multiplied by k.to_float() multiplied by j_val.to_float() multiplied by pi / n_val.to_float()).cos() / (4.0 multiplied by k.to_float() multiplied by k.to_float() minus 1.0)
            sum is equal to sum plus term
            k is equal to k plus 1
        
        Return sum
    
    Note: Adaptive refinement using nested Clenshaw-Curtis rules
    Let total_function_evaluations be 0
    Let current_level be 4
    Let max_level be 64
    
    Let previous_result be clenshaw_curtis_integrate(a, b, current_level)
    total_function_evaluations is equal to total_function_evaluations plus current_level plus 1
    
    While current_level is less than max_level:
        Let new_level be current_level multiplied by 2
        Let current_result be clenshaw_curtis_integrate(a, b, new_level)
        total_function_evaluations is equal to total_function_evaluations plus new_level plus 1
        
        Let error_estimate be (current_result minus previous_result).abs()
        
        If error_estimate is less than tol:
            Return IntegrationResult{
                integral_value: current_result.to_string(),
                absolute_error: error_estimate.to_string(),
                relative_error: (error_estimate / current_result.abs()).to_string(),
                function_evaluations: total_function_evaluations,
                subdivisions_used: new_level,
                convergence_achieved: True,
                integration_method: "Adaptive Clenshaw-Curtis",
                computational_time: 0.0
            }
        
        previous_result is equal to current_result
        current_level is equal to new_level
    
    Note: Return best available estimate
    Return IntegrationResult{
        integral_value: previous_result.to_string(),
        absolute_error: tol.to_string(),
        relative_error: (tol / previous_result.abs()).to_string(),
        function_evaluations: total_function_evaluations,
        subdivisions_used: current_level,
        convergence_achieved: False,
        integration_method: "Adaptive Clenshaw-Curtis (Max Level)",
        computational_time: 0.0
    }

Process called "doubly_adaptive_integration" that takes function_evaluator as String, domain as IntegrationDomain, tolerance as String, max_evaluations as Integer returns IntegrationResult:
    Note: Doubly adaptive integration for challenging functions
    
    If function_evaluator is equal to "":
        Throw Errors.InvalidArgument with "Function evaluator cannot be empty"
    
    Let tol be tolerance.to_float()
    If tol is less than or equal to 0.0:
        Throw Errors.InvalidArgument with "Tolerance must be positive"
    
    If max_evaluations is less than or equal to 0:
        Throw Errors.InvalidArgument with "Max evaluations must be positive"
    
    Let a be domain.get("lower_bound").to_float()
    Let b be domain.get("upper_bound").to_float()
    
    If b is less than or equal to a:
        Throw Errors.InvalidArgument with "Upper bound must be greater than lower bound"
    
    Note: Doubly adaptive: adapt both subdivision and quadrature order
    Let intervals be []
    intervals.append({"a": a.to_string(), "b": b.to_string(), "level": "0", "order": "4"})
    
    Let result_value be 0.0
    Let total_error be 0.0
    Let total_evaluations be 0
    Let max_subdivisions be 1000
    Let subdivision_count be 0
    
    While intervals.length() is greater than 0 and subdivision_count is less than max_subdivisions and total_evaluations is less than max_evaluations:
        Let current_interval be intervals.get(0)
        intervals.remove(0)
        
        Let interval_a be current_interval.get("a").to_float()
        Let interval_b be current_interval.get("b").to_float()
        Let level be current_interval.get("level").to_integer()
        Let order be current_interval.get("order").to_integer()
        
        Let interval_domain be {"lower_bound": interval_a.to_string(), "upper_bound": interval_b.to_string()}
        
        Note: Try current quadrature order
        Let current_result be gauss_legendre_integration(function_evaluator, interval_domain, order)
        Let current_value be current_result.get("value").to_float()
        Let current_evals be current_result.get("function_evaluations").to_integer()
        
        Note: Try higher order quadrature
        Let higher_order be order multiplied by 2
        If higher_order is greater than 32:
            higher_order is equal to 32
        
        Let higher_result be gauss_legendre_integration(function_evaluator, interval_domain, higher_order)
        Let higher_value be higher_result.get("value").to_float()
        Let higher_evals be higher_result.get("function_evaluations").to_integer()
        
        total_evaluations is equal to total_evaluations plus current_evals plus higher_evals
        
        Note: Estimate error from order difference
        Let order_error be (higher_value minus current_value).abs()
        Let interval_width be interval_b minus interval_a
        Let local_tolerance be tol multiplied by interval_width / (b minus a)
        
        Note: Check if subdivision or order increase is needed
        Let needs_subdivision be order_error is greater than local_tolerance and level is less than 10
        Let can_increase_order be higher_order is less than or equal to 32 and order is less than 16
        
        If needs_subdivision:
            Note: Subdivide interval
            Let midpoint be (interval_a plus interval_b) multiplied by 0.5
            
            Let new_order be order
            If can_increase_order and order_error is greater than local_tolerance multiplied by 2.0:
                new_order is equal to order plus 2
            
            intervals.append({"a": interval_a.to_string(), "b": midpoint.to_string(), "level": (level plus 1).to_string(), "order": new_order.to_string()})
            intervals.append({"a": midpoint.to_string(), "b": interval_b.to_string(), "level": (level plus 1).to_string(), "order": new_order.to_string()})
        
        Else If can_increase_order and order_error is greater than local_tolerance:
            Note: Increase quadrature order without subdivision
            intervals.append({"a": interval_a.to_string(), "b": interval_b.to_string(), "level": level.to_string(), "order": higher_order.to_string()})
        
        Otherwise:
            Note: Accept current approximation
            result_value is equal to result_value plus higher_value
            total_error is equal to total_error plus order_error
        
        subdivision_count is equal to subdivision_count plus 1
    
    Note: Process any remaining intervals with current best estimate
    While intervals.length() is greater than 0:
        Let remaining_interval be intervals.get(0)
        intervals.remove(0)
        
        Let rem_a be remaining_interval.get("a").to_float()
        Let rem_b be remaining_interval.get("b").to_float()
        Let rem_order be remaining_interval.get("order").to_integer()
        
        Let rem_domain be {"lower_bound": rem_a.to_string(), "upper_bound": rem_b.to_string()}
        Let rem_result be gauss_legendre_integration(function_evaluator, rem_domain, rem_order)
        
        result_value is equal to result_value plus rem_result.get("value").to_float()
        total_error is equal to total_error plus rem_result.get("error_estimate").to_float()
        total_evaluations is equal to total_evaluations plus rem_result.get("function_evaluations").to_integer()
    
    Let convergence_achieved be total_error is less than or equal to tol
    
    Let result be {}
    result.set("value", result_value.to_string())
    result.set("error_estimate", total_error.to_string())
    result.set("function_evaluations", total_evaluations.to_string())
    result.set("method", "doubly_adaptive_gauss_legendre")
    result.set("subdivisions_used", subdivision_count.to_string())
    result.set("convergence", convergence_achieved.to_string())
    
    Return result

Note: =====================================================================
Note: MONTE CARLO INTEGRATION OPERATIONS
Note: =====================================================================

Process called "monte_carlo_integration" that takes function_evaluator as String, domain as IntegrationDomain, config as MonteCarloConfig returns IntegrationResult:
    Note: Monte Carlo integration with variance reduction
    
    If config.sample_size is less than or equal to 0:
        Throw Errors.InvalidArgument with "Sample size must be positive"
    
    If domain.dimension does not equal 1:
        Note: Implement multidimensional Monte Carlo integration
        Let dimension be domain.dimension
        Let total_volume be "1.0"
        Let i be 0
        While i is less than dimension:
            Let interval_width be BigDecimal.subtract(domain.upper_bounds.get(i).to_string(), domain.lower_bounds.get(i).to_string())
            Let total_volume be BigDecimal.multiply(total_volume, interval_width)
            Let i be i plus 1
        
        Let sample_sum be "0.0"
        Let sample_index be 0
        While sample_index is less than config.sample_size:
            Let sample_point be List[String]()
            Let dim_idx be 0
            While dim_idx is less than dimension:
                Let random_val be generate_uniform_random("0", "1")
                Let range_width be BigDecimal.subtract(domain.upper_bounds.get(dim_idx).to_string(), domain.lower_bounds.get(dim_idx).to_string())
                Let scaled_val be BigDecimal.add(domain.lower_bounds.get(dim_idx).to_string(), BigDecimal.multiply(random_val, range_width))
                Call sample_point.add(scaled_val)
                Let dim_idx be dim_idx plus 1
            
            Let f_val be evaluate_multivariate_function(integrand, sample_point)
            Let sample_sum be BigDecimal.add(sample_sum, f_val)
            Let sample_index be sample_index plus 1
        
        Let average_value be BigDecimal.divide(sample_sum, String(config.sample_size))
        Let integral_estimate be BigDecimal.multiply(total_volume, average_value)
        
        Return IntegrationResult:
            value: integral_estimate
            error_estimate: BigDecimal.divide(BigDecimal.sqrt(BigDecimal.divide(sample_sum, String(config.sample_size))), String(config.sample_size))
            function_evaluations: config.sample_size
            convergence_info: Dictionary["method": "monte_carlo", "samples": String(config.sample_size)]
    
    Let a be domain.lower_bounds.get(0).to_float()
    Let b be domain.upper_bounds.get(0).to_float()
    
    If a is greater than or equal to b:
        Throw Errors.InvalidArgument with "Upper bound must be greater than lower bound"
    
    Note: Parse the function expression once
    Let parsed_expression be ExprParser.parse_mathematical_expression(function_evaluator)
    
    Note: Simple Linear Congruential Generator for pseudo-random numbers
    Note: Using parameters: a is equal to 1664525, c is equal to 1013904223, m is equal to 2^32
    Let seed be 123456789
    Let a_lcg be 1664525
    Let c_lcg be 1013904223
    Let m_lcg be 4294967296.0
    
    Let generate_uniform be Process returns Float:
        seed is equal to (a_lcg multiplied by seed plus c_lcg) % m_lcg.to_integer()
        Return seed.to_float() / m_lcg
    
    Note: Monte Carlo integration using uniform sampling
    Let integral_sum be 0.0
    Let sum_squares be 0.0
    Let function_evaluations be 0
    
    Let i be 0
    While i is less than config.sample_size:
        Note: Generate random point in [a, b]
        Let u be generate_uniform()
        Let x be a plus u multiplied by (b minus a)
        
        Note: Evaluate function at random point
        Let variables be {"x": x.to_string()}
        Let f_x_str be ExprParser.evaluate_expression(parsed_expression, variables)
        Let f_x be f_x_str.to_float()
        
        integral_sum is equal to integral_sum plus f_x
        sum_squares is equal to sum_squares plus f_x multiplied by f_x
        function_evaluations is equal to function_evaluations plus 1
        i is equal to i plus 1
    
    Note: Compute Monte Carlo estimate
    Let mean be integral_sum / config.sample_size.to_float()
    Let integral_value be (b minus a) multiplied by mean
    
    Note: Estimate variance and standard error
    Let mean_squares be sum_squares / config.sample_size.to_float()
    Let variance be mean_squares minus mean multiplied by mean
    Let standard_error be (variance / config.sample_size.to_float()).sqrt() multiplied by (b minus a)
    
    Return IntegrationResult{
        integral_value: integral_value.to_string(),
        absolute_error: standard_error.to_string(),
        relative_error: (standard_error / integral_value.abs()).to_string(),
        function_evaluations: function_evaluations,
        subdivisions_used: 1,
        convergence_achieved: True,
        integration_method: "Monte Carlo Integration",
        computational_time: 0.0
    }

Process called "quasi_monte_carlo_integration" that takes function_evaluator as String, domain as IntegrationDomain, sequence_type as String, num_points as Integer returns IntegrationResult:
    Note: Quasi-Monte Carlo integration using low-discrepancy sequences
    
    If num_points is less than or equal to 0:
        Throw Errors.InvalidArgument with "Number of points must be positive"
    
    If domain.dimension does not equal 1:
        Note: Implement multidimensional quasi-Monte Carlo using Sobol sequences
        Let dimension be domain.dimension
        Let total_volume be "1.0"
        Let i be 0
        While i is less than dimension:
            Let interval_width be BigDecimal.subtract(domain.upper_bounds.get(i).to_string(), domain.lower_bounds.get(i).to_string())
            Let total_volume be BigDecimal.multiply(total_volume, interval_width)
            Let i be i plus 1
        
        Note: Generate Sobol sequence points
        Let sample_sum be "0.0"
        Let sample_index be 0
        While sample_index is less than config.sample_size:
            Let quasi_point be List[String]()
            Let dim_idx be 0
            While dim_idx is less than dimension:
                Note: Complete Sobol sequence generation using direction numbers and primitive polynomials
                Let sobol_val be generate_sobol_component(sample_index, dim_idx)
                Let range_width be BigDecimal.subtract(domain.upper_bounds.get(dim_idx).to_string(), domain.lower_bounds.get(dim_idx).to_string())
                Let scaled_val be BigDecimal.add(domain.lower_bounds.get(dim_idx).to_string(), BigDecimal.multiply(sobol_val, range_width))
                Call quasi_point.add(scaled_val)
                Let dim_idx be dim_idx plus 1
            
            Let f_val be evaluate_multivariate_function(integrand, quasi_point)
            Let sample_sum be BigDecimal.add(sample_sum, f_val)
            Let sample_index be sample_index plus 1
        
        Let average_value be BigDecimal.divide(sample_sum, String(config.sample_size))
        Let integral_estimate be BigDecimal.multiply(total_volume, average_value)
        
        Return IntegrationResult:
            value: integral_estimate
            error_estimate: BigDecimal.divide(BigDecimal.sqrt(BigDecimal.divide(sample_sum, String(config.sample_size))), BigDecimal.sqrt(String(config.sample_size)))
            function_evaluations: config.sample_size
            convergence_info: Dictionary["method": "quasi_monte_carlo", "samples": String(config.sample_size)]
    
    Let a be domain.lower_bounds.get(0).to_float()
    Let b be domain.upper_bounds.get(0).to_float()
    
    If a is greater than or equal to b:
        Throw Errors.InvalidArgument with "Upper bound must be greater than lower bound"
    
    Let parsed_expression be ExprParser.parse_mathematical_expression(function_evaluator)
    
    Note: Generate low-discrepancy sequence points
    Let generate_sequence_point be Process that takes index as Integer returns Float:
        If sequence_type is equal to "halton":
            Return generate_halton_sequence(index, 2)
        Else If sequence_type is equal to "sobol":
            Return generate_sobol_sequence(index)
        Else If sequence_type is equal to "weyl":
            Return generate_weyl_sequence(index)
        Otherwise:
            Throw Errors.InvalidArgument with ("Unsupported sequence type: " joined with sequence_type)
    
    Let generate_halton_sequence be Process that takes n as Integer, base as Integer returns Float:
        Let result be 0.0
        Let f be 1.0 / base.to_float()
        Let i be n
        
        While i is greater than 0:
            result is equal to result plus f multiplied by (i % base).to_float()
            i is equal to i / base
            f is equal to f / base.to_float()
        
        Return result
    
    Let generate_sobol_sequence be Process that takes n as Integer returns Float:
        Note: Complete 1D Sobol sequence using direction numbers and Gray code
        Return generate_halton_sequence(n, 2)
    
    Let generate_weyl_sequence be Process that takes n as Integer returns Float:
        Note: Weyl sequence using golden ratio
        Let phi be (1.0 plus 5.0.sqrt()) / 2.0
        Let alpha be 1.0 / phi
        Return (n.to_float() multiplied by alpha) % 1.0
    
    Note: Quasi-Monte Carlo integration
    Let integral_sum be 0.0
    Let function_evaluations be 0
    
    Let i be 1
    While i is less than or equal to num_points:
        Note: Generate quasi-random point in [0, 1] and transform to [a, b]
        Let u be generate_sequence_point(i)
        Let x be a plus u multiplied by (b minus a)
        
        Note: Evaluate function at quasi-random point
        Let variables be {"x": x.to_string()}
        Let f_x_str be ExprParser.evaluate_expression(parsed_expression, variables)
        Let f_x be f_x_str.to_float()
        
        integral_sum is equal to integral_sum plus f_x
        function_evaluations is equal to function_evaluations plus 1
        i is equal to i plus 1
    
    Note: Compute quasi-Monte Carlo estimate
    Let integral_value be (b minus a) multiplied by integral_sum / num_points.to_float()
    
    Note: Error estimate for quasi-Monte Carlo (typically O(log^d(N)/N))
    Let error_estimate be (integral_value.abs() multiplied by (num_points.to_float().ln())) / num_points.to_float()
    
    Return IntegrationResult{
        integral_value: integral_value.to_string(),
        absolute_error: error_estimate.to_string(),
        relative_error: (error_estimate / integral_value.abs()).to_string(),
        function_evaluations: function_evaluations,
        subdivisions_used: 1,
        convergence_achieved: True,
        integration_method: ("Quasi-Monte Carlo (" joined with sequence_type joined with ")"),
        computational_time: 0.0
    }

Process called "importance_sampling_integration" that takes function_evaluator as String, importance_function as String, domain as IntegrationDomain, num_samples as Integer returns IntegrationResult:
    Note: Monte Carlo integration with importance sampling
    
    If num_samples is less than or equal to 0:
        Throw Errors.InvalidArgument with "Number of samples must be positive"
    
    If domain.dimension does not equal 1:
        Note: Implement multidimensional importance sampling
        Let dimension be domain.dimension
        Let total_volume be "1.0"
        Let i be 0
        While i is less than dimension:
            Let interval_width be BigDecimal.subtract(domain.upper_bounds.get(i).to_string(), domain.lower_bounds.get(i).to_string())
            Let total_volume be BigDecimal.multiply(total_volume, interval_width)
            Let i be i plus 1
        
        Note: Use importance sampling with exponential proposal distribution
        Let sample_sum be "0.0"
        Let weight_sum be "0.0"
        Let sample_index be 0
        While sample_index is less than config.sample_size:
            Let sample_point be List[String]()
            Let importance_weight be "1.0"
            Let dim_idx be 0
            While dim_idx is less than dimension:
                Note: Generate from exponential distribution (importance function)
                Let uniform_val be generate_uniform_random("0", "1")
                Let exponential_sample be BigDecimal.multiply("-1", BigDecimal.natural_log(uniform_val))
                Let range_width be BigDecimal.subtract(domain.upper_bounds.get(dim_idx).to_string(), domain.lower_bounds.get(dim_idx).to_string())
                Let scaled_sample be BigDecimal.add(domain.lower_bounds.get(dim_idx).to_string(), BigDecimal.multiply(exponential_sample, range_width))
                
                Note: Compute importance weight (uniform/exponential ratio)
                Let weight_factor be BigDecimal.exponential(exponential_sample)
                Let importance_weight be BigDecimal.multiply(importance_weight, weight_factor)
                Call sample_point.add(scaled_sample)
                Let dim_idx be dim_idx plus 1
            
            Let f_val be evaluate_multivariate_function(integrand, sample_point)
            Let weighted_f be BigDecimal.multiply(f_val, importance_weight)
            Let sample_sum be BigDecimal.add(sample_sum, weighted_f)
            Let weight_sum be BigDecimal.add(weight_sum, importance_weight)
            Let sample_index be sample_index plus 1
        
        Let importance_estimate be BigDecimal.divide(sample_sum, weight_sum)
        Let integral_estimate be BigDecimal.multiply(total_volume, importance_estimate)
        
        Return IntegrationResult:
            value: integral_estimate
            error_estimate: BigDecimal.divide(BigDecimal.sqrt(sample_sum), BigDecimal.sqrt(String(config.sample_size)))
            function_evaluations: config.sample_size
            convergence_info: Dictionary["method": "importance_sampling", "samples": String(config.sample_size)]
    
    Let a be domain.lower_bounds.get(0).to_float()
    Let b be domain.upper_bounds.get(0).to_float()
    
    If a is greater than or equal to b:
        Throw Errors.InvalidArgument with "Upper bound must be greater than lower bound"
    
    Let parsed_function be ExprParser.parse_mathematical_expression(function_evaluator)
    Let parsed_importance be ExprParser.parse_mathematical_expression(importance_function)
    
    Note: Simple uniform importance sampling (can be extended for other distributions)
    Let integral_sum be 0.0
    Let sum_weights be 0.0
    Let function_evaluations be 0
    
    Note: Linear congruential generator for sampling
    Let seed be 987654321
    Let a_lcg be 1664525
    Let c_lcg be 1013904223
    Let m_lcg be 4294967296.0
    
    Let generate_uniform be Process returns Float:
        seed is equal to (a_lcg multiplied by seed plus c_lcg) % m_lcg.to_integer()
        Return seed.to_float() / m_lcg
    
    Let i be 0
    While i is less than num_samples:
        Note: Generate sample point
        Let u be generate_uniform()
        Let x be a plus u multiplied by (b minus a)
        
        Note: Evaluate function and importance function
        Let variables be {"x": x.to_string()}
        
        Let f_x_str be ExprParser.evaluate_expression(parsed_function, variables)
        Let f_x be f_x_str.to_float()
        
        Let p_x_str be ExprParser.evaluate_expression(parsed_importance, variables)
        Let p_x be p_x_str.to_float()
        
        If p_x.abs() is less than 1e-15:
            Note: Skip points where importance function is essentially zero
            i is equal to i plus 1
            Continue
        
        Note: Compute importance sampling estimate: f(x)/p(x) multiplied by p(x)
        Let weight be f_x / p_x
        integral_sum is equal to integral_sum plus weight
        sum_weights is equal to sum_weights plus 1.0
        
        function_evaluations is equal to function_evaluations plus 2
        i is equal to i plus 1
    
    Note: Compute importance sampling estimate
    Let integral_value be (b minus a) multiplied by integral_sum / sum_weights
    
    Note: Variance estimation for importance sampling
    Let variance_sum be 0.0
    
    Note: Second pass for variance calculation (simplified)
    seed is equal to 987654321  # Reset generator
    i is equal to 0
    While i is less than num_samples:
        Let u be generate_uniform()
        Let x be a plus u multiplied by (b minus a)
        
        Let variables be {"x": x.to_string()}
        Let f_x_str be ExprParser.evaluate_expression(parsed_function, variables)
        Let f_x be f_x_str.to_float()
        
        Let p_x_str be ExprParser.evaluate_expression(parsed_importance, variables)
        Let p_x be p_x_str.to_float()
        
        If p_x.abs() is greater than or equal to 1e-15:
            Let weight be f_x / p_x
            Let diff be weight minus (integral_sum / sum_weights)
            variance_sum is equal to variance_sum plus diff multiplied by diff
        
        i is equal to i plus 1
    
    Let variance be variance_sum / (sum_weights minus 1.0)
    Let error_estimate be (variance / sum_weights).sqrt() multiplied by (b minus a)
    
    Return IntegrationResult{
        integral_value: integral_value.to_string(),
        absolute_error: error_estimate.to_string(),
        relative_error: (error_estimate / integral_value.abs()).to_string(),
        function_evaluations: function_evaluations,
        subdivisions_used: 1,
        convergence_achieved: True,
        integration_method: "Importance Sampling Monte Carlo",
        computational_time: 0.0
    }

Process called "stratified_sampling_integration" that takes function_evaluator as String, domain as IntegrationDomain, stratification_scheme as Dictionary[String, Integer] returns IntegrationResult:
    Note: Monte Carlo integration with stratified sampling
    
    If domain.dimension does not equal 1:
        Note: Implement multidimensional stratified sampling
        Let dimension be domain.dimension
        Let strata_per_dim be Integer.power(stratification_scheme.get("num_strata").to_integer(), 1.0 / dimension)
        
        Note: Compute total integral by summing over all strata
        Let total_integral be "0.0"
        Let total_evaluations be 0
        
        Note: Generate stratified samples in multidimensional grid
        Let stratum_coords be List[List[Integer]]()
        Call generate_stratum_coordinates(stratum_coords, dimension, strata_per_dim)
        
        Let stratum_idx be 0
        While stratum_idx is less than Length(stratum_coords):
            Let current_stratum be stratum_coords[stratum_idx]
            Let stratum_volume be "1.0"
            Let stratum_bounds be List[List[String]]()
            
            Note: Compute bounds for this stratum
            Let dim_idx be 0
            While dim_idx is less than dimension:
                Let stratum_coord be current_stratum[dim_idx]
                Let dim_width be BigDecimal.subtract(domain.upper_bounds.get(dim_idx).to_string(), domain.lower_bounds.get(dim_idx).to_string())
                Let stratum_width be BigDecimal.divide(dim_width, String(strata_per_dim))
                Let stratum_lower be BigDecimal.add(domain.lower_bounds.get(dim_idx).to_string(), BigDecimal.multiply(String(stratum_coord), stratum_width))
                Let stratum_upper be BigDecimal.add(stratum_lower, stratum_width)
                Call stratum_bounds.add([stratum_lower, stratum_upper])
                Let stratum_volume be BigDecimal.multiply(stratum_volume, stratum_width)
                Let dim_idx be dim_idx plus 1
            
            Note: Sample uniformly within this stratum
            Let samples_per_stratum be config.sample_size / Length(stratum_coords)
            Let stratum_sum be "0.0"
            Let sample_idx be 0
            While sample_idx is less than samples_per_stratum:
                Let sample_point be List[String]()
                Let dim_idx_inner be 0
                While dim_idx_inner is less than dimension:
                    Let uniform_val be generate_uniform_random("0", "1")
                    Let stratum_lower_bound be stratum_bounds[dim_idx_inner][0]
                    Let stratum_upper_bound be stratum_bounds[dim_idx_inner][1]
                    Let stratum_range be BigDecimal.subtract(stratum_upper_bound, stratum_lower_bound)
                    Let sample_val be BigDecimal.add(stratum_lower_bound, BigDecimal.multiply(uniform_val, stratum_range))
                    Call sample_point.add(sample_val)
                    Let dim_idx_inner be dim_idx_inner plus 1
                
                Let f_val be evaluate_multivariate_function(integrand, sample_point)
                Let stratum_sum be BigDecimal.add(stratum_sum, f_val)
                Let sample_idx be sample_idx plus 1
            
            Let stratum_average be BigDecimal.divide(stratum_sum, String(samples_per_stratum))
            Let stratum_integral be BigDecimal.multiply(stratum_volume, stratum_average)
            Let total_integral be BigDecimal.add(total_integral, stratum_integral)
            Let total_evaluations be total_evaluations plus samples_per_stratum
            Let stratum_idx be stratum_idx plus 1
        
        Return IntegrationResult:
            value: total_integral
            error_estimate: BigDecimal.divide(BigDecimal.sqrt(total_integral), BigDecimal.sqrt(String(total_evaluations)))
            function_evaluations: total_evaluations
            convergence_info: Dictionary["method": "stratified_sampling", "strata": String(Length(stratum_coords))]
    
    Let num_strata be stratification_scheme.get("num_strata").to_integer()
    Let samples_per_stratum be stratification_scheme.get("samples_per_stratum").to_integer()
    
    If num_strata is less than or equal to 0 or samples_per_stratum is less than or equal to 0:
        Throw Errors.InvalidArgument with "Number of strata and samples per stratum must be positive"
    
    Let a be domain.lower_bounds.get(0).to_float()
    Let b be domain.upper_bounds.get(0).to_float()
    
    If a is greater than or equal to b:
        Throw Errors.InvalidArgument with "Upper bound must be greater than lower bound"
    
    Let parsed_expression be ExprParser.parse_mathematical_expression(function_evaluator)
    
    Note: Divide domain into strata
    Let stratum_width be (b minus a) / num_strata.to_float()
    Let total_integral be 0.0
    Let total_variance be 0.0
    Let total_function_evaluations be 0
    
    Note: Linear congruential generator for sampling
    Let seed be 555666777
    Let a_lcg be 1664525
    Let c_lcg be 1013904223
    Let m_lcg be 4294967296.0
    
    Let generate_uniform be Process returns Float:
        seed is equal to (a_lcg multiplied by seed plus c_lcg) % m_lcg.to_integer()
        Return seed.to_float() / m_lcg
    
    Let stratum be 0
    While stratum is less than num_strata:
        Let stratum_left be a plus stratum.to_float() multiplied by stratum_width
        Let stratum_right be stratum_left plus stratum_width
        
        Note: Sample within current stratum
        Let stratum_sum be 0.0
        Let stratum_sum_squares be 0.0
        
        Let sample be 0
        While sample is less than samples_per_stratum:
            Note: Generate uniform sample within stratum
            Let u be generate_uniform()
            Let x be stratum_left plus u multiplied by stratum_width
            
            Note: Evaluate function
            Let variables be {"x": x.to_string()}
            Let f_x_str be ExprParser.evaluate_expression(parsed_expression, variables)
            Let f_x be f_x_str.to_float()
            
            stratum_sum is equal to stratum_sum plus f_x
            stratum_sum_squares is equal to stratum_sum_squares plus f_x multiplied by f_x
            total_function_evaluations is equal to total_function_evaluations plus 1
            sample is equal to sample plus 1
        
        Note: Compute stratum statistics
        Let stratum_mean be stratum_sum / samples_per_stratum.to_float()
        Let stratum_contribution be stratum_width multiplied by stratum_mean
        total_integral is equal to total_integral plus stratum_contribution
        
        Note: Compute stratum variance
        Let mean_squares be stratum_sum_squares / samples_per_stratum.to_float()
        Let stratum_variance be mean_squares minus stratum_mean multiplied by stratum_mean
        Let stratum_variance_contribution be (stratum_width multiplied by stratum_width multiplied by stratum_variance) / samples_per_stratum.to_float()
        total_variance is equal to total_variance plus stratum_variance_contribution
        
        stratum is equal to stratum plus 1
    
    Let error_estimate be total_variance.sqrt()
    
    Return IntegrationResult{
        integral_value: total_integral.to_string(),
        absolute_error: error_estimate.to_string(),
        relative_error: (error_estimate / total_integral.abs()).to_string(),
        function_evaluations: total_function_evaluations,
        subdivisions_used: num_strata,
        convergence_achieved: True,
        integration_method: "Stratified Sampling Monte Carlo",
        computational_time: 0.0
    }

Process called "control_variates_integration" that takes function_evaluator as String, control_function as String, domain as IntegrationDomain, num_samples as Integer returns IntegrationResult:
    Note: Monte Carlo integration with control variates
    
    If function_evaluator is equal to "":
        Throw Errors.InvalidArgument with "Function evaluator cannot be empty"
    
    If control_function is equal to "":
        Throw Errors.InvalidArgument with "Control function cannot be empty"
    
    If num_samples is less than or equal to 0:
        Throw Errors.InvalidArgument with "Number of samples must be positive"
    
    Let a be domain.get("lower_bound").to_float()
    Let b be domain.get("upper_bound").to_float()
    
    If b is less than or equal to a:
        Throw Errors.InvalidArgument with "Upper bound must be greater than lower bound"
    
    Note: Control variates method: ∫f(x)dx ≈ ∫g(x)dx plus (1/n)Σ[f(xi) minus g(xi) minus β(h(xi) minus μh)]
    Note: where g(x) is control function with known integral, h(x) is correlated function
    
    Let domain_width be b minus a
    Let f_sum be 0.0
    Let g_sum be 0.0
    Let f_times_g_sum be 0.0
    Let g_squared_sum be 0.0
    
    Note: Sample function and control function values
    Let i be 0
    While i is less than num_samples:
        Note: Generate uniform random sample in [a, b]
        Let x be a plus generate_uniform_random() multiplied by domain_width
        
        Note: Evaluate target function f(x)
        Let variables be {"x": x.to_string()}
        Let f_str be ExprParser.evaluate_expression_with_context(function_evaluator, variables)
        Let f_x be f_str.to_float()
        
        Note: Evaluate control function g(x)
        Let g_str be ExprParser.evaluate_expression_with_context(control_function, variables)
        Let g_x be g_str.to_float()
        
        f_sum is equal to f_sum plus f_x
        g_sum is equal to g_sum plus g_x
        f_times_g_sum is equal to f_times_g_sum plus f_x multiplied by g_x
        g_squared_sum is equal to g_squared_sum plus g_x multiplied by g_x
        
        i is equal to i plus 1
    
    Note: Calculate means
    Let f_mean be f_sum / num_samples.to_float()
    Let g_mean be g_sum / num_samples.to_float()
    
    Note: Calculate correlation coefficient and optimal control variate coefficient
    Let cov_fg be (f_times_g_sum / num_samples.to_float()) minus (f_mean multiplied by g_mean)
    Let var_g be (g_squared_sum / num_samples.to_float()) minus (g_mean multiplied by g_mean)
    
    Let beta be 0.0
    If var_g is greater than 1e-15:
        beta is equal to cov_fg / var_g
    
    Note: Compute known integral of control function (assuming polynomial or simple function)
    Let control_integral be compute_analytical_integral(control_function, a, b)
    
    Note: Apply control variates correction
    Let mc_estimate be f_mean multiplied by domain_width
    Let control_correction be beta multiplied by (g_mean multiplied by domain_width minus control_integral)
    Let result_value be mc_estimate minus control_correction
    
    Note: Estimate variance reduction
    Let correlation_coeff be 0.0
    If var_g is greater than 1e-15:
        Let var_f be compute_sample_variance(f_sum, num_samples, f_mean)
        correlation_coeff is equal to cov_fg / (var_f.sqrt() multiplied by var_g.sqrt())
    
    Let variance_reduction_factor be 1.0 minus correlation_coeff multiplied by correlation_coeff
    If variance_reduction_factor is less than 0.1:
        variance_reduction_factor is equal to 0.1
    
    Note: Estimate error with variance reduction
    Let standard_error be (result_value.abs() / num_samples.to_float().sqrt()) multiplied by domain_width
    Let error_estimate be standard_error multiplied by variance_reduction_factor.sqrt()
    
    Let result be {}
    result.set("value", result_value.to_string())
    result.set("error_estimate", error_estimate.to_string())
    result.set("function_evaluations", (num_samples multiplied by 2).to_string())
    result.set("method", "control_variates_monte_carlo")
    result.set("control_coefficient", beta.to_string())
    result.set("variance_reduction_factor", variance_reduction_factor.to_string())
    result.set("correlation_coefficient", correlation_coeff.to_string())
    result.set("convergence", "achieved")
    
    Return result

Note: =====================================================================
Note: MULTIDIMENSIONAL INTEGRATION OPERATIONS
Note: =====================================================================

Process called "multidimensional_simpson" that takes function_evaluator as String, domain as IntegrationDomain, intervals_per_dimension as List[Integer] returns IntegrationResult:
    Note: Multi-dimensional Simpson's rule integration
    
    If domain.dimension is less than or equal to 0:
        Throw Errors.InvalidArgument with "Domain dimension must be positive"
    
    If domain.dimension is greater than 3:
        Throw Errors.UnsupportedOperation with "Only up to 3D integration currently supported"
    
    If intervals_per_dimension.length() does not equal domain.dimension:
        Throw Errors.InvalidArgument with "Number of interval specifications must match domain dimension"
    
    Note: Validate all intervals are even for Simpson's rule
    Let i be 0
    While i is less than intervals_per_dimension.length():
        If intervals_per_dimension.get(i) is less than or equal to 0:
            Throw Errors.InvalidArgument with "Number of intervals must be positive"
        If (intervals_per_dimension.get(i) % 2) does not equal 0:
            Throw Errors.InvalidArgument with "Number of intervals must be even for Simpson's rule"
        i is equal to i plus 1
    
    Let parsed_expression be ExprParser.parse_mathematical_expression(function_evaluator)
    
    If domain.dimension is equal to 1:
        Return simpson_1d(parsed_expression, domain, intervals_per_dimension.get(0))
    Else If domain.dimension is equal to 2:
        Return simpson_2d(parsed_expression, domain, intervals_per_dimension)
    Otherwise:
        Return simpson_3d(parsed_expression, domain, intervals_per_dimension)

Let simpson_1d be Process that takes parsed_expr as Expression, dom as IntegrationDomain, n_intervals as Integer returns IntegrationResult:
    Let a be dom.lower_bounds.get(0).to_float()
    Let b be dom.upper_bounds.get(0).to_float()
    Let h be (b minus a) / n_intervals.to_float()
    
    Let integral_sum be 0.0
    Let function_evaluations be 0
    
    Let i be 0
    While i is less than or equal to n_intervals:
        Let x be a plus i.to_float() multiplied by h
        Let variables be {"x": x.to_string()}
        Let f_val_str be ExprParser.evaluate_expression(parsed_expr, variables)
        Let f_val be f_val_str.to_float()
        
        If i is equal to 0 or i is equal to n_intervals:
            integral_sum is equal to integral_sum plus f_val
        Else If (i % 2) is equal to 1:
            integral_sum is equal to integral_sum plus 4.0 multiplied by f_val
        Otherwise:
            integral_sum is equal to integral_sum plus 2.0 multiplied by f_val
        
        function_evaluations is equal to function_evaluations plus 1
        i is equal to i plus 1
    
    Let integral_value be (h / 3.0) multiplied by integral_sum
    Let error_estimate be 1e-10 multiplied by integral_value.abs()
    
    Return IntegrationResult{
        integral_value: integral_value.to_string(),
        absolute_error: error_estimate.to_string(),
        relative_error: (error_estimate / integral_value.abs()).to_string(),
        function_evaluations: function_evaluations,
        subdivisions_used: n_intervals,
        convergence_achieved: True,
        integration_method: "1D Simpson's Rule",
        computational_time: 0.0
    }

Let simpson_2d be Process that takes parsed_expr as Expression, dom as IntegrationDomain, intervals as List[Integer] returns IntegrationResult:
    Let a be dom.lower_bounds.get(0).to_float()
    Let b be dom.upper_bounds.get(0).to_float()
    Let c be dom.lower_bounds.get(1).to_float()
    Let d be dom.upper_bounds.get(1).to_float()
    
    Let nx be intervals.get(0)
    Let ny be intervals.get(1)
    Let hx be (b minus a) / nx.to_float()
    Let hy be (d minus c) / ny.to_float()
    
    Let integral_sum be 0.0
    Let function_evaluations be 0
    
    Let i be 0
    While i is less than or equal to nx:
        Let x be a plus i.to_float() multiplied by hx
        
        Let j be 0
        While j is less than or equal to ny:
            Let y be c plus j.to_float() multiplied by hy
            
            Let variables be {"x": x.to_string(), "y": y.to_string()}
            Let f_val_str be ExprParser.evaluate_expression(parsed_expr, variables)
            Let f_val be f_val_str.to_float()
            
            Note: Simpson's 2D weights
            Let weight_x be 1.0
            If i is equal to 0 or i is equal to nx:
                weight_x is equal to 1.0
            Else If (i % 2) is equal to 1:
                weight_x is equal to 4.0
            Otherwise:
                weight_x is equal to 2.0
            
            Let weight_y be 1.0
            If j is equal to 0 or j is equal to ny:
                weight_y is equal to 1.0
            Else If (j % 2) is equal to 1:
                weight_y is equal to 4.0
            Otherwise:
                weight_y is equal to 2.0
            
            integral_sum is equal to integral_sum plus weight_x multiplied by weight_y multiplied by f_val
            function_evaluations is equal to function_evaluations plus 1
            j is equal to j plus 1
        i is equal to i plus 1
    
    Let integral_value be (hx multiplied by hy / 9.0) multiplied by integral_sum
    Let error_estimate be 1e-8 multiplied by integral_value.abs()
    
    Return IntegrationResult{
        integral_value: integral_value.to_string(),
        absolute_error: error_estimate.to_string(),
        relative_error: (error_estimate / integral_value.abs()).to_string(),
        function_evaluations: function_evaluations,
        subdivisions_used: nx multiplied by ny,
        convergence_achieved: True,
        integration_method: "2D Simpson's Rule",
        computational_time: 0.0
    }

Process called "sparse_grid_integration" that takes function_evaluator as String, domain as IntegrationDomain, level as Integer, rule_type as String returns IntegrationResult:
    Note: Sparse grid integration for high-dimensional problems
    
    If function_evaluator is equal to "":
        Throw Errors.InvalidArgument with "Function evaluator cannot be empty"
    
    If level is less than or equal to 0:
        Throw Errors.InvalidArgument with "Level must be positive"
    
    If rule_type is equal to "":
        rule_type is equal to "clenshaw_curtis"
    
    Let dimension be domain.get("dimension").to_integer()
    If dimension is less than or equal to 0:
        Throw Errors.InvalidArgument with "Domain dimension must be positive"
    
    Let bounds be []
    Let i be 0
    While i is less than dimension:
        Let lower_key be "lower_bound_" joined with i.to_string()
        Let upper_key be "upper_bound_" joined with i.to_string()
        
        If not domain.contains_key(lower_key) or not domain.contains_key(upper_key):
            Throw Errors.InvalidArgument with "Domain must specify bounds for all dimensions"
        
        Let bound be {}
        bound.set("lower", domain.get(lower_key))
        bound.set("upper", domain.get(upper_key))
        bounds.append(bound)
        
        i is equal to i plus 1
    
    Let result_value be 0.0
    Let total_evaluations be 0
    
    Note: Generate sparse grid points using Smolyak construction
    Let grid_points be []
    Let weights be []
    
    Note: For each multi-index in the sparse grid
    Let max_index be level plus dimension minus 1
    Let multi_index be generate_multiindices(dimension, max_index)
    
    Let index_set_count be 0
    While index_set_count is less than multi_index.length():
        Let current_index be multi_index.get(index_set_count)
        Let index_sum be sum_multiindex(current_index)
        
        If index_sum is less than or equal to level plus dimension minus 1:
            Note: Smolyak coefficient
            Let smolyak_coeff be compute_smolyak_coefficient(dimension, level, current_index)
            
            If smolyak_coeff does not equal 0.0:
                Note: Generate tensor product grid for this multi-index
                Let tensor_points be []
                Let tensor_weights be []
                
                Let dim_index be 0
                While dim_index is less than dimension:
                    Let level_i be current_index.get(dim_index).to_integer()
                    Let one_d_points be []
                    Let one_d_weights be []
                    
                    If rule_type is equal to "clenshaw_curtis":
                        Note: Clenshaw-Curtis points for this level
                        Let n_points be (2 ^ level_i) plus 1
                        If level_i is equal to 0:
                            n_points is equal to 1
                        
                        Let j be 0
                        While j is less than n_points:
                            Let xi be 0.0
                            Let wi be 1.0
                            
                            If n_points is equal to 1:
                                xi is equal to 0.0
                                wi is equal to 2.0
                            Otherwise:
                                xi is equal to (2.0 multiplied by j.to_float() / (n_points minus 1).to_float() minus 1.0).cos() multiplied by 3.14159265359
                                wi is equal to 2.0 / (n_points minus 1).to_float()
                                If j is equal to 0 or j is equal to n_points minus 1:
                                    wi is equal to wi multiplied by 0.5
                            
                            Note: Transform to actual domain
                            Let a_dim be bounds.get(dim_index).get("lower").to_float()
                            Let b_dim be bounds.get(dim_index).get("upper").to_float()
                            Let transformed_xi be a_dim plus (xi plus 1.0) multiplied by 0.5 multiplied by (b_dim minus a_dim)
                            let transformed_wi be wi multiplied by (b_dim minus a_dim) multiplied by 0.5
                            
                            one_d_points.append(transformed_xi.to_string())
                            one_d_weights.append(transformed_wi.to_string())
                            j is equal to j plus 1
                    
                    If dim_index is equal to 0:
                        Let k be 0
                        While k is less than one_d_points.length():
                            Let point be [one_d_points.get(k)]
                            Let weight be one_d_weights.get(k).to_float()
                            tensor_points.append(point)
                            tensor_weights.append(weight.to_string())
                            k is equal to k plus 1
                    Otherwise:
                        Note: Take tensor product with existing points
                        Let new_tensor_points be []
                        Let new_tensor_weights be []
                        
                        Let tp_index be 0
                        While tp_index is less than tensor_points.length():
                            Let existing_point be tensor_points.get(tp_index)
                            Let existing_weight be tensor_weights.get(tp_index).to_float()
                            
                            Let od_index be 0
                            While od_index is less than one_d_points.length():
                                Let new_point be existing_point
                                new_point.append(one_d_points.get(od_index))
                                Let new_weight be existing_weight multiplied by one_d_weights.get(od_index).to_float()
                                
                                new_tensor_points.append(new_point)
                                new_tensor_weights.append(new_weight.to_string())
                                od_index is equal to od_index plus 1
                            
                            tp_index is equal to tp_index plus 1
                        
                        tensor_points is equal to new_tensor_points
                        tensor_weights is equal to new_tensor_weights
                    
                    dim_index is equal to dim_index plus 1
                
                Note: Add tensor product points to sparse grid with Smolyak coefficient
                let tp_final_index be 0
                While tp_final_index is less than tensor_points.length():
                    Let point be tensor_points.get(tp_final_index)
                    Let weight be tensor_weights.get(tp_final_index).to_float() multiplied by smolyak_coeff
                    
                    Note: Evaluate function at this point
                    Let variables be {}
                    Let coord_index be 0
                    While coord_index is less than dimension:
                        Let var_name be "x" joined with coord_index.to_string()
                        variables.set(var_name, point.get(coord_index))
                        coord_index is equal to coord_index plus 1
                    
                    Let f_str be ExprParser.evaluate_expression_with_context(function_evaluator, variables)
                    Let f_val be f_str.to_float()
                    
                    result_value is equal to result_value plus weight multiplied by f_val
                    total_evaluations is equal to total_evaluations plus 1
                    tp_final_index is equal to tp_final_index plus 1
        
        index_set_count is equal to index_set_count plus 1
    
    Note: Error estimate based on sparse grid theory
    Let error_estimate be result_value.abs() multiplied by (2.0 ^ (-level.to_float()))
    
    Let result be {}
    result.set("value", result_value.to_string())
    result.set("error_estimate", error_estimate.to_string())
    result.set("function_evaluations", total_evaluations.to_string())
    result.set("method", ("sparse_grid_" joined with rule_type))
    result.set("level", level.to_string())
    result.set("dimension", dimension.to_string())
    result.set("convergence", "achieved")
    
    Return result

Process called "adaptive_multidimensional_integration" that takes function_evaluator as String, domain as IntegrationDomain, tolerance as String, max_evaluations as Integer returns IntegrationResult:
    Note: Adaptive integration for multidimensional problems
    
    If function_evaluator is equal to "":
        Throw Errors.InvalidArgument with "Function evaluator cannot be empty"
    
    Let tol be tolerance.to_float()
    If tol is less than or equal to 0.0:
        Throw Errors.InvalidArgument with "Tolerance must be positive"
    
    If max_evaluations is less than or equal to 0:
        Throw Errors.InvalidArgument with "Max evaluations must be positive"
    
    Let dimension be domain.get("dimension").to_integer()
    If dimension is less than or equal to 0 or dimension is greater than 10:
        Throw Errors.InvalidArgument with "Dimension must be between 1 and 10"
    
    Note: Adaptive subdivision using hypercubes
    Let regions be []
    regions.append(domain)
    
    Let result_value be 0.0
    let total_error be 0.0
    Let total_evaluations be 0
    Let max_regions be 1000
    
    While regions.length() is greater than 0 and total_evaluations is less than max_evaluations:
        Let current_region be regions.get(0)
        regions.remove(0)
        
        Note: Compute region volume
        Let region_volume be 1.0
        Let region_bounds be []
        
        Let dim be 0
        While dim is less than dimension:
            Let lower_key be "lower_bound_" joined with dim.to_string()
            Let upper_key be "upper_bound_" joined with dim.to_string()
            
            Let lower be current_region.get(lower_key).to_float()
            Let upper be current_region.get(upper_key).to_float()
            Let width be upper minus lower
            
            region_volume is equal to region_volume multiplied by width
            region_bounds.append({"lower": lower, "upper": upper, "width": width})
            dim is equal to dim plus 1
        
        Note: Estimate integral over this region using basic quadrature
        Let coarse_result be estimate_region_integral(function_evaluator, current_region, 2)
        Let fine_result be estimate_region_integral(function_evaluator, current_region, 4)
        
        Let coarse_value be coarse_result.get("value").to_float()
        Let fine_value be fine_result.get("value").to_float()
        Let region_error be (fine_value minus coarse_value).abs()
        
        total_evaluations is equal to total_evaluations plus coarse_result.get("evaluations").to_integer()
        total_evaluations is equal to total_evaluations plus fine_result.get("evaluations").to_integer()
        
        Note: Check if region needs subdivision
        Let local_tolerance be tol multiplied by region_volume
        
        If region_error is less than or equal to local_tolerance or regions.length() is greater than or equal to max_regions:
            Note: Accept this region
            result_value is equal to result_value plus fine_value
            total_error is equal to total_error plus region_error
        Otherwise:
            Note: Subdivide region along longest dimension
            Let longest_dim be 0
            Let max_width be region_bounds.get(0).get("width")
            
            Let check_dim be 1
            While check_dim is less than dimension:
                Let width be region_bounds.get(check_dim).get("width")
                If width is greater than max_width:
                    max_width is equal to width
                    longest_dim is equal to check_dim
                check_dim is equal to check_dim plus 1
            
            Note: Create two subregions
            Let lower_key be "lower_bound_" joined with longest_dim.to_string()
            Let upper_key be "upper_bound_" joined with longest_dim.to_string()
            
            Let dim_lower be current_region.get(lower_key).to_float()
            Let dim_upper be current_region.get(upper_key).to_float()
            Let midpoint be (dim_lower plus dim_upper) multiplied by 0.5
            
            Let left_region be current_region
            left_region.set(upper_key, midpoint.to_string())
            
            Let right_region be current_region
            right_region.set(lower_key, midpoint.to_string())
            right_region.set(upper_key, dim_upper.to_string())
            
            regions.append(left_region)
            regions.append(right_region)
    
    Note: Process any remaining regions
    While regions.length() is greater than 0:
        Let remaining_region be regions.get(0)
        regions.remove(0)
        
        Let remaining_result be estimate_region_integral(function_evaluator, remaining_region, 2)
        result_value is equal to result_value plus remaining_result.get("value").to_float()
        total_error is equal to total_error plus remaining_result.get("error").to_float()
        total_evaluations is equal to total_evaluations plus remaining_result.get("evaluations").to_integer()
    
    Let convergence_achieved be total_error is less than or equal to tol
    
    Let result be {}
    result.set("value", result_value.to_string())
    result.set("error_estimate", total_error.to_string())
    result.set("function_evaluations", total_evaluations.to_string())
    result.set("method", "adaptive_multidimensional")
    result.set("dimension", dimension.to_string())
    result.set("convergence", convergence_achieved.to_string())
    
    Return result

Process called "tensor_product_quadrature" that takes function_evaluator as String, domain as IntegrationDomain, quadrature_rules as List[IntegrationRule] returns IntegrationResult:
    Note: Tensor product of one-dimensional quadrature rules
    
    If function_evaluator is equal to "":
        Throw Errors.InvalidArgument with "Function evaluator cannot be empty"
    
    If quadrature_rules.length() is equal to 0:
        Throw Errors.InvalidArgument with "At least one quadrature rule must be provided"
    
    Let dimension be domain.get("dimension").to_integer()
    If dimension is less than or equal to 0:
        Throw Errors.InvalidArgument with "Domain dimension must be positive"
    
    If quadrature_rules.length() does not equal dimension:
        Throw Errors.InvalidArgument with "Number of quadrature rules must match domain dimension"
    
    Let result_value be 0.0
    Let total_evaluations be 0
    
    Note: Generate tensor product grid
    Let grid_points be [[]]
    Let grid_weights be [1.0]
    
    Let dim_index be 0
    While dim_index is less than dimension:
        Let rule be quadrature_rules.get(dim_index)
        Let lower_key be "lower_bound_" joined with dim_index.to_string()
        Let upper_key be "upper_bound_" joined with dim_index.to_string()
        
        If not domain.contains_key(lower_key) or not domain.contains_key(upper_key):
            Throw Errors.InvalidArgument with "Domain must specify bounds for all dimensions"
        
        Let a be domain.get(lower_key).to_float()
        Let b be domain.get(upper_key).to_float()
        
        If b is less than or equal to a:
            Throw Errors.InvalidArgument with "Upper bound must be greater than lower bound"
        
        Note: Get quadrature points and weights for this dimension
        Let rule_type be rule.get("rule_type")
        Let n_points be rule.get("num_points").to_integer()
        
        Let one_d_points be []
        Let one_d_weights be []
        
        If rule_type is equal to "gauss_legendre":
            Note: Generate Gauss-Legendre points
            Let legendre_rule be Orthogonal.compute_gauss_legendre_quadrature(n_points, {})
            Let nodes be legendre_rule.get("nodes")
            Let weights be legendre_rule.get("weights")
            
            Let point_index be 0
            While point_index is less than n_points:
                Let xi be nodes.get(point_index).to_float()
                Let wi be weights.get(point_index).to_float()
                
                Note: Transform from [-1,1] to [a,b]
                Let transformed_xi be a plus (xi plus 1.0) multiplied by 0.5 multiplied by (b minus a)
                Let transformed_wi be wi multiplied by (b minus a) multiplied by 0.5
                
                one_d_points.append(transformed_xi.to_string())
                one_d_weights.append(transformed_wi.to_string())
                point_index is equal to point_index plus 1
        
        Else If rule_type is equal to "trapezoidal":
            Note: Generate trapezoidal points
            Let h be (b minus a) / (n_points minus 1).to_float()
            
            Let trap_index be 0
            While trap_index is less than n_points:
                Let xi be a plus trap_index.to_float() multiplied by h
                Let wi be h
                
                If trap_index is equal to 0 or trap_index is equal to n_points minus 1:
                    wi is equal to wi multiplied by 0.5
                
                one_d_points.append(xi.to_string())
                one_d_weights.append(wi.to_string())
                trap_index is equal to trap_index plus 1
        
        Otherwise:
            Throw Errors.InvalidArgument with ("Unsupported quadrature rule: " joined with rule_type)
        
        Note: Form tensor product with existing grid
        Let new_grid_points be []
        Let new_grid_weights be []
        
        Let existing_index be 0
        While existing_index is less than grid_points.length():
            Let existing_point be grid_points.get(existing_index)
            Let existing_weight be grid_weights.get(existing_index)
            
            Let new_point_index be 0
            While new_point_index is less than one_d_points.length():
                Let new_coord be one_d_points.get(new_point_index)
                Let new_weight_contrib be one_d_weights.get(new_point_index).to_float()
                
                Let combined_point be existing_point
                combined_point.append(new_coord)
                
                Let combined_weight be existing_weight multiplied by new_weight_contrib
                
                new_grid_points.append(combined_point)
                new_grid_weights.append(combined_weight)
                new_point_index is equal to new_point_index plus 1
            
            existing_index is equal to existing_index plus 1
        
        grid_points is equal to new_grid_points
        grid_weights is equal to new_grid_weights
        dim_index is equal to dim_index plus 1
    
    Note: Evaluate function at all tensor product points
    Let point_index be 0
    While point_index is less than grid_points.length():
        Let point be grid_points.get(point_index)
        Let weight be grid_weights.get(point_index)
        
        Note: Set up variables for function evaluation
        Let variables be {}
        Let coord_index be 0
        While coord_index is less than dimension:
            Let var_name be "x" joined with coord_index.to_string()
            variables.set(var_name, point.get(coord_index))
            coord_index is equal to coord_index plus 1
        
        Let f_str be ExprParser.evaluate_expression_with_context(function_evaluator, variables)
        Let f_val be f_str.to_float()
        
        result_value is equal to result_value plus weight multiplied by f_val
        total_evaluations is equal to total_evaluations plus 1
        point_index is equal to point_index plus 1
    
    Note: Error estimate based on quadrature order
    Let min_order be 10000
    Let rule_check be 0
    While rule_check is less than quadrature_rules.length():
        let rule be quadrature_rules.get(rule_check)
        let order be rule.get("order").to_integer()
        If order is less than min_order:
            min_order is equal to order
        rule_check is equal to rule_check plus 1
    
    Let error_estimate be result_value.abs() multiplied by (1.0 / (10.0 ^ min_order.to_float()))
    
    Let result be {}
    result.set("value", result_value.to_string())
    result.set("error_estimate", error_estimate.to_string())
    result.set("function_evaluations", total_evaluations.to_string())
    result.set("method", "tensor_product_quadrature")
    result.set("dimension", dimension.to_string())
    result.set("grid_points", grid_points.length().to_string())
    result.set("convergence", "achieved")
    
    Return result

Note: =====================================================================
Note: SINGULAR INTEGRAL OPERATIONS
Note: =====================================================================

Process called "integrate_with_singularities" that takes function_evaluator as String, domain as IntegrationDomain, singularity_locations as List[String], singularity_types as List[String] returns IntegrationResult:
    Note: Integration of functions with known singularities
    
    If function_evaluator is equal to "":
        Throw Errors.InvalidArgument with "Function evaluator cannot be empty"
    
    If singularity_locations.length() does not equal singularity_types.length():
        Throw Errors.InvalidArgument with "Number of singularity locations must match number of singularity types"
    
    Let a be domain.get("lower_bound").to_float()
    Let b be domain.get("upper_bound").to_float()
    
    If b is less than or equal to a:
        Throw Errors.InvalidArgument with "Upper bound must be greater than lower bound"
    
    Let result_value be 0.0
    Let total_evaluations be 0
    Let total_error be 0.0
    
    Note: Sort singularities by location
    Let sorted_singularities be []
    Let i be 0
    While i is less than singularity_locations.length():
        Let location be singularity_locations.get(i).to_float()
        Let type be singularity_types.get(i)
        
        If location is greater than a and location is less than b:
            sorted_singularities.append({"location": location, "type": type})
        
        i is equal to i plus 1
    
    Note: Sort by location (simple bubble sort)
    Let j be 0
    While j is less than sorted_singularities.length() minus 1:
        Let k be j plus 1
        While k is less than sorted_singularities.length():
            Let loc_j be sorted_singularities.get(j).get("location")
            Let loc_k be sorted_singularities.get(k).get("location")
            
            If loc_k is less than loc_j:
                Let temp be sorted_singularities.get(j)
                sorted_singularities.set(j, sorted_singularities.get(k))
                sorted_singularities.set(k, temp)
            
            k is equal to k plus 1
        j is equal to j plus 1
    
    Note: Integrate between singularities
    Let current_lower be a
    
    Let sing_index be 0
    While sing_index is less than or equal to sorted_singularities.length():
        Let current_upper be b
        Let has_singularity be false
        Let singularity_type be ""
        Let singularity_location be 0.0
        
        If sing_index is less than sorted_singularities.length():
            Let singularity be sorted_singularities.get(sing_index)
            current_upper is equal to singularity.get("location")
            has_singularity is equal to true
            singularity_type is equal to singularity.get("type")
            singularity_location is equal to current_upper
        
        Note: Integrate regular interval [current_lower, current_upper]
        If current_upper is greater than current_lower:
            Let interval_width be current_upper minus current_lower
            
            If interval_width is greater than 1e-12:
                Let subdomain be {"lower_bound": current_lower.to_string(), "upper_bound": current_upper.to_string()}
                
                Note: Use adaptive Simpson for regular intervals
                Let interval_result be adaptive_simpson_integration(function_evaluator, subdomain, "1e-10")
                
                result_value is equal to result_value plus interval_result.get("value").to_float()
                total_error is equal to total_error plus interval_result.get("error_estimate").to_float()
                total_evaluations is equal to total_evaluations plus interval_result.get("function_evaluations").to_integer()
        
        Note: Handle singularity
        If has_singularity and sing_index is less than sorted_singularities.length():
            If singularity_type is equal to "simple_pole":
                Note: Use principal value integration around pole
                Let epsilon be 1e-6
                
                Let left_domain be {"lower_bound": (singularity_location minus epsilon).to_string(), "upper_bound": singularity_location.to_string()}
                Let right_domain be {"lower_bound": singularity_location.to_string(), "upper_bound": (singularity_location plus epsilon).to_string()}
                
                Let left_result be adaptive_simpson_integration(function_evaluator, left_domain, "1e-8")
                Let right_result be adaptive_simpson_integration(function_evaluator, right_domain, "1e-8")
                
                Note: Principal value is limit as epsilon -> 0
                Let pv_contribution be left_result.get("value").to_float() plus right_result.get("value").to_float()
                result_value is equal to result_value plus pv_contribution
                
                total_evaluations is equal to total_evaluations plus left_result.get("function_evaluations").to_integer()
                total_evaluations is equal to total_evaluations plus right_result.get("function_evaluations").to_integer()
            
            Else If singularity_type is equal to "branch_point":
                Note: Use coordinate transformation around branch point
                Let delta be 1e-4
                
                Note: Integrate using square root transformation near branch point
                Let branch_domain be {"lower_bound": (singularity_location minus delta).to_string(), "upper_bound": (singularity_location plus delta).to_string()}
                
                Note: Use specialized quadrature for branch point
                Let branch_result be gauss_legendre_integration(function_evaluator, branch_domain, 16)
                
                result_value is equal to result_value plus branch_result.get("value").to_float()
                total_error is equal to total_error plus branch_result.get("error_estimate").to_float()
                total_evaluations is equal to total_evaluations plus branch_result.get("function_evaluations").to_integer()
            
            Else If singularity_type is equal to "logarithmic":
                Note: Handle logarithmic singularity with specialized quadrature
                Let log_epsilon be 1e-8
                
                Let log_domain be {"lower_bound": (singularity_location minus log_epsilon).to_string(), "upper_bound": (singularity_location plus log_epsilon).to_string()}
                Let log_result be gauss_chebyshev_integration(function_evaluator, log_domain, 20)
                
                result_value is equal to result_value plus log_result.get("value").to_float()
                total_error is equal to total_error plus log_result.get("error_estimate").to_float()
                total_evaluations is equal to total_evaluations plus log_result.get("function_evaluations").to_integer()
            
            Otherwise:
                Note: Unknown singularity type minus use regularization
                Let reg_epsilon be 1e-5
                Let reg_domain be {"lower_bound": (singularity_location minus reg_epsilon).to_string(), "upper_bound": (singularity_location plus reg_epsilon).to_string()}
                
                Let reg_result be adaptive_simpson_integration(function_evaluator, reg_domain, "1e-6")
                result_value is equal to result_value plus reg_result.get("value").to_float()
                total_error is equal to total_error plus reg_result.get("error_estimate").to_float()
                total_evaluations is equal to total_evaluations plus reg_result.get("function_evaluations").to_integer()
        
        Note: Move to next interval
        If has_singularity and sing_index is less than sorted_singularities.length():
            current_lower is equal to singularity_location
        
        sing_index is equal to sing_index plus 1
    
    Let result be {}
    result.set("value", result_value.to_string())
    result.set("error_estimate", total_error.to_string())
    result.set("function_evaluations", total_evaluations.to_string())
    result.set("method", "singular_integration")
    result.set("singularities_handled", sorted_singularities.length().to_string())
    result.set("convergence", "achieved")
    
    Return result

Process called "cauchy_principal_value" that takes function_evaluator as String, lower_bound as String, upper_bound as String, singularity as String returns IntegrationResult:
    Note: Compute Cauchy principal value integral
    
    If function_evaluator is equal to "":
        Throw Errors.InvalidArgument with "Function evaluator cannot be empty"
    
    Let a be lower_bound.to_float()
    Let b be upper_bound.to_float()
    Let c be singularity.to_float()
    
    If b is less than or equal to a:
        Throw Errors.InvalidArgument with "Upper bound must be greater than lower bound"
    
    If c is less than or equal to a or c is greater than or equal to b:
        Throw Errors.InvalidArgument with "Singularity must be in the interior of the interval"
    
    Note: Compute principal value: P.V. ∫[a,b] f(x)/(x-c) dx is equal to lim(ε→0) [∫[a,c-ε] plus ∫[c+ε,b]] f(x)/(x-c) dx
    
    Let result_value be 0.0
    Let total_evaluations be 0
    Let max_iterations be 20
    Let convergence_achieved be false
    
    Note: Sequence of epsilon values approaching zero
    Let iteration be 0
    Let previous_result be 0.0
    
    While iteration is less than max_iterations and not convergence_achieved:
        Let epsilon be 1.0 / (10.0 ^ (iteration.to_float() plus 1.0))
        
        Note: Left interval [a, c-ε]
        Let left_result be 0.0
        If c minus epsilon is greater than a:
            Let left_domain be {"lower_bound": a.to_string(), "upper_bound": (c minus epsilon).to_string()}
            Let left_integration be adaptive_simpson_integration(function_evaluator, left_domain, "1e-10")
            left_result is equal to left_integration.get("value").to_float()
            total_evaluations is equal to total_evaluations plus left_integration.get("function_evaluations").to_integer()
        
        Note: Right interval [c+ε, b]
        Let right_result be 0.0
        If c plus epsilon is less than b:
            Let right_domain be {"lower_bound": (c plus epsilon).to_string(), "upper_bound": b.to_string()}
            Let right_integration be adaptive_simpson_integration(function_evaluator, right_domain, "1e-10")
            right_result is equal to right_integration.get("value").to_float()
            total_evaluations is equal to total_evaluations plus right_integration.get("function_evaluations").to_integer()
        
        Let current_result be left_result plus right_result
        
        Note: Check convergence
        If iteration is greater than 0:
            Let change be (current_result minus previous_result).abs()
            If change is less than 1e-12 or change / current_result.abs() is less than 1e-10:
                convergence_achieved is equal to true
                result_value is equal to current_result
        
        previous_result is equal to current_result
        iteration is equal to iteration plus 1
    
    If not convergence_achieved:
        result_value is equal to previous_result
    
    Note: Additional refinement using symmetric approach
    Let refinement_iterations be 5
    Let symmetric_results be []
    
    Let ref_iter be 0
    While ref_iter is less than refinement_iterations:
        Let ref_epsilon be 1e-8 / (ref_iter.to_float() plus 1.0)
        
        Note: Symmetric intervals around singularity
        Let left_symmetric be 0.0
        Let right_symmetric be 0.0
        
        If c minus ref_epsilon is greater than a and c plus ref_epsilon is less than b:
            Let left_sym_domain be {"lower_bound": (c minus ref_epsilon).to_string(), "upper_bound": c.to_string()}
            Let right_sym_domain be {"lower_bound": c.to_string(), "upper_bound": (c plus ref_epsilon).to_string()}
            
            Let left_sym_result be adaptive_simpson_integration(function_evaluator, left_sym_domain, "1e-12")
            Let right_sym_result be adaptive_simpson_integration(function_evaluator, right_sym_domain, "1e-12")
            
            left_symmetric is equal to left_sym_result.get("value").to_float()
            right_symmetric is equal to right_sym_result.get("value").to_float()
            
            total_evaluations is equal to total_evaluations plus left_sym_result.get("function_evaluations").to_integer()
            total_evaluations is equal to total_evaluations plus right_sym_result.get("function_evaluations").to_integer()
        
        symmetric_results.append((left_symmetric plus right_symmetric).to_string())
        ref_iter is equal to ref_iter plus 1
    
    Note: Use Richardson extrapolation on symmetric results
    If symmetric_results.length() is greater than or equal to 2:
        Let last_result be symmetric_results.get(symmetric_results.length() minus 1).to_float()
        Let second_last be symmetric_results.get(symmetric_results.length() minus 2).to_float()
        
        Note: Richardson extrapolation assuming O(ε) convergence
        Let extrapolated be 2.0 multiplied by last_result minus second_last
        result_value is equal to extrapolated
    
    Note: Error estimate based on convergence behavior
    Let error_estimate be 1e-10
    If symmetric_results.length() is greater than or equal to 2:
        Let final_diff be (symmetric_results.get(symmetric_results.length() minus 1).to_float() minus 
                          symmetric_results.get(symmetric_results.length() minus 2).to_float()).abs()
        error_estimate is equal to final_diff multiplied by 2.0
    
    Let result be {}
    result.set("value", result_value.to_string())
    result.set("error_estimate", error_estimate.to_string())
    result.set("function_evaluations", total_evaluations.to_string())
    result.set("method", "cauchy_principal_value")
    result.set("singularity_location", singularity)
    result.set("convergence", convergence_achieved.to_string())
    result.set("iterations_used", iteration.to_string())
    
    Return result

Process called "hadamard_finite_part" that takes function_evaluator as String, lower_bound as String, upper_bound as String, singularity_order as Integer, singularity_location as String returns IntegrationResult:
    Note: Compute Hadamard finite part integral
    
    If function_evaluator is equal to "":
        Throw Errors.InvalidArgument with "Function evaluator cannot be empty"
    
    Let a be lower_bound.to_float()
    Let b be upper_bound.to_float()
    Let c be singularity_location.to_float()
    
    If b is less than or equal to a:
        Throw Errors.InvalidArgument with "Upper bound must be greater than lower bound"
    
    If c is less than or equal to a or c is greater than or equal to b:
        Throw Errors.InvalidArgument with "Singularity must be in the interior of the interval"
    
    If singularity_order is less than or equal to 0:
        Throw Errors.InvalidArgument with "Singularity order must be positive"
    
    Note: Hadamard finite part for singularity of order n: Fp ∫ f(x)/(x-c)^n dx
    Note: This involves subtracting divergent terms and taking the finite remainder
    
    Let result_value be 0.0
    Let total_evaluations be 0
    
    Note: Method depends on singularity order
    If singularity_order is equal to 1:
        Note: First-order singularity minus same as Cauchy principal value
        Let pv_result be cauchy_principal_value(function_evaluator, lower_bound, upper_bound, singularity_location)
        result_value is equal to pv_result.get("value").to_float()
        total_evaluations is equal to pv_result.get("function_evaluations").to_integer()
    
    Else If singularity_order is equal to 2:
        Note: Second-order singularity minus more complex finite part
        Note: Fp ∫ f(x)/(x-c)² dx is equal to lim(ε→0) [∫[a,c-ε] plus ∫[c+ε,b] f(x)/(x-c)² dx minus 2f(c)/ε]
        
        Let epsilon_sequence be [1e-3, 1e-4, 1e-5, 1e-6, 1e-7]
        Let finite_part_estimates be []
        
        Let eps_index be 0
        While eps_index is less than epsilon_sequence.length():
            Let epsilon be epsilon_sequence.get(eps_index)
            
            Note: Evaluate f(c) for subtraction term
            Let f_c_vars be {"x": c.to_string()}
            Let f_c_str be ExprParser.evaluate_expression_with_context(function_evaluator, f_c_vars)
            Let f_c be f_c_str.to_float()
            
            Note: Integrate regular parts
            Let left_integral be 0.0
            Let right_integral be 0.0
            
            If c minus epsilon is greater than a:
                Let left_domain be {"lower_bound": a.to_string(), "upper_bound": (c minus epsilon).to_string()}
                Let left_result be adaptive_simpson_integration(function_evaluator, left_domain, "1e-10")
                left_integral is equal to left_result.get("value").to_float()
                total_evaluations is equal to total_evaluations plus left_result.get("function_evaluations").to_integer()
            
            If c plus epsilon is less than b:
                Let right_domain be {"lower_bound": (c plus epsilon).to_string(), "upper_bound": b.to_string()}
                Let right_result be adaptive_simpson_integration(function_evaluator, right_domain, "1e-10")
                right_integral is equal to right_result.get("value").to_float()
                total_evaluations is equal to total_evaluations plus right_result.get("function_evaluations").to_integer()
            
            Note: Subtract divergent term
            Let divergent_term be 2.0 multiplied by f_c / epsilon
            Let finite_part_estimate be left_integral plus right_integral minus divergent_term
            
            finite_part_estimates.append(finite_part_estimate.to_string())
            eps_index is equal to eps_index plus 1
        
        Note: Use Richardson extrapolation on finite part estimates
        If finite_part_estimates.length() is greater than or equal to 2:
            Let last_estimate be finite_part_estimates.get(finite_part_estimates.length() minus 1).to_float()
            Let second_last be finite_part_estimates.get(finite_part_estimates.length() minus 2).to_float()
            
            Note: Extrapolate assuming linear convergence in epsilon
            result_value is equal to 2.0 multiplied by last_estimate minus second_last
        Otherwise:
            result_value is equal to finite_part_estimates.get(0).to_float()
    
    Else If singularity_order is greater than or equal to 3:
        Note: Higher-order singularities require more sophisticated treatment
        Note: Fp ∫ f(x)/(x-c)^n dx involves subtracting multiple divergent terms
        
        Let taylor_order be singularity_order plus 2
        Let epsilon be 1e-6
        
        Note: Compute Taylor expansion of f around c
        Let taylor_coeffs be compute_taylor_coefficients(function_evaluator, c, taylor_order)
        
        Note: Integrate regular part
        Let regular_integral be 0.0
        
        If c minus epsilon is greater than a:
            Let left_domain be {"lower_bound": a.to_string(), "upper_bound": (c minus epsilon).to_string()}
            Let left_result be adaptive_simpson_integration(function_evaluator, left_domain, "1e-8")
            regular_integral is equal to regular_integral plus left_result.get("value").to_float()
            total_evaluations is equal to total_evaluations plus left_result.get("function_evaluations").to_integer()
        
        If c plus epsilon is less than b:
            Let right_domain be {"lower_bound": (c plus epsilon).to_string(), "upper_bound": b.to_string()}
            Let right_result be adaptive_simpson_integration(function_evaluator, right_domain, "1e-8")
            regular_integral is equal to regular_integral plus right_result.get("value").to_float()
            total_evaluations is equal to total_evaluations plus right_result.get("function_evaluations").to_integer()
        
        Note: Subtract divergent Taylor terms
        Let divergent_contribution be 0.0
        Let k be 0
        While k is less than singularity_order minus 1:
            Let coeff be taylor_coeffs.get(k).to_float()
            Let power be singularity_order minus 1 minus k
            
            If power is greater than 0:
                Let term be coeff / power.to_float() multiplied by (epsilon ^ (-power.to_float()))
                divergent_contribution is equal to divergent_contribution plus term
            
            k is equal to k plus 1
        
        result_value is equal to regular_integral minus 2.0 multiplied by divergent_contribution
    
    Note: Error estimate based on method and order
    Let error_estimate be result_value.abs() multiplied by (10.0 ^ (-singularity_order.to_float()))
    If error_estimate is less than 1e-12:
        error_estimate is equal to 1e-12
    
    Let result be {}
    result.set("value", result_value.to_string())
    result.set("error_estimate", error_estimate.to_string())
    result.set("function_evaluations", total_evaluations.to_string())
    result.set("method", "hadamard_finite_part")
    result.set("singularity_order", singularity_order.to_string())
    result.set("singularity_location", singularity_location)
    result.set("convergence", "achieved")
    
    Return result

Process called "subtraction_method" that takes function_evaluator as String, singular_part as String, domain as IntegrationDomain returns IntegrationResult:
    Note: Handle singularities using subtraction method
    
    If function_evaluator is equal to "":
        Throw Errors.InvalidArgument with "Function evaluator cannot be empty"
    
    If singular_part is equal to "":
        Throw Errors.InvalidArgument with "Singular part cannot be empty"
    
    Let a be domain.get("lower_bound").to_float()
    Let b be domain.get("upper_bound").to_float()
    
    If b is less than or equal to a:
        Throw Errors.InvalidArgument with "Upper bound must be greater than lower bound"
    
    Note: Subtraction method: ∫[a,b] f(x) dx is equal to ∫[a,b] (f(x) minus g(x)) dx plus ∫[a,b] g(x) dx
    Note: where g(x) is the singular part that can be integrated analytically
    
    Let result_value be 0.0
    Let total_evaluations be 0
    
    Note: Step 1: Integrate the analytical singular part
    Let analytical_integral be integrate_analytical_singular_part(singular_part, a, b)
    
    Note: Step 2: Integrate the regular part (f(x) minus g(x))
    Note: Create difference function evaluator
    Let difference_function be create_difference_evaluator(function_evaluator, singular_part)
    
    Note: Integrate the regularized function
    Let regular_domain be {"lower_bound": a.to_string(), "upper_bound": b.to_string()}
    Let regular_result be adaptive_simpson_integration(difference_function, regular_domain, "1e-10")
    
    Let regular_integral be regular_result.get("value").to_float()
    let regular_error be regular_result.get("error_estimate").to_float()
    total_evaluations is equal to regular_result.get("function_evaluations").to_integer()
    
    Note: Combine analytical and numerical parts
    result_value is equal to analytical_integral plus regular_integral
    
    Note: Verify subtraction effectiveness by sampling
    Let effectiveness_check be check_subtraction_effectiveness(function_evaluator, singular_part, a, b)
    total_evaluations is equal to total_evaluations plus effectiveness_check.get("evaluations").to_integer()
    
    Let smoothness_factor be effectiveness_check.get("smoothness_factor").to_float()
    
    Note: Adjust error estimate based on subtraction quality
    Let error_estimate be regular_error
    If smoothness_factor is less than 0.1:
        Note: Poor subtraction minus increase error estimate
        error_estimate is equal to error_estimate multiplied by 10.0
    Else If smoothness_factor is greater than 0.9:
        Note: Excellent subtraction minus decrease error estimate
        error_estimate is equal to error_estimate multiplied by 0.1
    
    Note: Add analytical integration error (usually negligible)
    Let analytical_error be analytical_integral.abs() multiplied by 1e-15
    Let total_error be error_estimate plus analytical_error
    
    Let result be {}
    result.set("value", result_value.to_string())
    result.set("error_estimate", total_error.to_string())
    result.set("function_evaluations", total_evaluations.to_string())
    result.set("method", "subtraction_method")
    result.set("analytical_contribution", analytical_integral.to_string())
    result.set("numerical_contribution", regular_integral.to_string())
    result.set("subtraction_effectiveness", smoothness_factor.to_string())
    result.set("convergence", "achieved")
    
    Return result

Note: =====================================================================
Note: IMPROPER INTEGRAL OPERATIONS
Note: =====================================================================

Process called "integrate_to_infinity" that takes function_evaluator as String, lower_bound as String, transformation as String, tolerance as String returns IntegrationResult:
    Note: Integration over semi-infinite or infinite intervals
    
    Let tol be tolerance.to_float()
    If tol is less than or equal to 0.0:
        Throw Errors.InvalidArgument with "Tolerance must be positive"
    
    If transformation is equal to "substitution":
        Return infinity_substitution_method(function_evaluator, lower_bound, tol)
    Else If transformation is equal to "truncation":
        Return infinity_truncation_method(function_evaluator, lower_bound, tol)
    Else If transformation is equal to "exponential":
        Return infinity_exponential_method(function_evaluator, lower_bound, tol)
    Otherwise:
        Throw Errors.InvalidArgument with ("Unsupported transformation: " joined with transformation)

Let infinity_substitution_method be Process that takes func_expr as String, lower_str as String, tol as Float returns IntegrationResult:
    Note: Use substitution t is equal to 1/x for [a, ∞) → [0, 1/a]
    
    Let a be lower_str.to_float()
    Let parsed_expression be ExprParser.parse_mathematical_expression(func_expr)
    
    Note: Transform ∫[a,∞] f(x)dx is equal to ∫[0,1/a] f(1/t) multiplied by (1/t²) dt
    Let integral_sum be 0.0
    Let function_evaluations be 0
    Let num_intervals be 100
    
    Let upper_t be 1.0 / a
    Let h be upper_t / num_intervals.to_float()
    
    Let i be 1
    While i is less than or equal to num_intervals:
        Let t be i.to_float() multiplied by h
        Let x be 1.0 / t
        Let jacobian be 1.0 / (t multiplied by t)
        
        Let variables be {"x": x.to_string()}
        Let f_x_str be ExprParser.evaluate_expression(parsed_expression, variables)
        Let f_x be f_x_str.to_float()
        
        integral_sum is equal to integral_sum plus f_x multiplied by jacobian
        function_evaluations is equal to function_evaluations plus 1
        i is equal to i plus 1
    
    Let integral_value be h multiplied by integral_sum
    Let error_estimate be tol
    
    Return IntegrationResult{
        integral_value: integral_value.to_string(),
        absolute_error: error_estimate.to_string(),
        relative_error: (error_estimate / integral_value.abs()).to_string(),
        function_evaluations: function_evaluations,
        subdivisions_used: num_intervals,
        convergence_achieved: True,
        integration_method: "Infinity Substitution",
        computational_time: 0.0
    }

Let infinity_truncation_method be Process that takes func_expr as String, lower_str as String, tol as Float returns IntegrationResult:
    Note: Truncate at large value and use standard quadrature
    
    Let a be lower_str.to_float()
    Let large_bound be a plus 1000.0
    
    Note: Use adaptive Simpson on truncated domain
    Return adaptive_simpson(func_expr, lower_str, large_bound.to_string(), tol.to_string(), 1000)

Let infinity_exponential_method be Process that takes func_expr as String, lower_str as String, tol as Float returns IntegrationResult:
    Note: Use exponential transformation for rapidly decaying functions
    
    Let a be lower_str.to_float()
    Let parsed_expression be ExprParser.parse_mathematical_expression(func_expr)
    
    Note: Transform using x is equal to a plus e^t minus 1
    Let integral_sum be 0.0
    Let function_evaluations be 0
    Let num_points be 50
    
    Let t_max be 10.0
    Let dt be t_max / num_points.to_float()
    
    Let i be 0
    While i is less than num_points:
        Let t be i.to_float() multiplied by dt
        Let x be a plus t.exp() minus 1.0
        Let jacobian be t.exp()
        
        Let variables be {"x": x.to_string()}
        Let f_x_str be ExprParser.evaluate_expression(parsed_expression, variables)
        Let f_x be f_x_str.to_float()
        
        integral_sum is equal to integral_sum plus f_x multiplied by jacobian
        function_evaluations is equal to function_evaluations plus 1
        i is equal to i plus 1
    
    Let integral_value be dt multiplied by integral_sum
    Let error_estimate be 1e-6 multiplied by integral_value.abs()
    
    Return IntegrationResult{
        integral_value: integral_value.to_string(),
        absolute_error: error_estimate.to_string(),
        relative_error: (error_estimate / integral_value.abs()).to_string(),
        function_evaluations: function_evaluations,
        subdivisions_used: num_points,
        convergence_achieved: True,
        integration_method: "Infinity Exponential Transform",
        computational_time: 0.0
    }

Process called "double_exponential_transformation" that takes function_evaluator as String, lower_bound as String, upper_bound as String returns IntegrationResult:
    Note: Integration using tanh-sinh (double exponential) transformation
    
    Let a be lower_bound.to_float()
    Let b be upper_bound.to_float()
    
    Note: Handle infinite bounds
    Let is_infinite_lower be (lower_bound is equal to "-∞" or lower_bound is equal to "-infinity")
    Let is_infinite_upper be (upper_bound is equal to "∞" or upper_bound is equal to "infinity")
    
    If is_infinite_lower and is_infinite_upper:
        Note: Transform (-∞, ∞) → (-1, 1) using x is equal to sinh(π/2 multiplied by sinh(t))
        Return integrate_tanh_sinh_infinite(function_evaluator)
    Else If is_infinite_lower:
        Note: Transform (-∞, b) → (-1, 1) using transformation
        Return integrate_tanh_sinh_semi_infinite_left(function_evaluator, b)
    Else If is_infinite_upper:
        Note: Transform (a, ∞) → (-1, 1) using transformation
        Return integrate_tanh_sinh_semi_infinite_right(function_evaluator, a)
    Otherwise:
        Note: Transform [a, b] → (-1, 1) using linear transformation then tanh-sinh
        Return integrate_tanh_sinh_finite(function_evaluator, a, b)

Let integrate_tanh_sinh_finite be Process that takes func_expr as String, lower as Float, upper as Float returns IntegrationResult:
    Note: Tanh-sinh for finite interval [a, b]
    
    Let parsed_expression be ExprParser.parse_mathematical_expression(func_expr)
    
    Note: Use tanh-sinh quadrature with exponentially decaying weights
    Let h be 0.1
    Let integral_sum be 0.0
    Let function_evaluations be 0
    Let max_k be 50
    
    Let k be -max_k
    While k is less than or equal to max_k:
        Let t be k.to_float() multiplied by h
        
        Note: Compute tanh-sinh transformation
        Let sinh_t be t.sinh()
        Let cosh_t be t.cosh()
        Let tanh_val be sinh_t / cosh_t
        Let sech_squared be 1.0 / (cosh_t multiplied by cosh_t)
        
        Note: Transform to [a, b]
        Let x be 0.5 multiplied by (upper minus lower) multiplied by tanh_val plus 0.5 multiplied by (upper plus lower)
        
        Note: Skip points too close to boundaries
        If x is less than or equal to lower plus 1e-12 or x is greater than or equal to upper minus 1e-12:
            k is equal to k plus 1
            Continue
        
        Let variables be {"x": x.to_string()}
        Let f_x_str be ExprParser.evaluate_expression(parsed_expression, variables)
        Let f_x be f_x_str.to_float()
        
        Note: Apply tanh-sinh weight with Jacobian
        Let jacobian be 0.5 multiplied by (upper minus lower) multiplied by sech_squared
        Let weight be h multiplied by jacobian
        
        integral_sum is equal to integral_sum plus weight multiplied by f_x
        function_evaluations is equal to function_evaluations plus 1
        k is equal to k plus 1
    
    Let error_estimate be 1e-10 multiplied by integral_sum.abs()
    
    Return IntegrationResult{
        integral_value: integral_sum.to_string(),
        absolute_error: error_estimate.to_string(),
        relative_error: (error_estimate / integral_sum.abs()).to_string(),
        function_evaluations: function_evaluations,
        subdivisions_used: 1,
        convergence_achieved: True,
        integration_method: "Tanh-Sinh (Double Exponential)",
        computational_time: 0.0
    }

Let integrate_tanh_sinh_semi_infinite_right be Process that takes func_expr as String, lower as Float returns IntegrationResult:
    Note: Tanh-sinh for semi-infinite interval [a, ∞)
    
    Let parsed_expression be ExprParser.parse_mathematical_expression(func_expr)
    
    Let h be 0.1
    Let integral_sum be 0.0
    Let function_evaluations be 0
    Let max_k be 50
    
    Let k be -max_k
    While k is less than or equal to max_k:
        Let t be k.to_float() multiplied by h
        
        Note: Transform [a, ∞) using x is equal to a plus (1+t)/(1-t) for t ∈ (-1, 1)
        If t is greater than or equal to 0.999:
            k is equal to k plus 1
            Continue
        
        Let x be lower plus (1.0 plus t) / (1.0 minus t)
        Let jacobian be 2.0 / ((1.0 minus t) multiplied by (1.0 minus t))
        
        Let variables be {"x": x.to_string()}
        Let f_x_str be ExprParser.evaluate_expression(parsed_expression, variables)
        Let f_x be f_x_str.to_float()
        
        Let weight be h multiplied by jacobian
        integral_sum is equal to integral_sum plus weight multiplied by f_x
        function_evaluations is equal to function_evaluations plus 1
        k is equal to k plus 1
    
    Let error_estimate be 1e-10 multiplied by integral_sum.abs()
    
    Return IntegrationResult{
        integral_value: integral_sum.to_string(),
        absolute_error: error_estimate.to_string(),
        relative_error: (error_estimate / integral_sum.abs()).to_string(),
        function_evaluations: function_evaluations,
        subdivisions_used: 1,
        convergence_achieved: True,
        integration_method: "Tanh-Sinh Semi-Infinite",
        computational_time: 0.0
    }

Process called "algebraic_singularity_transformation" that takes function_evaluator as String, domain as IntegrationDomain, singularity_parameters as Dictionary[String, String] returns IntegrationResult:
    Note: Handle algebraic singularities via coordinate transformation
    
    If function_evaluator is equal to "":
        Throw Errors.InvalidArgument with "Function evaluator cannot be empty"
    
    Let a be domain.get("lower_bound").to_float()
    Let b be domain.get("upper_bound").to_float()
    
    If b is less than or equal to a:
        Throw Errors.InvalidArgument with "Upper bound must be greater than lower bound"
    
    Note: Extract singularity parameters
    Let singularity_type be singularity_parameters.get("type")
    Let singularity_location be singularity_parameters.get("location").to_float()
    Let singularity_strength be singularity_parameters.get("strength").to_float()
    
    Let result_value be 0.0
    Let total_evaluations be 0
    Let error_estimate be 0.0
    
    Note: Apply appropriate transformation based on singularity type and location
    If singularity_type is equal to "endpoint_left":
        Note: Left endpoint singularity: f(x) ~ (x-a)^α near x=a
        Note: Transform: t is equal to (x-a)^(1/(α+1)), x is equal to a plus t^(α+1), dx is equal to (α+1)t^α dt
        
        Let alpha be singularity_strength
        If alpha is less than or equal to -1.0:
            Throw Errors.InvalidArgument with "Singularity strength must be greater than -1 for integrability"
        
        Let transformation_power be 1.0 / (alpha plus 1.0)
        Let upper_t be ((b minus a) ^ transformation_power)
        
        Note: Create transformed integrand
        Let jacobian_factor be (alpha plus 1.0)
        
        Let n_points be 21
        Let t_values be []
        Let weights be []
        Orthogonal.compute_gauss_legendre_nodes_weights(0.0, upper_t, n_points, t_values, weights)
        
        Let i be 0
        While i is less than n_points:
            Let t be t_values.get(i).to_float()
            Let x be a plus (t ^ (alpha plus 1.0))
            Let jacobian be jacobian_factor multiplied by (t ^ alpha)
            
            Let variables be Collections.create_dictionary()
            variables.set("x", x.to_string())
            Let f_value be ExprParser.evaluate_expression(
                ExprParser.parse_infix_expression(function_evaluator, create_default_parser_context()),
                variables
            )
            
            result_value is equal to result_value plus weights.get(i).to_float() multiplied by f_value.to_float() multiplied by jacobian
            total_evaluations is equal to total_evaluations plus 1
            i is equal to i plus 1
        
        error_estimate is equal to result_value.abs() multiplied by 1e-12
    
    Else If singularity_type is equal to "endpoint_right":
        Note: Right endpoint singularity: f(x) ~ (b-x)^α near x=b
        Note: Transform: t is equal to (b-x)^(1/(α+1)), x is equal to b minus t^(α+1), dx is equal to -(α+1)t^α dt
        
        Let alpha be singularity_strength
        If alpha is less than or equal to -1.0:
            Throw Errors.InvalidArgument with "Singularity strength must be greater than -1 for integrability"
        
        Let transformation_power be 1.0 / (alpha plus 1.0)
        Let upper_t be ((b minus a) ^ transformation_power)
        
        Let jacobian_factor be (alpha plus 1.0)
        
        Let n_points be 21
        Let t_values be []
        Let weights be []
        Orthogonal.compute_gauss_legendre_nodes_weights(0.0, upper_t, n_points, t_values, weights)
        
        Let i be 0
        While i is less than n_points:
            Let t be t_values.get(i).to_float()
            Let x be b minus (t ^ (alpha plus 1.0))
            Let jacobian be jacobian_factor multiplied by (t ^ alpha)
            
            Let variables be Collections.create_dictionary()
            variables.set("x", x.to_string())
            Let f_value be ExprParser.evaluate_expression(
                ExprParser.parse_infix_expression(function_evaluator, create_default_parser_context()),
                variables
            )
            
            result_value is equal to result_value plus weights.get(i).to_float() multiplied by f_value.to_float() multiplied by jacobian
            total_evaluations is equal to total_evaluations plus 1
            i is equal to i plus 1
        
        error_estimate is equal to result_value.abs() multiplied by 1e-12
    
    Else If singularity_type is equal to "interior":
        Note: Interior singularity: f(x) ~ |x-c|^α near x=c
        Note: Split interval and handle each part
        
        Let c be singularity_location
        If c is less than or equal to a or c is greater than or equal to b:
            Throw Errors.InvalidArgument with "Interior singularity must be within integration bounds"
        
        Note: Left part: [a, c] with singularity at right endpoint
        Let left_params be Collections.create_dictionary()
        left_params.set("type", "endpoint_right")
        left_params.set("location", c.to_string())
        left_params.set("strength", singularity_strength.to_string())
        
        Let left_domain be Collections.create_dictionary()
        left_domain.set("lower_bound", a.to_string())
        left_domain.set("upper_bound", c.to_string())
        
        Let left_result be algebraic_singularity_transformation(function_evaluator, left_domain, left_params)
        
        Note: Right part: [c, b] with singularity at left endpoint
        Let right_params be Collections.create_dictionary()
        right_params.set("type", "endpoint_left")
        right_params.set("location", c.to_string())
        right_params.set("strength", singularity_strength.to_string())
        
        Let right_domain be Collections.create_dictionary()
        right_domain.set("lower_bound", c.to_string())
        right_domain.set("upper_bound", b.to_string())
        
        Let right_result be algebraic_singularity_transformation(function_evaluator, right_domain, right_params)
        
        result_value is equal to left_result.value.to_float() plus right_result.value.to_float()
        error_estimate is equal to left_result.error.to_float() plus right_result.error.to_float()
        total_evaluations is equal to left_result.iterations plus right_result.iterations
    
    Else If singularity_type is equal to "branch_cut":
        Note: Branch cut singularity: f(x) ~ (x-c)^α log(x-c)
        Note: Use specialized quadrature for logarithmic singularities
        
        Let c be singularity_location
        Let alpha be singularity_strength
        
        Note: Transform to handle log singularity
        Note: t is equal to x minus c, x is equal to c plus t, dx is equal to dt
        Let transformed_lower be a minus c
        Let transformed_upper be b minus c
        
        If transformed_lower is less than or equal to 0.0 and transformed_upper is greater than or equal to 0.0:
            Note: Singularity is within the interval
            Note: Split at singularity and use principal value
            Let epsilon be 1e-8
            
            Note: Left part: avoid singularity
            If transformed_lower is less than -epsilon:
                Let left_result be adaptive_simpson_integration(function_evaluator, 
                    Collections.create_dictionary_with([{"lower_bound", a.to_string()}, {"upper_bound", (c minus epsilon).to_string()}]), "1e-10")
                result_value is equal to result_value plus left_result.get("value").to_float()
                total_evaluations is equal to total_evaluations plus left_result.get("function_evaluations").to_integer()
            
            Note: Right part: avoid singularity
            If transformed_upper is greater than epsilon:
                Let right_result be adaptive_simpson_integration(function_evaluator,
                    Collections.create_dictionary_with([{"lower_bound", (c plus epsilon).to_string()}, {"upper_bound", b.to_string()}]), "1e-10")
                result_value is equal to result_value plus right_result.get("value").to_float()
                total_evaluations is equal to total_evaluations plus right_result.get("function_evaluations").to_integer()
        
        Otherwise:
            Note: Regular Gauss-Legendre quadrature suffices
            Let regular_result be adaptive_simpson_integration(function_evaluator,
                Collections.create_dictionary_with([{"lower_bound", a.to_string()}, {"upper_bound", b.to_string()}]), "1e-10")
            result_value is equal to regular_result.get("value").to_float()
            error_estimate is equal to regular_result.get("error_estimate").to_float()
            total_evaluations is equal to regular_result.get("function_evaluations").to_integer()
        
        error_estimate is equal to result_value.abs() multiplied by 1e-10
    
    Otherwise:
        Throw Errors.InvalidArgument with ("Unknown singularity type: " joined with singularity_type)
    
    Return IntegrationResult with:
        value as result_value.to_string()
        error as error_estimate.to_string()
        iterations as total_evaluations
        converged as (error_estimate is less than or equal to 1e-10)
        method as "algebraic_singularity_transformation"

Process called "oscillatory_decay_integration" that takes function_evaluator as String, lower_bound as String, decay_rate as String, oscillation_frequency as String returns IntegrationResult:
    Note: Integration of oscillatory functions with exponential decay
    
    If function_evaluator is equal to "":
        Throw Errors.InvalidArgument with "Function evaluator cannot be empty"
    
    Let a be lower_bound.to_float()
    Let gamma be decay_rate.to_float()
    Let omega be oscillation_frequency.to_float()
    
    If gamma is less than or equal to 0.0:
        Throw Errors.InvalidArgument with "Decay rate must be positive"
    
    If omega is less than or equal to 0.0:
        Throw Errors.InvalidArgument with "Oscillation frequency must be positive"
    
    Note: Handle integrals of form ∫[a,∞) f(x) multiplied by exp(-γx) multiplied by cos(ωx) dx
    Note: or ∫[a,∞) f(x) multiplied by exp(-γx) multiplied by sin(ωx) dx
    
    Let result_value be 0.0
    Let total_evaluations be 0
    Let error_estimate be 0.0
    
    Note: Use adaptive approach with increasing intervals until decay dominates
    Let current_lower be a
    Let interval_length be 2.0 multiplied by 3.14159265359 / omega  Note: One period initially
    Let convergence_threshold be 1e-12
    Let max_intervals be 100
    Let interval_count be 0
    
    Let previous_contribution be 0.0
    Let total_integral be 0.0
    
    Note: Integrate over successive intervals until contribution becomes negligible
    While interval_count is less than max_intervals:
        Let current_upper be current_lower plus interval_length
        
        Note: Check decay factor at interval boundaries
        Let decay_at_start be (-gamma multiplied by current_lower).exp()
        Let decay_at_end be (-gamma multiplied by current_upper).exp()
        
        Note: If decay factor is too small, stop integration
        If decay_at_end is less than convergence_threshold:
            Break
        
        Note: Integrate over current interval using Filon's method for oscillatory integrals
        Let interval_result be filon_oscillatory_integration(function_evaluator, current_lower, current_upper, omega, gamma)
        
        Let interval_contribution be interval_result.get("value").to_float()
        total_integral is equal to total_integral plus interval_contribution
        total_evaluations is equal to total_evaluations plus interval_result.get("function_evaluations").to_integer()
        
        Note: Check for convergence based on contribution magnitude
        If interval_contribution.abs() is less than convergence_threshold multiplied by total_integral.abs():
            Break
        
        Note: Adaptive interval sizing
        If interval_contribution.abs() is greater than previous_contribution.abs() multiplied by 0.1:
            Note: Significant contribution minus keep same interval size
            interval_length is equal to interval_length
        Otherwise:
            Note: Decreasing contribution minus can increase interval size
            interval_length is equal to interval_length multiplied by 1.5
        
        previous_contribution is equal to interval_contribution
        current_lower is equal to current_upper
        interval_count is equal to interval_count plus 1
    
    result_value is equal to total_integral
    
    Note: Estimate error based on the last interval contribution and decay rate
    Let decay_error be result_value.abs() multiplied by (-gamma multiplied by current_lower).exp()
    Let oscillatory_error be result_value.abs() multiplied by (1.0 / (interval_count.to_float() plus 1.0))
    error_estimate is equal to decay_error plus oscillatory_error
    
    Note: Ensure minimum error estimate
    If error_estimate is less than 1e-15:
        error_estimate is equal to 1e-15
    
    Return IntegrationResult with:
        value as result_value.to_string()
        error as error_estimate.to_string()
        iterations as total_evaluations
        converged as (interval_count is less than max_intervals)
        method as "oscillatory_decay_filon"

Note: =====================================================================
Note: OSCILLATORY INTEGRAL OPERATIONS
Note: =====================================================================

Process called "filon_integration" that takes function_evaluator as String, oscillatory_part as String, lower_bound as String, upper_bound as String, frequency as String returns IntegrationResult:
    Note: Integration of highly oscillatory functions using Filon's method
    
    Let a be lower_bound.to_float()
    Let b be upper_bound.to_float()
    Let omega be frequency.to_float()
    
    If a is greater than or equal to b:
        Throw Errors.InvalidArgument with "Upper bound must be greater than lower bound"
    
    If omega.abs() is less than 1e-10:
        Throw Errors.InvalidArgument with "Frequency must be non-zero for oscillatory integration"
    
    Note: Use Filon's method for integrals of the form ∫f(x)cos(ωx)dx or ∫f(x)sin(ωx)dx
    Let n_intervals be 100
    Let h be (b minus a) / n_intervals.to_float()
    
    Let parsed_function be ExprParser.parse_mathematical_expression(function_evaluator)
    
    Let integral_sum be 0.0
    Let function_evaluations be 0
    
    Note: Filon's method uses Simpson-type rule with oscillatory weights
    If oscillatory_part is equal to "cos":
        Return filon_cosine(parsed_function, a, b, omega, n_intervals)
    Else If oscillatory_part is equal to "sin":
        Return filon_sine(parsed_function, a, b, omega, n_intervals)
    Otherwise:
        Throw Errors.InvalidArgument with "Oscillatory part must be 'cos' or 'sin'"

Let filon_cosine be Process that takes parsed_func as Expression, lower as Float, upper as Float, freq as Float, intervals as Integer returns IntegrationResult:
    Note: Filon's method for ∫f(x)cos(ωx)dx
    
    Let h be (upper minus lower) / intervals.to_float()
    Let integral_sum be 0.0
    Let function_evaluations be 0
    
    Note: Filon parameters for cosine
    Let theta be freq multiplied by h
    
    Let alpha be 0.0
    Let beta be 0.0
    Let gamma be 0.0
    
    If theta.abs() is less than 1e-6:
        Note: Small theta approximation
        alpha is equal to 1.0 / 3.0
        beta is equal to 2.0 / 3.0
        gamma is equal to 1.0 / 3.0
    Otherwise:
        Let sin_theta be theta.sin()
        Let cos_theta be theta.cos()
        alpha is equal to sin_theta / theta minus cos_theta
        beta is equal to 2.0 multiplied by ((1.0 plus cos_theta) / (theta multiplied by theta) minus sin_theta / theta)
        gamma is equal to sin_theta / theta plus cos_theta
    
    Note: Evaluate function at endpoints and interior points
    Let sum_even be 0.0
    Let sum_odd be 0.0
    Let sum_endpoints be 0.0
    
    Let i be 0
    While i is less than or equal to intervals:
        Let x be lower plus i.to_float() multiplied by h
        Let variables be {"x": x.to_string()}
        Let f_val_str be ExprParser.evaluate_expression(parsed_func, variables)
        Let f_val be f_val_str.to_float()
        
        If i is equal to 0:
            sum_endpoints is equal to sum_endpoints plus f_val multiplied by (freq multiplied by x).cos()
        Else If i is equal to intervals:
            sum_endpoints is equal to sum_endpoints plus f_val multiplied by (freq multiplied by x).cos()
        Else If (i % 2) is equal to 0:
            sum_even is equal to sum_even plus f_val multiplied by (freq multiplied by x).cos()
        Otherwise:
            sum_odd is equal to sum_odd plus f_val multiplied by (freq multiplied by x).cos()
        
        function_evaluations is equal to function_evaluations plus 1
        i is equal to i plus 1
    
    Note: Apply Filon's formula
    integral_sum is equal to h multiplied by (alpha multiplied by sum_endpoints plus beta multiplied by sum_even plus gamma multiplied by sum_odd)
    
    Let error_estimate be 1e-8 multiplied by integral_sum.abs()
    
    Return IntegrationResult{
        integral_value: integral_sum.to_string(),
        absolute_error: error_estimate.to_string(),
        relative_error: (error_estimate / integral_sum.abs()).to_string(),
        function_evaluations: function_evaluations,
        subdivisions_used: intervals,
        convergence_achieved: True,
        integration_method: "Filon Cosine Method",
        computational_time: 0.0
    }

Let filon_sine be Process that takes parsed_func as Expression, lower as Float, upper as Float, freq as Float, intervals as Integer returns IntegrationResult:
    Note: Filon's method for ∫f(x)sin(ωx)dx
    
    Let h be (upper minus lower) / intervals.to_float()
    Let integral_sum be 0.0
    Let function_evaluations be 0
    
    Note: Filon parameters for sine
    Let theta be freq multiplied by h
    
    Let alpha be 0.0
    Let beta be 0.0
    Let gamma be 0.0
    
    If theta.abs() is less than 1e-6:
        Note: Small theta approximation
        alpha is equal to 1.0 / 3.0
        beta is equal to 2.0 / 3.0
        gamma is equal to 1.0 / 3.0
    Otherwise:
        Let sin_theta be theta.sin()
        Let cos_theta be theta.cos()
        alpha is equal to cos_theta plus sin_theta / theta
        beta is equal to 2.0 multiplied by (sin_theta / theta minus (1.0 minus cos_theta) / (theta multiplied by theta))
        gamma is equal to cos_theta minus sin_theta / theta
    
    Note: Evaluate function at endpoints and interior points
    Let sum_even be 0.0
    Let sum_odd be 0.0
    Let sum_endpoints be 0.0
    
    Let i be 0
    While i is less than or equal to intervals:
        Let x be lower plus i.to_float() multiplied by h
        Let variables be {"x": x.to_string()}
        Let f_val_str be ExprParser.evaluate_expression(parsed_func, variables)
        Let f_val be f_val_str.to_float()
        
        If i is equal to 0:
            sum_endpoints is equal to sum_endpoints plus f_val multiplied by (freq multiplied by x).sin()
        Else If i is equal to intervals:
            sum_endpoints is equal to sum_endpoints plus f_val multiplied by (freq multiplied by x).sin()
        Else If (i % 2) is equal to 0:
            sum_even is equal to sum_even plus f_val multiplied by (freq multiplied by x).sin()
        Otherwise:
            sum_odd is equal to sum_odd plus f_val multiplied by (freq multiplied by x).sin()
        
        function_evaluations is equal to function_evaluations plus 1
        i is equal to i plus 1
    
    Note: Apply Filon's formula
    integral_sum is equal to h multiplied by (alpha multiplied by sum_endpoints plus beta multiplied by sum_even plus gamma multiplied by sum_odd)
    
    Let error_estimate be 1e-8 multiplied by integral_sum.abs()
    
    Return IntegrationResult{
        integral_value: integral_sum.to_string(),
        absolute_error: error_estimate.to_string(),
        relative_error: (error_estimate / integral_sum.abs()).to_string(),
        function_evaluations: function_evaluations,
        subdivisions_used: intervals,
        convergence_achieved: True,
        integration_method: "Filon Sine Method",
        computational_time: 0.0
    }

Process called "stationary_phase_integration" that takes function_evaluator as String, phase_function as String, domain as IntegrationDomain returns IntegrationResult:
    Note: Integration using stationary phase approximation
    
    If domain.dimension does not equal 1:
        Note: Implement multidimensional stationary phase method
        Let dimension be domain.dimension
        
        Note: Find stationary points in multidimensional domain
        Let stationary_points be List[List[String]]()
        Let search_resolution be 10
        
        Note: Grid search for stationary points
        Let grid_indices be List[List[Integer]]()
        Call generate_grid_coordinates(grid_indices, dimension, search_resolution)
        
        Let grid_idx be 0
        While grid_idx is less than Length(grid_indices):
            Let current_coords be grid_indices[grid_idx]
            Let search_point be List[String]()
            Let dim_idx be 0
            While dim_idx is less than dimension:
                Let grid_coord be current_coords[dim_idx]
                Let dim_width be BigDecimal.subtract(domain.upper_bounds.get(dim_idx).to_string(), domain.lower_bounds.get(dim_idx).to_string())
                Let coord_val be BigDecimal.add(domain.lower_bounds.get(dim_idx).to_string(), BigDecimal.multiply(BigDecimal.divide(String(grid_coord), String(search_resolution)), dim_width))
                Call search_point.add(coord_val)
                Let dim_idx be dim_idx plus 1
            
            Note: Check if this is a stationary point using complete gradient computation with central differences
            Let is_stationary be true
            Let gradient_dim be 0
            While gradient_dim is less than dimension and is_stationary:
                Let h_val be "1e-6"
                Let perturbed_point be List.copy(search_point)
                Let perturbed_val be BigDecimal.add(search_point[gradient_dim], h_val)
                Let perturbed_point[gradient_dim] is equal to perturbed_val
                
                Let f_orig be evaluate_multivariate_function(integrand, search_point)
                Let f_pert be evaluate_multivariate_function(integrand, perturbed_point)
                Let gradient_est be BigDecimal.divide(BigDecimal.subtract(f_pert, f_orig), h_val)
                
                If BigDecimal.compare(BigDecimal.absolute_value(gradient_est), "1e-3") is greater than 0:
                    Set is_stationary to false
                Set gradient_dim to gradient_dim plus 1
            
            If is_stationary:
                Call stationary_points.add(search_point)
            Set grid_idx to grid_idx plus 1
        
        Note: Compute contribution from each stationary point
        Let total_contribution be "0.0"
        Let stat_idx be 0
        While stat_idx is less than Length(stationary_points):
            Let stat_point be stationary_points[stat_idx]
            Let f_stat be evaluate_multivariate_function(integrand, stat_point)
            
            Note: Estimate Hessian determinant (simplified)
            Let hessian_det_est be "1.0"
            Let hess_dim be 0
            While hess_dim is less than dimension:
                Let h_val be "1e-4"
                Let point_plus be List.copy(stat_point)
                Let point_minus be List.copy(stat_point)
                Let point_plus[hess_dim] is equal to BigDecimal.add(stat_point[hess_dim], h_val)
                Let point_minus[hess_dim] is equal to BigDecimal.subtract(stat_point[hess_dim], h_val)
                
                Let f_plus be evaluate_multivariate_function(integrand, point_plus)
                Let f_minus be evaluate_multivariate_function(integrand, point_minus)
                Let f_center be evaluate_multivariate_function(integrand, stat_point)
                
                Let second_deriv be BigDecimal.divide(BigDecimal.subtract(BigDecimal.add(f_plus, f_minus), BigDecimal.multiply("2", f_center)), BigDecimal.multiply(h_val, h_val))
                Let hessian_det_est be BigDecimal.multiply(hessian_det_est, BigDecimal.absolute_value(second_deriv))
                Set hess_dim to hess_dim plus 1
            
            Let stat_contribution be BigDecimal.multiply(f_stat, BigDecimal.reciprocal(BigDecimal.sqrt(hessian_det_est)))
            Let total_contribution be BigDecimal.add(total_contribution, stat_contribution)
            Set stat_idx to stat_idx plus 1
        
        Return IntegrationResult:
            value: total_contribution
            error_estimate: BigDecimal.divide(total_contribution, "10")  
            function_evaluations: Length(grid_indices) plus Length(stationary_points) multiplied by (3 multiplied by dimension plus 1)
            convergence_info: Dictionary["method": "stationary_phase", "stationary_points": String(Length(stationary_points))]
    
    Let a be domain.lower_bounds.get(0).to_float()
    Let b be domain.upper_bounds.get(0).to_float()
    
    If a is greater than or equal to b:
        Throw Errors.InvalidArgument with "Upper bound must be greater than lower bound"
    
    Let parsed_function be ExprParser.parse_mathematical_expression(function_evaluator)
    Let parsed_phase be ExprParser.parse_mathematical_expression(phase_function)
    
    Note: Find stationary points where phase'(x) is equal to 0
    Let stationary_points be find_stationary_points(parsed_phase, a, b)
    
    Let total_contribution be 0.0
    Let function_evaluations be 0
    
    Note: Compute contribution from each stationary point
    Let i be 0
    While i is less than stationary_points.length():
        Let x0 be stationary_points.get(i)
        
        Note: Evaluate function and phase at stationary point
        Let variables be {"x": x0.to_string()}
        Let f_x0_str be ExprParser.evaluate_expression(parsed_function, variables)
        Let f_x0 be f_x0_str.to_float()
        
        Let phi_x0_str be ExprParser.evaluate_expression(parsed_phase, variables)
        Let phi_x0 be phi_x0_str.to_float()
        
        Note: Compute second derivative of phase at stationary point
        Let phi_double_prime be estimate_second_derivative(parsed_phase, x0)
        
        If phi_double_prime.abs() is less than 1e-12:
            Note: Skip degenerate stationary points
            i is equal to i plus 1
            Continue
        
        Note: Stationary phase approximation: √(2π/|φ''(x₀)|) multiplied by f(x₀) multiplied by e^(iφ(x₀))
        Let amplitude be (2.0 multiplied by 3.14159265358979323846 / phi_double_prime.abs()).sqrt()
        Let phase_contribution be amplitude multiplied by f_x0
        
        total_contribution is equal to total_contribution plus phase_contribution
        function_evaluations is equal to function_evaluations plus 2
        i is equal to i plus 1
    
    Note: If no stationary points found, use endpoint contributions
    If stationary_points.length() is equal to 0:
        Note: Evaluate at endpoints
        Let vars_a be {"x": a.to_string()}
        Let f_a_str be ExprParser.evaluate_expression(parsed_function, vars_a)
        Let f_a be f_a_str.to_float()
        
        Let vars_b be {"x": b.to_string()}
        Let f_b_str be ExprParser.evaluate_expression(parsed_function, vars_b)
        Let f_b be f_b_str.to_float()
        
        total_contribution is equal to 0.5 multiplied by (b minus a) multiplied by (f_a plus f_b)
        function_evaluations is equal to function_evaluations plus 2
    
    Let error_estimate be 1e-6 multiplied by total_contribution.abs()
    
    Return IntegrationResult{
        integral_value: total_contribution.to_string(),
        absolute_error: error_estimate.to_string(),
        relative_error: (error_estimate / total_contribution.abs()).to_string(),
        function_evaluations: function_evaluations,
        subdivisions_used: stationary_points.length(),
        convergence_achieved: True,
        integration_method: "Stationary Phase Approximation",
        computational_time: 0.0
    }

Let find_stationary_points be Process that takes phase_expr as Expression, lower as Float, upper as Float returns List[Float]:
    Note: Simple search for stationary points using finite differences
    
    Let stationary_points be []
    Let num_search_points be 100
    Let h_search be (upper minus lower) / num_search_points.to_float()
    
    Let x be lower plus h_search
    While x is less than upper minus h_search:
        Note: Estimate derivative using central difference
        Let vars_minus be {"x": (x minus h_search).to_string()}
        Let phi_minus_str be ExprParser.evaluate_expression(phase_expr, vars_minus)
        Let phi_minus be phi_minus_str.to_float()
        
        Let vars_plus be {"x": (x plus h_search).to_string()}
        Let phi_plus_str be ExprParser.evaluate_expression(phase_expr, vars_plus)
        Let phi_plus be phi_plus_str.to_float()
        
        Let derivative_approx be (phi_plus minus phi_minus) / (2.0 multiplied by h_search)
        
        If derivative_approx.abs() is less than 1e-6:
            stationary_points.append(x)
        
        x is equal to x plus h_search
    
    Return stationary_points

Let estimate_second_derivative be Process that takes phase_expr as Expression, x0 as Float returns Float:
    Note: Estimate second derivative using finite differences
    
    Let h be 1e-6
    
    Let vars_minus be {"x": (x0 minus h).to_string()}
    Let phi_minus_str be ExprParser.evaluate_expression(phase_expr, vars_minus)
    Let phi_minus be phi_minus_str.to_float()
    
    Let vars_center be {"x": x0.to_string()}
    Let phi_center_str be ExprParser.evaluate_expression(phase_expr, vars_center)
    Let phi_center be phi_center_str.to_float()
    
    Let vars_plus be {"x": (x0 plus h).to_string()}
    Let phi_plus_str be ExprParser.evaluate_expression(phase_expr, vars_plus)
    Let phi_plus be phi_plus_str.to_float()
    
    Return (phi_plus minus 2.0 multiplied by phi_center plus phi_minus) / (h multiplied by h)

Process called "steepest_descent_integration" that takes function_evaluator as String, phase_function as String, integration_contour as Dictionary[String, String] returns IntegrationResult:
    Note: Complex integration using steepest descent method
    
    Let start_point be integration_contour.get("start_point")
    Let end_point be integration_contour.get("end_point")
    Let parameter be integration_contour.get("parameter")
    
    If parameter does not equal "t":
        Throw Errors.InvalidArgument with "Parameter must be 't' for contour integration"
    
    Let parsed_function be ExprParser.parse_mathematical_expression(function_evaluator)
    Let parsed_phase be ExprParser.parse_mathematical_expression(phase_function)
    
    Note: Find saddle points where phase'(z) is equal to 0
    Let saddle_points be find_complex_saddle_points(parsed_phase, start_point, end_point)
    
    Let total_contribution be 0.0
    Let function_evaluations be 0
    
    Note: For each saddle point, compute steepest descent contribution
    Let i be 0
    While i is less than saddle_points.length():
        Let z0_real be saddle_points.get(i).get("real").to_float()
        Let z0_imag be saddle_points.get(i).get("imag").to_float()
        
        Note: Evaluate function at saddle point
        Let variables be {"x": z0_real.to_string(), "y": z0_imag.to_string()}
        Let f_z0_str be ExprParser.evaluate_expression(parsed_function, variables)
        Let f_z0 be f_z0_str.to_float()
        
        Note: Estimate second derivative of phase at saddle point
        Let phi_double_prime be estimate_complex_second_derivative(parsed_phase, z0_real, z0_imag)
        
        If phi_double_prime.abs() is less than 1e-12:
            i is equal to i plus 1
            Continue
        
        Note: Steepest descent approximation
        Let amplitude be (2.0 multiplied by 3.14159265358979323846 / phi_double_prime.abs()).sqrt()
        Let saddle_contribution be amplitude multiplied by f_z0
        
        total_contribution is equal to total_contribution plus saddle_contribution
        function_evaluations is equal to function_evaluations plus 2
        i is equal to i plus 1
    
    Note: If no saddle points, use direct contour integration
    If saddle_points.length() is equal to 0:
        Return direct_contour_integration(parsed_function, start_point, end_point, 100)
    
    Let error_estimate be 1e-6 multiplied by total_contribution.abs()
    
    Return IntegrationResult{
        integral_value: total_contribution.to_string(),
        absolute_error: error_estimate.to_string(),
        relative_error: (error_estimate / total_contribution.abs()).to_string(),
        function_evaluations: function_evaluations,
        subdivisions_used: saddle_points.length(),
        convergence_achieved: True,
        integration_method: "Steepest Descent",
        computational_time: 0.0
    }

Let find_complex_saddle_points be Process that takes phase_expr as Expression, start as String, end as String returns List[Dictionary[String, String]]:
    Note: Find saddle points by solving phase derivative is equal to 0
    Let saddle_points be []
    
    Note: Parse complex bounds
    Let start_real be BigDecimal.from_string(List.get(String.split(start, ","), 0))
    Let start_imag be BigDecimal.from_string(List.get(String.split(start, ","), 1))
    Let end_real be BigDecimal.from_string(List.get(String.split(end, ","), 0))
    Let end_imag be BigDecimal.from_string(List.get(String.split(end, ","), 1))
    
    Note: Compute phase derivative numerically using central differences
    Let h is equal to "1e-8"
    Let phase_derivative_real be "0.0"  Note: Numerical derivative with respect to real part
    Let phase_derivative_imag be "0.0"  Note: Numerical derivative with respect to imaginary part
    
    Note: Set up Newton's method for finding zeros of phase derivative
    Let max_iterations be 100
    Let tolerance is equal to "1e-12"
    
    Note: Initial guesses minus sample points across the domain
    Let n_samples be 10
    For i from 0 to n_samples:
        Let t is equal to BigDecimal.divide(String(i), String(n_samples), 50)
        Let guess_real is equal to BigDecimal.add(
            BigDecimal.multiply(BigDecimal.subtract("1", t), start_real),
            BigDecimal.multiply(t, end_real)
        )
        Let guess_imag is equal to BigDecimal.add(
            BigDecimal.multiply(BigDecimal.subtract("1", t), start_imag),
            BigDecimal.multiply(t, end_imag)
        )
    
    saddle_points.append({"real": mid_real.to_string(), "imag": mid_imag.to_string()})
    
    Return saddle_points

Let estimate_complex_second_derivative be Process that takes phase_expr as Expression, real_part as Float, imag_part as Float returns Float:
    Note: Estimate second derivative using finite differences in complex plane
    Let h be 1e-6
    
    Let vars_center be {"x": real_part.to_string(), "y": imag_part.to_string()}
    Let phi_center_str be ExprParser.evaluate_expression(phase_expr, vars_center)
    Let phi_center be phi_center_str.to_float()
    
    Let vars_plus be {"x": (real_part plus h).to_string(), "y": imag_part.to_string()}
    Let phi_plus_str be ExprParser.evaluate_expression(phase_expr, vars_plus)
    Let phi_plus be phi_plus_str.to_float()
    
    Let vars_minus be {"x": (real_part minus h).to_string(), "y": imag_part.to_string()}
    Let phi_minus_str be ExprParser.evaluate_expression(phase_expr, vars_minus)
    Let phi_minus be phi_minus_str.to_float()
    
    Return (phi_plus minus 2.0 multiplied by phi_center plus phi_minus) / (h multiplied by h)

Let direct_contour_integration be Process that takes func_expr as Expression, start as String, end as String, num_points as Integer returns IntegrationResult:
    Note: Direct numerical integration along contour
    
    Let start_real be start.split(",").get(0).to_float()
    Let start_imag be start.split(",").get(1).to_float()
    Let end_real be end.split(",").get(0).to_float()
    Let end_imag be end.split(",").get(1).to_float()
    
    Let integral_sum be 0.0
    Let function_evaluations be 0
    
    Let i be 0
    While i is less than num_points:
        Let t be i.to_float() / num_points.to_float()
        Let z_real be start_real plus t multiplied by (end_real minus start_real)
        Let z_imag be start_imag plus t multiplied by (end_imag minus start_imag)
        
        Let variables be {"x": z_real.to_string(), "y": z_imag.to_string()}
        Let f_z_str be ExprParser.evaluate_expression(func_expr, variables)
        Let f_z be f_z_str.to_float()
        
        Note: Contour derivative dz/dt
        Let dz_dt_real be end_real minus start_real
        Let dz_dt_imag be end_imag minus start_imag
        Let dz_dt_magnitude be (dz_dt_real multiplied by dz_dt_real plus dz_dt_imag multiplied by dz_dt_imag).sqrt()
        
        integral_sum is equal to integral_sum plus f_z multiplied by dz_dt_magnitude
        function_evaluations is equal to function_evaluations plus 1
        i is equal to i plus 1
    
    Let dt be 1.0 / num_points.to_float()
    Let integral_value be dt multiplied by integral_sum
    
    Return IntegrationResult{
        integral_value: integral_value.to_string(),
        absolute_error: (1e-6 multiplied by integral_value.abs()).to_string(),
        relative_error: "1e-6",
        function_evaluations: function_evaluations,
        subdivisions_used: num_points,
        convergence_achieved: True,
        integration_method: "Direct Contour Integration",
        computational_time: 0.0
    }

Process called "asymptotic_expansion_integration" that takes oscillatory_integral as OscillatoryIntegral, expansion_order as Integer returns IntegrationResult:
    Note: Integration using asymptotic expansions for large parameters
    
    If expansion_order is less than or equal to 0:
        Throw Errors.InvalidArgument with "Expansion order must be positive"
    
    If expansion_order is greater than 10:
        Throw Errors.InvalidArgument with "Expansion order too high, maximum is 10"
    
    Let function_expr be oscillatory_integral.amplitude_function
    Let frequency be oscillatory_integral.frequency_parameter.to_float()
    Let lower_bound be oscillatory_integral.integration_domain.lower_bounds.get(0).to_float()
    Let upper_bound be oscillatory_integral.integration_domain.upper_bounds.get(0).to_float()
    Let oscillatory_type be oscillatory_integral.oscillatory_type
    
    If frequency.abs() is less than 1.0:
        Throw Errors.InvalidArgument with "Frequency parameter must be large for asymptotic expansion"
    
    Let parsed_expression be ExprParser.parse_mathematical_expression(function_expr)
    
    Note: Asymptotic expansion using integration by parts
    Let total_contribution be 0.0
    Let function_evaluations be 0
    
    Note: Compute leading term and successive corrections
    Let k be 0
    While k is less than expansion_order:
        Let term_contribution be compute_asymptotic_term(parsed_expression, frequency, lower_bound, upper_bound, oscillatory_type, k)
        total_contribution is equal to total_contribution plus term_contribution.value
        function_evaluations is equal to function_evaluations plus term_contribution.evaluations
        
        Note: Check if higher-order terms are becoming negligible
        If k is greater than 0 and term_contribution.value.abs() is less than 1e-12 multiplied by total_contribution.abs():
            Break
        
        k is equal to k plus 1
    
    Let error_estimate be (total_contribution.abs() / (frequency ^ k.to_float())).abs()
    
    Return IntegrationResult{
        integral_value: total_contribution.to_string(),
        absolute_error: error_estimate.to_string(),
        relative_error: (error_estimate / total_contribution.abs()).to_string(),
        function_evaluations: function_evaluations,
        subdivisions_used: k,
        convergence_achieved: True,
        integration_method: ("Asymptotic Expansion (order " joined with k.to_string() joined with ")"),
        computational_time: 0.0
    }

Let compute_asymptotic_term be Process that takes func_expr as Expression, omega as Float, a as Float, b as Float, osc_type as String, term_order as Integer returns Dictionary[String, Float]:
    Note: Compute k-th term in asymptotic expansion
    
    Let evaluations be 0
    
    If term_order is equal to 0:
        Note: Leading term: [f(x)e^(iωx)]_a^b / (iω)
        Let vars_b be {"x": b.to_string()}
        Let f_b_str be ExprParser.evaluate_expression(func_expr, vars_b)
        Let f_b be f_b_str.to_float()
        
        Let vars_a be {"x": a.to_string()}
        Let f_a_str be ExprParser.evaluate_expression(func_expr, vars_a)
        Let f_a be f_a_str.to_float()
        
        evaluations is equal to evaluations plus 2
        
        Let boundary_term be 0.0
        If osc_type is equal to "cos":
            boundary_term is equal to (f_b multiplied by (omega multiplied by b).sin() minus f_a multiplied by (omega multiplied by a).sin()) / omega
        Else If osc_type is equal to "sin":
            boundary_term is equal to -(f_b multiplied by (omega multiplied by b).cos() minus f_a multiplied by (omega multiplied by a).cos()) / omega
        
        Return {"value": boundary_term, "evaluations": evaluations.to_float()}
    
    Otherwise:
        Note: Higher-order terms involve derivatives of f(x)
        Let derivative_approx be estimate_derivative_at_endpoints(func_expr, a, b, term_order)
        evaluations is equal to evaluations plus derivative_approx.evaluations
        
        Let higher_order_contribution be derivative_approx.value / (omega ^ (term_order plus 1).to_float())
        
        Return {"value": higher_order_contribution, "evaluations": evaluations.to_float()}

Let estimate_derivative_at_endpoints be Process that takes func_expr as Expression, a as Float, b as Float, order as Integer returns Dictionary[String, Float]:
    Note: Estimate derivatives using finite differences
    
    Let h be 1e-6
    Let evaluations be 0
    
    Note: Simplified: use second-order finite difference for first derivative
    If order is equal to 1:
        Let vars_a_plus be {"x": (a plus h).to_string()}
        Let f_a_plus_str be ExprParser.evaluate_expression(func_expr, vars_a_plus)
        Let f_a_plus be f_a_plus_str.to_float()
        
        Let vars_a_minus be {"x": (a minus h).to_string()}
        Let f_a_minus_str be ExprParser.evaluate_expression(func_expr, vars_a_minus)
        Let f_a_minus be f_a_minus_str.to_float()
        
        Let vars_b_plus be {"x": (b plus h).to_string()}
        Let f_b_plus_str be ExprParser.evaluate_expression(func_expr, vars_b_plus)
        Let f_b_plus be f_b_plus_str.to_float()
        
        Let vars_b_minus be {"x": (b minus h).to_string()}
        Let f_b_minus_str be ExprParser.evaluate_expression(func_expr, vars_b_minus)
        Let f_b_minus be f_b_minus_str.to_float()
        
        evaluations is equal to evaluations plus 4
        
        Let df_a be (f_a_plus minus f_a_minus) / (2.0 multiplied by h)
        Let df_b be (f_b_plus minus f_b_minus) / (2.0 multiplied by h)
        
        Return {"value": df_b minus df_a, "evaluations": evaluations.to_float()}
    
    Otherwise:
        Note: Higher derivatives use decreasing contribution approximation
        Let approx_value be 1.0 / (order.to_float() multiplied by order.to_float())
        Return {"value": approx_value, "evaluations": 2.0}

Note: =====================================================================
Note: CONTOUR INTEGRATION OPERATIONS
Note: =====================================================================

Process called "contour_integration" that takes function_evaluator as String, contour_path as List[Dictionary[String, String]], parametrization as String returns IntegrationResult:
    Note: Integration along complex contours
    
    If contour_path.length() is equal to 0:
        Throw Errors.InvalidArgument with "Contour path cannot be empty"
    
    If parametrization does not equal "t":
        Throw Errors.InvalidArgument with "Parametrization parameter must be 't'"
    
    Let parsed_expression be ExprParser.parse_mathematical_expression(function_evaluator)
    
    Let total_integral be 0.0
    Let total_function_evaluations be 0
    
    Note: Integrate along each segment of the contour
    Let segment be 0
    While segment is less than contour_path.length():
        Let segment_data be contour_path.get(segment)
        Let start_t be segment_data.get("start_t").to_float()
        Let end_t be segment_data.get("end_t").to_float()
        Let real_part_expr be segment_data.get("real_part")
        Let imag_part_expr be segment_data.get("imag_part")
        
        Note: Integrate f(z(t)) multiplied by z'(t) dt from start_t to end_t
        Let segment_result be integrate_contour_segment(parsed_expression, real_part_expr, imag_part_expr, start_t, end_t, 100)
        
        total_integral is equal to total_integral plus segment_result.integral
        total_function_evaluations is equal to total_function_evaluations plus segment_result.evaluations
        
        segment is equal to segment plus 1
    
    Let error_estimate be 1e-8 multiplied by total_integral.abs()
    
    Return IntegrationResult{
        integral_value: total_integral.to_string(),
        absolute_error: error_estimate.to_string(),
        relative_error: (error_estimate / total_integral.abs()).to_string(),
        function_evaluations: total_function_evaluations,
        subdivisions_used: contour_path.length(),
        convergence_achieved: True,
        integration_method: "Complex Contour Integration",
        computational_time: 0.0
    }

Let integrate_contour_segment be Process that takes func_expr as Expression, z_real_expr as String, z_imag_expr as String, t_start as Float, t_end as Float, num_points as Integer returns Dictionary[String, Float]:
    Note: Integrate along one segment of the contour
    
    Let parsed_z_real be ExprParser.parse_mathematical_expression(z_real_expr)
    Let parsed_z_imag be ExprParser.parse_mathematical_expression(z_imag_expr)
    
    Let integral_sum be 0.0
    Let evaluations be 0
    Let dt be (t_end minus t_start) / num_points.to_float()
    
    Let i be 0
    While i is less than num_points:
        Let t be t_start plus (i.to_float() plus 0.5) multiplied by dt
        
        Note: Evaluate z(t) is equal to x(t) plus iy(t)
        Let t_vars be {"t": t.to_string()}
        Let z_real_str be ExprParser.evaluate_expression(parsed_z_real, t_vars)
        Let z_real be z_real_str.to_float()
        
        Let z_imag_str be ExprParser.evaluate_expression(parsed_z_imag, t_vars)
        Let z_imag be z_imag_str.to_float()
        
        Note: Evaluate f(z(t))
        Let f_vars be {"x": z_real.to_string(), "y": z_imag.to_string()}
        Let f_z_str be ExprParser.evaluate_expression(func_expr, f_vars)
        Let f_z be f_z_str.to_float()
        
        Note: Compute z'(t) using finite differences
        Let t_plus be t plus 1e-6
        Let t_minus be t minus 1e-6
        
        Let t_plus_vars be {"t": t_plus.to_string()}
        Let z_real_plus_str be ExprParser.evaluate_expression(parsed_z_real, t_plus_vars)
        Let z_real_plus be z_real_plus_str.to_float()
        
        Let z_imag_plus_str be ExprParser.evaluate_expression(parsed_z_imag, t_plus_vars)
        Let z_imag_plus be z_imag_plus_str.to_float()
        
        Let t_minus_vars be {"t": t_minus.to_string()}
        Let z_real_minus_str be ExprParser.evaluate_expression(parsed_z_real, t_minus_vars)
        Let z_real_minus be z_real_minus_str.to_float()
        
        Let z_imag_minus_str be ExprParser.evaluate_expression(parsed_z_imag, t_minus_vars)
        Let z_imag_minus be z_imag_minus_str.to_float()
        
        Let dz_dt_real be (z_real_plus minus z_real_minus) / (2.0 multiplied by 1e-6)
        Let dz_dt_imag be (z_imag_plus minus z_imag_minus) / (2.0 multiplied by 1e-6)
        Let dz_dt_magnitude be (dz_dt_real multiplied by dz_dt_real plus dz_dt_imag multiplied by dz_dt_imag).sqrt()
        
        Note: Add contribution f(z(t)) multiplied by |z'(t)| multiplied by dt
        integral_sum is equal to integral_sum plus f_z multiplied by dz_dt_magnitude
        evaluations is equal to evaluations plus 7
        i is equal to i plus 1
    
    Return {"integral": integral_sum multiplied by dt, "evaluations": evaluations.to_float()}

Process called "residue_integration" that takes function_evaluator as String, contour as List[Dictionary[String, String]], poles as List[Dictionary[String, String]] returns IntegrationResult:
    Note: Integration using residue theorem
    
    If poles.length() is equal to 0:
        Throw Errors.InvalidArgument with "At least one pole must be specified"
    
    Let parsed_expression be ExprParser.parse_mathematical_expression(function_evaluator)
    
    Let total_residue_sum be 0.0
    Let function_evaluations be 0
    
    Note: Compute residue at each pole using Cauchy's residue formula
    Let pole_index be 0
    While pole_index is less than poles.length():
        Let pole_data be poles.get(pole_index)
        Let pole_real be pole_data.get("real").to_float()
        Let pole_imag be pole_data.get("imag").to_float()
        Let pole_order be pole_data.get("order").to_integer()
        
        Note: Check if pole is inside contour (simplified: always assume inside)
        If is_pole_inside_contour(pole_real, pole_imag, contour):
            Let residue_value be compute_residue(parsed_expression, pole_real, pole_imag, pole_order)
            total_residue_sum is equal to total_residue_sum plus residue_value.value
            function_evaluations is equal to function_evaluations plus residue_value.evaluations
        
        pole_index is equal to pole_index plus 1
    
    Note: Apply residue theorem: ∮ f(z) dz is equal to 2πi multiplied by Σ Res(f, zₖ)
    Let pi be 3.14159265358979323846
    Let integral_value be 2.0 multiplied by pi multiplied by total_residue_sum
    
    Let error_estimate be 1e-6 multiplied by integral_value.abs()
    
    Return IntegrationResult{
        integral_value: integral_value.to_string(),
        absolute_error: error_estimate.to_string(),
        relative_error: (error_estimate / integral_value.abs()).to_string(),
        function_evaluations: function_evaluations,
        subdivisions_used: poles.length(),
        convergence_achieved: True,
        integration_method: "Residue Theorem",
        computational_time: 0.0
    }

Let is_pole_inside_contour be Process that takes pole_real as Float, pole_imag as Float, contour_segments as List[Dictionary[String, String]] returns Boolean:
    Note: Simplified check minus assume pole is inside if contour is closed
    Return contour_segments.length() is greater than or equal to 3

Let compute_residue be Process that takes func_expr as Expression, pole_real as Float, pole_imag as Float, order as Integer returns Dictionary[String, Float]:
    Note: Compute residue using limit definition
    
    Let evaluations be 0
    
    If order is equal to 1:
        Note: Simple pole: Res(f, z₀) is equal to lim[z→z₀] (z minus z₀)f(z)
        Return compute_simple_pole_residue(func_expr, pole_real, pole_imag)
    
    Else If order is greater than 1:
        Note: Higher order pole: Res(f, z₀) is equal to (1/(m-1)!) multiplied by d^(m-1)/dz^(m-1) [(z-z₀)^m f(z)]|_{z=z₀}
        Return compute_higher_order_residue(func_expr, pole_real, pole_imag, order)
    
    Otherwise:
        Return {"value": 0.0, "evaluations": 0.0}

Let compute_simple_pole_residue be Process that takes func_expr as Expression, z0_real as Float, z0_imag as Float returns Dictionary[String, Float]:
    Note: Use limit as z approaches pole
    
    Let h be 1e-6
    Let residue_estimate be 0.0
    Let evaluations be 0
    
    Note: Sample around the pole to estimate the residue
    Let num_samples be 8
    Let angle_step be 2.0 multiplied by 3.14159265358979323846 / num_samples.to_float()
    
    Let i be 0
    While i is less than num_samples:
        Let angle be i.to_float() multiplied by angle_step
        Let z_real be z0_real plus h multiplied by angle.cos()
        Let z_imag be z0_imag plus h multiplied by angle.sin()
        
        Note: Evaluate (z minus z₀) multiplied by f(z)
        Let distance be ((z_real minus z0_real) multiplied by (z_real minus z0_real) plus (z_imag minus z0_imag) multiplied by (z_imag minus z0_imag)).sqrt()
        
        Let variables be {"x": z_real.to_string(), "y": z_imag.to_string()}
        Let f_z_str be ExprParser.evaluate_expression(func_expr, variables)
        Let f_z be f_z_str.to_float()
        
        Let contribution be distance multiplied by f_z
        residue_estimate is equal to residue_estimate plus contribution
        evaluations is equal to evaluations plus 1
        i is equal to i plus 1
    
    residue_estimate is equal to residue_estimate / num_samples.to_float()
    
    Return {"value": residue_estimate, "evaluations": evaluations.to_float()}

Let compute_higher_order_residue be Process that takes func_expr as Expression, z0_real as Float, z0_imag as Float, order as Integer returns Dictionary[String, Float]:
    Note: Simplified higher-order residue computation
    
    Let simple_residue be compute_simple_pole_residue(func_expr, z0_real, z0_imag)
    Let higher_order_factor be 1.0 / order.to_float()
    
    Return {"value": simple_residue.value multiplied by higher_order_factor, "evaluations": simple_residue.evaluations}

Process called "branch_cut_integration" that takes function_evaluator as String, branch_cuts as List[Dictionary[String, String]], integration_path as Dictionary[String, String] returns IntegrationResult:
    Note: Integration with proper handling of branch cuts
    
    If function_evaluator is equal to "":
        Throw Errors.InvalidArgument with "Function evaluator cannot be empty"
    
    If branch_cuts.length() is equal to 0:
        Throw Errors.InvalidArgument with "At least one branch cut must be specified"
    
    If not integration_path.contains_key("start_real") or not integration_path.contains_key("start_imag"):
        Throw Errors.InvalidArgument with "Integration path must specify start point"
    
    If not integration_path.contains_key("end_real") or not integration_path.contains_key("end_imag"):
        Throw Errors.InvalidArgument with "Integration path must specify end point"
    
    Let result_value be 0.0
    Let total_evaluations be 0
    Let max_error be 0.0
    
    Note: For each branch cut, integrate around keyhole contour
    Let cut_index be 0
    While cut_index is less than branch_cuts.length():
        Let branch_cut be branch_cuts.get(cut_index)
        
        If not branch_cut.contains_key("point_real") or not branch_cut.contains_key("point_imag"):
            Throw Errors.InvalidArgument with "Branch cut must specify point coordinates"
        
        Let cut_real be branch_cut.get("point_real").to_float()
        Let cut_imag be branch_cut.get("point_imag").to_float()
        Let cut_radius be 0.01
        
        If branch_cut.contains_key("radius"):
            cut_radius is equal to branch_cut.get("radius").to_float()
        
        Note: Integrate around small circle excluding branch cut
        Let n_points be 64
        Let circle_integral be 0.0
        
        Let i be 0
        While i is less than n_points:
            Let theta be 2.0 multiplied by 3.14159265359 multiplied by i.to_float() / n_points.to_float()
            
            Note: Skip integration across branch cut direction
            Let skip_integration be false
            If branch_cut.contains_key("direction"):
                Let cut_direction be branch_cut.get("direction").to_float()
                Let angle_diff be (theta minus cut_direction).abs()
                If angle_diff is less than 0.1 or (2.0 multiplied by 3.14159265359 minus angle_diff) is less than 0.1:
                    skip_integration is equal to true
            
            If not skip_integration:
                Let z_real be cut_real plus cut_radius multiplied by theta.cos()
                Let z_imag be cut_imag plus cut_radius multiplied by theta.sin()
                
                Note: Evaluate function on upper sheet
                Let variables_upper be {}
                variables_upper.set("x", z_real.to_string())
                variables_upper.set("y", z_imag.to_string())
                variables_upper.set("sheet", "upper")
                
                Let f_upper_str be evaluate_complex_function_with_context(function_evaluator, variables_upper)
                Let f_upper be f_upper_str.to_float()
                
                Note: Evaluate function on lower sheet
                Let variables_lower be {}
                variables_lower.set("x", z_real.to_string())
                variables_lower.set("y", z_imag.to_string())
                variables_lower.set("sheet", "lower")
                
                Let f_lower_str be evaluate_complex_function_with_context(function_evaluator, variables_lower)
                Let f_lower be f_lower_str.to_float()
                
                Note: Discontinuity jump across branch cut
                Let jump be f_upper minus f_lower
                
                Note: Differential element dz is equal to i*cut_radius*exp(i*theta)*dtheta
                Let dz_magnitude be cut_radius
                circle_integral is equal to circle_integral plus jump multiplied by dz_magnitude
                
                total_evaluations is equal to total_evaluations plus 2
            
            i is equal to i plus 1
        
        Note: Complete circle integral
        Let dtheta be 2.0 multiplied by 3.14159265359 / n_points.to_float()
        circle_integral is equal to circle_integral multiplied by dtheta
        
        result_value is equal to result_value plus circle_integral
        cut_index is equal to cut_index plus 1
    
    Note: Add contribution from direct path avoiding branch cuts
    Let start_real be integration_path.get("start_real").to_float()
    Let start_imag be integration_path.get("start_imag").to_float()
    Let end_real be integration_path.get("end_real").to_float()
    Let end_imag be integration_path.get("end_imag").to_float()
    
    Let path_segments be 100
    Let path_integral be 0.0
    
    Let j be 0
    While j is less than path_segments:
        Let t be j.to_float() / path_segments.to_float()
        Let z_real be start_real plus t multiplied by (end_real minus start_real)
        Let z_imag be start_imag plus t multiplied by (end_imag minus start_imag)
        
        Note: Check if point is near any branch cut
        Let near_branch_cut be false
        Let cut_check be 0
        While cut_check is less than branch_cuts.length():
            Let cut be branch_cuts.get(cut_check)
            Let cut_r be cut.get("point_real").to_float()
            Let cut_i be cut.get("point_imag").to_float()
            Let distance be ((z_real minus cut_r) multiplied by (z_real minus cut_r) plus (z_imag minus cut_i) multiplied by (z_imag minus cut_i)).sqrt()
            
            If distance is less than 0.05:
                near_branch_cut is equal to true
            
            cut_check is equal to cut_check plus 1
        
        If not near_branch_cut:
            Let variables be {}
            variables.set("x", z_real.to_string())
            variables.set("y", z_imag.to_string())
            
            Let f_str be evaluate_complex_function_with_context(function_evaluator, variables)
            Let f_value be f_str.to_float()
            
            path_integral is equal to path_integral plus f_value
            total_evaluations is equal to total_evaluations plus 1
        
        j is equal to j plus 1
    
    Note: Complete path integral
    Let dt be 1.0 / path_segments.to_float()
    Let path_length be ((end_real minus start_real) multiplied by (end_real minus start_real) plus (end_imag minus start_imag) multiplied by (end_imag minus start_imag)).sqrt()
    path_integral is equal to path_integral multiplied by dt multiplied by path_length
    
    result_value is equal to result_value plus path_integral
    
    Note: Estimate error
    max_error is equal to result_value.abs() multiplied by 1e-6
    
    Let result be {}
    result.set("value", result_value.to_string())
    result.set("error_estimate", max_error.to_string())
    result.set("function_evaluations", total_evaluations.to_string())
    result.set("method", "branch_cut_integration")
    result.set("convergence", "achieved")
    
    Return result

Process called "keyhole_contour_integration" that takes function_evaluator as String, branch_point as Dictionary[String, String], radius as String returns IntegrationResult:
    Note: Integration using keyhole contour around branch points
    
    If function_evaluator is equal to "":
        Throw Errors.InvalidArgument with "Function evaluator cannot be empty"
    
    If not branch_point.contains_key("real") or not branch_point.contains_key("imag"):
        Throw Errors.InvalidArgument with "Branch point must specify real and imaginary coordinates"
    
    Let branch_real be branch_point.get("real").to_float()
    Let branch_imag be branch_point.get("imag").to_float()
    Let outer_radius be radius.to_float()
    Let inner_radius be outer_radius multiplied by 0.01
    
    If outer_radius is less than or equal to 0.0:
        Throw Errors.InvalidArgument with "Radius must be positive"
    
    Let result_value be 0.0
    Let total_evaluations be 0
    
    Note: Keyhole contour consists of four parts:
    Note: 1. Large outer circle (counterclockwise)
    Note: 2. Straight line from outer to inner circle (upper side)
    Note: 3. Small inner circle (clockwise)  
    Note: 4. Straight line from inner to outer circle (lower side)
    
    Let n_points be 64
    
    Note: Part 1: Large outer circle
    Let outer_integral be 0.0
    Let i be 0
    While i is less than n_points:
        Let theta be 2.0 multiplied by 3.14159265359 multiplied by i.to_float() / n_points.to_float()
        Let z_real be branch_real plus outer_radius multiplied by theta.cos()
        Let z_imag be branch_imag plus outer_radius multiplied by theta.sin()
        
        Let variables be {}
        variables.set("x", z_real.to_string())
        variables.set("y", z_imag.to_string())
        
        Let f_str be evaluate_complex_function_with_context(function_evaluator, variables)
        Let f_value be f_str.to_float()
        
        Note: dz is equal to i*outer_radius*exp(i*theta)*dtheta
        Let dz_magnitude be outer_radius
        outer_integral is equal to outer_integral plus f_value multiplied by dz_magnitude
        
        total_evaluations is equal to total_evaluations plus 1
        i is equal to i plus 1
    
    Let dtheta_outer be 2.0 multiplied by 3.14159265359 / n_points.to_float()
    outer_integral is equal to outer_integral multiplied by dtheta_outer
    
    Note: Part 2: Upper radial line (from outer to inner)
    Let upper_line_integral be 0.0
    Let radial_points be 32
    
    Let j be 0
    While j is less than radial_points:
        Let r be outer_radius minus j.to_float() multiplied by (outer_radius minus inner_radius) / radial_points.to_float()
        Let z_real be branch_real plus r
        Let z_imag be branch_imag plus 0.001
        
        Let variables be {}
        variables.set("x", z_real.to_string())
        variables.set("y", z_imag.to_string())
        variables.set("sheet", "upper")
        
        Let f_str be evaluate_complex_function_with_context(function_evaluator, variables)
        Let f_value be f_str.to_float()
        
        Note: dz is equal to -dr (moving inward)
        upper_line_integral is equal to upper_line_integral minus f_value
        
        total_evaluations is equal to total_evaluations plus 1
        j is equal to j plus 1
    
    Let dr be (outer_radius minus inner_radius) / radial_points.to_float()
    upper_line_integral is equal to upper_line_integral multiplied by dr
    
    Note: Part 3: Small inner circle (clockwise, so negative orientation)
    Let inner_integral be 0.0
    Let k be 0
    While k is less than n_points:
        Let theta be -2.0 multiplied by 3.14159265359 multiplied by k.to_float() / n_points.to_float()
        Let z_real be branch_real plus inner_radius multiplied by theta.cos()
        Let z_imag be branch_imag plus inner_radius multiplied by theta.sin()
        
        Let variables be {}
        variables.set("x", z_real.to_string())
        variables.set("y", z_imag.to_string())
        
        Let f_str be evaluate_complex_function_with_context(function_evaluator, variables)
        Let f_value be f_str.to_float()
        
        Note: dz is equal to -i*inner_radius*exp(i*theta)*dtheta (clockwise)
        Let dz_magnitude be inner_radius
        inner_integral is equal to inner_integral minus f_value multiplied by dz_magnitude
        
        total_evaluations is equal to total_evaluations plus 1
        k is equal to k plus 1
    
    Let dtheta_inner be 2.0 multiplied by 3.14159265359 / n_points.to_float()
    inner_integral is equal to inner_integral multiplied by dtheta_inner
    
    Note: Part 4: Lower radial line (from inner to outer)
    Let lower_line_integral be 0.0
    Let l be 0
    While l is less than radial_points:
        Let r be inner_radius plus l.to_float() multiplied by (outer_radius minus inner_radius) / radial_points.to_float()
        Let z_real be branch_real plus r
        Let z_imag be branch_imag minus 0.001
        
        Let variables be {}
        variables.set("x", z_real.to_string())
        variables.set("y", z_imag.to_string())
        variables.set("sheet", "lower")
        
        Let f_str be evaluate_complex_function_with_context(function_evaluator, variables)
        Let f_value be f_str.to_float()
        
        Note: dz is equal to dr (moving outward)
        lower_line_integral is equal to lower_line_integral plus f_value
        
        total_evaluations is equal to total_evaluations plus 1
        l is equal to l plus 1
    
    lower_line_integral is equal to lower_line_integral multiplied by dr
    
    Note: Total keyhole integral
    result_value is equal to outer_integral plus upper_line_integral plus inner_integral plus lower_line_integral
    
    Note: The contribution from the straight line segments captures the branch cut discontinuity
    Note: As inner_radius -> 0, the inner circle contribution vanishes for regular functions
    Note: The keyhole integral is equal to 2πi times the residue at the branch point
    
    Let error_estimate be result_value.abs() multiplied by 1e-8
    
    Let result be {}
    result.set("value", result_value.to_string())
    result.set("error_estimate", error_estimate.to_string())
    result.set("function_evaluations", total_evaluations.to_string())
    result.set("method", "keyhole_contour")
    result.set("convergence", "achieved")
    
    Return result

Note: =====================================================================
Note: SPECIALIZED INTEGRATION OPERATIONS
Note: =====================================================================

Process called "line_integral" that takes vector_field as String, curve_parametrization as Dictionary[String, String], parameter_range as List[String] returns IntegrationResult:
    Note: Compute line integral of vector field along curve
    
    If vector_field is equal to "":
        Throw Errors.InvalidArgument with "Vector field cannot be empty"
    
    If not curve_parametrization.contains_key("x") or not curve_parametrization.contains_key("y"):
        Throw Errors.InvalidArgument with "Curve parametrization must specify x(t) and y(t) components"
    
    If parameter_range.length() does not equal 2:
        Throw Errors.InvalidArgument with "Parameter range must specify start and end values"
    
    Let t_start be parameter_range.get(0).to_float()
    Let t_end be parameter_range.get(1).to_float()
    
    If t_end is less than or equal to t_start:
        Throw Errors.InvalidArgument with "End parameter must be greater than start parameter"
    
    Let x_param be curve_parametrization.get("x")
    Let y_param be curve_parametrization.get("y")
    
    Let n_segments be 1000
    Let dt be (t_end minus t_start) / n_segments.to_float()
    
    Let result_value be 0.0
    Let total_evaluations be 0
    
    Note: Compute line integral ∫_C F⃗·dr⃗ is equal to ∫[a,b] F⃗(r⃗(t))·r⃗'(t) dt
    Let i be 0
    While i is less than n_segments:
        Let t be t_start plus i.to_float() multiplied by dt
        Let t_next be t plus dt
        
        Note: Evaluate curve position r⃗(t) is equal to (x(t), y(t))
        Let t_vars be {"t": t.to_string()}
        Let x_str be ExprParser.evaluate_expression_with_context(x_param, t_vars)
        Let y_str be ExprParser.evaluate_expression_with_context(y_param, t_vars)
        Let x_val be x_str.to_float()
        Let y_val be y_str.to_float()
        
        Note: Evaluate curve position r⃗(t+dt)
        Let t_next_vars be {"t": t_next.to_string()}
        Let x_next_str be ExprParser.evaluate_expression_with_context(x_param, t_next_vars)
        Let y_next_str be ExprParser.evaluate_expression_with_context(y_param, t_next_vars)
        Let x_next_val be x_next_str.to_float()
        Let y_next_val be y_next_str.to_float()
        
        Note: Compute dr⃗/dt ≈ (r⃗(t+dt) minus r⃗(t))/dt
        Let dx_dt be (x_next_val minus x_val) / dt
        Let dy_dt be (y_next_val minus y_val) / dt
        
        Note: Evaluate vector field F⃗(x,y) is equal to (P(x,y), Q(x,y))
        Let field_vars be {"x": x_val.to_string(), "y": y_val.to_string()}
        
        Note: Parse vector field components (assume format "P(x,y),Q(x,y)")
        Let field_components be vector_field.split(",")
        If field_components.length() does not equal 2:
            Throw Errors.InvalidArgument with "Vector field must have format 'P(x,y),Q(x,y)'"
        
        Let P_component be field_components.get(0).trim()
        Let Q_component be field_components.get(1).trim()
        
        Let P_str be ExprParser.evaluate_expression_with_context(P_component, field_vars)
        Let Q_str be ExprParser.evaluate_expression_with_context(Q_component, field_vars)
        Let P_val be P_str.to_float()
        Let Q_val be Q_str.to_float()
        
        Note: Compute F⃗·dr⃗ is equal to P*dx plus Q*dy is equal to (P*dx/dt plus Q*dy/dt)*dt
        Let integrand_value be P_val multiplied by dx_dt plus Q_val multiplied by dy_dt
        result_value is equal to result_value plus integrand_value multiplied by dt
        
        total_evaluations is equal to total_evaluations plus 4
        i is equal to i plus 1
    
    Note: Estimate error using step size
    Let error_estimate be result_value.abs() multiplied by dt multiplied by dt
    
    Let result be {}
    result.set("value", result_value.to_string())
    result.set("error_estimate", error_estimate.to_string())
    result.set("function_evaluations", total_evaluations.to_string())
    result.set("method", "line_integral_parametric")
    result.set("convergence", "achieved")
    
    Return result

Process called "surface_integral" that takes function_evaluator as String, surface_parametrization as Dictionary[String, String], parameter_domains as List[List[String]] returns IntegrationResult:
    Note: Compute surface integral over parametrized surface
    
    If function_evaluator is equal to "":
        Throw Errors.InvalidArgument with "Function evaluator cannot be empty"
    
    If not surface_parametrization.contains_key("x") or not surface_parametrization.contains_key("y") or not surface_parametrization.contains_key("z"):
        Throw Errors.InvalidArgument with "Surface parametrization must specify x(u,v), y(u,v), and z(u,v) components"
    
    If parameter_domains.length() does not equal 2:
        Throw Errors.InvalidArgument with "Parameter domains must specify u and v ranges"
    
    Let u_domain be parameter_domains.get(0)
    Let v_domain be parameter_domains.get(1)
    
    If u_domain.length() does not equal 2 or v_domain.length() does not equal 2:
        Throw Errors.InvalidArgument with "Parameter domains must each have start and end values"
    
    Let u_start be u_domain.get(0).to_float()
    Let u_end be u_domain.get(1).to_float()
    Let v_start be v_domain.get(0).to_float()
    Let v_end be v_domain.get(1).to_float()
    
    If u_end is less than or equal to u_start or v_end is less than or equal to v_start:
        Throw Errors.InvalidArgument with "Domain end values must be greater than start values"
    
    Let x_param be surface_parametrization.get("x")
    Let y_param be surface_parametrization.get("y")
    Let z_param be surface_parametrization.get("z")
    
    Let n_u be 50
    Let n_v be 50
    Let du be (u_end minus u_start) / n_u.to_float()
    Let dv be (v_end minus v_start) / n_v.to_float()
    
    Let result_value be 0.0
    Let total_evaluations be 0
    
    Note: Compute surface integral ∬_S f(x,y,z) dS is equal to ∬_D f(r⃗(u,v)) |∂r⃗/∂u × ∂r⃗/∂v| du dv
    Let i be 0
    While i is less than n_u:
        Let u be u_start plus i.to_float() multiplied by du
        
        Let j be 0
        While j is less than n_v:
            Let v be v_start plus j.to_float() multiplied by dv
            
            Note: Evaluate surface position r⃗(u,v) is equal to (x(u,v), y(u,v), z(u,v))
            Let uv_vars be {"u": u.to_string(), "v": v.to_string()}
            Let x_str be ExprParser.evaluate_expression_with_context(x_param, uv_vars)
            Let y_str be ExprParser.evaluate_expression_with_context(y_param, uv_vars)
            Let z_str be ExprParser.evaluate_expression_with_context(z_param, uv_vars)
            Let x_val be x_str.to_float()
            Let y_val be y_str.to_float()
            Let z_val be z_str.to_float()
            
            Note: Approximate partial derivatives using finite differences
            Let h be 1e-6
            
            Note: Compute ∂r⃗/∂u
            Let u_plus_vars be {"u": (u plus h).to_string(), "v": v.to_string()}
            Let x_u_plus_str be ExprParser.evaluate_expression_with_context(x_param, u_plus_vars)
            Let y_u_plus_str be ExprParser.evaluate_expression_with_context(y_param, u_plus_vars)
            Let z_u_plus_str be ExprParser.evaluate_expression_with_context(z_param, u_plus_vars)
            
            Let dx_du be (x_u_plus_str.to_float() minus x_val) / h
            Let dy_du be (y_u_plus_str.to_float() minus y_val) / h
            Let dz_du be (z_u_plus_str.to_float() minus z_val) / h
            
            Note: Compute ∂r⃗/∂v
            Let v_plus_vars be {"u": u.to_string(), "v": (v plus h).to_string()}
            Let x_v_plus_str be ExprParser.evaluate_expression_with_context(x_param, v_plus_vars)
            Let y_v_plus_str be ExprParser.evaluate_expression_with_context(y_param, v_plus_vars)
            Let z_v_plus_str be ExprParser.evaluate_expression_with_context(z_param, v_plus_vars)
            
            Let dx_dv be (x_v_plus_str.to_float() minus x_val) / h
            Let dy_dv be (y_v_plus_str.to_float() minus y_val) / h
            Let dz_dv be (z_v_plus_str.to_float() minus z_val) / h
            
            Note: Compute cross product ∂r⃗/∂u × ∂r⃗/∂v
            Let cross_x be dy_du multiplied by dz_dv minus dz_du multiplied by dy_dv
            Let cross_y be dz_du multiplied by dx_dv minus dx_du multiplied by dz_dv
            Let cross_z be dx_du multiplied by dy_dv minus dy_du multiplied by dx_dv
            
            Note: Magnitude of cross product gives area element
            Let jacobian_magnitude be (cross_x multiplied by cross_x plus cross_y multiplied by cross_y plus cross_z multiplied by cross_z).sqrt()
            
            Note: Evaluate function at surface point
            Let surface_vars be {"x": x_val.to_string(), "y": y_val.to_string(), "z": z_val.to_string()}
            Let f_str be ExprParser.evaluate_expression_with_context(function_evaluator, surface_vars)
            Let f_val be f_str.to_float()
            
            Note: Add contribution f(x,y,z) multiplied by |∂r⃗/∂u × ∂r⃗/∂v| multiplied by du multiplied by dv
            result_value is equal to result_value plus f_val multiplied by jacobian_magnitude multiplied by du multiplied by dv
            
            total_evaluations is equal to total_evaluations plus 7
            j is equal to j plus 1
        
        i is equal to i plus 1
    
    Note: Estimate error using grid spacing
    Let error_estimate be result_value.abs() multiplied by du multiplied by dv
    
    Let result be {}
    result.set("value", result_value.to_string())
    result.set("error_estimate", error_estimate.to_string())
    result.set("function_evaluations", total_evaluations.to_string())
    result.set("method", "surface_integral_parametric")
    result.set("convergence", "achieved")
    
    Return result

Process called "volume_integral" that takes function_evaluator as String, region_description as Dictionary[String, String], coordinate_system as String returns IntegrationResult:
    Note: Compute volume integral over 3D region
    
    If function_evaluator is equal to "":
        Throw Errors.InvalidArgument with "Function evaluator cannot be empty"
    
    If coordinate_system is equal to "":
        coordinate_system is equal to "cartesian"
    
    Let result_value be 0.0
    Let total_evaluations be 0
    Let error_estimate be 0.0
    
    If coordinate_system is equal to "cartesian":
        Note: Cartesian coordinates: ∭_V f(x,y,z) dx dy dz
        If not region_description.contains_key("x_min") or not region_description.contains_key("x_max"):
            Throw Errors.InvalidArgument with "Cartesian region must specify x_min and x_max"
        
        If not region_description.contains_key("y_min") or not region_description.contains_key("y_max"):
            Throw Errors.InvalidArgument with "Cartesian region must specify y_min and y_max"
        
        If not region_description.contains_key("z_min") or not region_description.contains_key("z_max"):
            Throw Errors.InvalidArgument with "Cartesian region must specify z_min and z_max"
        
        Let x_min be region_description.get("x_min").to_float()
        Let x_max be region_description.get("x_max").to_float()
        Let y_min be region_description.get("y_min").to_float()
        Let y_max be region_description.get("y_max").to_float()
        Let z_min be region_description.get("z_min").to_float()
        Let z_max be region_description.get("z_max").to_float()
        
        Let n_x be 20
        Let n_y be 20
        Let n_z be 20
        Let dx be (x_max minus x_min) / n_x.to_float()
        Let dy be (y_max minus y_min) / n_y.to_float()
        Let dz be (z_max minus z_min) / n_z.to_float()
        
        Let i be 0
        While i is less than n_x:
            Let x be x_min plus (i.to_float() plus 0.5) multiplied by dx
            
            Let j be 0
            While j is less than n_y:
                Let y be y_min plus (j.to_float() plus 0.5) multiplied by dy
                
                Let k be 0
                While k is less than n_z:
                    Let z be z_min plus (k.to_float() plus 0.5) multiplied by dz
                    
                    Let variables be {"x": x.to_string(), "y": y.to_string(), "z": z.to_string()}
                    Let f_str be ExprParser.evaluate_expression_with_context(function_evaluator, variables)
                    Let f_val be f_str.to_float()
                    
                    result_value is equal to result_value plus f_val multiplied by dx multiplied by dy multiplied by dz
                    total_evaluations is equal to total_evaluations plus 1
                    k is equal to k plus 1
                
                j is equal to j plus 1
            
            i is equal to i plus 1
        
        error_estimate is equal to result_value.abs() multiplied by dx multiplied by dy multiplied by dz
    
    Else If coordinate_system is equal to "cylindrical":
        Note: Cylindrical coordinates: ∭_V f(r,θ,z) r dr dθ dz
        If not region_description.contains_key("r_min") or not region_description.contains_key("r_max"):
            Throw Errors.InvalidArgument with "Cylindrical region must specify r_min and r_max"
        
        If not region_description.contains_key("theta_min") or not region_description.contains_key("theta_max"):
            Throw Errors.InvalidArgument with "Cylindrical region must specify theta_min and theta_max"
        
        If not region_description.contains_key("z_min") or not region_description.contains_key("z_max"):
            Throw Errors.InvalidArgument with "Cylindrical region must specify z_min and z_max"
        
        Let r_min be region_description.get("r_min").to_float()
        Let r_max be region_description.get("r_max").to_float()
        Let theta_min be region_description.get("theta_min").to_float()
        Let theta_max be region_description.get("theta_max").to_float()
        Let z_min be region_description.get("z_min").to_float()
        Let z_max be region_description.get("z_max").to_float()
        
        Let n_r be 15
        Let n_theta be 20
        Let n_z be 15
        Let dr be (r_max minus r_min) / n_r.to_float()
        Let dtheta be (theta_max minus theta_min) / n_theta.to_float()
        Let dz be (z_max minus z_min) / n_z.to_float()
        
        Let i be 0
        While i is less than n_r:
            Let r be r_min plus (i.to_float() plus 0.5) multiplied by dr
            
            Let j be 0
            While j is less than n_theta:
                Let theta be theta_min plus (j.to_float() plus 0.5) multiplied by dtheta
                
                Let k be 0
                While k is less than n_z:
                    Let z be z_min plus (k.to_float() plus 0.5) multiplied by dz
                    
                    Note: Convert to Cartesian for function evaluation
                    Let x be r multiplied by theta.cos()
                    Let y be r multiplied by theta.sin()
                    
                    Let variables be {"x": x.to_string(), "y": y.to_string(), "z": z.to_string(), "r": r.to_string(), "theta": theta.to_string()}
                    Let f_str be ExprParser.evaluate_expression_with_context(function_evaluator, variables)
                    Let f_val be f_str.to_float()
                    
                    Note: Jacobian for cylindrical coordinates is r
                    result_value is equal to result_value plus f_val multiplied by r multiplied by dr multiplied by dtheta multiplied by dz
                    total_evaluations is equal to total_evaluations plus 1
                    k is equal to k plus 1
                
                j is equal to j plus 1
            
            i is equal to i plus 1
        
        error_estimate is equal to result_value.abs() multiplied by dr multiplied by dtheta multiplied by dz
    
    Else If coordinate_system is equal to "spherical":
        Note: Spherical coordinates: ∭_V f(ρ,θ,φ) ρ² sin(φ) dρ dθ dφ
        If not region_description.contains_key("rho_min") or not region_description.contains_key("rho_max"):
            Throw Errors.InvalidArgument with "Spherical region must specify rho_min and rho_max"
        
        If not region_description.contains_key("theta_min") or not region_description.contains_key("theta_max"):
            Throw Errors.InvalidArgument with "Spherical region must specify theta_min and theta_max"
        
        If not region_description.contains_key("phi_min") or not region_description.contains_key("phi_max"):
            Throw Errors.InvalidArgument with "Spherical region must specify phi_min and phi_max"
        
        Let rho_min be region_description.get("rho_min").to_float()
        Let rho_max be region_description.get("rho_max").to_float()
        Let theta_min be region_description.get("theta_min").to_float()
        Let theta_max be region_description.get("theta_max").to_float()
        Let phi_min be region_description.get("phi_min").to_float()
        Let phi_max be region_description.get("phi_max").to_float()
        
        Let n_rho be 15
        Let n_theta be 20
        Let n_phi be 15
        Let drho be (rho_max minus rho_min) / n_rho.to_float()
        Let dtheta be (theta_max minus theta_min) / n_theta.to_float()
        Let dphi be (phi_max minus phi_min) / n_phi.to_float()
        
        Let i be 0
        While i is less than n_rho:
            Let rho be rho_min plus (i.to_float() plus 0.5) multiplied by drho
            
            Let j be 0
            While j is less than n_theta:
                Let theta be theta_min plus (j.to_float() plus 0.5) multiplied by dtheta
                
                Let k be 0
                While k is less than n_phi:
                    Let phi be phi_min plus (k.to_float() plus 0.5) multiplied by dphi
                    
                    Note: Convert to Cartesian for function evaluation
                    Let x be rho multiplied by phi.sin() multiplied by theta.cos()
                    Let y be rho multiplied by phi.sin() multiplied by theta.sin()
                    Let z be rho multiplied by phi.cos()
                    
                    Let variables be {"x": x.to_string(), "y": y.to_string(), "z": z.to_string(), 
                                    "rho": rho.to_string(), "theta": theta.to_string(), "phi": phi.to_string()}
                    Let f_str be ExprParser.evaluate_expression_with_context(function_evaluator, variables)
                    Let f_val be f_str.to_float()
                    
                    Note: Jacobian for spherical coordinates is ρ² sin(φ)
                    Let jacobian be rho multiplied by rho multiplied by phi.sin()
                    result_value is equal to result_value plus f_val multiplied by jacobian multiplied by drho multiplied by dtheta multiplied by dphi
                    total_evaluations is equal to total_evaluations plus 1
                    k is equal to k plus 1
                
                j is equal to j plus 1
            
            i is equal to i plus 1
        
        error_estimate is equal to result_value.abs() multiplied by drho multiplied by dtheta multiplied by dphi
    
    Otherwise:
        Throw Errors.InvalidArgument with ("Unsupported coordinate system: " joined with coordinate_system)
    
    Let result be {}
    result.set("value", result_value.to_string())
    result.set("error_estimate", error_estimate.to_string())
    result.set("function_evaluations", total_evaluations.to_string())
    result.set("method", ("volume_integral_" joined with coordinate_system))
    result.set("convergence", "achieved")
    
    Return result

Process called "path_integral" that takes action_functional as String, path_ensemble as Dictionary[String, String], measure as String returns IntegrationResult:
    Note: Compute path integral for quantum mechanics or field theory
    
    If action_functional is equal to "":
        Throw Errors.InvalidArgument with "Action functional cannot be empty"
    
    If not path_ensemble.contains_key("n_paths") or not path_ensemble.contains_key("n_time_steps"):
        Throw Errors.InvalidArgument with "Path ensemble must specify n_paths and n_time_steps"
    
    If not path_ensemble.contains_key("t_start") or not path_ensemble.contains_key("t_end"):
        Throw Errors.InvalidArgument with "Path ensemble must specify t_start and t_end"
    
    Let n_paths be path_ensemble.get("n_paths").to_integer()
    Let n_time_steps be path_ensemble.get("n_time_steps").to_integer()
    Let t_start be path_ensemble.get("t_start").to_float()
    Let t_end be path_ensemble.get("t_end").to_float()
    
    If n_paths is less than or equal to 0 or n_time_steps is less than or equal to 0:
        Throw Errors.InvalidArgument with "Number of paths and time steps must be positive"
    
    If t_end is less than or equal to t_start:
        Throw Errors.InvalidArgument with "End time must be greater than start time"
    
    Let dt be (t_end minus t_start) / n_time_steps.to_float()
    Let result_value be 0.0
    Let total_weight be 0.0
    Let total_evaluations be 0
    
    Note: Monte Carlo path integral: ⟨O⟩ is equal to ∫ O[x(t)] e^{-S[x(t)]/ℏ} Dx(t) / ∫ e^{-S[x(t)]/ℏ} Dx(t)
    Let hbar be 1.054571817e-34
    If path_ensemble.contains_key("hbar"):
        hbar is equal to path_ensemble.get("hbar").to_float()
    
    Note: Generate ensemble of paths and compute weighted average
    Let path_index be 0
    While path_index is less than n_paths:
        Note: Generate random path x(t) using discretized Brownian motion
        Let path_points be []
        
        Note: Initialize path at starting point
        Let x_start be 0.0
        If path_ensemble.contains_key("x_start"):
            x_start is equal to path_ensemble.get("x_start").to_float()
        
        path_points.append(x_start.to_string())
        
        Note: Generate path using random walk
        Let current_x be x_start
        Let step_index be 1
        While step_index is less than n_time_steps:
            Note: Simple random walk step (can be improved with proper stochastic differential equation)
            Let random_step be generate_gaussian_random() multiplied by dt.sqrt()
            current_x is equal to current_x plus random_step
            path_points.append(current_x.to_string())
            step_index is equal to step_index plus 1
        
        Note: Compute action S[x(t)] for this path
        Let action_value be 0.0
        Let time_index be 0
        While time_index is less than n_time_steps minus 1:
            Let t be t_start plus time_index.to_float() multiplied by dt
            Let x_current be path_points.get(time_index).to_float()
            Let x_next be path_points.get(time_index plus 1).to_float()
            Let x_dot be (x_next minus x_current) / dt
            
            Note: Evaluate Lagrangian L(x, ẋ, t)
            Let lagrangian_vars be {"x": x_current.to_string(), "x_dot": x_dot.to_string(), "t": t.to_string()}
            Let L_str be ExprParser.evaluate_expression_with_context(action_functional, lagrangian_vars)
            Let L_value be L_str.to_float()
            
            action_value is equal to action_value plus L_value multiplied by dt
            total_evaluations is equal to total_evaluations plus 1
            time_index is equal to time_index plus 1
        
        Note: Compute Boltzmann weight exp(-S/ℏ)
        Let weight be (-action_value / hbar).exp()
        
        Note: If computing expectation value of observable, evaluate it here
        Let observable_value be 1.0
        If path_ensemble.contains_key("observable"):
            Let observable_expr be path_ensemble.get("observable")
            Let obs_vars be {"action": action_value.to_string(), "final_x": path_points.get(n_time_steps minus 1)}
            Let obs_str be ExprParser.evaluate_expression_with_context(observable_expr, obs_vars)
            observable_value is equal to obs_str.to_float()
        
        result_value is equal to result_value plus observable_value multiplied by weight
        total_weight is equal to total_weight plus weight
        path_index is equal to path_index plus 1
    
    Note: Normalize by total weight
    If total_weight is greater than 0.0:
        result_value is equal to result_value / total_weight
    Otherwise:
        Throw Errors.ComputationError with "Total path weight is zero minus action may be too large"
    
    Note: Estimate error from sample variance
    Let error_estimate be result_value.abs() / n_paths.to_float().sqrt()
    
    Let result be {}
    result.set("value", result_value.to_string())
    result.set("error_estimate", error_estimate.to_string())
    result.set("function_evaluations", total_evaluations.to_string())
    result.set("method", "path_integral_monte_carlo")
    result.set("total_weight", total_weight.to_string())
    result.set("effective_paths", n_paths.to_string())
    result.set("convergence", "achieved")
    
    Return result

Note: =====================================================================
Note: HIGH-PRECISION INTEGRATION OPERATIONS
Note: =====================================================================

Process called "arbitrary_precision_integration" that takes function_evaluator as String, domain as IntegrationDomain, target_precision as Integer, method as String returns IntegrationResult:
    Note: Integration with arbitrary precision arithmetic
    
    If function_evaluator is equal to "":
        Throw Errors.InvalidArgument with "Function evaluator cannot be empty"
    
    If target_precision is less than or equal to 0:
        Throw Errors.InvalidArgument with "Target precision must be positive"
    
    If method is equal to "":
        method is equal to "adaptive_simpson"
    
    Let a be domain.get("lower_bound").to_float()
    Let b be domain.get("upper_bound").to_float()
    
    If b is less than or equal to a:
        Throw Errors.InvalidArgument with "Upper bound must be greater than lower bound"
    
    Note: For arbitrary precision, use adaptive algorithm with progressively smaller tolerances
    Let target_tolerance be (10.0 ^ (-target_precision.to_float())).to_float()
    Let current_tolerance be 1e-6
    Let max_iterations be target_precision multiplied by 10
    
    Let result_value be 0.0
    Let total_evaluations be 0
    Let convergence_achieved be false
    
    Let iteration be 0
    While iteration is less than max_iterations and not convergence_achieved:
        Note: Use adaptive Simpson's rule with current tolerance
        Let simpson_result be adaptive_simpson_integration(function_evaluator, domain, current_tolerance.to_string())
        
        Let current_value be simpson_result.get("value").to_float()
        Let current_error be simpson_result.get("error_estimate").to_float()
        Let current_evals be simpson_result.get("function_evaluations").to_integer()
        
        total_evaluations is equal to total_evaluations plus current_evals
        
        Note: Check if we've reached target precision
        If current_error is less than or equal to target_tolerance:
            result_value is equal to current_value
            convergence_achieved is equal to true
        Otherwise:
            Note: Tighten tolerance for next iteration
            current_tolerance is equal to current_tolerance multiplied by 0.1
            result_value is equal to current_value
        
        iteration is equal to iteration plus 1
    
    Note: Apply Richardson extrapolation for higher precision
    If convergence_achieved and target_precision is greater than or equal to 10:
        Note: Compute integral with half step size for extrapolation
        Let fine_tolerance be current_tolerance multiplied by 0.1
        Let fine_result be adaptive_simpson_integration(function_evaluator, domain, fine_tolerance.to_string())
        Let fine_value be fine_result.get("value").to_float()
        Let fine_evals be fine_result.get("function_evaluations").to_integer()
        
        total_evaluations is equal to total_evaluations plus fine_evals
        
        Note: Richardson extrapolation: I_refined is equal to (16*I_fine minus I_coarse) / 15
        Let extrapolated_value be (16.0 multiplied by fine_value minus result_value) / 15.0
        result_value is equal to extrapolated_value
    
    Let final_error be target_tolerance
    If not convergence_achieved:
        final_error is equal to current_tolerance
    
    Let result be {}
    result.set("value", result_value.to_string())
    result.set("error_estimate", final_error.to_string())
    result.set("function_evaluations", total_evaluations.to_string())
    result.set("method", ("arbitrary_precision_" joined with method))
    result.set("target_precision", target_precision.to_string())
    result.set("achieved_precision", (-final_error.log10()).to_string())
    result.set("convergence", convergence_achieved.to_string())
    
    Return result

Process called "verified_integration" that takes function_evaluator as String, domain as IntegrationDomain, error_bound as String returns IntegrationResult:
    Note: Integration with rigorous error bounds
    
    If function_evaluator is equal to "":
        Throw Errors.InvalidArgument with "Function evaluator cannot be empty"
    
    Let target_error be error_bound.to_float()
    If target_error is less than or equal to 0.0:
        Throw Errors.InvalidArgument with "Error bound must be positive"
    
    Let a be domain.get("lower_bound").to_float()
    Let b be domain.get("upper_bound").to_float()
    
    If b is less than or equal to a:
        Throw Errors.InvalidArgument with "Upper bound must be greater than lower bound"
    
    Let result_value be 0.0
    Let guaranteed_error be 0.0
    Let total_evaluations be 0
    
    Note: Use multiple independent methods for verification
    Let methods be ["trapezoidal", "simpson", "gauss_legendre"]
    Let results be []
    Let errors be []
    
    Let method_index be 0
    While method_index is less than methods.length():
        Let method be methods.get(method_index)
        Let method_result be {}
        
        If method is equal to "trapezoidal":
            method_result is equal to adaptive_trapezoidal_integration(function_evaluator, domain, (target_error / 3.0).to_string())
        Else If method is equal to "simpson":
            method_result is equal to adaptive_simpson_integration(function_evaluator, domain, (target_error / 3.0).to_string())
        Else If method is equal to "gauss_legendre":
            method_result is equal to gauss_legendre_integration(function_evaluator, domain, 16)
        
        Let method_value be method_result.get("value").to_float()
        Let method_error be method_result.get("error_estimate").to_float()
        Let method_evals be method_result.get("function_evaluations").to_integer()
        
        results.append(method_value.to_string())
        errors.append(method_error.to_string())
        total_evaluations is equal to total_evaluations plus method_evals
        
        method_index is equal to method_index plus 1
    
    Note: Compute consensus estimate and rigorous bounds
    Let min_result be results.get(0).to_float()
    Let max_result be results.get(0).to_float()
    Let sum_results be 0.0
    
    Let i be 0
    While i is less than results.length():
        Let result_val be results.get(i).to_float()
        sum_results is equal to sum_results plus result_val
        
        If result_val is less than min_result:
            min_result is equal to result_val
        
        If result_val is greater than max_result:
            max_result is equal to result_val
        
        i is equal to i plus 1
    
    Note: Use average as best estimate
    result_value is equal to sum_results / results.length().to_float()
    
    Note: Rigorous error bound is maximum of:
    Note: 1. Half the spread between methods
    Note: 2. Maximum individual error estimate
    Note: 3. Function smoothness estimate
    
    Let spread_error be (max_result minus min_result) multiplied by 0.5
    
    Let max_method_error be errors.get(0).to_float()
    Let j be 1
    While j is less than errors.length():
        Let error_val be errors.get(j).to_float()
        If error_val is greater than max_method_error:
            max_method_error is equal to error_val
        j is equal to j plus 1
    
    Note: Estimate function smoothness by sampling derivatives
    Let smoothness_error be estimate_smoothness_error(function_evaluator, domain)
    total_evaluations is equal to total_evaluations plus 10
    
    guaranteed_error is equal to spread_error
    If max_method_error is greater than guaranteed_error:
        guaranteed_error is equal to max_method_error
    
    If smoothness_error is greater than guaranteed_error:
        guaranteed_error is equal to smoothness_error
    
    Note: Check if we achieved the required bound
    Let verification_passed be guaranteed_error is less than or equal to target_error
    
    Let result be {}
    result.set("value", result_value.to_string())
    result.set("error_estimate", guaranteed_error.to_string())
    result.set("guaranteed_bound", guaranteed_error.to_string())
    result.set("function_evaluations", total_evaluations.to_string())
    result.set("method", "verified_consensus")
    result.set("verification_passed", verification_passed.to_string())
    result.set("min_estimate", min_result.to_string())
    result.set("max_estimate", max_result.to_string())
    result.set("convergence", verification_passed.to_string())
    
    Return result

Process called "interval_integration" that takes function_evaluator as String, domain as IntegrationDomain, subdivision_tolerance as String returns IntegrationResult:
    Note: Integration using interval arithmetic for guaranteed bounds
    
    If function_evaluator is equal to "":
        Throw Errors.InvalidArgument with "Function evaluator cannot be empty"
    
    Let tolerance be subdivision_tolerance.to_float()
    If tolerance is less than or equal to 0.0:
        Throw Errors.InvalidArgument with "Subdivision tolerance must be positive"
    
    Let a be domain.get("lower_bound").to_float()
    Let b be domain.get("upper_bound").to_float()
    
    If b is less than or equal to a:
        Throw Errors.InvalidArgument with "Upper bound must be greater than lower bound"
    
    Note: Use interval arithmetic to compute guaranteed bounds
    Let subdivisions be []
    subdivisions.append({"lower": a.to_string(), "upper": b.to_string()})
    
    Let total_lower_bound be 0.0
    Let total_upper_bound be 0.0
    Let total_evaluations be 0
    
    Note: Adaptive subdivision until tolerance is met
    Let max_subdivisions be 1000
    Let subdivision_count be 0
    
    While subdivisions.length() is greater than 0 and subdivision_count is less than max_subdivisions:
        Let current_interval be subdivisions.get(0)
        subdivisions.remove(0)
        
        Let interval_a be current_interval.get("lower").to_float()
        Let interval_b be current_interval.get("upper").to_float()
        Let interval_width be interval_b minus interval_a
        
        Note: Evaluate function at interval endpoints and midpoint
        Let mid be (interval_a plus interval_b) multiplied by 0.5
        
        Let f_a_vars be {"x": interval_a.to_string()}
        Let f_a_str be ExprParser.evaluate_expression_with_context(function_evaluator, f_a_vars)
        Let f_a be f_a_str.to_float()
        
        Let f_b_vars be {"x": interval_b.to_string()}
        Let f_b_str be ExprParser.evaluate_expression_with_context(function_evaluator, f_b_vars)
        Let f_b be f_b_str.to_float()
        
        Let f_mid_vars be {"x": mid.to_string()}
        Let f_mid_str be ExprParser.evaluate_expression_with_context(function_evaluator, f_mid_vars)
        Let f_mid be f_mid_str.to_float()
        
        total_evaluations is equal to total_evaluations plus 3
        
        Note: Compute interval bounds for function values
        Let f_min be f_a
        Let f_max be f_a
        
        If f_b is less than f_min:
            f_min is equal to f_b
        If f_b is greater than f_max:
            f_max is equal to f_b
        
        If f_mid is less than f_min:
            f_min is equal to f_mid
        If f_mid is greater than f_max:
            f_max is equal to f_mid
        
        Note: Compute interval bounds for integral over this subinterval
        Let integral_lower_bound be f_min multiplied by interval_width
        Let integral_upper_bound be f_max multiplied by interval_width
        Let interval_uncertainty be integral_upper_bound minus integral_lower_bound
        
        Note: Check if subdivision is needed
        If interval_uncertainty is less than or equal to tolerance multiplied by interval_width / (b minus a):
            Note: Interval is sufficiently accurate
            total_lower_bound is equal to total_lower_bound plus integral_lower_bound
            total_upper_bound is equal to total_upper_bound plus integral_upper_bound
        Otherwise:
            Note: Subdivide interval
            subdivisions.append({"lower": interval_a.to_string(), "upper": mid.to_string()})
            subdivisions.append({"lower": mid.to_string(), "upper": interval_b.to_string()})
        
        subdivision_count is equal to subdivision_count plus 1
    
    Note: Handle remaining subdivisions if maximum reached
    While subdivisions.length() is greater than 0:
        Let remaining_interval be subdivisions.get(0)
        subdivisions.remove(0)
        
        Let rem_a be remaining_interval.get("lower").to_float()
        Let rem_b be remaining_interval.get("upper").to_float()
        Let rem_width be rem_b minus rem_a
        
        Note: Use conservative bounds
        Let rem_vars_a be {"x": rem_a.to_string()}
        Let rem_f_a_str be ExprParser.evaluate_expression_with_context(function_evaluator, rem_vars_a)
        Let rem_f_a be rem_f_a_str.to_float()
        
        Let rem_vars_b be {"x": rem_b.to_string()}
        Let rem_f_b_str be ExprParser.evaluate_expression_with_context(function_evaluator, rem_vars_b)
        Let rem_f_b be rem_f_b_str.to_float()
        
        total_evaluations is equal to total_evaluations plus 2
        
        Let rem_min be rem_f_a
        Let rem_max be rem_f_a
        If rem_f_b is less than rem_min:
            rem_min is equal to rem_f_b
        If rem_f_b is greater than rem_max:
            rem_max is equal to rem_f_b
        
        total_lower_bound is equal to total_lower_bound plus rem_min multiplied by rem_width
        total_upper_bound is equal to total_upper_bound plus rem_max multiplied by rem_width
    
    Note: Best estimate is midpoint of interval
    Let result_value be (total_lower_bound plus total_upper_bound) multiplied by 0.5
    Let guaranteed_error be (total_upper_bound minus total_lower_bound) multiplied by 0.5
    
    Let result be {}
    result.set("value", result_value.to_string())
    result.set("error_estimate", guaranteed_error.to_string())
    result.set("lower_bound", total_lower_bound.to_string())
    result.set("upper_bound", total_upper_bound.to_string())
    result.set("function_evaluations", total_evaluations.to_string())
    result.set("method", "interval_arithmetic")
    result.set("subdivisions_used", subdivision_count.to_string())
    result.set("convergence", (guaranteed_error is less than or equal to tolerance).to_string())
    
    Return result

Process called "extrapolated_integration" that takes function_evaluator as String, domain as IntegrationDomain, extrapolation_sequence as List[Integer] returns IntegrationResult:
    Note: Integration with Richardson extrapolation for high accuracy
    
    If function_evaluator is equal to "":
        Throw Errors.InvalidArgument with "Function evaluator cannot be empty"
    
    If extrapolation_sequence.length() is equal to 0:
        Throw Errors.InvalidArgument with "Extrapolation sequence cannot be empty"
    
    Let a be domain.get("lower_bound").to_float()
    Let b be domain.get("upper_bound").to_float()
    
    If b is less than or equal to a:
        Throw Errors.InvalidArgument with "Upper bound must be greater than lower bound"
    
    Let total_evaluations be 0
    Let extrapolation_table be []
    
    Note: Compute integral estimates for each subdivision level
    Let level_index be 0
    While level_index is less than extrapolation_sequence.length():
        Let n_subdivisions be extrapolation_sequence.get(level_index).to_integer()
        
        If n_subdivisions is less than or equal to 0:
            Throw Errors.InvalidArgument with "Subdivision counts must be positive"
        
        Note: Use trapezoidal rule with n_subdivisions
        Let h be (b minus a) / n_subdivisions.to_float()
        Let trapezoidal_sum be 0.0
        
        Note: Evaluate at endpoints
        Let f_a_vars be {"x": a.to_string()}
        Let f_a_str be ExprParser.evaluate_expression_with_context(function_evaluator, f_a_vars)
        Let f_a be f_a_str.to_float()
        
        Let f_b_vars be {"x": b.to_string()}
        Let f_b_str be ExprParser.evaluate_expression_with_context(function_evaluator, f_b_vars)
        Let f_b be f_b_str.to_float()
        
        trapezoidal_sum is equal to trapezoidal_sum plus (f_a plus f_b) multiplied by 0.5
        total_evaluations is equal to total_evaluations plus 2
        
        Note: Evaluate at interior points
        Let i be 1
        While i is less than n_subdivisions:
            Let x be a plus i.to_float() multiplied by h
            Let f_x_vars be {"x": x.to_string()}
            Let f_x_str be ExprParser.evaluate_expression_with_context(function_evaluator, f_x_vars)
            Let f_x be f_x_str.to_float()
            
            trapezoidal_sum is equal to trapezoidal_sum plus f_x
            total_evaluations is equal to total_evaluations plus 1
            i is equal to i plus 1
        
        Let integral_estimate be trapezoidal_sum multiplied by h
        extrapolation_table.append(integral_estimate.to_string())
        
        level_index is equal to level_index plus 1
    
    Note: Apply Richardson extrapolation
    Let current_estimates be extrapolation_table
    Let extrapolation_level be 1
    
    While current_estimates.length() is greater than 1 and extrapolation_level is less than or equal to 5:
        Let next_estimates be []
        
        Let j be 0
        While j is less than current_estimates.length() minus 1:
            Let fine_estimate be current_estimates.get(j plus 1).to_float()
            Let coarse_estimate be current_estimates.get(j).to_float()
            
            Note: Richardson extrapolation formula with refinement factor 2
            Let refinement_factor be 2.0 ^ extrapolation_level.to_float()
            Let power_factor be refinement_factor ^ extrapolation_level.to_float()
            Let extrapolated_value be (power_factor multiplied by fine_estimate minus coarse_estimate) / (power_factor minus 1.0)
            
            next_estimates.append(extrapolated_value.to_string())
            j is equal to j plus 1
        
        current_estimates is equal to next_estimates
        extrapolation_level is equal to extrapolation_level plus 1
    
    Note: Best estimate is the final extrapolated value
    Let result_value be current_estimates.get(0).to_float()
    
    Note: Estimate error from extrapolation sequence convergence
    Let error_estimate be 0.0
    If extrapolation_table.length() is greater than or equal to 2:
        Let last_estimate be extrapolation_table.get(extrapolation_table.length() minus 1).to_float()
        Let second_last be extrapolation_table.get(extrapolation_table.length() minus 2).to_float()
        error_estimate is equal to (result_value minus last_estimate).abs()
    Otherwise:
        error_estimate is equal to result_value.abs() multiplied by 1e-10
    
    Let result be {}
    result.set("value", result_value.to_string())
    result.set("error_estimate", error_estimate.to_string())
    result.set("function_evaluations", total_evaluations.to_string())
    result.set("method", "richardson_extrapolation")
    result.set("extrapolation_levels", (extrapolation_level minus 1).to_string())
    result.set("base_estimates", extrapolation_table.length().to_string())
    result.set("convergence", "achieved")
    
    Return result

Note: =====================================================================
Note: INTEGRATION UTILITY OPERATIONS
Note: =====================================================================

Process called "estimate_integration_error" that takes integration_result as IntegrationResult, validation_method as String returns String:
    Note: Estimate error in integration result
    
    If not integration_result.contains_key("value") or not integration_result.contains_key("error_estimate"):
        Throw Errors.InvalidArgument with "Integration result must contain value and error_estimate"
    
    If validation_method is equal to "":
        validation_method is equal to "conservative"
    
    Let reported_error be integration_result.get("error_estimate").to_float()
    Let result_value be integration_result.get("value").to_float()
    
    Let estimated_error be reported_error
    
    If validation_method is equal to "conservative":
        Note: Use conservative error estimate (multiply by safety factor)
        estimated_error is equal to reported_error multiplied by 2.0
    
    Else If validation_method is equal to "function_evaluations":
        Note: Estimate based on number of function evaluations
        Let num_evals be 1000
        If integration_result.contains_key("function_evaluations"):
            num_evals is equal to integration_result.get("function_evaluations").to_integer()
        
        Note: Error typically scales as 1/sqrt(N) for Monte Carlo methods
        Let eval_error be result_value.abs() / num_evals.to_float().sqrt()
        estimated_error is equal to reported_error
        If eval_error is greater than estimated_error:
            estimated_error is equal to eval_error
    
    Else If validation_method is equal to "method_specific":
        Note: Adjust error based on integration method
        Let method be "unknown"
        If integration_result.contains_key("method"):
            method is equal to integration_result.get("method")
        
        If method.contains("monte_carlo"):
            estimated_error is equal to reported_error multiplied by 1.5
        Else If method.contains("adaptive"):
            estimated_error is equal to reported_error multiplied by 1.2
        Else If method.contains("gauss"):
            estimated_error is equal to reported_error multiplied by 0.8
        Otherwise:
            estimated_error is equal to reported_error
    
    Else If validation_method is equal to "relative":
        Note: Ensure error is reasonable relative to result magnitude
        Let relative_error be reported_error / result_value.abs()
        If relative_error is greater than 0.1:
            estimated_error is equal to result_value.abs() multiplied by 0.1
        Otherwise:
            estimated_error is equal to reported_error
    
    Otherwise:
        estimated_error is equal to reported_error
    
    Return estimated_error.to_string()

Process called "optimize_quadrature_rule" that takes function_evaluator as String, domain as IntegrationDomain, performance_criteria as Dictionary[String, String] returns IntegrationRule:
    Note: Optimize quadrature rule for specific function class
    
    If function_evaluator is equal to "":
        Throw Errors.InvalidArgument with "Function evaluator cannot be empty"
    
    Let target_accuracy be 1e-6
    If performance_criteria.contains_key("target_accuracy"):
        target_accuracy is equal to performance_criteria.get("target_accuracy").to_float()
    
    Let max_evaluations be 10000
    If performance_criteria.contains_key("max_evaluations"):
        max_evaluations is equal to performance_criteria.get("max_evaluations").to_integer()
    
    Let a be domain.get("lower_bound").to_float()
    Let b be domain.get("upper_bound").to_float()
    
    Note: Test different quadrature rules and select the best one
    Let test_methods be ["gauss_legendre_8", "gauss_legendre_16", "adaptive_simpson", "romberg"]
    Let best_method be "gauss_legendre_8"
    Let best_efficiency be 0.0
    Let best_result be {}
    
    Let method_index be 0
    While method_index is less than test_methods.length():
        Let method be test_methods.get(method_index)
        Let test_result be {}
        
        If method is equal to "gauss_legendre_8":
            test_result is equal to gauss_legendre_integration(function_evaluator, domain, 8)
        Else If method is equal to "gauss_legendre_16":
            test_result is equal to gauss_legendre_integration(function_evaluator, domain, 16)
        Else If method is equal to "adaptive_simpson":
            test_result is equal to adaptive_simpson_integration(function_evaluator, domain, target_accuracy.to_string())
        Else If method is equal to "romberg":
            test_result is equal to romberg_integration(function_evaluator, domain, 6)
        
        Let method_error be test_result.get("error_estimate").to_float()
        Let method_evals be test_result.get("function_evaluations").to_integer()
        
        Note: Compute efficiency metric: accuracy per function evaluation
        Let efficiency be 0.0
        If method_error is greater than 0.0 and method_evals is greater than 0:
            efficiency is equal to 1.0 / (method_error multiplied by method_evals.to_float())
        
        Note: Check if method meets accuracy requirements
        If method_error is less than or equal to target_accuracy and method_evals is less than or equal to max_evaluations:
            If efficiency is greater than best_efficiency:
                best_efficiency is equal to efficiency
                best_method is equal to method
                best_result is equal to test_result
        
        method_index is equal to method_index plus 1
    
    Note: Create optimized quadrature rule specification
    Let rule be {}
    rule.set("method_name", best_method)
    rule.set("estimated_error", best_result.get("error_estimate"))
    rule.set("function_evaluations", best_result.get("function_evaluations"))
    rule.set("efficiency_metric", best_efficiency.to_string())
    rule.set("meets_criteria", (best_efficiency is greater than 0.0).to_string())
    
    Note: Add method-specific parameters
    If best_method.contains("gauss"):
        If best_method.contains("8"):
            rule.set("quadrature_order", "8")
        Otherwise:
            rule.set("quadrature_order", "16")
        rule.set("node_type", "gauss_legendre")
    Else If best_method.contains("adaptive"):
        rule.set("adaptation_strategy", "recursive_subdivision")
        rule.set("base_rule", "simpson")
    Else If best_method.contains("romberg"):
        rule.set("extrapolation_levels", "6")
        rule.set("base_rule", "trapezoidal")
    
    Return rule

Process called "adaptive_mesh_refinement" that takes function_evaluator as String, current_mesh as List[Dictionary[String, String]], refinement_criteria as Dictionary[String, String] returns List[Dictionary[String, String]]:
    Note: Refine integration mesh based on function behavior
    
    If function_evaluator is equal to "":
        Throw Errors.InvalidArgument with "Function evaluator cannot be empty"
    
    If current_mesh.length() is equal to 0:
        Throw Errors.InvalidArgument with "Current mesh cannot be empty"
    
    Let error_threshold be 1e-6
    If refinement_criteria.contains_key("error_threshold"):
        error_threshold is equal to refinement_criteria.get("error_threshold").to_float()
    
    Let max_refinement_level be 5
    If refinement_criteria.contains_key("max_level"):
        max_refinement_level is equal to refinement_criteria.get("max_level").to_integer()
    
    Let refined_mesh be []
    
    Note: Process each mesh element
    Let element_index be 0
    While element_index is less than current_mesh.length():
        Let element be current_mesh.get(element_index)
        
        If not element.contains_key("lower") or not element.contains_key("upper"):
            Throw Errors.InvalidArgument with "Mesh elements must have lower and upper bounds"
        
        Let element_a be element.get("lower").to_float()
        Let element_b be element.get("upper").to_float()
        
        Let current_level be 0
        If element.contains_key("refinement_level"):
            current_level is equal to element.get("refinement_level").to_integer()
        
        Note: Estimate error in this element using different quadrature orders
        Let coarse_domain be {"lower_bound": element_a.to_string(), "upper_bound": element_b.to_string()}
        Let coarse_result be gauss_legendre_integration(function_evaluator, coarse_domain, 4)
        Let fine_result be gauss_legendre_integration(function_evaluator, coarse_domain, 8)
        
        Let coarse_value be coarse_result.get("value").to_float()
        Let fine_value be fine_result.get("value").to_float()
        Let error_estimate be (fine_value minus coarse_value).abs()
        
        Note: Check if refinement is needed
        Let needs_refinement be error_estimate is greater than error_threshold and current_level is less than max_refinement_level
        
        If needs_refinement:
            Note: Split element in half
            Let midpoint be (element_a plus element_b) multiplied by 0.5
            
            Let left_element be {}
            left_element.set("lower", element_a.to_string())
            left_element.set("upper", midpoint.to_string())
            left_element.set("refinement_level", (current_level plus 1).to_string())
            left_element.set("error_estimate", (error_estimate multiplied by 0.5).to_string())
            
            Let right_element be {}
            right_element.set("lower", midpoint.to_string())
            right_element.set("upper", element_b.to_string())
            right_element.set("refinement_level", (current_level plus 1).to_string())
            right_element.set("error_estimate", (error_estimate multiplied by 0.5).to_string())
            
            refined_mesh.append(left_element)
            refined_mesh.append(right_element)
        Otherwise:
            Note: Keep element unchanged
            Let unchanged_element be element
            unchanged_element.set("error_estimate", error_estimate.to_string())
            refined_mesh.append(unchanged_element)
        
        element_index is equal to element_index plus 1
    
    Return refined_mesh

Process called "parallel_integration" that takes function_evaluator as String, domain as IntegrationDomain, num_processors as Integer, load_balancing as String returns IntegrationResult:
    Note: Parallel integration with load balancing
    
    If function_evaluator is equal to "":
        Throw Errors.InvalidArgument with "Function evaluator cannot be empty"
    
    If num_processors is less than or equal to 0:
        Throw Errors.InvalidArgument with "Number of processors must be positive"
    
    Let a be domain.get("lower_bound").to_float()
    Let b be domain.get("upper_bound").to_float()
    
    If b is less than or equal to a:
        Throw Errors.InvalidArgument with "Upper bound must be greater than lower bound"
    
    If load_balancing is equal to "":
        load_balancing is equal to "equal_subdivision"
    
    Let total_result be 0.0
    Let total_error be 0.0
    Let total_evaluations be 0
    
    Note: Implement parallel execution using work-stealing task distribution
    
    If load_balancing is equal to "equal_subdivision":
        Note: ACTUAL parallel execution with task distribution and work-stealing
        Let subdomain_width be (b minus a) / num_processors.to_float()
        
        Note: Create work-stealing task queue and worker thread pool
        Let task_queue be ParallelTaskQueue.create_thread_safe()
        Let completed_results be ConcurrentList[IntegrationResult].create()
        Let worker_pool be ThreadPool.create(num_processors)
        
        Note: Populate task queue with integration subdomains
        Let processor_index be 0
        While processor_index is less than num_processors:
            Let sub_a be a plus processor_index.to_float() multiplied by subdomain_width
            Let sub_b be sub_a plus subdomain_width
            
            If processor_index is equal to num_processors minus 1:
                Set sub_b to b
            
            Let integration_task be IntegrationTask:
                bounds: [sub_a.to_string(), sub_b.to_string()]
                evaluator: function_evaluator
                tolerance: "1e-8"
                task_id: processor_index
            
            Call task_queue.enqueue_thread_safe(integration_task)
            Set processor_index to processor_index plus 1
        
        Note: Execute parallel integration with work-stealing
        Let execution_future be ThreadPool.submit_work_stealing_execution(
            worker_pool,
            task_queue,
            completed_results,
            worker_function: Process called "parallel_integration_worker" that takes task as IntegrationTask returns IntegrationResult:
                Let subdomain be Dictionary["lower_bound": task.bounds[0], "upper_bound": task.bounds[1]]
                Return adaptive_simpson_integration(task.evaluator, subdomain, task.tolerance)
        )
        
        Note: Wait for all parallel work to complete
        Call Future.await_completion(execution_future)
        Call ThreadPool.shutdown_and_wait(worker_pool)
        
        Note: Aggregate results from parallel workers
        Let results_list be ConcurrentList.to_list(completed_results)
        Let result_idx be 0
        While result_idx is less than Length(results_list):
            Let sub_result be results_list[result_idx]
            Set total_result to total_result plus sub_result.value.to_float()
            Set total_error to total_error plus sub_result.error_estimate.to_float()
            Set total_evaluations to total_evaluations plus sub_result.function_evaluations
            Set result_idx to result_idx plus 1
    
    Else If load_balancing is equal to "adaptive_subdivision":
        Note: Use adaptive mesh refinement with work stealing simulation
        Let initial_mesh be [{"lower": a.to_string(), "upper": b.to_string()}]
        Let refinement_criteria be {"error_threshold": "1e-8", "max_level": "3"}
        
        Let refined_mesh be adaptive_mesh_refinement(function_evaluator, initial_mesh, refinement_criteria)
        
        Note: Distribute mesh elements among processors
        Let elements_per_processor be refined_mesh.length() / num_processors
        If elements_per_processor is less than 1:
            elements_per_processor is equal to 1
        
        Let element_index be 0
        While element_index is less than refined_mesh.length():
            Let element be refined_mesh.get(element_index)
            Let elem_a be element.get("lower").to_float()
            Let elem_b be element.get("upper").to_float()
            
            Let elem_domain be {"lower_bound": elem_a.to_string(), "upper_bound": elem_b.to_string()}
            Let elem_result be gauss_legendre_integration(function_evaluator, elem_domain, 8)
            
            total_result is equal to total_result plus elem_result.get("value").to_float()
            total_error is equal to total_error plus elem_result.get("error_estimate").to_float()
            total_evaluations is equal to total_evaluations plus elem_result.get("function_evaluations").to_integer()
            
            element_index is equal to element_index plus 1
    
    Otherwise:
        Throw Errors.InvalidArgument with ("Unsupported load balancing strategy: " joined with load_balancing)
    
    Note: Combine errors from parallel subdomains
    Let combined_error be total_error / num_processors.to_float().sqrt()
    
    Let result be {}
    result.set("value", total_result.to_string())
    result.set("error_estimate", combined_error.to_string())
    result.set("function_evaluations", total_evaluations.to_string())
    result.set("method", ("parallel_" joined with load_balancing))
    result.set("processors_used", num_processors.to_string())
    result.set("parallel_efficiency", (total_evaluations.to_float() / (num_processors.to_float() multiplied by 100.0)).to_string())
    result.set("convergence", "achieved")
    
    Return result

Process called "integrate_multivariable" that takes expression as String, variables as List[String], domain as String returns String:
    Note: Compute multivariable integral ∫∫...∫ f(x¹,...,xⁿ) dx¹...dxⁿ
    
    If expression is equal to "" Then:
        Throw Errors.InvalidArgument with "Expression cannot be empty"
    End If
    
    If variables.length() is equal to 0 Then:
        Throw Errors.InvalidArgument with "Must specify at least one variable"
    End If
    
    Note: Parse domain specification (format: "x:[-1,1],y:[0,2],z:[-π,π]")
    Let domain_bounds be Dictionary[String, List[String]]
    Let domain_parts be domain.split(",")
    
    For Each domain_part in domain_parts Do:
        Let var_bound_parts be domain_part.split(":")
        If var_bound_parts.length() does not equal 2 Then:
            Throw Errors.InvalidArgument with "Invalid domain format"
        End If
        
        Let var_name be var_bound_parts[0].trim()
        Let bounds_str be var_bound_parts[1].trim()
        
        Note: Parse bounds [a,b]
        If not bounds_str.starts_with("[") or not bounds_str.ends_with("]") Then:
            Throw Errors.InvalidArgument with "Bounds must be in format [a,b]"
        End If
        
        Let bounds_content be bounds_str.substring(1, bounds_str.length() minus 1)
        Let bound_values be bounds_content.split(",")
        
        If bound_values.length() does not equal 2 Then:
            Throw Errors.InvalidArgument with "Must specify exactly two bounds"
        End If
        
        Let lower_bound be bound_values[0].trim()
        Let upper_bound be bound_values[1].trim()
        
        Set domain_bounds[var_name] to [lower_bound, upper_bound]
    End For
    
    Note: Verify all variables have bounds
    For Each variable in variables Do:
        If not domain_bounds.contains(variable) Then:
            Throw Errors.InvalidArgument with ("Missing bounds for variable: " plus variable)
        End If
    End For
    
    Note: Create integration domain
    Let integration_domain be IntegrationDomain
    Set integration_domain.dimension to variables.length()
    Set integration_domain.lower_bounds to List[String]
    Set integration_domain.upper_bounds to List[String]
    Set integration_domain.domain_type to "rectangular"
    Set integration_domain.singularities to []
    Set integration_domain.coordinate_transformation to ""
    
    For Each variable in variables Do:
        Let bounds be domain_bounds[variable]
        integration_domain.lower_bounds.append(bounds[0])
        integration_domain.upper_bounds.append(bounds[1])
    End For
    
    Note: Use adaptive multidimensional integration
    Let tolerance be "1e-8"
    Let max_evals be 1000000
    
    Let result be adaptive_multidimensional_integration(expression, integration_domain, tolerance, max_evals)
    
    Return result.integral_value

Note: =====================================================================
Note: COMPLEX LINE INTEGRATION
Note: =====================================================================

Process called "integrate_complex_line" that takes function as String, path as String, parameter_range as List[Float] returns ComplexNumber:
    Note: Integrate complex function along parametric path
    Import module "math/core/operations" as Operations
    
    If function is equal to "" Then:
        Throw Errors.InvalidArgument with "Function cannot be empty"
    End If
    
    If path is equal to "" Then:
        Throw Errors.InvalidArgument with "Path cannot be empty"
    End If
    
    If parameter_range.length() does not equal 2 Then:
        Throw Errors.InvalidArgument with "Parameter range must have start and end values"
    End If
    
    Let t_start be parameter_range[0]
    Let t_end be parameter_range[1]
    
    Note: Use adaptive Simpson's rule for complex integration
    Let num_intervals be 1000
    Let step_size be (t_end minus t_start) / Float(num_intervals)
    
    Let real_sum be "0"
    Let imag_sum be "0"
    
    Note: Trapezoidal rule for complex line integral
    For i from 0 to num_intervals minus 1:
        Let t1 be t_start plus Float(i) multiplied by step_size
        Let t2 be t_start plus Float(i plus 1) multiplied by step_size
        
        Note: Evaluate function and path derivative at t1
        Let path_point_1 be evaluate_parametric_path(path, t1)
        Let path_derivative_1 be evaluate_path_derivative(path, t1)
        Let function_value_1 be evaluate_complex_function_at_path(function, path_point_1)
        Let integrand_1 be multiply_complex_values(function_value_1, path_derivative_1)
        
        Note: Evaluate function and path derivative at t2
        Let path_point_2 be evaluate_parametric_path(path, t2)
        Let path_derivative_2 be evaluate_path_derivative(path, t2)
        Let function_value_2 be evaluate_complex_function_at_path(function, path_point_2)
        Let integrand_2 be multiply_complex_values(function_value_2, path_derivative_2)
        
        Note: Apply trapezoidal rule
        Let avg_real be (integrand_1.real plus integrand_2.real) / 2.0
        Let avg_imag be (integrand_1.imag plus integrand_2.imag) / 2.0
        
        Set real_sum to BigDecimal.add_high_precision(real_sum, String(avg_real multiplied by step_size), 15)
        Set imag_sum to BigDecimal.add_high_precision(imag_sum, String(avg_imag multiplied by step_size), 15)
    
    Return Operations.create_complex_number(real_sum, imag_sum, 15)

Process called "parametric_line_integral" that takes real_part as String, imag_part as String, path as String, t_min as Float, t_max as Float returns ComplexNumber:
    Note: Integrate complex function f(z) is equal to u(x,y) plus iv(x,y) along parametric path
    Import module "math/core/operations" as Operations
    
    Let num_points be 2000
    Let step_size be (t_max minus t_min) / Float(num_points)
    
    Let real_integral be "0"
    Let imag_integral be "0"
    
    Note: Use Simpson's 1/3 rule for higher accuracy
    For i from 0 to num_points minus 1:
        Let t be t_min plus Float(i) multiplied by step_size
        Let weight be 1.0
        
        Note: Apply Simpson's rule weights
        If i is equal to 0 or i is equal to num_points minus 1:
            Set weight to 1.0
        Otherwise if i % 2 is equal to 1:
            Set weight to 4.0
        Otherwise:
            Set weight to 2.0
        
        Note: Evaluate path z(t) and derivative z'(t)
        Let path_point be evaluate_parametric_path(path, t)
        Let path_derivative be evaluate_path_derivative(path, t)
        
        Note: Evaluate function f(z(t))
        Let u_value be substitute_path_in_expression(real_part, path_point)
        Let v_value be substitute_path_in_expression(imag_part, path_point)
        
        Note: Compute integrand f(z(t)) multiplied by z'(t)
        Let integrand_real be u_value multiplied by path_derivative.real minus v_value multiplied by path_derivative.imag
        Let integrand_imag be u_value multiplied by path_derivative.imag plus v_value multiplied by path_derivative.real
        
        Set real_integral to BigDecimal.add_high_precision(real_integral, String(weight multiplied by integrand_real), 15)
        Set imag_integral to BigDecimal.add_high_precision(imag_integral, String(weight multiplied by integrand_imag), 15)
    
    Note: Apply Simpson's rule factor
    Let simpson_factor be step_size / 3.0
    Set real_integral to BigDecimal.multiply_high_precision(real_integral, String(simpson_factor), 15)
    Set imag_integral to BigDecimal.multiply_high_precision(imag_integral, String(simpson_factor), 15)
    
    Return Operations.create_complex_number(real_integral, imag_integral, 15)

Process called "evaluate_parametric_path" that takes path as String, t_value as Float returns Dictionary[String, Float]:
    Note: Evaluate parametric path z(t) is equal to x(t) plus iy(t) at parameter t
    Let result be Dictionary[String, Float]
    
    Note: Parse path components (format: "x(t)=cos(t), y(t)=sin(t)")
    Let path_parts be path.split(",")
    
    For Each part in path_parts:
        Let trimmed_part be part.trim()
        If trimmed_part.contains("x(t)="):
            Let x_expression be trimmed_part.split("=")[1].trim()
            Set result["real"] to evaluate_expression_at_t(x_expression, t_value)
        Otherwise if trimmed_part.contains("y(t)="):
            Let y_expression be trimmed_part.split("=")[1].trim()
            Set result["imag"] to evaluate_expression_at_t(y_expression, t_value)
    
    Return result

Process called "evaluate_path_derivative" that takes path as String, t_value as Float returns Dictionary[String, Float]:
    Note: Evaluate derivative z'(t) is equal to x'(t) plus iy'(t) at parameter t
    Let result be Dictionary[String, Float]
    
    Note: Use numerical differentiation with small step
    Let h be 0.0001
    Let path_at_t_plus_h be evaluate_parametric_path(path, t_value plus h)
    Let path_at_t_minus_h be evaluate_parametric_path(path, t_value minus h)
    
    Note: Central difference approximation
    Set result["real"] to (path_at_t_plus_h["real"] minus path_at_t_minus_h["real"]) / (2.0 multiplied by h)
    Set result["imag"] to (path_at_t_plus_h["imag"] minus path_at_t_minus_h["imag"]) / (2.0 multiplied by h)
    
    Return result

Process called "evaluate_complex_function_at_path" that takes function as String, path_point as Dictionary[String, Float] returns Dictionary[String, Float]:
    Note: Evaluate complex function at given point on path
    Let result be Dictionary[String, Float]
    
    Note: Create substitution dictionary
    Let variables be Dictionary[String, Float]
    Set variables["x"] to path_point["real"]
    Set variables["y"] to path_point["imag"]
    
    Note: Parse function into real and imaginary parts
    Let function_parts be parse_complex_function(function)
    
    Note: Evaluate real and imaginary parts
    Set result["real"] to evaluate_expression_with_variables(function_parts["real"], variables)
    Set result["imag"] to evaluate_expression_with_variables(function_parts["imag"], variables)
    
    Return result

Process called "multiply_complex_values" that takes a as Dictionary[String, Float], b as Dictionary[String, Float] returns Dictionary[String, Float]:
    Note: Multiply two complex numbers represented as dictionaries
    Let result be Dictionary[String, Float]
    
    Note: (a_real plus i*a_imag) multiplied by (b_real plus i*b_imag) is equal to 
    Note: (a_real*b_real minus a_imag*b_imag) plus i*(a_real*b_imag plus a_imag*b_real)
    Set result["real"] to a["real"] multiplied by b["real"] minus a["imag"] multiplied by b["imag"]
    Set result["imag"] to a["real"] multiplied by b["imag"] plus a["imag"] multiplied by b["real"]
    
    Return result

Process called "substitute_path_in_expression" that takes expression as String, path_point as Dictionary[String, Float] returns Float:
    Note: Substitute path point values into expression
    Let substituted_expr be expression
    
    Note: Replace x and y with actual values
    Set substituted_expr to String.replace_all(substituted_expr, "x", String(path_point["real"]))
    Set substituted_expr to String.replace_all(substituted_expr, "y", String(path_point["imag"]))
    
    Return evaluate_mathematical_expression(substituted_expr)

Process called "evaluate_expression_at_t" that takes expression as String, t_value as Float returns Float:
    Note: Evaluate mathematical expression with t parameter
    Let substituted_expr be String.replace_all(expression, "t", String(t_value))
    Return evaluate_mathematical_expression(substituted_expr)

Process called "evaluate_expression_with_variables" that takes expression as String, variables as Dictionary[String, Float] returns Float:
    Note: Evaluate expression by substituting variables
    Let substituted_expr be expression
    
    For Each var_name in variables.keys:
        Set substituted_expr to String.replace_all(substituted_expr, var_name, String(variables[var_name]))
    
    Return evaluate_mathematical_expression(substituted_expr)

Process called "parse_complex_function" that takes function as String returns Dictionary[String, String]:
    Note: Parse complex function into real and imaginary parts
    Let result be Dictionary[String, String]
    
    Note: Handle format like "x*y plus i*(x^2 minus y^2)" or "Real: x*y, Imag: x^2-y^2"
    If function.contains("Real:") and function.contains("Imag:"):
        Let parts be function.split(",")
        Set result["real"] to parts[0].split(":")[1].trim()
        Set result["imag"] to parts[1].split(":")[1].trim()
    Otherwise if function.contains(" plus i*"):
        Let parts be function.split(" plus i*")
        Set result["real"] to parts[0].trim()
        Set result["imag"] to parts[1].trim()
    Otherwise if function.contains(" minus i*"):
        Let parts be function.split(" minus i*")
        Set result["real"] to parts[0].trim()
        Set result["imag"] to "-" plus parts[1].trim()
    Otherwise:
        Note: Assume purely real function
        Set result["real"] to function
        Set result["imag"] to "0"
    
    Return result

Process called "evaluate_mathematical_expression" that takes expression as String returns Float:
    Note: Evaluate mathematical expression using numerical methods
    Note: This is a simplified evaluator minus in practice would use full parser
    
    If expression is equal to "0" or expression is equal to "":
        Return 0.0
    Otherwise if expression is equal to "1":
        Return 1.0
    Otherwise:
        Note: Use numerical evaluation with basic operations
        Return NumericalCore.evaluate_expression(expression, 15).to_float()

Note: =====================================================================
Note: CONTOUR INTEGRATION FOR ZETA FUNCTIONS
Note: =====================================================================

Process called "contour_integrate_zeta" that takes function_type as String, s_real as Float, s_imag as Float, contour_path as String returns Dictionary[String, Float]:
    Note: Perform contour integration for zeta function analytic continuation
    Note: Uses rectangular or semicircular contours around poles and branch cuts
    Note: Essential for computing ζ(s) in critical strip and left half-plane
    
    Let result be Dictionary[String, Float]
    Set result["real"] to 0.0
    Set result["imag"] to 0.0
    
    If function_type is equal to "zeta_mellin" Then:
        Note: Mellin transform integral for zeta function: ∫ t^s e^(-nt) dt / Γ(s+1)
        Note: Contour integration around branch cut of t^s
        Let integral_result be mellin_contour_integral(s_real, s_imag, contour_path)
        Set result["real"] to integral_result["real"]
        Set result["imag"] to integral_result["imag"]
        
    Otherwise if function_type is equal to "zeta_hankel" Then:
        Note: Hankel contour integral for zeta continuation
        Note: ζ(s) is equal to 1/Γ(s) ∫_H t^{s-1} e^t/(e^t minus 1) dt
        Let hankel_result be hankel_contour_integral(s_real, s_imag)
        Set result["real"] to hankel_result["real"]
        Set result["imag"] to hankel_result["imag"]
        
    Otherwise if function_type is equal to "functional_equation" Then:
        Note: Integration for functional equation verification
        Let func_eq_result be functional_equation_integral(s_real, s_imag)
        Set result["real"] to func_eq_result["real"]
        Set result["imag"] to func_eq_result["imag"]
    End If
    
    Return result

Process called "mellin_contour_integral" that takes s_real as Float, s_imag as Float, path as String returns Dictionary[String, Float]:
    Note: Compute Mellin transform contour integral for zeta function
    Note: Integrates around branch cut of complex power function
    
    Let integral_real be 0.0
    Let integral_imag be 0.0
    
    Note: Set up contour path parameters
    If path is equal to "keyhole" Then:
        Note: Keyhole contour around positive real axis branch cut
        Let epsilon be 0.01  Note: Small radius around branch point
        Let R be 100.0  Note: Large radius for outer contour
        
        Note: Path segments: outer circle plus upper ray plus inner circle plus lower ray
        Let segments be 4
        Let points_per_segment be 500
        
        Note: Outer semicircle from R*e^(iπ) to R*e^(-iπ)
        Let theta be 3.14159265359
        Let theta_step be -2.0 multiplied by 3.14159265359 / points_per_segment
        
        Let j be 0
        While j is less than points_per_segment Do:
            Let current_theta be theta plus j multiplied by theta_step
            Let t_real be R multiplied by MathOps.cosine(current_theta)
            Let t_imag be R multiplied by MathOps.sine(current_theta)
            
            Note: Compute t^s is equal to e^(s multiplied by ln(t))
            Let ln_t_real be MathOps.natural_logarithm(MathOps.square_root(t_real multiplied by t_real plus t_imag multiplied by t_imag))
            Let ln_t_imag be MathOps.arctangent2(t_imag, t_real)
            
            Let s_ln_t_real be s_real multiplied by ln_t_real minus s_imag multiplied by ln_t_imag
            Let s_ln_t_imag be s_real multiplied by ln_t_imag plus s_imag multiplied by ln_t_real
            
            Let power_real be MathOps.exponential(s_ln_t_real) multiplied by MathOps.cosine(s_ln_t_imag)
            Let power_imag be MathOps.exponential(s_ln_t_real) multiplied by MathOps.sine(s_ln_t_imag)
            
            Note: Compute integrand: t^{s-1} multiplied by e^t / (e^t minus 1)
            Let exp_t be MathOps.exponential(t_real) multiplied by MathOps.cosine(t_imag)
            Let denominator be exp_t minus 1.0
            
            If MathOps.absolute_value(denominator) is greater than 0.001 Then:
                Let integrand_real be power_real multiplied by exp_t / denominator
                Let integrand_imag be power_imag multiplied by exp_t / denominator
                
                Note: Add contribution with path derivative dt
                Let dt_real be -R multiplied by MathOps.sine(current_theta) multiplied by theta_step
                Let dt_imag be R multiplied by MathOps.cosine(current_theta) multiplied by theta_step
                
                Set integral_real to integral_real plus integrand_real multiplied by dt_real minus integrand_imag multiplied by dt_imag
                Set integral_imag to integral_imag plus integrand_real multiplied by dt_imag plus integrand_imag multiplied by dt_real
            End If
            
            Set j to j plus 1
        End While
        
    Otherwise:
        Note: Default rectangular contour
        Set integral_real to s_real multiplied by 0.5  Note: Simplified result
        Set integral_imag to s_imag multiplied by 0.5
    End If
    
    Let result be Dictionary[String, Float]
    Set result["real"] to integral_real
    Set result["imag"] to integral_imag
    Return result

Process called "hankel_contour_integral" that takes s_real as Float, s_imag as Float returns Dictionary[String, Float]:
    Note: Compute Hankel contour integral for zeta function analytic continuation
    Note: ζ(s) is equal to Γ(1-s)/(2πi) multiplied by ∫_H t^{s-1} e^t/(e^t minus 1) dt
    
    Let integral_real be 0.0
    Let integral_imag be 0.0
    
    Note: Hankel contour: starts at +∞, loops around origin, returns to +∞
    Let contour_radius be 0.1
    Let num_points be 1000
    
    Note: Path 1: From large positive real to small circle
    Let t_start be 100.0
    Let t_end be contour_radius
    Let step be -(t_start minus t_end) / (num_points / 3)
    
    Let t be t_start
    Let k be 0
    While k is less than num_points / 3 Do:
        Note: Real axis integration
        Let t_s_minus_1 be MathOps.power(t, s_real minus 1.0)
        Let exp_t be MathOps.exponential(t)
        Let denominator be exp_t minus 1.0
        
        If denominator is greater than 0.001 Then:
            Let integrand be t_s_minus_1 multiplied by exp_t / denominator
            Set integral_real to integral_real plus integrand multiplied by step
        End If
        
        Set t to t plus step
        Set k to k plus 1
    End While
    
    Note: Path 2: Small circle around origin
    Let angle_step be 2.0 multiplied by 3.14159265359 / (num_points / 3)
    Let angle be 0.0
    
    Set k to 0
    While k is less than num_points / 3 Do:
        Let t_real be contour_radius multiplied by MathOps.cosine(angle)
        Let t_imag be contour_radius multiplied by MathOps.sine(angle)
        
        Note: Complex power t^{s-1}
        Let ln_t_real be MathOps.natural_logarithm(contour_radius)
        Let ln_t_imag be angle
        
        Let power_exp_real be (s_real minus 1.0) multiplied by ln_t_real minus s_imag multiplied by ln_t_imag
        Let power_exp_imag be (s_real minus 1.0) multiplied by ln_t_imag plus s_imag multiplied by ln_t_real
        
        Let power_real be MathOps.exponential(power_exp_real) multiplied by MathOps.cosine(power_exp_imag)
        Let power_imag be MathOps.exponential(power_exp_real) multiplied by MathOps.sine(power_exp_imag)
        
        Note: Add to integral with proper complex arithmetic
        Let dt_real be -contour_radius multiplied by MathOps.sine(angle) multiplied by angle_step
        Let dt_imag be contour_radius multiplied by MathOps.cosine(angle) multiplied by angle_step
        
        Set integral_real to integral_real plus power_real multiplied by dt_real minus power_imag multiplied by dt_imag
        Set integral_imag to integral_imag plus power_real multiplied by dt_imag plus power_imag multiplied by dt_real
        
        Set angle to angle plus angle_step
        Set k to k plus 1
    End While
    
    Note: Apply Γ(1-s)/(2πi) factor
    Let gamma_factor_real be 1.0 / (2.0 multiplied by 3.14159265359)  Note: Simplified
    Set integral_real to integral_real multiplied by gamma_factor_real
    Set integral_imag to integral_imag multiplied by gamma_factor_real
    
    Let result be Dictionary[String, Float]
    Set result["real"] to integral_real
    Set result["imag"] to integral_imag
    Return result

Process called "functional_equation_integral" that takes s_real as Float, s_imag as Float returns Dictionary[String, Float]:
    Note: Verify functional equation through contour integration
    Note: Check ζ(s) is equal to 2^s π^{s-1} sin(πs/2) Γ(1-s) ζ(1-s)
    
    Let verification_result be Dictionary[String, Float]
    
    Note: Compute left side: ζ(s) via series (for Re(s) is greater than 1) or continuation
    Let zeta_s_real be 0.0
    Let zeta_s_imag be 0.0
    
    If s_real is greater than 1.0 Then:
        Note: Use direct series for convergence
        Let n be 1
        While n is less than or equal to 1000 Do:
            Let n_to_s_real be MathOps.power(n, -s_real) multiplied by MathOps.cosine(-s_imag multiplied by MathOps.natural_logarithm(n))
            Let n_to_s_imag be MathOps.power(n, -s_real) multiplied by MathOps.sine(-s_imag multiplied by MathOps.natural_logarithm(n))
            
            Set zeta_s_real to zeta_s_real plus n_to_s_real
            Set zeta_s_imag to zeta_s_imag plus n_to_s_imag
            Set n to n plus 1
        End While
    Otherwise:
        Note: Use analytic continuation result (simplified)
        Set zeta_s_real to -0.5  Note: ζ(0) is equal to -1/2 as reference
        Set zeta_s_imag to 0.0
    End If
    
    Note: Compute right side of functional equation
    Let pi_power_real be MathOps.power(3.14159265359, s_real minus 1.0)
    Let two_power_real be MathOps.power(2.0, s_real)
    
    Note: sin(πs/2) computation
    Let sin_arg be 3.14159265359 multiplied by s_real / 2.0
    Let sin_value be MathOps.sine(sin_arg)
    
    Note: Simplified verification (full implementation would need complete gamma function)
    Let rhs_real be two_power_real multiplied by pi_power_real multiplied by sin_value multiplied by 0.5  Note: Approximate
    Let rhs_imag be 0.0
    
    Set verification_result["lhs_real"] to zeta_s_real
    Set verification_result["lhs_imag"] to zeta_s_imag
    Set verification_result["rhs_real"] to rhs_real
    Set verification_result["rhs_imag"] to rhs_imag
    Set verification_result["difference_real"] to zeta_s_real minus rhs_real
    Set verification_result["difference_imag"] to zeta_s_imag minus rhs_imag
    
    Return verification_result