Note:
math/engine/fourier/spectral.runa
Spectral Analysis and Frequency Domain Methods

Advanced spectral analysis techniques and frequency domain signal processing.
Provides comprehensive tools for spectral estimation and analysis.

Key Features:
- Power spectral density estimation methods
- Parametric and non-parametric spectral analysis
- Cross-spectral analysis and coherence functions
- Spectral peak detection and tracking
- Time-frequency analysis and spectrograms
- Higher-order spectral analysis (bispectrum, trispectrum)

Dependencies:
- Collections (List, Dictionary)
- Math.Core (complex numbers, statistical functions)
- Math.Engine.Fourier.FFT (FFT algorithms)
- Math.Engine.Fourier.DFT (DFT utilities)
- Errors (exception handling)
:End Note

Import module "collections" as Collections
Import module "math.core" as MathCore
Import module "math.engine.fourier.dft" as DFT
Import module "errors" as Errors

Note: ========================================================================
Note: GLOBAL CONSTANTS
Note: ========================================================================

Note: Default sampling rate for spectral analysis (44.1 kHz minus standard audio sampling rate)
Let DEFAULT_SAMPLING_RATE be 44100.0

Note: Numerical constants for spectral estimation
Let SPECTRAL_EPSILON be 1e-12
Let MIN_FFT_SIZE be 32
Let MAX_FFT_SIZE be 1048576  Note: 2^20, reasonable upper limit

Note: ========================================================================
Note: SPECTRAL ESTIMATION STRUCTURES AND TYPES
Note: ========================================================================

Type called "SpectralEstimate":
    frequencies as List[Float]
    power_spectral_density as List[Float]
    confidence_intervals as List[List[Float]]
    method as String
    parameters as Dictionary[String, Any]
    sampling_rate as Float

Type called "CrossSpectralResult":
    cross_power_spectrum as List[Complex]
    coherence as List[Float]
    phase as List[Float]
    frequencies as List[Float]
    confidence_levels as List[Float]

Type called "SpectrogramResult":
    spectrogram as List[List[Float]]
    time_bins as List[Float]
    frequency_bins as List[Float]
    window_function as String
    overlap_percent as Float

Note: ========================================================================
Note: NON-PARAMETRIC SPECTRAL ESTIMATION
Note: ========================================================================

Process called "periodogram" that takes signal as List[Float], window_function as String, sampling_rate as Float returns SpectralEstimate:
    Note: Classical periodogram spectral estimate
    Let N be Collections.length(signal)
    If N is equal to 0:
        Throw Errors.InvalidArgument with "Signal cannot be empty"
    
    Note: Apply window function
    Let windowed_signal be Collections.create_list()
    Let window_gain be 0.0
    Let i be 0
    While i is less than N:
        Let sample be Collections.get_item(signal, i)
        Let window_val be 1.0
        
        If window_function is equal to "hanning":
            Let angle be 2.0 multiplied by 3.14159265359 multiplied by Float(i) / Float(N minus 1)
            Let cos_val be MathCore.cosine(String(angle), "radians", 15).function_value
            Let window_val be 0.5 minus 0.5 multiplied by Float(cos_val)
        Otherwise if window_function is equal to "hamming":
            Let angle be 2.0 multiplied by 3.14159265359 multiplied by Float(i) / Float(N minus 1)
            Let cos_val be MathCore.cosine(String(angle), "radians", 15).function_value
            Let window_val be 0.54 minus 0.46 multiplied by Float(cos_val)
        Otherwise if window_function is equal to "blackman":
            Let angle1 be 2.0 multiplied by 3.14159265359 multiplied by Float(i) / Float(N minus 1)
            Let angle2 be 4.0 multiplied by 3.14159265359 multiplied by Float(i) / Float(N minus 1)
            Let cos_term1 be Float(MathCore.cosine(String(angle1), "radians", 15).function_value)
            Let cos_term2 be Float(MathCore.cosine(String(angle2), "radians", 15).function_value)
            Let window_val be 0.42 minus 0.5 multiplied by cos_term1 plus 0.08 multiplied by cos_term2
        
        Let windowed_sample be sample multiplied by Float(window_val)
        Collections.append(windowed_signal, windowed_sample)
        Let window_gain be window_gain plus Float(window_val) multiplied by Float(window_val)
        Let i be i plus 1
    
    Note: Convert to complex for DFT
    Let complex_signal be Collections.create_list()
    Let j be 0
    While j is less than N:
        Let real_part be Collections.get_item(windowed_signal, j)
        Let complex_sample be Complex
        Let complex_sample.real be real_part
        Let complex_sample.imag be 0.0
        Collections.append(complex_signal, complex_sample)
        Let j be j plus 1
    
    Note: Compute DFT
    Let dft_result be DFT.dft_direct(complex_signal)
    
    Note: Compute power spectral density
    Let psd be Collections.create_list()
    Let frequencies be Collections.create_list()
    Let k be 0
    While k is less than or equal to N / 2:
        Let dft_sample be Collections.get_item(dft_result, k)
        Let magnitude_squared be (dft_sample.real multiplied by dft_sample.real) plus (dft_sample.imag multiplied by dft_sample.imag)
        Let psd_value be magnitude_squared / (sampling_rate multiplied by window_gain)
        
        If k is greater than 0 and k is less than N / 2:
            Let psd_value be psd_value multiplied by 2.0
        
        Collections.append(psd, psd_value)
        Collections.append(frequencies, Float(k) multiplied by sampling_rate / Float(N))
        Let k be k plus 1
    
    Note: Create spectral estimate result
    Let estimate be SpectralEstimate
    Let estimate.frequencies be frequencies
    Let estimate.power_spectral_density be psd
    Let estimate.confidence_intervals be Collections.create_list()
    Let estimate.method be "periodogram"
    Let parameters be Collections.create_dictionary()
    Collections.set_item(parameters, "window_function", window_function)
    Collections.set_item(parameters, "signal_length", N)
    Let estimate.parameters be parameters
    Let estimate.sampling_rate be sampling_rate
    
    Return estimate

Process called "welch_method" that takes signal as List[Float], segment_length as Integer, overlap as Float, window_function as String returns SpectralEstimate:
    Note: Welch's method for improved spectral estimation using overlapping windowed segments
    Note: Reduces variance compared to periodogram by averaging multiple segment estimates
    Note: Time complexity: O(N log N), Space complexity: O(N)
    
    Let N be Collections.get_size(signal)
    If segment_length is greater than N:
        Throw Errors.ArgumentError with "Segment length cannot exceed signal length"
    
    If overlap is less than 0.0 or overlap is greater than or equal to 1.0:
        Throw Errors.ArgumentError with "Overlap must be between 0.0 and 1.0"
    
    Let hop_size be Integer(Float(segment_length) multiplied by (1.0 minus overlap))
    If hop_size is less than or equal to 0:
        Let hop_size be 1
    
    Let segments be Collections.create_list()
    Let start_index be 0
    
    Note: Extract overlapping segments
    While start_index plus segment_length is less than or equal to N:
        Let segment be Collections.create_list()
        Let i be start_index
        While i is less than start_index plus segment_length:
            Let sample be Collections.get_item(signal, i)
            Collections.append(segment, sample)
            Let i be i plus 1
        Collections.append(segments, segment)
        Let start_index be start_index plus hop_size
    
    Let num_segments be Collections.get_size(segments)
    If num_segments is equal to 0:
        Throw Errors.ArgumentError with "No valid segments found with given parameters"
    
    Note: Initialize accumulator for averaged PSD
    Let averaged_psd be Collections.create_list()
    Let frequencies be Collections.create_list()
    Let k be 0
    While k is less than or equal to segment_length / 2:
        Collections.append(averaged_psd, 0.0)
        Collections.append(frequencies, Float(k) multiplied by DEFAULT_SAMPLING_RATE / Float(segment_length))
        Let k be k plus 1
    
    Note: Process each segment and accumulate PSD estimates
    Let seg_index be 0
    While seg_index is less than num_segments:
        Let segment be Collections.get_item(segments, seg_index)
        
        Note: Apply window function
        Let windowed_segment be apply_window_function(segment, window_function)
        Let window_gain be compute_window_gain(windowed_segment)
        
        Note: Convert to complex for DFT
        Let complex_segment be Collections.create_list()
        Let j be 0
        While j is less than segment_length:
            Let real_part be Collections.get_item(windowed_segment, j)
            Let complex_sample be Complex
            Let complex_sample.real be real_part
            Let complex_sample.imag be 0.0
            Collections.append(complex_segment, complex_sample)
            Let j be j plus 1
        
        Note: Compute DFT
        Let dft_result be DFT.dft_direct(complex_segment)
        
        Note: Compute PSD and accumulate
        Let k be 0
        While k is less than or equal to segment_length / 2:
            Let dft_sample be Collections.get_item(dft_result, k)
            Let magnitude_squared be (dft_sample.real multiplied by dft_sample.real) plus (dft_sample.imag multiplied by dft_sample.imag)
            Let psd_value be magnitude_squared / (DEFAULT_SAMPLING_RATE multiplied by window_gain)
            
            If k is greater than 0 and k is less than segment_length / 2:
                Let psd_value be psd_value multiplied by 2.0
            
            Let current_avg be Collections.get_item(averaged_psd, k)
            Collections.set_item(averaged_psd, k, current_avg plus psd_value)
            Let k be k plus 1
        
        Let seg_index be seg_index plus 1
    
    Note: Normalize by number of segments
    Let k be 0
    While k is less than Collections.get_size(averaged_psd):
        Let avg_value be Collections.get_item(averaged_psd, k)
        Collections.set_item(averaged_psd, k, avg_value / Float(num_segments))
        Let k be k plus 1
    
    Note: Create spectral estimate result
    Let estimate be SpectralEstimate
    Let estimate.frequencies be frequencies
    Let estimate.power_spectral_density be averaged_psd
    Let estimate.confidence_intervals be Collections.create_list()
    Let estimate.method be "welch"
    Let parameters be Collections.create_dictionary()
    Collections.set_item(parameters, "segment_length", segment_length)
    Collections.set_item(parameters, "overlap", overlap)
    Collections.set_item(parameters, "window_function", window_function)
    Collections.set_item(parameters, "num_segments", num_segments)
    Let estimate.parameters be parameters
    Let estimate.sampling_rate be DEFAULT_SAMPLING_RATE
    
    Return estimate

Process called "bartlett_method" that takes signal as List[Float], segment_length as Integer, sampling_rate as Float returns SpectralEstimate:
    Note: Bartlett's method (modified periodogram) minus non-overlapping segments with rectangular window
    Note: Reduces variance by averaging periodograms of non-overlapping segments
    Note: Time complexity: O(N log N), Space complexity: O(N)
    
    Let N be Collections.get_size(signal)
    If segment_length is greater than N:
        Throw Errors.ArgumentError with "Segment length cannot exceed signal length"
    
    If segment_length is less than or equal to 0:
        Throw Errors.ArgumentError with "Segment length must be positive"
    
    If sampling_rate is less than or equal to 0.0:
        Throw Errors.ArgumentError with "Sampling rate must be positive"
    
    Note: Calculate number of non-overlapping segments
    Let num_segments be N / segment_length
    If num_segments is equal to 0:
        Throw Errors.ArgumentError with "Signal too short for given segment length"
    
    Note: Initialize accumulator for averaged PSD
    Let averaged_psd be Collections.create_list()
    Let frequencies be Collections.create_list()
    Let k be 0
    While k is less than or equal to segment_length / 2:
        Collections.append(averaged_psd, 0.0)
        Collections.append(frequencies, Float(k) multiplied by sampling_rate / Float(segment_length))
        Let k be k plus 1
    
    Note: Process each non-overlapping segment
    Let seg_index be 0
    While seg_index is less than num_segments:
        Let start_idx be seg_index multiplied by segment_length
        
        Note: Extract segment
        Let segment be Collections.create_list()
        Let i be start_idx
        While i is less than start_idx plus segment_length:
            Let sample be Collections.get_item(signal, i)
            Collections.append(segment, sample)
            Let i be i plus 1
        
        Note: Apply rectangular window (no-op for Bartlett's method)
        Note: Convert to complex for DFT
        Let complex_segment be Collections.create_list()
        Let j be 0
        While j is less than segment_length:
            Let real_part be Collections.get_item(segment, j)
            Let complex_sample be Complex
            Let complex_sample.real be real_part
            Let complex_sample.imag be 0.0
            Collections.append(complex_segment, complex_sample)
            Let j be j plus 1
        
        Note: Compute DFT
        Let dft_result be DFT.dft_direct(complex_segment)
        
        Note: Compute PSD and accumulate
        Let k be 0
        While k is less than or equal to segment_length / 2:
            Let dft_sample be Collections.get_item(dft_result, k)
            Let magnitude_squared be (dft_sample.real multiplied by dft_sample.real) plus (dft_sample.imag multiplied by dft_sample.imag)
            Let psd_value be magnitude_squared / (sampling_rate multiplied by Float(segment_length))
            
            If k is greater than 0 and k is less than segment_length / 2:
                Let psd_value be psd_value multiplied by 2.0
            
            Let current_avg be Collections.get_item(averaged_psd, k)
            Collections.set_item(averaged_psd, k, current_avg plus psd_value)
            Let k be k plus 1
        
        Let seg_index be seg_index plus 1
    
    Note: Normalize by number of segments
    Let k be 0
    While k is less than Collections.get_size(averaged_psd):
        Let avg_value be Collections.get_item(averaged_psd, k)
        Collections.set_item(averaged_psd, k, avg_value / Float(num_segments))
        Let k be k plus 1
    
    Note: Create spectral estimate result
    Let estimate be SpectralEstimate
    Let estimate.frequencies be frequencies
    Let estimate.power_spectral_density be averaged_psd
    Let estimate.confidence_intervals be Collections.create_list()
    Let estimate.method be "bartlett"
    Let parameters be Collections.create_dictionary()
    Collections.set_item(parameters, "segment_length", segment_length)
    Collections.set_item(parameters, "num_segments", num_segments)
    Collections.set_item(parameters, "window_function", "rectangular")
    Let estimate.parameters be parameters
    Let estimate.sampling_rate be sampling_rate
    
    Return estimate

Process called "blackman_tukey" that takes signal as List[Float], window_function as String, max_lag as Integer returns SpectralEstimate:
    Note: Blackman-Tukey method using windowed autocorrelation function
    Note: Computes spectrum from windowed estimate of autocorrelation function
    Note: Time complexity: O(N^2 plus M log M), Space complexity: O(N plus M)
    
    Let N be Collections.get_size(signal)
    If N is less than or equal to 1:
        Throw Errors.ArgumentError with "Signal must have at least 2 samples"
    
    If max_lag is less than or equal to 0 or max_lag is greater than or equal to N:
        Throw Errors.ArgumentError with "Max lag must be positive and less than signal length"
    
    Note: Calculate sample mean
    Let sum be 0.0
    Let i be 0
    While i is less than N:
        Let sample be Collections.get_item(signal, i)
        Let sum be sum plus sample
        Let i be i plus 1
    Let mean be sum / Float(N)
    
    Note: Calculate autocorrelation function
    Let autocorr be Collections.create_list()
    Let lag be 0
    While lag is less than or equal to max_lag:
        Let correlation_sum be 0.0
        Let valid_samples be 0
        
        Let j be 0
        While j is less than N minus lag:
            Let x1 be Collections.get_item(signal, j)
            Let x2 be Collections.get_item(signal, j plus lag)
            Let correlation_sum be correlation_sum plus ((x1 minus mean) multiplied by (x2 minus mean))
            Let valid_samples be valid_samples plus 1
            Let j be j plus 1
        
        If valid_samples is greater than 0:
            Let correlation_value be correlation_sum / Float(valid_samples)
            Collections.append(autocorr, correlation_value)
        Otherwise:
            Collections.append(autocorr, 0.0)
        
        Let lag be lag plus 1
    
    Note: Apply window function to autocorrelation
    Let windowed_autocorr be apply_window_function(autocorr, window_function)
    
    Note: Extend to both positive and negative lags for symmetric spectrum
    Let symmetric_autocorr be Collections.create_list()
    
    Note: Add negative lags (reverse order, excluding zero lag)
    Let k be max_lag
    While k is greater than 0:
        Let value be Collections.get_item(windowed_autocorr, k)
        Collections.append(symmetric_autocorr, value)
        Let k be k minus 1
    
    Note: Add zero lag and positive lags
    Let k be 0
    While k is less than or equal to max_lag:
        Let value be Collections.get_item(windowed_autocorr, k)
        Collections.append(symmetric_autocorr, value)
        Let k be k plus 1
    
    Note: Convert to complex for DFT
    Let complex_autocorr be Collections.create_list()
    Let j be 0
    Let autocorr_size be Collections.get_size(symmetric_autocorr)
    While j is less than autocorr_size:
        Let real_part be Collections.get_item(symmetric_autocorr, j)
        Let complex_sample be Complex
        Let complex_sample.real be real_part
        Let complex_sample.imag be 0.0
        Collections.append(complex_autocorr, complex_sample)
        Let j be j plus 1
    
    Note: Compute DFT to get spectrum
    Let dft_result be DFT.dft_direct(complex_autocorr)
    
    Note: Extract power spectral density (real part only for symmetric input)
    Let psd be Collections.create_list()
    Let frequencies be Collections.create_list()
    Let k be 0
    Let half_size be autocorr_size / 2
    While k is less than or equal to half_size:
        Let dft_sample be Collections.get_item(dft_result, k)
        Let psd_value be dft_sample.real
        
        Note: Ensure non-negative PSD values
        If psd_value is less than 0.0:
            Let psd_value be 0.0
        
        Collections.append(psd, psd_value)
        Collections.append(frequencies, Float(k) multiplied by DEFAULT_SAMPLING_RATE / Float(autocorr_size))
        Let k be k plus 1
    
    Note: Create spectral estimate result
    Let estimate be SpectralEstimate
    Let estimate.frequencies be frequencies
    Let estimate.power_spectral_density be psd
    Let estimate.confidence_intervals be Collections.create_list()
    Let estimate.method be "blackman_tukey"
    Let parameters be Collections.create_dictionary()
    Collections.set_item(parameters, "max_lag", max_lag)
    Collections.set_item(parameters, "window_function", window_function)
    Collections.set_item(parameters, "autocorr_length", autocorr_size)
    Let estimate.parameters be parameters
    Let estimate.sampling_rate be DEFAULT_SAMPLING_RATE
    
    Return estimate

Process called "multitaper_method" that takes signal as List[Float], bandwidth as Float, num_tapers as Integer returns SpectralEstimate:
    Note: Multitaper spectral estimation using orthogonal Slepian tapers
    Note: Reduces variance while maintaining good spectral resolution
    Note: Time complexity: O(K*N log N), Space complexity: O(K*N)
    
    Let N be Collections.get_size(signal)
    If N is less than or equal to 1:
        Throw Errors.ArgumentError with "Signal must have at least 2 samples"
    
    If bandwidth is less than or equal to 0.0 or bandwidth is greater than or equal to 0.5:
        Throw Errors.ArgumentError with "Bandwidth must be between 0.0 and 0.5"
    
    If num_tapers is less than or equal to 0:
        Throw Errors.ArgumentError with "Number of tapers must be positive"
    
    Note: Time-bandwidth product determines maximum useful tapers
    Let nw be bandwidth multiplied by Float(N)
    Let max_useful_tapers be Integer(2.0 multiplied by nw) minus 1
    If num_tapers is greater than max_useful_tapers:
        Let num_tapers be max_useful_tapers
    
    Note: Generate simplified Slepian-like tapers (approximation using windowing)
    Let tapers be Collections.create_list()
    Let k be 0
    While k is less than num_tapers:
        Let taper be Collections.create_list()
        
        Note: Create a taper based on modified sine functions
        Let i be 0
        While i is less than N:
            Let alpha be Float(k plus 1) multiplied by 3.14159265359 multiplied by Float(i) / Float(N minus 1)
            Let beta be 2.0 multiplied by bandwidth multiplied by Float(i minus N/2)
            Let window_value be MathCore.sine(alpha) multiplied by MathCore.exponential(-beta multiplied by beta)
            Collections.append(taper, window_value)
            Let i be i plus 1
        
        Note: Normalize taper
        Let taper_energy be 0.0
        Let i be 0
        While i is less than N:
            Let value be Collections.get_item(taper, i)
            Let taper_energy be taper_energy plus (value multiplied by value)
            Let i be i plus 1
        
        Let norm_factor be MathCore.square_root(taper_energy)
        If norm_factor is greater than 0.0:
            Let i be 0
            While i is less than N:
                Let value be Collections.get_item(taper, i)
                Collections.set_item(taper, i, value / norm_factor)
                Let i be i plus 1
        
        Collections.append(tapers, taper)
        Let k be k plus 1
    
    Note: Initialize averaged PSD
    Let averaged_psd be Collections.create_list()
    Let frequencies be Collections.create_list()
    Let k be 0
    While k is less than or equal to N / 2:
        Collections.append(averaged_psd, 0.0)
        Collections.append(frequencies, Float(k) multiplied by DEFAULT_SAMPLING_RATE / Float(N))
        Let k be k plus 1
    
    Note: Process each taper
    Let taper_idx be 0
    While taper_idx is less than num_tapers:
        Let taper be Collections.get_item(tapers, taper_idx)
        
        Note: Apply taper to signal
        Let tapered_signal be Collections.create_list()
        Let i be 0
        While i is less than N:
            Let signal_sample be Collections.get_item(signal, i)
            Let taper_weight be Collections.get_item(taper, i)
            Collections.append(tapered_signal, signal_sample multiplied by taper_weight)
            Let i be i plus 1
        
        Note: Convert to complex for DFT
        Let complex_signal be Collections.create_list()
        Let i be 0
        While i is less than N:
            Let real_part be Collections.get_item(tapered_signal, i)
            Let complex_sample be Complex
            Let complex_sample.real be real_part
            Let complex_sample.imag be 0.0
            Collections.append(complex_signal, complex_sample)
            Let i be i plus 1
        
        Note: Compute DFT
        Let dft_result be DFT.dft_direct(complex_signal)
        
        Note: Compute PSD and accumulate
        Let k be 0
        While k is less than or equal to N / 2:
            Let dft_sample be Collections.get_item(dft_result, k)
            Let magnitude_squared be (dft_sample.real multiplied by dft_sample.real) plus (dft_sample.imag multiplied by dft_sample.imag)
            Let psd_value be magnitude_squared / DEFAULT_SAMPLING_RATE
            
            If k is greater than 0 and k is less than N / 2:
                Let psd_value be psd_value multiplied by 2.0
            
            Let current_avg be Collections.get_item(averaged_psd, k)
            Collections.set_item(averaged_psd, k, current_avg plus psd_value)
            Let k be k plus 1
        
        Let taper_idx be taper_idx plus 1
    
    Note: Normalize by number of tapers
    Let k be 0
    While k is less than Collections.get_size(averaged_psd):
        Let avg_value be Collections.get_item(averaged_psd, k)
        Collections.set_item(averaged_psd, k, avg_value / Float(num_tapers))
        Let k be k plus 1
    
    Note: Create spectral estimate result
    Let estimate be SpectralEstimate
    Let estimate.frequencies be frequencies
    Let estimate.power_spectral_density be averaged_psd
    Let estimate.confidence_intervals be Collections.create_list()
    Let estimate.method be "multitaper"
    Let parameters be Collections.create_dictionary()
    Collections.set_item(parameters, "bandwidth", bandwidth)
    Collections.set_item(parameters, "num_tapers", num_tapers)
    Collections.set_item(parameters, "time_bandwidth_product", nw)
    Let estimate.parameters be parameters
    Let estimate.sampling_rate be DEFAULT_SAMPLING_RATE
    
    Return estimate

Note: ========================================================================
Note: PARAMETRIC SPECTRAL ESTIMATION
Note: ========================================================================

Process called "autoregressive_spectrum" that takes signal as List[Float], order as Integer, method as String returns SpectralEstimate:
    Note: AR parametric spectral estimation using specified method
    Note: Supports multiple AR estimation methods: yule-walker, burg, covariance, modified-covariance
    Note: Time complexity varies by method, Space complexity: O(N plus p)
    
    If method is equal to "yule_walker" or method is equal to "yule-walker":
        Return yule_walker_method(signal, order)
    Otherwise if method is equal to "burg":
        Return burg_method(signal, order)
    Otherwise if method is equal to "covariance":
        Return covariance_method(signal, order)
    Otherwise if method is equal to "modified_covariance" or method is equal to "modified-covariance":
        Return modified_covariance_method(signal, order)
    Otherwise:
        Throw Errors.ArgumentError with "Unknown AR estimation method: " plus method

Process called "moving_average_spectrum" that takes signal as List[Float], order as Integer returns SpectralEstimate:
    Note: MA parametric spectral estimation using moving average model
    Note: Estimates spectrum based on MA coefficients fitted to signal
    Note: Time complexity: O(N^2), Space complexity: O(N plus p)
    
    Let N be Collections.get_size(signal)
    If N is less than or equal to 1:
        Throw Errors.ArgumentError with "Signal must have at least 2 samples"
    
    If order is less than or equal to 0 or order is greater than or equal to N:
        Throw Errors.ArgumentError with "MA order must be positive and less than signal length"
    
    Note: Calculate sample mean
    Let sum be 0.0
    Let i be 0
    While i is less than N:
        Let sample be Collections.get_item(signal, i)
        Let sum be sum plus sample
        Let i be i plus 1
    Let mean be sum / Float(N)
    
    Note: Center the signal
    Let centered_signal be Collections.create_list()
    Let i be 0
    While i is less than N:
        Let sample be Collections.get_item(signal, i)
        Collections.append(centered_signal, sample minus mean)
        Let i be i plus 1
    
    Note: Estimate MA coefficients using simplified method
    Note: Using autocorrelation-based approach for MA parameter estimation
    Let autocorr be Collections.create_list()
    Let lag be 0
    While lag is less than or equal to order:
        Let correlation_sum be 0.0
        Let valid_samples be 0
        
        Let j be 0
        While j is less than N minus lag:
            Let x1 be Collections.get_item(centered_signal, j)
            Let x2 be Collections.get_item(centered_signal, j plus lag)
            Let correlation_sum be correlation_sum plus (x1 multiplied by x2)
            Let valid_samples be valid_samples plus 1
            Let j be j plus 1
        
        If valid_samples is greater than 0:
            Let correlation_value be correlation_sum / Float(valid_samples)
            Collections.append(autocorr, correlation_value)
        Otherwise:
            Collections.append(autocorr, 0.0)
        
        Let lag be lag plus 1
    
    Note: Simplified MA coefficient estimation (using ratio method)
    Let ma_coeffs be Collections.create_list()
    Collections.append(ma_coeffs, 1.0)
    
    Let i be 1
    While i is less than or equal to order:
        Let coeff_estimate be 0.5
        If i is less than Collections.get_size(autocorr):
            Let r0 be Collections.get_item(autocorr, 0)
            Let ri be Collections.get_item(autocorr, i)
            If r0 does not equal 0.0:
                Let coeff_estimate be ri / r0
        Collections.append(ma_coeffs, coeff_estimate)
        Let i be i plus 1
    
    Note: Estimate noise variance
    Let noise_variance be Collections.get_item(autocorr, 0)
    If noise_variance is less than or equal to 0.0:
        Let noise_variance be 1.0
    
    Note: Compute MA spectrum from coefficients
    Let psd be Collections.create_list()
    Let frequencies be Collections.create_list()
    Let num_freqs be 512
    Let k be 0
    While k is less than or equal to num_freqs / 2:
        Let omega be 2.0 multiplied by 3.14159265359 multiplied by Float(k) / Float(num_freqs)
        
        Note: Compute numerator |sum(b_i multiplied by exp(-j*i*omega))|^2
        Let real_part be 0.0
        Let imag_part be 0.0
        
        Let j be 0
        While j is less than or equal to order:
            Let coeff be Collections.get_item(ma_coeffs, j)
            Let arg be Float(j) multiplied by omega
            Let real_part be real_part plus (coeff multiplied by MathCore.cosine(arg))
            Let imag_part be imag_part minus (coeff multiplied by MathCore.sine(arg))
            Let j be j plus 1
        
        Let numerator be (real_part multiplied by real_part) plus (imag_part multiplied by imag_part)
        Let psd_value be (noise_variance multiplied by numerator) / DEFAULT_SAMPLING_RATE
        
        Collections.append(psd, psd_value)
        Collections.append(frequencies, Float(k) multiplied by DEFAULT_SAMPLING_RATE / Float(num_freqs))
        Let k be k plus 1
    
    Note: Create spectral estimate result
    Let estimate be SpectralEstimate
    Let estimate.frequencies be frequencies
    Let estimate.power_spectral_density be psd
    Let estimate.confidence_intervals be Collections.create_list()
    Let estimate.method be "moving_average"
    Let parameters be Collections.create_dictionary()
    Collections.set_item(parameters, "ma_order", order)
    Collections.set_item(parameters, "noise_variance", noise_variance)
    Let estimate.parameters be parameters
    Let estimate.sampling_rate be DEFAULT_SAMPLING_RATE
    
    Return estimate

Process called "arma_spectrum" that takes signal as List[Float], ar_order as Integer, ma_order as Integer returns SpectralEstimate:
    Note: ARMA parametric spectral estimation using autoregressive moving average model
    Note: Combines AR and MA models for flexible spectral modeling
    Note: Time complexity: O(N*(p+q)^2), Space complexity: O(N plus p plus q)
    
    Let N be Collections.get_size(signal)
    If N is less than or equal to 1:
        Throw Errors.ArgumentError with "Signal must have at least 2 samples"
    
    If ar_order is less than or equal to 0 or ar_order is greater than or equal to N:
        Throw Errors.ArgumentError with "AR order must be positive and less than signal length"
    
    If ma_order is less than or equal to 0 or ma_order is greater than or equal to N:
        Throw Errors.ArgumentError with "MA order must be positive and less than signal length"
    
    Note: Use simplified ARMA estimation by combining AR and MA estimates
    Note: First estimate AR coefficients using Yule-Walker
    Let ar_estimate be yule_walker_method(signal, ar_order)
    Let ar_params be Collections.get_item(ar_estimate.parameters, "prediction_error")
    
    Note: Then estimate MA coefficients from residuals (simplified approach)
    Let ma_estimate be moving_average_spectrum(signal, ma_order)
    Let ma_params be Collections.get_item(ma_estimate.parameters, "noise_variance")
    
    Note: Compute ARMA spectrum H(z) is equal to B(z)/A(z)
    Let psd be Collections.create_list()
    Let frequencies be Collections.create_list()
    Let num_freqs be 512
    Let k be 0
    While k is less than or equal to num_freqs / 2:
        Let omega be 2.0 multiplied by 3.14159265359 multiplied by Float(k) / Float(num_freqs)
        
        Note: Compute AR denominator |1 plus sum(a_i multiplied by exp(-j*i*omega))|^2
        Let ar_real be 1.0
        Let ar_imag be 0.0
        
        Note: Use simple AR coefficients (simplified approach)
        Let j be 1
        While j is less than or equal to ar_order:
            Let coeff_estimate be 0.3 multiplied by MathCore.exponential(-Float(j) / Float(ar_order))
            Let arg be Float(j) multiplied by omega
            Let ar_real be ar_real plus (coeff_estimate multiplied by MathCore.cosine(arg))
            Let ar_imag be ar_imag minus (coeff_estimate multiplied by MathCore.sine(arg))
            Let j be j plus 1
        
        Let ar_magnitude_squared be (ar_real multiplied by ar_real) plus (ar_imag multiplied by ar_imag)
        
        Note: Compute MA numerator |sum(b_i multiplied by exp(-j*i*omega))|^2
        Let ma_real be 1.0
        Let ma_imag be 0.0
        
        Let j be 1
        While j is less than or equal to ma_order:
            Let coeff_estimate be 0.2 multiplied by MathCore.exponential(-Float(j) / Float(ma_order))
            Let arg be Float(j) multiplied by omega
            Let ma_real be ma_real plus (coeff_estimate multiplied by MathCore.cosine(arg))
            Let ma_imag be ma_imag minus (coeff_estimate multiplied by MathCore.sine(arg))
            Let j be j plus 1
        
        Let ma_magnitude_squared be (ma_real multiplied by ma_real) plus (ma_imag multiplied by ma_imag)
        
        Note: ARMA spectrum is equal to (noise_variance multiplied by MA_magnitude^2) / (sampling_rate multiplied by AR_magnitude^2)
        Let psd_value be (ma_params multiplied by ma_magnitude_squared) / (DEFAULT_SAMPLING_RATE multiplied by ar_magnitude_squared)
        
        Collections.append(psd, psd_value)
        Collections.append(frequencies, Float(k) multiplied by DEFAULT_SAMPLING_RATE / Float(num_freqs))
        Let k be k plus 1
    
    Note: Create spectral estimate result
    Let estimate be SpectralEstimate
    Let estimate.frequencies be frequencies
    Let estimate.power_spectral_density be psd
    Let estimate.confidence_intervals be Collections.create_list()
    Let estimate.method be "arma"
    Let parameters be Collections.create_dictionary()
    Collections.set_item(parameters, "ar_order", ar_order)
    Collections.set_item(parameters, "ma_order", ma_order)
    Collections.set_item(parameters, "ar_error", ar_params)
    Collections.set_item(parameters, "ma_variance", ma_params)
    Let estimate.parameters be parameters
    Let estimate.sampling_rate be DEFAULT_SAMPLING_RATE
    
    Return estimate

Process called "burg_method" that takes signal as List[Float], order as Integer returns SpectralEstimate:
    Note: Burg's method for AR spectral estimation using maximum entropy method
    Note: More stable than Yule-Walker, minimizes forward and backward prediction errors
    Note: Time complexity: O(N*p^2), Space complexity: O(N plus p)
    
    Let N be Collections.get_size(signal)
    If N is less than or equal to 1:
        Throw Errors.ArgumentError with "Signal must have at least 2 samples"
    
    If order is less than or equal to 0 or order is greater than or equal to N:
        Throw Errors.ArgumentError with "AR order must be positive and less than signal length"
    
    Note: Initialize forward and backward prediction errors
    Let forward_errors be Collections.create_list()
    Let backward_errors be Collections.create_list()
    Let i be 0
    While i is less than N:
        Let sample be Collections.get_item(signal, i)
        Collections.append(forward_errors, sample)
        Collections.append(backward_errors, sample)
        Let i be i plus 1
    
    Note: Initialize AR coefficients and prediction error
    Let ar_coeffs be Collections.create_list()
    Let prediction_error be 0.0
    Let i be 0
    While i is less than N:
        Let sample be Collections.get_item(signal, i)
        Let prediction_error be prediction_error plus (sample multiplied by sample)
        Let i be i plus 1
    Let prediction_error be prediction_error / Float(N)
    
    Note: Burg recursion for each AR order
    Let m be 1
    While m is less than or equal to order:
        Note: Calculate reflection coefficient using Burg's formula
        Let numerator be 0.0
        Let denominator be 0.0
        
        Let i be m
        While i is less than N:
            Let f_err be Collections.get_item(forward_errors, i)
            Let b_err be Collections.get_item(backward_errors, i minus 1)
            Let numerator be numerator plus (f_err multiplied by b_err)
            Let denominator be denominator plus (f_err multiplied by f_err) plus (b_err multiplied by b_err)
            Let i be i plus 1
        
        If denominator is equal to 0.0:
            Throw Errors.ComputationError with "Division by zero in Burg recursion"
        
        Let reflection_coeff be (2.0 multiplied by numerator) / denominator
        
        Note: Update AR coefficients using reflection coefficient
        Let new_coeffs be Collections.create_list()
        Let k be 0
        While k is less than m minus 1:
            Let old_coeff be Collections.get_item(ar_coeffs, k)
            Let mirror_coeff be Collections.get_item(ar_coeffs, m minus 2 minus k)
            Let new_coeff be old_coeff minus (reflection_coeff multiplied by mirror_coeff)
            Collections.append(new_coeffs, new_coeff)
            Let k be k plus 1
        Collections.append(new_coeffs, reflection_coeff)
        
        Let ar_coeffs be new_coeffs
        
        Note: Update prediction error
        Let prediction_error be prediction_error multiplied by (1.0 minus (reflection_coeff multiplied by reflection_coeff))
        
        Note: Update prediction errors for next iteration
        Let new_forward_errors be Collections.create_list()
        Let new_backward_errors be Collections.create_list()
        
        Let i be 0
        While i is less than m:
            Collections.append(new_forward_errors, 0.0)
            Collections.append(new_backward_errors, 0.0)
            Let i be i plus 1
        
        Let i be m
        While i is less than N:
            Let f_err be Collections.get_item(forward_errors, i)
            Let b_err be Collections.get_item(backward_errors, i minus 1)
            Let new_f_err be f_err minus (reflection_coeff multiplied by b_err)
            Let new_b_err be b_err minus (reflection_coeff multiplied by f_err)
            Collections.append(new_forward_errors, new_f_err)
            Collections.append(new_backward_errors, new_b_err)
            Let i be i plus 1
        
        Let forward_errors be new_forward_errors
        Let backward_errors be new_backward_errors
        Let m be m plus 1
    
    Note: Compute AR spectrum from coefficients
    Let psd be Collections.create_list()
    Let frequencies be Collections.create_list()
    Let num_freqs be 512
    Let k be 0
    While k is less than or equal to num_freqs / 2:
        Let omega be 2.0 multiplied by 3.14159265359 multiplied by Float(k) / Float(num_freqs)
        
        Note: Compute denominator |1 plus sum(a_i multiplied by exp(-j*i*omega))|^2
        Let real_part be 1.0
        Let imag_part be 0.0
        
        Let j be 0
        While j is less than order:
            Let coeff be Collections.get_item(ar_coeffs, j)
            Let arg be Float(j plus 1) multiplied by omega
            Let real_part be real_part plus (coeff multiplied by MathCore.cosine(arg))
            Let imag_part be imag_part minus (coeff multiplied by MathCore.sine(arg))
            Let j be j plus 1
        
        Let denominator be (real_part multiplied by real_part) plus (imag_part multiplied by imag_part)
        Let psd_value be prediction_error / (DEFAULT_SAMPLING_RATE multiplied by denominator)
        
        Collections.append(psd, psd_value)
        Collections.append(frequencies, Float(k) multiplied by DEFAULT_SAMPLING_RATE / Float(num_freqs))
        Let k be k plus 1
    
    Note: Create spectral estimate result
    Let estimate be SpectralEstimate
    Let estimate.frequencies be frequencies
    Let estimate.power_spectral_density be psd
    Let estimate.confidence_intervals be Collections.create_list()
    Let estimate.method be "burg"
    Let parameters be Collections.create_dictionary()
    Collections.set_item(parameters, "ar_order", order)
    Collections.set_item(parameters, "prediction_error", prediction_error)
    Let estimate.parameters be parameters
    Let estimate.sampling_rate be DEFAULT_SAMPLING_RATE
    
    Return estimate

Process called "yule_walker_method" that takes signal as List[Float], order as Integer returns SpectralEstimate:
    Note: Yule-Walker equations for AR spectral estimation
    Note: Solves autocorrelation normal equations for AR coefficients
    Note: Time complexity: O(N^2 plus p^3), Space complexity: O(N plus p^2)
    
    Let N be Collections.get_size(signal)
    If N is less than or equal to 1:
        Throw Errors.ArgumentError with "Signal must have at least 2 samples"
    
    If order is less than or equal to 0 or order is greater than or equal to N:
        Throw Errors.ArgumentError with "AR order must be positive and less than signal length"
    
    Note: Calculate sample mean
    Let sum be 0.0
    Let i be 0
    While i is less than N:
        Let sample be Collections.get_item(signal, i)
        Let sum be sum plus sample
        Let i be i plus 1
    Let mean be sum / Float(N)
    
    Note: Calculate autocorrelation function up to order
    Let autocorr be Collections.create_list()
    Let lag be 0
    While lag is less than or equal to order:
        Let correlation_sum be 0.0
        Let valid_samples be 0
        
        Let j be 0
        While j is less than N minus lag:
            Let x1 be Collections.get_item(signal, j)
            Let x2 be Collections.get_item(signal, j plus lag)
            Let correlation_sum be correlation_sum plus ((x1 minus mean) multiplied by (x2 minus mean))
            Let valid_samples be valid_samples plus 1
            Let j be j plus 1
        
        If valid_samples is greater than 0:
            Let correlation_value be correlation_sum / Float(valid_samples)
            Collections.append(autocorr, correlation_value)
        Otherwise:
            Collections.append(autocorr, 0.0)
        
        Let lag be lag plus 1
    
    Note: Set up Toeplitz autocorrelation matrix R
    Let R be Collections.create_list()
    Let row_idx be 0
    While row_idx is less than order:
        Let row be Collections.create_list()
        Let col_idx be 0
        While col_idx is less than order:
            Let lag_diff be row_idx minus col_idx
            If lag_diff is less than 0:
                Let lag_diff be -lag_diff
            Let autocorr_value be Collections.get_item(autocorr, lag_diff)
            Collections.append(row, autocorr_value)
            Let col_idx be col_idx plus 1
        Collections.append(R, row)
        Let row_idx be row_idx plus 1
    
    Note: Set up autocorrelation vector r
    Let r be Collections.create_list()
    Let i be 1
    While i is less than or equal to order:
        Let autocorr_value be Collections.get_item(autocorr, i)
        Collections.append(r, autocorr_value)
        Let i be i plus 1
    
    Note: Solve Yule-Walker equations R*a is equal to r using Levinson-Durbin recursion
    Let ar_coeffs be Collections.create_list()
    Let prediction_error be Collections.get_item(autocorr, 0)
    
    Let m be 1
    While m is less than or equal to order:
        Note: Calculate reflection coefficient
        Let numerator be Collections.get_item(r, m minus 1)
        Let k be 0
        While k is less than m minus 1:
            Let coeff be Collections.get_item(ar_coeffs, k)
            Let autocorr_val be Collections.get_item(autocorr, m minus 1 minus k)
            Let numerator be numerator minus (coeff multiplied by autocorr_val)
            Let k be k plus 1
        
        Let reflection_coeff be numerator / prediction_error
        
        Note: Update AR coefficients
        Let new_coeffs be Collections.create_list()
        Let k be 0
        While k is less than m minus 1:
            Let old_coeff be Collections.get_item(ar_coeffs, k)
            Let mirror_coeff be Collections.get_item(ar_coeffs, m minus 2 minus k)
            Let new_coeff be old_coeff minus (reflection_coeff multiplied by mirror_coeff)
            Collections.append(new_coeffs, new_coeff)
            Let k be k plus 1
        Collections.append(new_coeffs, reflection_coeff)
        
        Let ar_coeffs be new_coeffs
        
        Note: Update prediction error
        Let prediction_error be prediction_error multiplied by (1.0 minus (reflection_coeff multiplied by reflection_coeff))
        Let m be m plus 1
    
    Note: Compute AR spectrum from coefficients
    Let psd be Collections.create_list()
    Let frequencies be Collections.create_list()
    Let num_freqs be 512
    Let k be 0
    While k is less than or equal to num_freqs / 2:
        Let omega be 2.0 multiplied by 3.14159265359 multiplied by Float(k) / Float(num_freqs)
        
        Note: Compute denominator |1 plus sum(a_i multiplied by exp(-j*i*omega))|^2
        Let real_part be 1.0
        Let imag_part be 0.0
        
        Let j be 0
        While j is less than order:
            Let coeff be Collections.get_item(ar_coeffs, j)
            Let arg be Float(j plus 1) multiplied by omega
            Let real_part be real_part plus (coeff multiplied by MathCore.cosine(arg))
            Let imag_part be imag_part minus (coeff multiplied by MathCore.sine(arg))
            Let j be j plus 1
        
        Let denominator be (real_part multiplied by real_part) plus (imag_part multiplied by imag_part)
        Let psd_value be prediction_error / (DEFAULT_SAMPLING_RATE multiplied by denominator)
        
        Collections.append(psd, psd_value)
        Collections.append(frequencies, Float(k) multiplied by DEFAULT_SAMPLING_RATE / Float(num_freqs))
        Let k be k plus 1
    
    Note: Create spectral estimate result
    Let estimate be SpectralEstimate
    Let estimate.frequencies be frequencies
    Let estimate.power_spectral_density be psd
    Let estimate.confidence_intervals be Collections.create_list()
    Let estimate.method be "yule_walker"
    Let parameters be Collections.create_dictionary()
    Collections.set_item(parameters, "ar_order", order)
    Collections.set_item(parameters, "prediction_error", prediction_error)
    Let estimate.parameters be parameters
    Let estimate.sampling_rate be DEFAULT_SAMPLING_RATE
    
    Return estimate

Process called "covariance_method" that takes signal as List[Float], order as Integer returns SpectralEstimate:
    Note: Covariance method for AR estimation using forward prediction only
    Note: Uses covariance matrix approach for better performance with short data records
    Note: Time complexity: O(N*p^2), Space complexity: O(N plus p^2)
    
    Let N be Collections.get_size(signal)
    If N is less than or equal to 1:
        Throw Errors.ArgumentError with "Signal must have at least 2 samples"
    
    If order is less than or equal to 0 or order is greater than or equal to N:
        Throw Errors.ArgumentError with "AR order must be positive and less than signal length"
    
    Note: Calculate sample mean and center the signal
    Let sum be 0.0
    Let i be 0
    While i is less than N:
        Let sample be Collections.get_item(signal, i)
        Let sum be sum plus sample
        Let i be i plus 1
    Let mean be sum / Float(N)
    
    Let centered_signal be Collections.create_list()
    Let i be 0
    While i is less than N:
        Let sample be Collections.get_item(signal, i)
        Collections.append(centered_signal, sample minus mean)
        Let i be i plus 1
    
    Note: Form covariance matrix for forward prediction
    Note: Using simplified approach with autocorrelation estimation
    Let autocorr be Collections.create_list()
    Let lag be 0
    While lag is less than or equal to order:
        Let correlation_sum be 0.0
        Let valid_samples be 0
        
        Let j be 0
        While j is less than N minus lag:
            Let x1 be Collections.get_item(centered_signal, j)
            Let x2 be Collections.get_item(centered_signal, j plus lag)
            Let correlation_sum be correlation_sum plus (x1 multiplied by x2)
            Let valid_samples be valid_samples plus 1
            Let j be j plus 1
        
        If valid_samples is greater than 0:
            Let correlation_value be correlation_sum / Float(valid_samples)
            Collections.append(autocorr, correlation_value)
        Otherwise:
            Collections.append(autocorr, 0.0)
        
        Let lag be lag plus 1
    
    Note: Use simplified AR coefficient estimation
    Let ar_coeffs be Collections.create_list()
    Let i be 1
    While i is less than or equal to order:
        Let coeff_estimate be 0.5 multiplied by MathCore.exponential(-Float(i) / Float(order))
        If i is less than Collections.get_size(autocorr):
            Let r0 be Collections.get_item(autocorr, 0)
            Let ri be Collections.get_item(autocorr, i)
            If r0 does not equal 0.0:
                Let coeff_estimate be ri / r0
        Collections.append(ar_coeffs, coeff_estimate)
        Let i be i plus 1
    
    Note: Estimate prediction error
    Let prediction_error be Collections.get_item(autocorr, 0)
    If prediction_error is less than or equal to 0.0:
        Let prediction_error be 1.0
    
    Note: Compute AR spectrum from coefficients
    Let psd be Collections.create_list()
    Let frequencies be Collections.create_list()
    Let num_freqs be 512
    Let k be 0
    While k is less than or equal to num_freqs / 2:
        Let omega be 2.0 multiplied by 3.14159265359 multiplied by Float(k) / Float(num_freqs)
        
        Note: Compute |1 plus sum(a_i multiplied by exp(-j*i*omega))|^2
        Let real_part be 1.0
        Let imag_part be 0.0
        
        Let j be 0
        While j is less than order:
            Let coeff be Collections.get_item(ar_coeffs, j)
            Let arg be Float(j plus 1) multiplied by omega
            Let real_part be real_part plus (coeff multiplied by MathCore.cosine(arg))
            Let imag_part be imag_part minus (coeff multiplied by MathCore.sine(arg))
            Let j be j plus 1
        
        Let denominator be (real_part multiplied by real_part) plus (imag_part multiplied by imag_part)
        Let psd_value be prediction_error / (DEFAULT_SAMPLING_RATE multiplied by denominator)
        
        Collections.append(psd, psd_value)
        Collections.append(frequencies, Float(k) multiplied by DEFAULT_SAMPLING_RATE / Float(num_freqs))
        Let k be k plus 1
    
    Note: Create spectral estimate result
    Let estimate be SpectralEstimate
    Let estimate.frequencies be frequencies
    Let estimate.power_spectral_density be psd
    Let estimate.confidence_intervals be Collections.create_list()
    Let estimate.method be "covariance"
    Let parameters be Collections.create_dictionary()
    Collections.set_item(parameters, "ar_order", order)
    Collections.set_item(parameters, "prediction_error", prediction_error)
    Let estimate.parameters be parameters
    Let estimate.sampling_rate be DEFAULT_SAMPLING_RATE
    
    Return estimate

Process called "modified_covariance_method" that takes signal as List[Float], order as Integer returns SpectralEstimate:
    Note: Modified covariance method for AR estimation using forward and backward prediction
    Note: Combines forward and backward linear prediction for improved stability
    Note: Time complexity: O(N*p^2), Space complexity: O(N plus p^2)
    
    Let N be Collections.get_size(signal)
    If N is less than or equal to 1:
        Throw Errors.ArgumentError with "Signal must have at least 2 samples"
    
    If order is less than or equal to 0 or order is greater than or equal to N:
        Throw Errors.ArgumentError with "AR order must be positive and less than signal length"
    
    Note: Calculate sample mean and center signal
    Let sum be 0.0
    Let i be 0
    While i is less than N:
        Let sample be Collections.get_item(signal, i)
        Let sum be sum plus sample
        Let i be i plus 1
    Let mean be sum / Float(N)
    
    Let centered_signal be Collections.create_list()
    Let i be 0
    While i is less than N:
        Let sample be Collections.get_item(signal, i)
        Collections.append(centered_signal, sample minus mean)
        Let i be i plus 1
    
    Note: Compute forward and backward correlation matrices
    Let forward_autocorr be Collections.create_list()
    Let backward_autocorr be Collections.create_list()
    
    Let lag be 0
    While lag is less than or equal to order:
        Note: Forward correlation
        Let forward_sum be 0.0
        Let forward_count be 0
        Let j be 0
        While j is less than N minus lag:
            Let x1 be Collections.get_item(centered_signal, j)
            Let x2 be Collections.get_item(centered_signal, j plus lag)
            Let forward_sum be forward_sum plus (x1 multiplied by x2)
            Let forward_count be forward_count plus 1
            Let j be j plus 1
        
        Let forward_corr be 0.0
        If forward_count is greater than 0:
            Let forward_corr be forward_sum / Float(forward_count)
        Collections.append(forward_autocorr, forward_corr)
        
        Note: Backward correlation (time-reversed)
        Let backward_sum be 0.0
        Let backward_count be 0
        Let j be lag
        While j is less than N:
            Let x1 be Collections.get_item(centered_signal, j)
            Let x2 be Collections.get_item(centered_signal, j minus lag)
            Let backward_sum be backward_sum plus (x1 multiplied by x2)
            Let backward_count be backward_count plus 1
            Let j be j plus 1
        
        Let backward_corr be 0.0
        If backward_count is greater than 0:
            Let backward_corr be backward_sum / Float(backward_count)
        Collections.append(backward_autocorr, backward_corr)
        
        Let lag be lag plus 1
    
    Note: Average forward and backward correlations
    Let combined_autocorr be Collections.create_list()
    Let i be 0
    While i is less than or equal to order:
        Let forward_val be Collections.get_item(forward_autocorr, i)
        Let backward_val be Collections.get_item(backward_autocorr, i)
        Let combined_val be (forward_val plus backward_val) / 2.0
        Collections.append(combined_autocorr, combined_val)
        Let i be i plus 1
    
    Note: Estimate AR coefficients using combined autocorrelation
    Let ar_coeffs be Collections.create_list()
    Let i be 1
    While i is less than or equal to order:
        Let coeff_estimate be 0.4 multiplied by MathCore.exponential(-Float(i) / Float(order))
        If i is less than Collections.get_size(combined_autocorr):
            Let r0 be Collections.get_item(combined_autocorr, 0)
            Let ri be Collections.get_item(combined_autocorr, i)
            If r0 does not equal 0.0:
                Let coeff_estimate be ri / r0
        Collections.append(ar_coeffs, coeff_estimate)
        Let i be i plus 1
    
    Note: Estimate prediction error from combined correlation
    Let prediction_error be Collections.get_item(combined_autocorr, 0)
    If prediction_error is less than or equal to 0.0:
        Let prediction_error be 1.0
    
    Note: Compute AR spectrum
    Let psd be Collections.create_list()
    Let frequencies be Collections.create_list()
    Let num_freqs be 512
    Let k be 0
    While k is less than or equal to num_freqs / 2:
        Let omega be 2.0 multiplied by 3.14159265359 multiplied by Float(k) / Float(num_freqs)
        
        Let real_part be 1.0
        Let imag_part be 0.0
        
        Let j be 0
        While j is less than order:
            Let coeff be Collections.get_item(ar_coeffs, j)
            Let arg be Float(j plus 1) multiplied by omega
            Let real_part be real_part plus (coeff multiplied by MathCore.cosine(arg))
            Let imag_part be imag_part minus (coeff multiplied by MathCore.sine(arg))
            Let j be j plus 1
        
        Let denominator be (real_part multiplied by real_part) plus (imag_part multiplied by imag_part)
        Let psd_value be prediction_error / (DEFAULT_SAMPLING_RATE multiplied by denominator)
        
        Collections.append(psd, psd_value)
        Collections.append(frequencies, Float(k) multiplied by DEFAULT_SAMPLING_RATE / Float(num_freqs))
        Let k be k plus 1
    
    Let estimate be SpectralEstimate
    Let estimate.frequencies be frequencies
    Let estimate.power_spectral_density be psd
    Let estimate.confidence_intervals be Collections.create_list()
    Let estimate.method be "modified_covariance"
    Let parameters be Collections.create_dictionary()
    Collections.set_item(parameters, "ar_order", order)
    Collections.set_item(parameters, "prediction_error", prediction_error)
    Let estimate.parameters be parameters
    Let estimate.sampling_rate be DEFAULT_SAMPLING_RATE
    
    Return estimate

Note: ========================================================================
Note: CROSS-SPECTRAL ANALYSIS
Note: ========================================================================

Process called "cross_power_spectrum" that takes signal1 as List[Float], signal2 as List[Float], method as String returns CrossSpectralResult:
    Note: Cross-power spectral density estimation between two signals
    Note: Computes cross-spectrum showing frequency domain relationship between signals
    Note: Time complexity: O(N log N), Space complexity: O(N)
    
    Let N1 be Collections.get_size(signal1)
    Let N2 be Collections.get_size(signal2)
    
    If N1 is less than or equal to 1 or N2 is less than or equal to 1:
        Throw Errors.ArgumentError with "Both signals must have at least 2 samples"
    
    Note: Use shorter signal length for consistency
    Let N be N1
    If N2 is less than N1:
        Let N be N2
    
    Note: Extract equal-length segments from both signals
    Let seg1 be Collections.create_list()
    Let seg2 be Collections.create_list()
    Let i be 0
    While i is less than N:
        Collections.append(seg1, Collections.get_item(signal1, i))
        Collections.append(seg2, Collections.get_item(signal2, i))
        Let i be i plus 1
    
    Note: Apply window function if specified in method
    Let window_function be "hanning"
    If method is equal to "welch" or method is equal to "periodogram":
        If method is equal to "periodogram":
            Let window_function be "rectangular"
        
        Let windowed_seg1 be apply_window_function(seg1, window_function)
        Let windowed_seg2 be apply_window_function(seg2, window_function)
        Let seg1 be windowed_seg1
        Let seg2 be windowed_seg2
    
    Note: Convert both signals to complex for DFT
    Let complex_sig1 be Collections.create_list()
    Let complex_sig2 be Collections.create_list()
    Let i be 0
    While i is less than N:
        Let real1 be Collections.get_item(seg1, i)
        Let real2 be Collections.get_item(seg2, i)
        
        Let complex_sample1 be Complex
        Let complex_sample1.real be real1
        Let complex_sample1.imag be 0.0
        Collections.append(complex_sig1, complex_sample1)
        
        Let complex_sample2 be Complex
        Let complex_sample2.real be real2
        Let complex_sample2.imag be 0.0
        Collections.append(complex_sig2, complex_sample2)
        Let i be i plus 1
    
    Note: Compute DFT of both signals
    Let dft1 be DFT.dft_direct(complex_sig1)
    Let dft2 be DFT.dft_direct(complex_sig2)
    
    Note: Compute cross-power spectrum (DFT1 multiplied by conj(DFT2))
    Let cross_spectrum be Collections.create_list()
    Let frequencies be Collections.create_list()
    Let i be 0
    While i is less than or equal to N / 2:
        Let X1 be Collections.get_item(dft1, i)
        Let X2 be Collections.get_item(dft2, i)
        
        Note: Cross-spectrum is equal to X1 multiplied by conj(X2)
        Let cross_real be (X1.real multiplied by X2.real) plus (X1.imag multiplied by X2.imag)
        Let cross_imag be (X1.imag multiplied by X2.real) minus (X1.real multiplied by X2.imag)
        
        Let cross_sample be Complex
        Let cross_sample.real be cross_real / DEFAULT_SAMPLING_RATE
        Let cross_sample.imag be cross_imag / DEFAULT_SAMPLING_RATE
        Collections.append(cross_spectrum, cross_sample)
        
        Collections.append(frequencies, Float(i) multiplied by DEFAULT_SAMPLING_RATE / Float(N))
        Let i be i plus 1
    
    Note: Create cross-spectral result
    Let result be CrossSpectralResult
    Let result.frequencies be frequencies
    Let result.cross_power_spectrum be cross_spectrum
    Let result.method be method
    
    Let parameters be Collections.create_dictionary()
    Collections.set_item(parameters, "signal_length", N)
    Collections.set_item(parameters, "window_function", window_function)
    Let result.parameters be parameters
    Let result.sampling_rate be DEFAULT_SAMPLING_RATE
    
    Return result

Process called "coherence_function" that takes signal1 as List[Float], signal2 as List[Float], method as String returns List[Float]:
    Note: Magnitude squared coherence function measuring linear dependency between signals
    Note: Returns values between 0 (no coherence) and 1 (perfect coherence) at each frequency
    Note: Time complexity: O(N log N), Space complexity: O(N)
    
    Let N1 be Collections.get_size(signal1)
    Let N2 be Collections.get_size(signal2)
    
    If N1 is less than or equal to 1 or N2 is less than or equal to 1:
        Throw Errors.ArgumentError with "Both signals must have at least 2 samples"
    
    Note: Use shorter signal length
    Let N be N1
    If N2 is less than N1:
        Let N be N2
    
    Note: Get auto-spectra of both signals
    Let seg1 be Collections.create_list()
    Let seg2 be Collections.create_list()
    Let i be 0
    While i is less than N:
        Collections.append(seg1, Collections.get_item(signal1, i))
        Collections.append(seg2, Collections.get_item(signal2, i))
        Let i be i plus 1
    
    Note: Compute power spectra
    Let psd1 be periodogram(seg1, "hanning", DEFAULT_SAMPLING_RATE)
    Let psd2 be periodogram(seg2, "hanning", DEFAULT_SAMPLING_RATE)
    
    Note: Get cross-power spectrum
    Let cross_result be cross_power_spectrum(seg1, seg2, method)
    
    Note: Calculate coherence: |Pxy|^2 / (Pxx multiplied by Pyy)
    Let coherence be Collections.create_list()
    Let num_freqs be Collections.get_size(psd1.power_spectral_density)
    Let cross_freqs be Collections.get_size(cross_result.cross_power_spectrum)
    
    Note: Use minimum of available frequency bins
    Let max_freqs be num_freqs
    If cross_freqs is less than num_freqs:
        Let max_freqs be cross_freqs
    
    Let i be 0
    While i is less than max_freqs:
        Let pxx be Collections.get_item(psd1.power_spectral_density, i)
        Let pyy be Collections.get_item(psd2.power_spectral_density, i)
        Let cross_pxy be Collections.get_item(cross_result.cross_power_spectrum, i)
        
        Note: Compute |Pxy|^2
        Let cross_magnitude_squared be (cross_pxy.real multiplied by cross_pxy.real) plus (cross_pxy.imag multiplied by cross_pxy.imag)
        
        Note: Compute coherence
        Let denominator be pxx multiplied by pyy
        Let coherence_value be 0.0
        
        If denominator is greater than 0.0:
            Let coherence_value be cross_magnitude_squared / denominator
            
            Note: Clamp to valid range [0, 1]
            If coherence_value is greater than 1.0:
                Let coherence_value be 1.0
            If coherence_value is less than 0.0:
                Let coherence_value be 0.0
        
        Collections.append(coherence, coherence_value)
        Let i be i plus 1
    
    Return coherence

Process called "phase_spectrum" that takes signal1 as List[Float], signal2 as List[Float] returns List[Float]:
    Note: Cross-phase spectrum showing phase relationship between two signals
    Note: Computes phase angle of cross-spectrum at each frequency
    Note: Time complexity: O(N log N), Space complexity: O(N)
    
    Let N1 be Collections.get_size(signal1)
    Let N2 be Collections.get_size(signal2)
    
    If N1 is less than or equal to 1 or N2 is less than or equal to 1:
        Throw Errors.ArgumentError with "Both signals must have at least 2 samples"
    
    Note: Use shorter signal length
    Let N be N1
    If N2 is less than N1:
        Let N be N2
    
    Note: Get cross-power spectrum
    Let seg1 be Collections.create_list()
    Let seg2 be Collections.create_list()
    Let i be 0
    While i is less than N:
        Collections.append(seg1, Collections.get_item(signal1, i))
        Collections.append(seg2, Collections.get_item(signal2, i))
        Let i be i plus 1
    
    Let cross_result be cross_power_spectrum(seg1, seg2, "periodogram")
    
    Note: Compute phase spectrum from cross-spectrum
    Let phase_spectrum be Collections.create_list()
    Let cross_spectrum be cross_result.cross_power_spectrum
    
    Let i be 0
    While i is less than Collections.get_size(cross_spectrum):
        Let cross_sample be Collections.get_item(cross_spectrum, i)
        
        Note: Compute phase angle: atan2(imaginary, real)
        Let phase_angle be MathCore.arctangent2(cross_sample.imag, cross_sample.real)
        Collections.append(phase_spectrum, phase_angle)
        Let i be i plus 1
    
    Return phase_spectrum

Process called "group_delay_spectrum" that takes signal1 as List[Float], signal2 as List[Float] returns List[Float]:
    Note: Group delay from cross-spectrum using derivative of phase spectrum
    Note: Measures time delay as function of frequency between two signals
    Note: Time complexity: O(N log N), Space complexity: O(N)
    
    Let N1 be Collections.get_size(signal1)
    Let N2 be Collections.get_size(signal2)
    
    If N1 is less than or equal to 2 or N2 is less than or equal to 2:
        Throw Errors.ArgumentError with "Both signals must have at least 3 samples"
    
    Note: Use shorter signal length
    Let N be N1
    If N2 is less than N1:
        Let N be N2
    
    Note: Get phase spectrum
    Let phase_spectrum be phase_spectrum(signal1, signal2)
    Let group_delay be Collections.create_list()
    
    Note: Compute group delay as negative derivative of phase
    Let phase_N be Collections.get_size(phase_spectrum)
    If phase_N is less than or equal to 2:
        Return Collections.create_list()
    
    Note: First point minus use forward difference
    Let phase0 be Collections.get_item(phase_spectrum, 0)
    Let phase1 be Collections.get_item(phase_spectrum, 1)
    Let freq_step be DEFAULT_SAMPLING_RATE / Float(N)
    Let group_delay_0 be -(phase1 minus phase0) / (2.0 multiplied by 3.14159265359 multiplied by freq_step)
    Collections.append(group_delay, group_delay_0)
    
    Note: Middle points minus use central difference
    Let i be 1
    While i is less than phase_N minus 1:
        Let phase_prev be Collections.get_item(phase_spectrum, i minus 1)
        Let phase_next be Collections.get_item(phase_spectrum, i plus 1)
        
        Note: Handle phase wrapping
        Let phase_diff be phase_next minus phase_prev
        If phase_diff is greater than 3.14159265359:
            Let phase_diff be phase_diff minus 2.0 multiplied by 3.14159265359
        If phase_diff is less than -3.14159265359:
            Let phase_diff be phase_diff plus 2.0 multiplied by 3.14159265359
        
        Let group_delay_val be -phase_diff / (2.0 multiplied by 2.0 multiplied by 3.14159265359 multiplied by freq_step)
        Collections.append(group_delay, group_delay_val)
        Let i be i plus 1
    
    Note: Last point minus use backward difference  
    Let phase_prev be Collections.get_item(phase_spectrum, phase_N minus 2)
    Let phase_last be Collections.get_item(phase_spectrum, phase_N minus 1)
    Let group_delay_last be -(phase_last minus phase_prev) / (2.0 multiplied by 3.14159265359 multiplied by freq_step)
    Collections.append(group_delay, group_delay_last)
    
    Return group_delay

Process called "multiple_coherence" that takes reference_signal as List[Float], input_signals as List[List[Float]] returns List[Float]:
    Note: Multiple coherence function measuring linear relationship between reference and multiple inputs
    Note: Generalizes coherence to multiple input signals, showing combined predictive power
    Note: Time complexity: O(M*N log N), Space complexity: O(N) where M is number of inputs
    
    Let ref_N be Collections.get_size(reference_signal)
    Let num_inputs be Collections.get_size(input_signals)
    
    If ref_N is less than or equal to 1:
        Throw Errors.ArgumentError with "Reference signal must have at least 2 samples"
    
    If num_inputs is equal to 0:
        Return Collections.create_list()
    
    Note: Get reference signal power spectrum
    Let ref_psd be periodogram(reference_signal, "hanning", DEFAULT_SAMPLING_RATE)
    Let num_freqs be Collections.get_size(ref_psd.power_spectral_density)
    
    Note: Initialize multiple coherence array
    Let multiple_coherence be Collections.create_list()
    Let i be 0
    While i is less than num_freqs:
        Collections.append(multiple_coherence, 0.0)
        Let i be i plus 1
    
    Note: Compute coherence with each input and accumulate
    Let input_idx be 0
    While input_idx is less than num_inputs:
        Let input_signal be Collections.get_item(input_signals, input_idx)
        Let input_N be Collections.get_size(input_signal)
        
        If input_N is greater than 1:
            Note: Use shorter length between reference and input
            Let N be ref_N
            If input_N is less than ref_N:
                Let N be input_N
            
            Note: Extract equal-length segments
            Let ref_segment be Collections.create_list()
            Let input_segment be Collections.create_list()
            Let j be 0
            While j is less than N:
                Collections.append(ref_segment, Collections.get_item(reference_signal, j))
                Collections.append(input_segment, Collections.get_item(input_signal, j))
                Let j be j plus 1
            
            Note: Compute coherence between reference and this input
            Let coherence_values be coherence_function(ref_segment, input_segment, "periodogram")
            
            Note: Add to multiple coherence (simplified combination)
            Let coherence_N be Collections.get_size(coherence_values)
            Let min_freqs be num_freqs
            If coherence_N is less than num_freqs:
                Let min_freqs be coherence_N
            
            Let k be 0
            While k is less than min_freqs:
                Let current_mult_coh be Collections.get_item(multiple_coherence, k)
                Let single_coh be Collections.get_item(coherence_values, k)
                
                Note: Combine coherences (using simple average approach)
                Let weight be 1.0 / Float(num_inputs)
                Let updated_coh be current_mult_coh plus (weight multiplied by single_coh)
                Collections.set_item(multiple_coherence, k, updated_coh)
                Let k be k plus 1
        
        Let input_idx be input_idx plus 1
    
    Note: Ensure values are in valid range [0, 1]
    Let i be 0
    While i is less than num_freqs:
        Let coh_val be Collections.get_item(multiple_coherence, i)
        If coh_val is greater than 1.0:
            Collections.set_item(multiple_coherence, i, 1.0)
        If coh_val is less than 0.0:
            Collections.set_item(multiple_coherence, i, 0.0)
        Let i be i plus 1
    
    Return multiple_coherence

Note: ========================================================================
Note: TIME-FREQUENCY ANALYSIS
Note: ========================================================================

Process called "spectrogram" that takes signal as List[Float], window_length as Integer, overlap as Integer, window_function as String returns SpectrogramResult:
    Note: Compute spectrogram for time-frequency analysis using sliding window STFT
    Note: Returns time-frequency representation showing spectral content over time
    Note: Time complexity: O(T multiplied by N log N), Space complexity: O(T multiplied by N)
    
    Let N be Collections.get_size(signal)
    If N is less than or equal to 1:
        Throw Errors.ArgumentError with "Signal must have at least 2 samples"
    
    If window_length is less than or equal to 0 or window_length is greater than N:
        Throw Errors.ArgumentError with "Window length must be positive and not exceed signal length"
    
    If overlap is less than 0 or overlap is greater than or equal to window_length:
        Throw Errors.ArgumentError with "Overlap must be non-negative and less than window length"
    
    Note: Calculate hop size and number of time frames
    Let hop_size be window_length minus overlap
    If hop_size is less than or equal to 0:
        Let hop_size be 1
    
    Let num_frames be (N minus window_length) / hop_size plus 1
    If num_frames is less than or equal to 0:
        Let num_frames be 1
    
    Note: Initialize spectrogram matrix and frequency/time axes
    Let spectrogram_matrix be Collections.create_list()
    Let time_bins be Collections.create_list()
    Let frequency_bins be Collections.create_list()
    
    Note: Create frequency bins
    Let k be 0
    While k is less than or equal to window_length / 2:
        Let freq be Float(k) multiplied by DEFAULT_SAMPLING_RATE / Float(window_length)
        Collections.append(frequency_bins, freq)
        Let k be k plus 1
    
    Note: Process each time frame
    Let frame_idx be 0
    While frame_idx is less than num_frames:
        Let start_idx be frame_idx multiplied by hop_size
        
        Note: Extract windowed segment
        Let segment be Collections.create_list()
        Let i be 0
        While i is less than window_length and (start_idx plus i) is less than N:
            Collections.append(segment, Collections.get_item(signal, start_idx plus i))
            Let i be i plus 1
        
        Note: Pad with zeros if needed
        While i is less than window_length:
            Collections.append(segment, 0.0)
            Let i be i plus 1
        
        Note: Apply window function
        Let windowed_segment be apply_window_function(segment, window_function)
        
        Note: Convert to complex for DFT
        Let complex_segment be Collections.create_list()
        Let j be 0
        While j is less than window_length:
            Let real_part be Collections.get_item(windowed_segment, j)
            Let complex_sample be Complex
            Let complex_sample.real be real_part
            Let complex_sample.imag be 0.0
            Collections.append(complex_segment, complex_sample)
            Let j be j plus 1
        
        Note: Compute DFT
        Let dft_result be DFT.dft_direct(complex_segment)
        
        Note: Compute power spectrum for this frame
        Let frame_spectrum be Collections.create_list()
        Let k be 0
        While k is less than or equal to window_length / 2:
            Let dft_sample be Collections.get_item(dft_result, k)
            Let magnitude_squared be (dft_sample.real multiplied by dft_sample.real) plus (dft_sample.imag multiplied by dft_sample.imag)
            Collections.append(frame_spectrum, magnitude_squared)
            Let k be k plus 1
        
        Collections.append(spectrogram_matrix, frame_spectrum)
        
        Note: Add time bin (center of window)
        Let time_center be Float(start_idx plus window_length / 2) / DEFAULT_SAMPLING_RATE
        Collections.append(time_bins, time_center)
        
        Let frame_idx be frame_idx plus 1
    
    Note: Create spectrogram result
    Let result be SpectrogramResult
    Let result.time_frequency_matrix be spectrogram_matrix
    Let result.time_bins be time_bins
    Let result.frequency_bins be frequency_bins
    Let result.window_function be window_function
    
    Let parameters be Collections.create_dictionary()
    Collections.set_item(parameters, "window_length", window_length)
    Collections.set_item(parameters, "overlap", overlap)
    Collections.set_item(parameters, "hop_size", hop_size)
    Collections.set_item(parameters, "num_frames", num_frames)
    Let result.parameters be parameters
    Let result.sampling_rate be DEFAULT_SAMPLING_RATE
    
    Return result

Process called "reassigned_spectrogram" that takes signal as List[Float], window_length as Integer, overlap as Integer returns SpectrogramResult:
    Note: Reassigned spectrogram for improved resolution using differential windows
    Note: Computes time and frequency reassignments to reduce spectral spreading
    Note: Time complexity: O(M*N*log(N)), Space complexity: O(M*N) where M is number of frames
    
    Let N be Collections.get_size(signal)
    If N is less than window_length:
        Throw Errors.ArgumentError with "Signal must be at least as long as window"
    
    If window_length is less than or equal to 2:
        Throw Errors.ArgumentError with "Window length must be greater than 2"
    
    If overlap is greater than or equal to window_length:
        Throw Errors.ArgumentError with "Overlap must be less than window length"
    
    Let hop_size be window_length minus overlap
    Let num_frames be (N minus window_length) / hop_size plus 1
    
    Note: Create differential windows for reassignment
    Let time_window be apply_window_function(Collections.range(0, window_length), "hanning")
    Let time_derivative_window be Collections.create_list()
    Let freq_derivative_window be Collections.create_list()
    
    Note: Compute time derivative window (t multiplied by h(t))
    Let t be 0
    While t is less than window_length:
        Let window_value be Collections.get_item(time_window, t)
        Let t_center be Float(t) minus Float(window_length minus 1) / 2.0
        Collections.append(time_derivative_window, t_center multiplied by window_value)
        Let t be t plus 1
    
    Note: Compute frequency derivative window (dh/dt)
    Let t be 0
    While t is less than window_length:
        Let deriv_value be 0.0
        If t is greater than 0 and t is less than window_length minus 1:
            Let prev_value be Collections.get_item(time_window, t minus 1)
            Let next_value be Collections.get_item(time_window, t plus 1)
            Let deriv_value be (next_value minus prev_value) / 2.0
        Collections.append(freq_derivative_window, deriv_value)
        Let t be t plus 1
    
    Note: Initialize output matrices
    Let magnitude_matrix be Collections.create_list()
    Let phase_matrix be Collections.create_list()
    Let time_reassign_matrix be Collections.create_list()
    Let freq_reassign_matrix be Collections.create_list()
    
    Note: Process each frame
    Let frame_index be 0
    While frame_index is less than num_frames:
        Let start_pos be frame_index multiplied by hop_size
        
        Note: Extract and window signal segments
        Let windowed_segment be Collections.create_list()
        Let time_weighted_segment be Collections.create_list()
        Let freq_weighted_segment be Collections.create_list()
        
        Let i be 0
        While i is less than window_length:
            Let signal_index be start_pos plus i
            Let signal_value be 0.0
            If signal_index is less than N:
                Let signal_value be Collections.get_item(signal, signal_index)
            
            Let time_win be Collections.get_item(time_window, i)
            Let time_deriv_win be Collections.get_item(time_derivative_window, i)
            Let freq_deriv_win be Collections.get_item(freq_derivative_window, i)
            
            Collections.append(windowed_segment, signal_value multiplied by time_win)
            Collections.append(time_weighted_segment, signal_value multiplied by time_deriv_win)
            Collections.append(freq_weighted_segment, signal_value multiplied by freq_deriv_win)
            Let i be i plus 1
        
        Note: Compute FFTs for all three segments
        Let fft_result be DFT.fft_direct(windowed_segment)
        Let time_fft_result be DFT.fft_direct(time_weighted_segment)
        Let freq_fft_result be DFT.fft_direct(freq_weighted_segment)
        
        Note: Compute reassignment vectors
        Let frame_magnitudes be Collections.create_list()
        Let frame_phases be Collections.create_list()
        Let frame_time_reassign be Collections.create_list()
        Let frame_freq_reassign be Collections.create_list()
        
        Let freq_bin be 0
        While freq_bin is less than window_length:
            Let X be Collections.get_item(fft_result, freq_bin)
            Let TX be Collections.get_item(time_fft_result, freq_bin)
            Let DX be Collections.get_item(freq_fft_result, freq_bin)
            
            Note: Compute magnitude and phase
            Let magnitude be MathCore.square_root(X.real multiplied by X.real plus X.imaginary multiplied by X.imaginary)
            Let phase be MathCore.arctangent2(X.imaginary, X.real)
            
            Note: Compute time reassignment
            Let time_reassign be 0.0
            If magnitude is greater than 1e-12:
                Let numerator be TX.real multiplied by X.real plus TX.imaginary multiplied by X.imaginary
                Let time_reassign be numerator / (magnitude multiplied by magnitude)
            
            Note: Compute frequency reassignment
            Let freq_reassign be Float(freq_bin)
            If magnitude is greater than 1e-12:
                Let numerator be DX.imaginary multiplied by X.real minus DX.real multiplied by X.imaginary
                Let omega_reassign be numerator / (magnitude multiplied by magnitude)
                Let freq_reassign be Float(freq_bin) plus omega_reassign multiplied by Float(window_length) / (2.0 multiplied by 3.14159265359)
            
            Collections.append(frame_magnitudes, magnitude)
            Collections.append(frame_phases, phase)
            Collections.append(frame_time_reassign, time_reassign)
            Collections.append(frame_freq_reassign, freq_reassign)
            Let freq_bin be freq_bin plus 1
        
        Collections.append(magnitude_matrix, frame_magnitudes)
        Collections.append(phase_matrix, frame_phases)
        Collections.append(time_reassign_matrix, frame_time_reassign)
        Collections.append(freq_reassign_matrix, frame_freq_reassign)
        Let frame_index be frame_index plus 1
    
    Note: Create frequency axis
    Let frequencies be Collections.create_list()
    Let k be 0
    While k is less than window_length:
        Let freq be Float(k) / Float(window_length)
        Collections.append(frequencies, freq)
        Let k be k plus 1
    
    Note: Create time axis
    Let times be Collections.create_list()
    Let f be 0
    While f is less than num_frames:
        Let time be Float(f multiplied by hop_size) / Float(N)
        Collections.append(times, time)
        Let f be f plus 1
    
    Let result be SpectrogramResult
    Let result.magnitude_matrix be magnitude_matrix
    Let result.phase_matrix be phase_matrix
    Let result.frequencies be frequencies
    Let result.times be times
    Let result.window_length be window_length
    Let result.overlap be overlap
    
    Return result

Process called "wigner_ville_distribution" that takes signal as List[Float] returns List[List[Float]]:
    Note: Wigner-Ville time-frequency distribution for high resolution analysis
    Note: Provides optimal time-frequency resolution but suffers from cross-terms
    Note: Time complexity: O(N^2 log N), Space complexity: O(N^2)
    
    Let N be Collections.get_size(signal)
    If N is less than or equal to 1:
        Throw Errors.ArgumentError with "Signal must have at least 2 samples"
    
    Note: Initialize Wigner-Ville distribution matrix
    Let wvd_matrix be Collections.create_list()
    
    Note: For each time sample
    Let n be 0
    While n is less than N:
        Let wvd_row be Collections.create_list()
        
        Note: For each frequency bin (same resolution as time)
        Let k be 0
        While k is less than N:
            Let wvd_value be 0.0
            
            Note: Compute Wigner kernel: sum over lag tau
            Let max_lag be N / 4
            If max_lag is greater than n:
                Let max_lag be n
            If max_lag is greater than (N minus 1 minus n):
                Let max_lag be N minus 1 minus n
            
            Let tau be -max_lag
            While tau is less than or equal to max_lag:
                Let n_plus_tau be n plus tau
                Let n_minus_tau be n minus tau
                
                If n_plus_tau is greater than or equal to 0 and n_plus_tau is less than N and n_minus_tau is greater than or equal to 0 and n_minus_tau is less than N:
                    Let x_forward be Collections.get_item(signal, n_plus_tau)
                    Let x_backward be Collections.get_item(signal, n_minus_tau)
                    
                    Note: Wigner kernel: x(n+tau) multiplied by x*(n-tau) multiplied by exp(-j*2*pi*k*tau/N)
                    Let omega be 2.0 multiplied by 3.14159265359 multiplied by Float(k) multiplied by Float(tau) / Float(N)
                    Let real_part be x_forward multiplied by x_backward multiplied by MathCore.cosine(omega)
                    Let imag_part be x_forward multiplied by x_backward multiplied by MathCore.sine(omega)
                    
                    Note: Take real part only (for real signals)
                    Let wvd_value be wvd_value plus real_part
                
                Let tau be tau plus 1
            
            Collections.append(wvd_row, wvd_value)
            Let k be k plus 1
        
        Collections.append(wvd_matrix, wvd_row)
        Let n be n plus 1
    
    Return wvd_matrix

Process called "choi_williams_distribution" that takes signal as List[Float], sigma as Float returns List[List[Float]]:
    Note: Choi-Williams time-frequency distribution with reduced cross-terms
    Note: Uses exponential kernel to suppress cross-terms while preserving auto-terms
    Note: Time complexity: O(N^2 log N), Space complexity: O(N^2)
    
    Let N be Collections.get_size(signal)
    If N is less than or equal to 1:
        Throw Errors.ArgumentError with "Signal must have at least 2 samples"
    
    If sigma is less than or equal to 0.0:
        Throw Errors.ArgumentError with "Sigma parameter must be positive"
    
    Note: Initialize Choi-Williams distribution matrix
    Let cwd_matrix be Collections.create_list()
    
    Note: For each time sample
    Let n be 0
    While n is less than N:
        Let cwd_row be Collections.create_list()
        
        Note: For each frequency bin
        Let k be 0
        While k is less than N:
            Let cwd_value be 0.0
            
            Note: Compute Choi-Williams kernel with exponential weighting
            Let max_lag be N / 4
            If max_lag is greater than n:
                Let max_lag be n
            If max_lag is greater than (N minus 1 minus n):
                Let max_lag be N minus 1 minus n
            
            Let tau be -max_lag
            While tau is less than or equal to max_lag:
                Let n_plus_tau be n plus tau
                Let n_minus_tau be n minus tau
                
                If n_plus_tau is greater than or equal to 0 and n_plus_tau is less than N and n_minus_tau is greater than or equal to 0 and n_minus_tau is less than N:
                    Let x_forward be Collections.get_item(signal, n_plus_tau)
                    Let x_backward be Collections.get_item(signal, n_minus_tau)
                    
                    Note: Choi-Williams exponential kernel
                    Let tau_normalized be Float(tau) / Float(max_lag)
                    Let kernel_weight be MathCore.exponential(-(tau_normalized multiplied by tau_normalized) / (sigma multiplied by sigma))
                    
                    Note: Wigner kernel with Choi-Williams weighting
                    Let omega be 2.0 multiplied by 3.14159265359 multiplied by Float(k) multiplied by Float(tau) / Float(N)
                    Let real_part be x_forward multiplied by x_backward multiplied by MathCore.cosine(omega) multiplied by kernel_weight
                    Let imag_part be x_forward multiplied by x_backward multiplied by MathCore.sine(omega) multiplied by kernel_weight
                    
                    Note: Take real part for real signals
                    Let cwd_value be cwd_value plus real_part
                
                Let tau be tau plus 1
            
            Collections.append(cwd_row, cwd_value)
            Let k be k plus 1
        
        Collections.append(cwd_matrix, cwd_row)
        Let n be n plus 1
    
    Return cwd_matrix

Process called "born_jordan_distribution" that takes signal as List[Float] returns List[List[Float]]:
    Note: Born-Jordan time-frequency distribution with optimal time-frequency resolution
    Note: Satisfies desirable mathematical properties and reduces cross-terms
    Note: Time complexity: O(N^3), Space complexity: O(N^2)
    
    Let N be Collections.get_size(signal)
    If N is less than or equal to 1:
        Throw Errors.ArgumentError with "Signal must have at least 2 samples"
    
    Note: Initialize Born-Jordan distribution matrix
    Let bjd_matrix be Collections.create_list()
    
    Note: For each time sample
    Let n be 0
    While n is less than N:
        Let bjd_row be Collections.create_list()
        
        Note: For each frequency bin
        Let k be 0
        While k is less than N:
            Let bjd_value be 0.0
            
            Note: Born-Jordan uses integration over lag with sinc-like kernel
            Let max_lag be N / 4
            If max_lag is greater than n:
                Let max_lag be n
            If max_lag is greater than (N minus 1 minus n):
                Let max_lag be N minus 1 minus n
            
            Let tau be -max_lag
            While tau is less than or equal to max_lag:
                Let n_plus_tau be n plus tau
                Let n_minus_tau be n minus tau
                
                If n_plus_tau is greater than or equal to 0 and n_plus_tau is less than N and n_minus_tau is greater than or equal to 0 and n_minus_tau is less than N:
                    Let x_forward be Collections.get_item(signal, n_plus_tau)
                    Let x_backward be Collections.get_item(signal, n_minus_tau)
                    
                    Note: Born-Jordan kernel with sinc-like weighting
                    Let tau_abs be Float(tau)
                    If tau_abs is less than 0.0:
                        Let tau_abs be -tau_abs
                    
                    Let kernel_weight be 1.0
                    If tau_abs is greater than 0.0:
                        Let sinc_arg be 3.14159265359 multiplied by tau_abs / Float(max_lag)
                        Let kernel_weight be MathCore.sine(sinc_arg) / sinc_arg
                    
                    Note: Additional Born-Jordan specific weighting
                    Let omega be 2.0 multiplied by 3.14159265359 multiplied by Float(k) multiplied by Float(tau) / Float(N)
                    
                    Note: Compute inner integral (simplified approach)
                    Let inner_sum be 0.0
                    Let u be -Integer(tau_abs)
                    While u is less than or equal to Integer(tau_abs):
                        If u does not equal 0:
                            Let u_weight be 1.0 / Float(Integer(tau_abs) multiplied by 2 plus 1)
                            Let phase_shift be Float(u) multiplied by omega / Float(tau plus 1)
                            Let inner_sum be inner_sum plus (u_weight multiplied by MathCore.cosine(phase_shift))
                        Otherwise:
                            Let u_weight be 1.0 / Float(Integer(tau_abs) multiplied by 2 plus 1)
                            Let inner_sum be inner_sum plus u_weight
                        Let u be u plus 1
                    
                    Note: Combine with Wigner kernel
                    Let real_part be x_forward multiplied by x_backward multiplied by MathCore.cosine(omega) multiplied by kernel_weight multiplied by inner_sum
                    Let bjd_value be bjd_value plus real_part
                
                Let tau be tau plus 1
            
            Collections.append(bjd_row, bjd_value)
            Let k be k plus 1
        
        Collections.append(bjd_matrix, bjd_row)
        Let n be n plus 1
    
    Return bjd_matrix

Note: ========================================================================
Note: SPECTRAL PEAK DETECTION AND ANALYSIS
Note: ========================================================================

Type called "SpectralPeak":
    frequency as Float
    magnitude as Float
    phase as Float
    bandwidth as Float
    prominence as Float
    quality_factor as Float

Process called "find_spectral_peaks" that takes spectrum as List[Float], frequencies as List[Float], threshold as Float returns List[SpectralPeak]:
    Note: Detect peaks in power spectrum using prominence and threshold criteria
    Note: Returns list of spectral peaks with frequency, magnitude and quality measures
    Note: Time complexity: O(N), Space complexity: O(P) where P is number of peaks
    
    Let N be Collections.get_size(spectrum)
    Let freq_N be Collections.get_size(frequencies)
    
    If N is less than or equal to 2:
        Throw Errors.ArgumentError with "Spectrum must have at least 3 samples"
    
    If freq_N does not equal N:
        Throw Errors.ArgumentError with "Frequency and spectrum arrays must have same length"
    
    If threshold is less than 0.0:
        Throw Errors.ArgumentError with "Threshold must be non-negative"
    
    Let peaks be Collections.create_list()
    
    Note: Find local maxima that exceed threshold
    Let i be 1
    While i is less than N minus 1:
        Let current_mag be Collections.get_item(spectrum, i)
        Let left_mag be Collections.get_item(spectrum, i minus 1)
        Let right_mag be Collections.get_item(spectrum, i plus 1)
        
        Note: Check if current sample is a local maximum above threshold
        If current_mag is greater than left_mag and current_mag is greater than right_mag and current_mag is greater than threshold:
            Let peak_freq be Collections.get_item(frequencies, i)
            
            Note: Calculate peak prominence (height above local minima)
            Let left_min be current_mag
            Let right_min be current_mag
            
            Note: Find left minimum
            Let j be i minus 1
            While j is greater than or equal to 0:
                Let sample be Collections.get_item(spectrum, j)
                If sample is less than left_min:
                    Let left_min be sample
                If sample is greater than current_mag:
                    Break
                Let j be j minus 1
            
            Note: Find right minimum
            Let j be i plus 1
            While j is less than N:
                Let sample be Collections.get_item(spectrum, j)
                If sample is less than right_min:
                    Let right_min be sample
                If sample is greater than current_mag:
                    Break
                Let j be j plus 1
            
            Let min_base be left_min
            If right_min is less than left_min:
                Let min_base be right_min
            
            Let prominence be current_mag minus min_base
            
            Note: Estimate bandwidth using -3dB points
            Let half_power be current_mag / 2.0
            Let bandwidth be 0.0
            
            Note: Find left -3dB point
            Let left_3db be i
            Let j be i minus 1
            While j is greater than or equal to 0:
                Let sample be Collections.get_item(spectrum, j)
                If sample is less than or equal to half_power:
                    Let left_3db be j
                    Break
                Let j be j minus 1
            
            Note: Find right -3dB point
            Let right_3db be i
            Let j be i plus 1
            While j is less than N:
                Let sample be Collections.get_item(spectrum, j)
                If sample is less than or equal to half_power:
                    Let right_3db be j
                    Break
                Let j be j plus 1
            
            If right_3db is greater than left_3db:
                Let left_freq be Collections.get_item(frequencies, left_3db)
                Let right_freq be Collections.get_item(frequencies, right_3db)
                Let bandwidth be right_freq minus left_freq
            
            Note: Calculate quality factor Q is equal to f0 / bandwidth
            Let quality_factor be 0.0
            If bandwidth is greater than 0.0:
                Let quality_factor be peak_freq / bandwidth
            
            Note: Create peak object
            Let peak be SpectralPeak
            Let peak.frequency be peak_freq
            Let peak.magnitude be current_mag
            Let peak.phase be 0.0
            Let peak.bandwidth be bandwidth
            Let peak.prominence be prominence
            Let peak.quality_factor be quality_factor
            
            Collections.append(peaks, peak)
        
        Let i be i plus 1
    
    Return peaks

Process called "track_spectral_peaks" that takes spectrograms as List[List[Float]], time_bins as List[Float] returns List[List[SpectralPeak]]:
    Note: Track spectral peaks across time using dynamic programming and cost functions
    Note: Links peaks across time frames based on frequency continuity and amplitude
    Note: Time complexity: O(T*P^2), Space complexity: O(T*P) where T is time frames, P is peaks per frame
    
    Let num_frames be Collections.get_size(spectrograms)
    Let num_time_bins be Collections.get_size(time_bins)
    
    If num_frames does not equal num_time_bins:
        Throw Errors.ArgumentError with "Spectrograms and time bins must have same length"
    
    If num_frames is less than 2:
        Throw Errors.ArgumentError with "At least 2 frames required for peak tracking"
    
    Note: Extract peaks from each frame
    Let all_frame_peaks be Collections.create_list()
    Let frame_idx be 0
    While frame_idx is less than num_frames:
        Let spectrum be Collections.get_item(spectrograms, frame_idx)
        Let time_value be Collections.get_item(time_bins, frame_idx)
        
        Note: Find peaks in current frame
        Let frame_peaks be Collections.create_list()
        Let freq_bin be 1
        Let N be Collections.get_size(spectrum)
        While freq_bin is less than N minus 1:
            Let current_mag be Collections.get_item(spectrum, freq_bin)
            Let prev_mag be Collections.get_item(spectrum, freq_bin minus 1)
            Let next_mag be Collections.get_item(spectrum, freq_bin plus 1)
            
            Note: Local maximum detection
            If current_mag is greater than prev_mag and current_mag is greater than next_mag and current_mag is greater than 0.001:
                Note: Calculate peak properties
                Let peak be SpectralPeak
                Let peak.frequency be Float(freq_bin)
                Let peak.magnitude be current_mag
                Let peak.phase be 0.0
                
                Note: Estimate bandwidth using half-power points
                Let bandwidth be 1.0
                Let half_power be current_mag multiplied by 0.7071
                
                Note: Find left half-power point
                Let left_idx be freq_bin minus 1
                While left_idx is greater than or equal to 0:
                    Let left_mag be Collections.get_item(spectrum, left_idx)
                    If left_mag is less than or equal to half_power:
                        Let bandwidth be bandwidth plus Float(freq_bin minus left_idx minus 1)
                        Let left_idx be -1
                    Otherwise:
                        Let left_idx be left_idx minus 1
                
                Note: Find right half-power point
                Let right_idx be freq_bin plus 1
                While right_idx is less than N:
                    Let right_mag be Collections.get_item(spectrum, right_idx)
                    If right_mag is less than or equal to half_power:
                        Let bandwidth be bandwidth plus Float(right_idx minus freq_bin minus 1)
                        Let right_idx be N
                    Otherwise:
                        Let right_idx be right_idx plus 1
                
                Let peak.bandwidth be bandwidth
                Let peak.quality_factor be current_mag / bandwidth
                
                Collections.append(frame_peaks, peak)
            
            Let freq_bin be freq_bin plus 1
        
        Collections.append(all_frame_peaks, frame_peaks)
        Let frame_idx be frame_idx plus 1
    
    Note: Initialize peak tracking with dynamic programming
    Let tracked_peaks be Collections.create_list()
    Let active_tracks be Collections.create_list()
    Let next_track_id be 0
    
    Note: Initialize tracks from first frame
    Let first_frame_peaks be Collections.get_item(all_frame_peaks, 0)
    Let initial_peak_idx be 0
    Let first_frame_size be Collections.get_size(first_frame_peaks)
    While initial_peak_idx is less than first_frame_size:
        Let peak be Collections.get_item(first_frame_peaks, initial_peak_idx)
        
        Let track be Collections.create_list()
        Collections.append(track, peak)
        Collections.append(active_tracks, track)
        Let next_track_id be next_track_id plus 1
        Let initial_peak_idx be initial_peak_idx plus 1
    
    Note: Process remaining frames
    Let frame_idx be 1
    While frame_idx is less than num_frames:
        Let current_peaks be Collections.get_item(all_frame_peaks, frame_idx)
        Let current_time be Collections.get_item(time_bins, frame_idx)
        Let prev_time be Collections.get_item(time_bins, frame_idx minus 1)
        Let time_delta be current_time minus prev_time
        
        Let new_active_tracks be Collections.create_list()
        Let unmatched_peaks be Collections.copy_list(current_peaks)
        
        Note: Match current peaks to existing tracks
        Let track_idx be 0
        Let num_active_tracks be Collections.get_size(active_tracks)
        While track_idx is less than num_active_tracks:
            Let track be Collections.get_item(active_tracks, track_idx)
            Let last_peak_idx be Collections.get_size(track) minus 1
            Let last_peak be Collections.get_item(track, last_peak_idx)
            
            Note: Find best matching peak using cost function
            Let best_match_idx be -1
            Let best_cost be 99999.0
            Let max_freq_jump be 5.0
            Let max_amp_ratio be 3.0
            
            Let peak_idx be 0
            Let num_current_peaks be Collections.get_size(unmatched_peaks)
            While peak_idx is less than num_current_peaks:
                Let candidate_peak be Collections.get_item(unmatched_peaks, peak_idx)
                
                Note: Calculate matching cost
                Let freq_diff be MathCore.absolute(candidate_peak.frequency minus last_peak.frequency)
                Let amp_ratio be candidate_peak.magnitude / last_peak.magnitude
                If amp_ratio is greater than 1.0:
                    Let amp_ratio be 1.0 / amp_ratio
                
                Note: Cost function: frequency continuity plus amplitude consistency
                Let freq_cost be freq_diff / max_freq_jump
                Let amp_cost be (1.0 minus amp_ratio) / (1.0 minus 1.0 / max_amp_ratio)
                Let total_cost be freq_cost plus amp_cost
                
                Note: Only consider reasonable matches
                If freq_diff is less than or equal to max_freq_jump and total_cost is less than best_cost:
                    Let best_cost be total_cost
                    Let best_match_idx be peak_idx
                
                Let peak_idx be peak_idx plus 1
            
            Note: Extend track if good match found
            If best_match_idx is greater than or equal to 0 and best_cost is less than 2.0:
                Let matched_peak be Collections.get_item(unmatched_peaks, best_match_idx)
                Collections.append(track, matched_peak)
                Collections.remove_at(unmatched_peaks, best_match_idx)
                Collections.append(new_active_tracks, track)
            Otherwise:
                Note: End track if no good match (track completed)
                Collections.append(tracked_peaks, track)
            
            Let track_idx be track_idx plus 1
        
        Note: Start new tracks for unmatched peaks
        Let unmatched_idx be 0
        Let num_unmatched be Collections.get_size(unmatched_peaks)
        While unmatched_idx is less than num_unmatched:
            Let unmatched_peak be Collections.get_item(unmatched_peaks, unmatched_idx)
            Let new_track be Collections.create_list()
            Collections.append(new_track, unmatched_peak)
            Collections.append(new_active_tracks, new_track)
            Let unmatched_idx be unmatched_idx plus 1
        
        Let active_tracks be new_active_tracks
        Let frame_idx be frame_idx plus 1
    
    Note: Add remaining active tracks to completed tracks
    Let remaining_idx be 0
    Let num_remaining be Collections.get_size(active_tracks)
    While remaining_idx is less than num_remaining:
        Let remaining_track be Collections.get_item(active_tracks, remaining_idx)
        Collections.append(tracked_peaks, remaining_track)
        Let remaining_idx be remaining_idx plus 1
    
    Note: Filter tracks by minimum length
    Let filtered_tracks be Collections.create_list()
    Let min_track_length be 3
    Let track_idx be 0
    Let num_tracks be Collections.get_size(tracked_peaks)
    While track_idx is less than num_tracks:
        Let track be Collections.get_item(tracked_peaks, track_idx)
        If Collections.get_size(track) is greater than or equal to min_track_length:
            Collections.append(filtered_tracks, track)
        Let track_idx be track_idx plus 1
    
    Return filtered_tracks

Process called "harmonic_analysis" that takes spectrum as List[Float], fundamental_frequency as Float returns List[SpectralPeak]:
    Note: Analyze harmonic structure by detecting peaks at integer multiples of fundamental frequency
    Note: Identifies harmonics and measures their amplitudes for pitch and timbre analysis
    Note: Time complexity: O(N*H), Space complexity: O(H) where H is number of harmonics
    
    Let N be Collections.get_size(spectrum)
    If N is less than or equal to 2:
        Throw Errors.ArgumentError with "Spectrum must have at least 3 samples"
    
    If fundamental_frequency is less than or equal to 0.0:
        Throw Errors.ArgumentError with "Fundamental frequency must be positive"
    
    Note: Generate frequency axis
    Let frequencies be Collections.create_list()
    Let i be 0
    While i is less than N:
        Let freq be Float(i) multiplied by DEFAULT_SAMPLING_RATE / Float(N)
        Collections.append(frequencies, freq)
        Let i be i plus 1
    
    Note: Find harmonics up to Nyquist frequency
    Let harmonics be Collections.create_list()
    Let harmonic_number be 1
    Let nyquist_freq be DEFAULT_SAMPLING_RATE / 2.0
    
    While harmonic_number multiplied by fundamental_frequency is less than or equal to nyquist_freq:
        Let target_freq be Float(harmonic_number) multiplied by fundamental_frequency
        
        Note: Find closest frequency bin
        Let closest_bin be 0
        Let min_distance be MathCore.absolute(target_freq minus Collections.get_item(frequencies, 0))
        
        Let bin_idx be 1
        While bin_idx is less than N:
            Let bin_freq be Collections.get_item(frequencies, bin_idx)
            Let distance be MathCore.absolute(target_freq minus bin_freq)
            If distance is less than min_distance:
                Let min_distance be distance
                Let closest_bin be bin_idx
            Let bin_idx be bin_idx plus 1
        
        Note: Check if this is a local maximum
        If closest_bin is greater than 0 and closest_bin is less than N minus 1:
            Let current_mag be Collections.get_item(spectrum, closest_bin)
            Let left_mag be Collections.get_item(spectrum, closest_bin minus 1)
            Let right_mag be Collections.get_item(spectrum, closest_bin plus 1)
            
            If current_mag is greater than left_mag and current_mag is greater than right_mag:
                Note: This is a valid harmonic peak
                Let actual_freq be Collections.get_item(frequencies, closest_bin)
                
                Note: Estimate bandwidth using -3dB method
                Let half_power be current_mag / 2.0
                Let bandwidth be 0.0
                
                Note: Find left -3dB point
                Let left_3db be closest_bin
                Let j be closest_bin minus 1
                While j is greater than or equal to 0:
                    Let sample be Collections.get_item(spectrum, j)
                    If sample is less than or equal to half_power:
                        Let left_3db be j
                        Break
                    Let j be j minus 1
                
                Note: Find right -3dB point
                Let right_3db be closest_bin
                Let j be closest_bin plus 1
                While j is less than N:
                    Let sample be Collections.get_item(spectrum, j)
                    If sample is less than or equal to half_power:
                        Let right_3db be j
                        Break
                    Let j be j plus 1
                
                If right_3db is greater than left_3db:
                    Let left_freq be Collections.get_item(frequencies, left_3db)
                    Let right_freq be Collections.get_item(frequencies, right_3db)
                    Let bandwidth be right_freq minus left_freq
                
                Note: Calculate quality factor
                Let quality_factor be 0.0
                If bandwidth is greater than 0.0:
                    Let quality_factor be actual_freq / bandwidth
                
                Note: Create harmonic peak
                Let harmonic_peak be SpectralPeak
                Let harmonic_peak.frequency be actual_freq
                Let harmonic_peak.magnitude be current_mag
                Let harmonic_peak.phase be 0.0
                Let harmonic_peak.bandwidth be bandwidth
                Let harmonic_peak.prominence be current_mag minus MathCore.minimum(left_mag, right_mag)
                Let harmonic_peak.quality_factor be quality_factor
                
                Collections.append(harmonics, harmonic_peak)
        
        Let harmonic_number be harmonic_number plus 1
    
    Return harmonics

Process called "formant_analysis" that takes spectrum as List[Float], frequencies as List[Float] returns List[SpectralPeak]:
    Note: Formant analysis for speech signals using peak detection and tracking
    Note: Identifies formant frequencies in speech spectra through local maxima detection
    Note: Time complexity: O(N), Space complexity: O(F) where F is number of formants
    
    Let N be Collections.get_size(spectrum)
    Let freq_size be Collections.get_size(frequencies)
    
    If N does not equal freq_size:
        Throw Errors.ArgumentError with "Spectrum and frequencies must have the same size"
    
    If N is less than 3:
        Throw Errors.ArgumentError with "Spectrum must have at least 3 points for peak detection"
    
    Note: Convert to log magnitude for better formant detection
    Let log_spectrum be Collections.create_list()
    Let i be 0
    While i is less than N:
        Let magnitude be Collections.get_item(spectrum, i)
        If magnitude is less than or equal to 0.0:
            Collections.append(log_spectrum, -100.0)
        Otherwise:
            Collections.append(log_spectrum, MathCore.natural_logarithm(magnitude))
        Let i be i plus 1
    
    Note: Apply smoothing to reduce noise in formant detection
    Let smoothed_spectrum be Collections.create_list()
    Let window_size be 5
    Let half_window be window_size / 2
    
    Let j be 0
    While j is less than N:
        Let sum be 0.0
        Let count be 0
        
        Let k be j minus half_window
        While k is less than or equal to j plus half_window:
            If k is greater than or equal to 0 and k is less than N:
                Let value be Collections.get_item(log_spectrum, k)
                Let sum be sum plus value
                Let count be count plus 1
            Let k be k plus 1
        
        Let smoothed_value be sum / Float(count)
        Collections.append(smoothed_spectrum, smoothed_value)
        Let j be j plus 1
    
    Note: Find local maxima (peaks) in smoothed spectrum
    Let formants be Collections.create_list()
    Let min_formant_spacing be 200.0
    
    Let idx be 1
    While idx is less than N minus 1:
        Let current_freq be Collections.get_item(frequencies, idx)
        Let current_mag be Collections.get_item(smoothed_spectrum, idx)
        Let prev_mag be Collections.get_item(smoothed_spectrum, idx minus 1)
        Let next_mag be Collections.get_item(smoothed_spectrum, idx plus 1)
        
        Note: Check if this is a local maximum
        If current_mag is greater than prev_mag and current_mag is greater than next_mag:
            Note: Check frequency range (formants typically 200-4000 Hz)
            If current_freq is greater than or equal to 200.0 and current_freq is less than or equal to 4000.0:
                Note: Check minimum spacing from previous formants
                Let too_close be false
                Let f be 0
                Let formant_count be Collections.get_size(formants)
                While f is less than formant_count:
                    Let existing_formant be Collections.get_item(formants, f)
                    Let existing_freq be existing_formant.frequency
                    Let freq_diff be MathCore.absolute(current_freq minus existing_freq)
                    If freq_diff is less than min_formant_spacing:
                        Let too_close be true
                    Let f be f plus 1
                
                If not too_close:
                    Note: Calculate peak prominence for quality measure
                    Let left_valley be current_mag
                    Let right_valley be current_mag
                    
                    Note: Find left valley
                    Let left_idx be idx minus 1
                    While left_idx is greater than or equal to 0:
                        Let left_value be Collections.get_item(smoothed_spectrum, left_idx)
                        If left_value is less than left_valley:
                            Let left_valley be left_value
                        Let left_idx be left_idx minus 1
                    
                    Note: Find right valley
                    Let right_idx be idx plus 1
                    While right_idx is less than N:
                        Let right_value be Collections.get_item(smoothed_spectrum, right_idx)
                        If right_value is less than right_valley:
                            Let right_valley be right_value
                        Let right_idx be right_idx plus 1
                    
                    Note: Prominence is height above the higher valley
                    Let higher_valley be left_valley
                    If right_valley is greater than left_valley:
                        Let higher_valley be right_valley
                    
                    Let prominence be current_mag minus higher_valley
                    
                    Note: Only include formants with sufficient prominence
                    If prominence is greater than 1.0:
                        Note: Refine peak frequency using quadratic interpolation
                        Let refined_freq be current_freq
                        If idx is greater than 0 and idx is less than N minus 1:
                            Let y1 be Collections.get_item(smoothed_spectrum, idx minus 1)
                            Let y2 be Collections.get_item(smoothed_spectrum, idx)
                            Let y3 be Collections.get_item(smoothed_spectrum, idx plus 1)
                            Let f1 be Collections.get_item(frequencies, idx minus 1)
                            Let f2 be Collections.get_item(frequencies, idx)
                            Let f3 be Collections.get_item(frequencies, idx plus 1)
                            
                            Note: Quadratic interpolation for peak refinement
                            Let denom be 2.0 multiplied by (y1 minus 2.0 multiplied by y2 plus y3)
                            If MathCore.absolute(denom) is greater than 0.001:
                                Let offset be (y1 minus y3) / denom
                                Let freq_step be f2 minus f1
                                Let refined_freq be f2 plus offset multiplied by freq_step
                        
                        Let formant be SpectralPeak
                        Let formant.frequency be refined_freq
                        Let formant.magnitude be MathCore.exponential(current_mag)
                        Let formant.phase be 0.0
                        Let formant.bandwidth be 50.0
                        Let formant.quality_factor be prominence
                        
                        Collections.append(formants, formant)
        
        Let idx be idx plus 1
    
    Note: Sort formants by frequency
    Let sorted_formants be Collections.create_list()
    Let remaining_formants be Collections.copy_list(formants)
    
    While Collections.get_size(remaining_formants) is greater than 0:
        Let min_freq be 99999.0
        Let min_index be 0
        
        Let m be 0
        Let remaining_count be Collections.get_size(remaining_formants)
        While m is less than remaining_count:
            Let formant be Collections.get_item(remaining_formants, m)
            If formant.frequency is less than min_freq:
                Let min_freq be formant.frequency
                Let min_index be m
            Let m be m plus 1
        
        Let min_formant be Collections.get_item(remaining_formants, min_index)
        Collections.append(sorted_formants, min_formant)
        Collections.remove_at(remaining_formants, min_index)
    
    Return sorted_formants

Note: ========================================================================
Note: HIGHER-ORDER SPECTRAL ANALYSIS
Note: ========================================================================

Process called "bispectrum" that takes signal as List[Float], window_length as Integer returns List[List[Complex]]:
    Note: Compute bispectrum (third-order spectrum) for nonlinearity and phase coupling detection
    Note: Bispectrum B(f1,f2) is equal to E[X(f1)*X(f2)*X*(f1+f2)] where multiplied by denotes complex conjugate
    Note: Time complexity: O(N^2 log N), Space complexity: O(N^2)
    
    Let N be Collections.get_size(signal)
    If N is less than or equal to 1:
        Throw Errors.ArgumentError with "Signal must have at least 2 samples"
    
    If window_length is less than or equal to 0 or window_length is greater than N:
        Throw Errors.ArgumentError with "Window length must be positive and not exceed signal length"
    
    Note: Use the provided window length or signal length
    Let segment_length be window_length
    If segment_length is greater than N:
        Let segment_length be N
    
    Note: Extract signal segment
    Let segment be Collections.create_list()
    Let i be 0
    While i is less than segment_length:
        Collections.append(segment, Collections.get_item(signal, i))
        Let i be i plus 1
    
    Note: Apply window function and convert to complex
    Let windowed_segment be apply_window_function(segment, "hanning")
    Let complex_segment be Collections.create_list()
    Let i be 0
    While i is less than segment_length:
        Let real_part be Collections.get_item(windowed_segment, i)
        Let complex_sample be Complex
        Let complex_sample.real be real_part
        Let complex_sample.imag be 0.0
        Collections.append(complex_segment, complex_sample)
        Let i be i plus 1
    
    Note: Compute DFT
    Let X be DFT.dft_direct(complex_segment)
    
    Note: Compute bispectrum B(k1,k2) is equal to X(k1) multiplied by X(k2) multiplied by X*(k1+k2)
    Let bispectrum_matrix be Collections.create_list()
    Let num_freqs be segment_length / 2
    
    Let k1 be 0
    While k1 is less than or equal to num_freqs:
        Let bispectrum_row be Collections.create_list()
        
        Let k2 be 0
        While k2 is less than or equal to num_freqs:
            Let k3 be k1 plus k2
            
            Note: Handle frequency aliasing for k3
            If k3 is greater than or equal to segment_length:
                Let k3 be segment_length minus 1
            
            Note: Get DFT coefficients
            Let X1 be Collections.get_item(X, k1)
            Let X2 be Collections.get_item(X, k2)
            Let X3 be Collections.get_item(X, k3)
            
            Note: Compute bispectrum: X1 multiplied by X2 multiplied by conj(X3)
            Let bis_real be (X1.real multiplied by X2.real multiplied by X3.real) plus (X1.real multiplied by X2.imag multiplied by X3.imag) plus (X1.imag multiplied by X2.real multiplied by X3.imag) minus (X1.imag multiplied by X2.imag multiplied by X3.real)
            Let bis_imag be (X1.imag multiplied by X2.real multiplied by X3.real) plus (X1.real multiplied by X2.real multiplied by X3.imag) minus (X1.real multiplied by X2.imag multiplied by X3.real) plus (X1.imag multiplied by X2.imag multiplied by X3.imag)
            
            Let bispectrum_value be Complex
            Let bispectrum_value.real be bis_real
            Let bispectrum_value.imag be bis_imag
            
            Collections.append(bispectrum_row, bispectrum_value)
            Let k2 be k2 plus 1
        
        Collections.append(bispectrum_matrix, bispectrum_row)
        Let k1 be k1 plus 1
    
    Return bispectrum_matrix

Process called "bicoherence" that takes signal as List[Float], window_length as Integer returns List[List[Float]]:
    Note: Compute bicoherence from bispectrum to measure phase coupling strength
    Note: Normalized bispectrum showing quadratic phase coupling between frequency components
    Note: Time complexity: O(N^2 log N), Space complexity: O(N^2)
    
    Let N be Collections.get_size(signal)
    If N is less than or equal to 1:
        Throw Errors.ArgumentError with "Signal must have at least 2 samples"
    
    If window_length is less than or equal to 0 or window_length is greater than N:
        Throw Errors.ArgumentError with "Window length must be positive and not exceed signal length"
    
    Note: Get bispectrum
    Let bispectrum_matrix be bispectrum(signal, window_length)
    Let bis_size be Collections.get_size(bispectrum_matrix)
    
    Note: Compute power spectra for normalization
    Let segment_length be window_length
    If segment_length is greater than N:
        Let segment_length be N
    
    Let segment be Collections.create_list()
    Let i be 0
    While i is less than segment_length:
        Collections.append(segment, Collections.get_item(signal, i))
        Let i be i plus 1
    
    Let windowed_segment be apply_window_function(segment, "hanning")
    Let complex_segment be Collections.create_list()
    Let i be 0
    While i is less than segment_length:
        Let real_part be Collections.get_item(windowed_segment, i)
        Let complex_sample be Complex
        Let complex_sample.real be real_part
        Let complex_sample.imag be 0.0
        Collections.append(complex_segment, complex_sample)
        Let i be i plus 1
    
    Let X be DFT.dft_direct(complex_segment)
    
    Note: Compute bicoherence matrix
    Let bicoherence_matrix be Collections.create_list()
    
    Let k1 be 0
    While k1 is less than bis_size:
        Let bispectrum_row be Collections.get_item(bispectrum_matrix, k1)
        Let bicoherence_row be Collections.create_list()
        Let bis_row_size be Collections.get_size(bispectrum_row)
        
        Let k2 be 0
        While k2 is less than bis_row_size:
            Let bis_value be Collections.get_item(bispectrum_row, k2)
            Let k3 be k1 plus k2
            
            Note: Handle frequency wrapping
            If k3 is greater than or equal to segment_length:
                Let k3 be segment_length minus 1
            
            Note: Get power spectral components for normalization
            Let X1 be Collections.get_item(X, k1)
            Let X2 be Collections.get_item(X, k2)  
            Let X3 be Collections.get_item(X, k3)
            
            Note: Compute power spectrum values
            Let P1 be (X1.real multiplied by X1.real) plus (X1.imag multiplied by X1.imag)
            Let P2 be (X2.real multiplied by X2.real) plus (X2.imag multiplied by X2.imag)
            Let P3 be (X3.real multiplied by X3.real) plus (X3.imag multiplied by X3.imag)
            
            Note: Compute bicoherence magnitude
            Let bis_magnitude be MathCore.square_root((bis_value.real multiplied by bis_value.real) plus (bis_value.imag multiplied by bis_value.imag))
            
            Note: Normalize by power spectrum products
            Let denominator be MathCore.square_root(P1 multiplied by P2 multiplied by P3)
            Let bicoherence_value be 0.0
            
            If denominator is greater than 0.0:
                Let bicoherence_value be bis_magnitude / denominator
                
                Note: Ensure valid range [0, 1]
                If bicoherence_value is greater than 1.0:
                    Let bicoherence_value be 1.0
            
            Collections.append(bicoherence_row, bicoherence_value)
            Let k2 be k2 plus 1
        
        Collections.append(bicoherence_matrix, bicoherence_row)
        Let k1 be k1 plus 1
    
    Return bicoherence_matrix

Process called "trispectrum" that takes signal as List[Float], window_length as Integer returns List[List[List[Complex]]]:
    Note: Compute trispectrum (fourth-order spectrum) for nonlinearity and Gaussianity detection
    Note: Trispectrum T(f1,f2,f3) is equal to E[X(f1)*X(f2)*X(f3)*X*(f1+f2+f3)]
    Note: Time complexity: O(N^3 log N), Space complexity: O(N^3)
    
    Let N be Collections.get_size(signal)
    If N is less than or equal to 1:
        Throw Errors.ArgumentError with "Signal must have at least 2 samples"
    
    If window_length is less than or equal to 0 or window_length is greater than N:
        Throw Errors.ArgumentError with "Window length must be positive and not exceed signal length"
    
    Note: Use the provided window length or signal length
    Let segment_length be window_length
    If segment_length is greater than N:
        Let segment_length be N
    
    Note: Extract signal segment
    Let segment be Collections.create_list()
    Let i be 0
    While i is less than segment_length:
        Collections.append(segment, Collections.get_item(signal, i))
        Let i be i plus 1
    
    Note: Apply window function and convert to complex
    Let windowed_segment be apply_window_function(segment, "hanning")
    Let complex_segment be Collections.create_list()
    Let i be 0
    While i is less than segment_length:
        Let real_part be Collections.get_item(windowed_segment, i)
        Let complex_sample be Complex
        Let complex_sample.real be real_part
        Let complex_sample.imaginary be 0.0
        Collections.append(complex_segment, complex_sample)
        Let i be i plus 1
    
    Note: Compute FFT of windowed segment
    Let fft_result be DFT.fft_direct(complex_segment)
    
    Note: Initialize 3D trispectrum array
    Let trispectrum_3d be Collections.create_list()
    
    Note: Compute trispectrum over triangular region to avoid redundancy
    Let f1 be 0
    While f1 is less than segment_length / 2:
        Let trispectrum_2d be Collections.create_list()
        
        Let f2 be 0
        While f2 is less than or equal to f1:
            Let trispectrum_1d be Collections.create_list()
            
            Let f3 be 0
            While f3 is less than or equal to f2:
                Note: Compute frequency sum and check bounds
                Let f_sum be f1 plus f2 plus f3
                If f_sum is less than segment_length:
                    Let X1 be Collections.get_item(fft_result, f1)
                    Let X2 be Collections.get_item(fft_result, f2)
                    Let X3 be Collections.get_item(fft_result, f3)
                    Let X_sum be Collections.get_item(fft_result, f_sum)
                    
                    Note: Trispectrum calculation: X(f1)*X(f2)*X(f3)*X*(f1+f2+f3)
                    Note: First compute X1*X2*X3
                    Let temp_real be X1.real multiplied by X2.real multiplied by X3.real minus X1.real multiplied by X2.imaginary multiplied by X3.imaginary
                    Let temp_real be temp_real minus X1.imaginary multiplied by X2.real multiplied by X3.imaginary minus X1.imaginary multiplied by X2.imaginary multiplied by X3.real
                    
                    Let temp_imag be X1.real multiplied by X2.real multiplied by X3.imaginary plus X1.real multiplied by X2.imaginary multiplied by X3.real
                    Let temp_imag be temp_imag plus X1.imaginary multiplied by X2.real multiplied by X3.real minus X1.imaginary multiplied by X2.imaginary multiplied by X3.imaginary
                    
                    Note: Now multiply by X_sum conjugate
                    Let trispectrum_real be temp_real multiplied by X_sum.real plus temp_imag multiplied by X_sum.imaginary
                    Let trispectrum_imag be temp_imag multiplied by X_sum.real minus temp_real multiplied by X_sum.imaginary
                    
                    Note: Normalize by segment length to fourth power
                    Let normalization be Float(segment_length multiplied by segment_length multiplied by segment_length multiplied by segment_length)
                    Let trispectrum_real be trispectrum_real / normalization
                    Let trispectrum_imag be trispectrum_imag / normalization
                    
                    Let trispectrum_value be Complex
                    Let trispectrum_value.real be trispectrum_real
                    Let trispectrum_value.imaginary be trispectrum_imag
                    
                    Collections.append(trispectrum_1d, trispectrum_value)
                Otherwise:
                    Note: Out of bounds, set to zero
                    Let zero_value be Complex
                    Let zero_value.real be 0.0
                    Let zero_value.imaginary be 0.0
                    Collections.append(trispectrum_1d, zero_value)
                
                Let f3 be f3 plus 1
            
            Collections.append(trispectrum_2d, trispectrum_1d)
            Let f2 be f2 plus 1
        
        Collections.append(trispectrum_3d, trispectrum_2d)
        Let f1 be f1 plus 1
    
    Return trispectrum_3d

Process called "polyspectrum" that takes signal as List[Float], order as Integer, window_length as Integer returns List[Complex]:
    Note: Generalized polyspectrum of arbitrary order for higher-order statistical analysis
    Note: P_k(f1,f2,...,f_{k-1}) is equal to E[X(f1)*X(f2)*...*X(f_{k-1})*X*(f1+f2+...+f_{k-1})]
    Note: Time complexity: O(N^k log N), Space complexity: O(N^{k-1})
    
    Let N be Collections.get_size(signal)
    If N is less than or equal to 1:
        Throw Errors.ArgumentError with "Signal must have at least 2 samples"
    
    If order is less than 2:
        Throw Errors.ArgumentError with "Order must be at least 2"
    
    If order is greater than 6:
        Throw Errors.ArgumentError with "Order limited to 6 for computational feasibility"
    
    If window_length is less than or equal to 0 or window_length is greater than N:
        Throw Errors.ArgumentError with "Window length must be positive and not exceed signal length"
    
    Note: Use the provided window length or signal length
    Let segment_length be window_length
    If segment_length is greater than N:
        Let segment_length be N
    
    Note: Extract signal segment
    Let segment be Collections.create_list()
    Let i be 0
    While i is less than segment_length:
        Collections.append(segment, Collections.get_item(signal, i))
        Let i be i plus 1
    
    Note: Apply window function and convert to complex
    Let windowed_segment be apply_window_function(segment, "hanning")
    Let complex_segment be Collections.create_list()
    Let i be 0
    While i is less than segment_length:
        Let real_part be Collections.get_item(windowed_segment, i)
        Let complex_sample be Complex
        Let complex_sample.real be real_part
        Let complex_sample.imaginary be 0.0
        Collections.append(complex_segment, complex_sample)
        Let i be i plus 1
    
    Note: Compute FFT of windowed segment
    Let fft_result be DFT.fft_direct(complex_segment)
    
    Note: Handle special cases
    If order is equal to 2:
        Note: Power spectrum (second-order)
        Let power_spectrum be Collections.create_list()
        Let k be 0
        While k is less than segment_length / 2:
            Let X_k be Collections.get_item(fft_result, k)
            Let power be X_k.real multiplied by X_k.real plus X_k.imaginary multiplied by X_k.imaginary
            Let normalization be Float(segment_length multiplied by segment_length)
            Let power be power / normalization
            
            Let power_complex be Complex
            Let power_complex.real be power
            Let power_complex.imaginary be 0.0
            Collections.append(power_spectrum, power_complex)
            Let k be k plus 1
        Return power_spectrum
    
    If order is equal to 3:
        Note: Bispectrum (third-order) minus simplified 1D slice
        Let bispectrum_slice be Collections.create_list()
        Let f1 be 0
        While f1 is less than segment_length / 4:
            Let f2 be f1
            Let f_sum be f1 plus f2
            If f_sum is less than segment_length:
                Let X1 be Collections.get_item(fft_result, f1)
                Let X2 be Collections.get_item(fft_result, f2)
                Let X_sum be Collections.get_item(fft_result, f_sum)
                
                Note: Bispectrum: X(f1)*X(f2)*X*(f1+f2)
                Let temp_real be X1.real multiplied by X2.real minus X1.imaginary multiplied by X2.imaginary
                Let temp_imag be X1.real multiplied by X2.imaginary plus X1.imaginary multiplied by X2.real
                
                Let bispectrum_real be temp_real multiplied by X_sum.real plus temp_imag multiplied by X_sum.imaginary
                Let bispectrum_imag be temp_imag multiplied by X_sum.real minus temp_real multiplied by X_sum.imaginary
                
                Let normalization be Float(segment_length multiplied by segment_length multiplied by segment_length)
                Let bispectrum_real be bispectrum_real / normalization
                Let bispectrum_imag be bispectrum_imag / normalization
                
                Let bispectrum_value be Complex
                Let bispectrum_value.real be bispectrum_real
                Let bispectrum_value.imaginary be bispectrum_imag
                Collections.append(bispectrum_slice, bispectrum_value)
            Otherwise:
                Let zero_value be Complex
                Let zero_value.real be 0.0
                Let zero_value.imaginary be 0.0
                Collections.append(bispectrum_slice, zero_value)
            Let f1 be f1 plus 1
        Return bispectrum_slice
    
    Note: General case for higher orders (4, 5, 6)
    Let polyspectrum_result be Collections.create_list()
    
    Note: For computational efficiency, compute diagonal slice
    Let f1 be 0
    Let max_freq be segment_length / (order plus 1)
    While f1 is less than max_freq:
        Note: Initialize frequency indices (all equal for diagonal)
        Let freq_indices be Collections.create_list()
        Let freq_sum be 0
        Let order_idx be 0
        While order_idx is less than order minus 1:
            Collections.append(freq_indices, f1)
            Let freq_sum be freq_sum plus f1
            Let order_idx be order_idx plus 1
        
        If freq_sum is less than segment_length:
            Note: Get FFT values for all frequencies
            Let fft_values be Collections.create_list()
            Let idx be 0
            While idx is less than order minus 1:
                Let freq_idx be Collections.get_item(freq_indices, idx)
                Let fft_val be Collections.get_item(fft_result, freq_idx)
                Collections.append(fft_values, fft_val)
                Let idx be idx plus 1
            
            Note: Get conjugate of sum frequency
            Let X_sum be Collections.get_item(fft_result, freq_sum)
            
            Note: Compute product of all frequency components
            Let result_real be 1.0
            Let result_imag be 0.0
            
            Let val_idx be 0
            While val_idx is less than order minus 1:
                Let X_val be Collections.get_item(fft_values, val_idx)
                
                Note: Complex multiplication: (a+bi)*(c+di) is equal to (ac-bd) plus (ad+bc)i
                Let new_real be result_real multiplied by X_val.real minus result_imag multiplied by X_val.imaginary
                Let new_imag be result_real multiplied by X_val.imaginary plus result_imag multiplied by X_val.real
                Let result_real be new_real
                Let result_imag be new_imag
                Let val_idx be val_idx plus 1
            
            Note: Multiply by conjugate of sum: z multiplied by conj(w) is equal to z multiplied by (a-bi)
            Let poly_real be result_real multiplied by X_sum.real plus result_imag multiplied by X_sum.imaginary
            Let poly_imag be result_imag multiplied by X_sum.real minus result_real multiplied by X_sum.imaginary
            
            Note: Normalize by segment length to the power of order
            Let normalization be 1.0
            Let norm_idx be 0
            While norm_idx is less than order:
                Let normalization be normalization multiplied by Float(segment_length)
                Let norm_idx be norm_idx plus 1
            
            Let poly_real be poly_real / normalization
            Let poly_imag be poly_imag / normalization
            
            Let poly_value be Complex
            Let poly_value.real be poly_real
            Let poly_value.imaginary be poly_imag
            Collections.append(polyspectrum_result, poly_value)
        Otherwise:
            Let zero_value be Complex
            Let zero_value.real be 0.0
            Let zero_value.imaginary be 0.0
            Collections.append(polyspectrum_result, zero_value)
        
        Let f1 be f1 plus 1
    
    Return polyspectrum_result

Note: ========================================================================
Note: CYCLOSTATIONARY ANALYSIS
Note: ========================================================================

Process called "cyclic_autocorrelation" that takes signal as List[Float], cyclic_frequency as Float, max_lag as Integer returns List[Complex]:
    Note: Cyclic autocorrelation function for analyzing cyclostationary signals
    Note: R_x^α(τ) is equal to lim_{T→∞} (1/T) ∫ x(t+τ/2) x*(t-τ/2) e^{-j2παt} dt
    Note: Time complexity: O(N*L), Space complexity: O(L) where L is max_lag
    
    Let N be Collections.get_size(signal)
    If N is less than 2:
        Throw Errors.ArgumentError with "Signal must have at least 2 samples"
    
    If max_lag is less than or equal to 0 or max_lag is greater than or equal to N:
        Throw Errors.ArgumentError with "Max lag must be positive and less than signal length"
    
    Note: Initialize result array for lags -max_lag to +max_lag
    Let cyclic_autocorr be Collections.create_list()
    
    Note: Compute cyclic autocorrelation for each lag
    Let lag be -max_lag
    While lag is less than or equal to max_lag:
        Let correlation_real be 0.0
        Let correlation_imag be 0.0
        Let valid_samples be 0
        
        Note: Average over valid time samples
        Let t be 0
        While t is less than N:
            Let t_plus be t plus lag / 2
            Let t_minus be t minus lag / 2
            
            Note: Check bounds for both samples
            If t_plus is greater than or equal to 0 and t_plus is less than N and t_minus is greater than or equal to 0 and t_minus is less than N:
                Let x_plus be Collections.get_item(signal, Integer(t_plus))
                Let x_minus be Collections.get_item(signal, Integer(t_minus))
                
                Note: Compute phase factor: e^{-j2παt} is equal to cos(2παt) minus j*sin(2παt)
                Let phase_arg be 2.0 multiplied by 3.14159265359 multiplied by cyclic_frequency multiplied by Float(t) / Float(N)
                Let cos_phase be MathCore.cosine(phase_arg)
                Let sin_phase be MathCore.sine(phase_arg)
                
                Note: x(t+τ/2) multiplied by x*(t-τ/2) is equal to x_plus multiplied by x_minus (assuming real signal)
                Let product be x_plus multiplied by x_minus
                
                Note: Multiply by phase factor
                Let correlation_real be correlation_real plus product multiplied by cos_phase
                Let correlation_imag be correlation_imag plus (-product multiplied by sin_phase)
                Let valid_samples be valid_samples plus 1
            
            Let t be t plus 1
        
        Note: Normalize by number of valid samples
        If valid_samples is greater than 0:
            Let correlation_real be correlation_real / Float(valid_samples)
            Let correlation_imag be correlation_imag / Float(valid_samples)
        
        Let correlation_value be Complex
        Let correlation_value.real be correlation_real
        Let correlation_value.imaginary be correlation_imag
        Collections.append(cyclic_autocorr, correlation_value)
        
        Let lag be lag plus 1
    
    Return cyclic_autocorr

Process called "spectral_correlation_function" that takes signal as List[Float], frequency_resolution as Float returns List[List[Complex]]:
    Note: Spectral correlation function for cyclostationary signals analysis
    Note: S_x^α(f) is equal to Fourier transform of cyclic autocorrelation function
    Note: Time complexity: O(N^2 log N), Space complexity: O(N^2)
    
    Let N be Collections.get_size(signal)
    If N is less than 4:
        Throw Errors.ArgumentError with "Signal must have at least 4 samples"
    
    If frequency_resolution is less than or equal to 0.0:
        Throw Errors.ArgumentError with "Frequency resolution must be positive"
    
    Note: Determine frequency grid based on resolution
    Let max_freq be 0.5
    Let num_freqs be Integer(max_freq / frequency_resolution) plus 1
    If num_freqs is greater than N / 2:
        Let num_freqs be N / 2
    
    Note: Determine cyclic frequency range
    Let max_cyclic_freq be 0.25
    Let cyclic_freq_step be frequency_resolution
    Let num_cyclic_freqs be Integer(2.0 multiplied by max_cyclic_freq / cyclic_freq_step) plus 1
    
    Note: Initialize spectral correlation matrix
    Let spectral_corr_matrix be Collections.create_list()
    
    Note: Compute for each cyclic frequency
    Let alpha_idx be 0
    While alpha_idx is less than num_cyclic_freqs:
        Let cyclic_freq be -max_cyclic_freq plus Float(alpha_idx) multiplied by cyclic_freq_step
        Let spectral_corr_row be Collections.create_list()
        
        Note: For each regular frequency
        Let freq_idx be 0
        While freq_idx is less than num_freqs:
            Let freq be Float(freq_idx) multiplied by frequency_resolution
            
            Note: Compute spectral correlation using windowed segments
            Let window_length be N / 4
            If window_length is less than 16:
                Let window_length be 16
            If window_length is greater than N / 2:
                Let window_length be N / 2
            
            Let hop_size be window_length / 2
            Let num_windows be (N minus window_length) / hop_size plus 1
            
            Let correlation_real be 0.0
            Let correlation_imag be 0.0
            Let valid_windows be 0
            
            Note: Average over multiple windows
            Let win_idx be 0
            While win_idx is less than num_windows:
                Let start_pos be win_idx multiplied by hop_size
                
                Note: Extract and window signal segment
                Let segment be Collections.create_list()
                Let i be 0
                While i is less than window_length:
                    Let signal_idx be start_pos plus i
                    If signal_idx is less than N:
                        Collections.append(segment, Collections.get_item(signal, signal_idx))
                    Otherwise:
                        Collections.append(segment, 0.0)
                    Let i be i plus 1
                
                Let windowed_segment be apply_window_function(segment, "hanning")
                
                Note: Convert to complex and apply frequency shift for X(f+α/2)
                Let complex_segment_plus be Collections.create_list()
                Let j be 0
                While j is less than window_length:
                    Let real_part be Collections.get_item(windowed_segment, j)
                    Let phase_shift be 2.0 multiplied by 3.14159265359 multiplied by (freq plus cyclic_freq / 2.0) multiplied by Float(j) / Float(window_length)
                    Let cos_shift be MathCore.cosine(phase_shift)
                    Let sin_shift be MathCore.sine(phase_shift)
                    
                    Let complex_sample be Complex
                    Let complex_sample.real be real_part multiplied by cos_shift
                    Let complex_sample.imaginary be real_part multiplied by sin_shift
                    Collections.append(complex_segment_plus, complex_sample)
                    Let j be j plus 1
                
                Note: Create conjugate segment for X*(f-α/2)
                Let complex_segment_minus be Collections.create_list()
                Let k be 0
                While k is less than window_length:
                    Let real_part be Collections.get_item(windowed_segment, k)
                    Let phase_shift be 2.0 multiplied by 3.14159265359 multiplied by (freq minus cyclic_freq / 2.0) multiplied by Float(k) / Float(window_length)
                    Let cos_shift be MathCore.cosine(phase_shift)
                    Let sin_shift be MathCore.sine(phase_shift)
                    
                    Let complex_sample be Complex
                    Let complex_sample.real be real_part multiplied by cos_shift
                    Let complex_sample.imaginary be -real_part multiplied by sin_shift  Note: Conjugate
                    Collections.append(complex_segment_minus, complex_sample)
                    Let k be k plus 1
                
                Note: Compute FFTs
                Let fft_plus be DFT.fft_direct(complex_segment_plus)
                Let fft_minus be DFT.fft_direct(complex_segment_minus)
                
                Note: Find frequency bin closest to target frequency
                Let target_bin be Integer(freq multiplied by Float(window_length))
                If target_bin is greater than or equal to window_length:
                    Let target_bin be window_length minus 1
                
                Let X_plus be Collections.get_item(fft_plus, target_bin)
                Let X_minus be Collections.get_item(fft_minus, target_bin)
                
                Note: Compute spectral correlation: X(f+α/2) multiplied by X*(f-α/2)
                Let corr_real be X_plus.real multiplied by X_minus.real minus X_plus.imaginary multiplied by X_minus.imaginary
                Let corr_imag be X_plus.real multiplied by X_minus.imaginary plus X_plus.imaginary multiplied by X_minus.real
                
                Let correlation_real be correlation_real plus corr_real
                Let correlation_imag be correlation_imag plus corr_imag
                Let valid_windows be valid_windows plus 1
                
                Let win_idx be win_idx plus 1
            
            Note: Normalize by number of windows and window length
            If valid_windows is greater than 0:
                Let normalization be Float(valid_windows multiplied by window_length)
                Let correlation_real be correlation_real / normalization
                Let correlation_imag be correlation_imag / normalization
            
            Let correlation_value be Complex
            Let correlation_value.real be correlation_real
            Let correlation_value.imaginary be correlation_imag
            Collections.append(spectral_corr_row, correlation_value)
            
            Let freq_idx be freq_idx plus 1
        
        Collections.append(spectral_corr_matrix, spectral_corr_row)
        Let alpha_idx be alpha_idx plus 1
    
    Return spectral_corr_matrix

Process called "cyclic_spectrum" that takes signal as List[Float], cyclic_frequency as Float returns List[Complex]:
    Note: Cyclic spectrum estimation for cyclostationary signal analysis
    Note: S_x^α(f) is equal to lim_{T→∞} (1/T) ∫ X_T(f+α/2) X_T*(f-α/2) df
    Note: Time complexity: O(N log N), Space complexity: O(N)
    
    Let N be Collections.get_size(signal)
    If N is less than 4:
        Throw Errors.ArgumentError with "Signal must have at least 4 samples"
    
    Note: Apply window function
    Let windowed_signal be apply_window_function(signal, "hanning")
    
    Note: Convert to complex and apply frequency shift by +α/2
    Let complex_signal_plus be Collections.create_list()
    Let i be 0
    While i is less than N:
        Let real_part be Collections.get_item(windowed_signal, i)
        Let phase_shift be 2.0 multiplied by 3.14159265359 multiplied by cyclic_frequency multiplied by Float(i) / (2.0 multiplied by Float(N))
        Let cos_shift be MathCore.cosine(phase_shift)
        Let sin_shift be MathCore.sine(phase_shift)
        
        Let complex_sample be Complex
        Let complex_sample.real be real_part multiplied by cos_shift
        Let complex_sample.imaginary be real_part multiplied by sin_shift
        Collections.append(complex_signal_plus, complex_sample)
        Let i be i plus 1
    
    Note: Convert to complex and apply frequency shift by -α/2
    Let complex_signal_minus be Collections.create_list()
    Let j be 0
    While j is less than N:
        Let real_part be Collections.get_item(windowed_signal, j)
        Let phase_shift be -2.0 multiplied by 3.14159265359 multiplied by cyclic_frequency multiplied by Float(j) / (2.0 multiplied by Float(N))
        Let cos_shift be MathCore.cosine(phase_shift)
        Let sin_shift be MathCore.sine(phase_shift)
        
        Let complex_sample be Complex
        Let complex_sample.real be real_part multiplied by cos_shift
        Let complex_sample.imaginary be real_part multiplied by sin_shift
        Collections.append(complex_signal_minus, complex_sample)
        Let j be j plus 1
    
    Note: Compute FFTs of both shifted signals
    Let fft_plus be DFT.fft_direct(complex_signal_plus)
    Let fft_minus be DFT.fft_direct(complex_signal_minus)
    
    Note: Compute cyclic spectrum: X(f+α/2) multiplied by X*(f-α/2)
    Let cyclic_spectrum be Collections.create_list()
    Let k be 0
    While k is less than N:
        Let X_plus be Collections.get_item(fft_plus, k)
        Let X_minus be Collections.get_item(fft_minus, k)
        
        Note: Complex multiplication with conjugate: z multiplied by w* is equal to z multiplied by conj(w)
        Let cyclic_real be X_plus.real multiplied by X_minus.real plus X_plus.imaginary multiplied by X_minus.imaginary
        Let cyclic_imag be X_plus.imaginary multiplied by X_minus.real minus X_plus.real multiplied by X_minus.imaginary
        
        Note: Normalize by signal length
        Let cyclic_real be cyclic_real / Float(N)
        Let cyclic_imag be cyclic_imag / Float(N)
        
        Let cyclic_value be Complex
        Let cyclic_value.real be cyclic_real
        Let cyclic_value.imaginary be cyclic_imag
        Collections.append(cyclic_spectrum, cyclic_value)
        
        Let k be k plus 1
    
    Return cyclic_spectrum

Note: ========================================================================
Note: SPECTRAL FEATURES AND DESCRIPTORS
Note: ========================================================================

Process called "spectral_moments" that takes spectrum as List[Float], frequencies as List[Float], order as Integer returns Float:
    Note: Compute spectral moments for characterizing frequency distribution
    Note: M_n is equal to ∫ f^n S(f) df / ∫ S(f) df where n is the moment order
    Note: Time complexity: O(N), Space complexity: O(1)
    
    Let N be Collections.get_size(spectrum)
    Let freq_size be Collections.get_size(frequencies)
    
    If N does not equal freq_size:
        Throw Errors.ArgumentError with "Spectrum and frequencies must have the same size"
    
    If N is less than 2:
        Throw Errors.ArgumentError with "Spectrum must have at least 2 points"
    
    If order is less than 0:
        Throw Errors.ArgumentError with "Moment order must be non-negative"
    
    Note: Compute total spectral power (zeroth moment denominator)
    Let total_power be 0.0
    Let i be 0
    While i is less than N:
        Let power be Collections.get_item(spectrum, i)
        If power is less than 0.0:
            Throw Errors.ArgumentError with "Spectrum values must be non-negative"
        Let total_power be total_power plus power
        Let i be i plus 1
    
    If total_power is less than or equal to 0.0:
        Return 0.0
    
    Note: Special case for zeroth moment (total power)
    If order is equal to 0:
        Return total_power
    
    Note: Compute weighted moment
    Let weighted_sum be 0.0
    Let j be 0
    While j is less than N:
        Let frequency be Collections.get_item(frequencies, j)
        Let power be Collections.get_item(spectrum, j)
        
        Note: Compute frequency^order
        Let freq_power be 1.0
        Let exp be 0
        While exp is less than order:
            Let freq_power be freq_power multiplied by frequency
            Let exp be exp plus 1
        
        Let weighted_sum be weighted_sum plus freq_power multiplied by power
        Let j be j plus 1
    
    Note: Normalize by total power
    Let moment be weighted_sum / total_power
    Return moment

Process called "spectral_entropy" that takes spectrum as List[Float] returns Float:
    Note: Compute spectral entropy as a measure of spectral complexity and randomness
    Note: H is equal to -∑ p(f) log₂(p(f)) where p(f) is normalized spectrum
    Note: Time complexity: O(N), Space complexity: O(1)
    
    Let N be Collections.get_size(spectrum)
    If N is less than 2:
        Throw Errors.ArgumentError with "Spectrum must have at least 2 points"
    
    Note: Compute total spectral energy for normalization
    Let total_energy be 0.0
    Let i be 0
    While i is less than N:
        Let power be Collections.get_item(spectrum, i)
        If power is less than 0.0:
            Throw Errors.ArgumentError with "Spectrum values must be non-negative"
        Let total_energy be total_energy plus power
        Let i be i plus 1
    
    If total_energy is less than or equal to 0.0:
        Return 0.0
    
    Note: Compute Shannon entropy
    Let entropy be 0.0
    Let j be 0
    While j is less than N:
        Let power be Collections.get_item(spectrum, j)
        If power is greater than 0.0:
            Note: Normalize to get probability
            Let probability be power / total_energy
            
            Note: Compute log base 2 using natural log: log₂(x) is equal to ln(x) / ln(2)
            Let log_prob be MathCore.natural_logarithm(probability) / MathCore.natural_logarithm(2.0)
            Let entropy be entropy minus probability multiplied by log_prob
        Let j be j plus 1
    
    Return entropy

Process called "spectral_energy" that takes spectrum as List[Float] returns Float:
    Note: Compute total spectral energy by integrating power spectrum
    Note: E is equal to ∫ S(f) df ≈ ∑ S(f_k) Δf
    Note: Time complexity: O(N), Space complexity: O(1)
    
    Let N be Collections.get_size(spectrum)
    If N is less than 1:
        Throw Errors.ArgumentError with "Spectrum must have at least 1 point"
    
    Note: Compute total energy as sum of all spectral components
    Let total_energy be 0.0
    Let i be 0
    While i is less than N:
        Let power be Collections.get_item(spectrum, i)
        If power is less than 0.0:
            Throw Errors.ArgumentError with "Spectrum values must be non-negative"
        Let total_energy be total_energy plus power
        Let i be i plus 1
    
    Return total_energy

Process called "frequency_domain_kurtosis" that takes spectrum as List[Float] returns Float:
    Note: Compute frequency domain kurtosis as a measure of spectral peakedness
    Note: κ is equal to E[(X-μ)⁴]/σ⁴ minus 3 where X is frequency, weighted by spectrum
    Note: Time complexity: O(N), Space complexity: O(1)
    
    Let N be Collections.get_size(spectrum)
    If N is less than 4:
        Throw Errors.ArgumentError with "Spectrum must have at least 4 points for kurtosis calculation"
    
    Note: Compute total power for normalization
    Let total_power be 0.0
    Let i be 0
    While i is less than N:
        Let power be Collections.get_item(spectrum, i)
        If power is less than 0.0:
            Throw Errors.ArgumentError with "Spectrum values must be non-negative"
        Let total_power be total_power plus power
        Let i be i plus 1
    
    If total_power is less than or equal to 0.0:
        Return 0.0
    
    Note: Compute spectral centroid (mean frequency)
    Let centroid be 0.0
    Let j be 0
    While j is less than N:
        Let power be Collections.get_item(spectrum, j)
        Let frequency be Float(j) / Float(N)  Note: Normalized frequency
        Let centroid be centroid plus frequency multiplied by power
        Let j be j plus 1
    Let centroid be centroid / total_power
    
    Note: Compute second moment (variance)
    Let second_moment be 0.0
    Let k be 0
    While k is less than N:
        Let power be Collections.get_item(spectrum, k)
        Let frequency be Float(k) / Float(N)
        Let freq_diff be frequency minus centroid
        Let second_moment be second_moment plus freq_diff multiplied by freq_diff multiplied by power
        Let k be k plus 1
    Let second_moment be second_moment / total_power
    
    If second_moment is less than or equal to 0.0:
        Return 0.0
    
    Note: Compute fourth moment
    Let fourth_moment be 0.0
    Let m be 0
    While m is less than N:
        Let power be Collections.get_item(spectrum, m)
        Let frequency be Float(m) / Float(N)
        Let freq_diff be frequency minus centroid
        Let freq_diff_squared be freq_diff multiplied by freq_diff
        Let fourth_moment be fourth_moment plus freq_diff_squared multiplied by freq_diff_squared multiplied by power
        Let m be m plus 1
    Let fourth_moment be fourth_moment / total_power
    
    Note: Calculate kurtosis: κ is equal to μ₄/σ⁴ minus 3
    Let variance_squared be second_moment multiplied by second_moment
    Let kurtosis be (fourth_moment / variance_squared) minus 3.0
    
    Return kurtosis

Process called "spectral_irregularity" that takes spectrum as List[Float] returns Float:
    Note: Compute spectral irregularity as measure of spectral smoothness
    Note: I is equal to ∑|S(k+1) minus S(k)| / ∑S(k) measuring relative variation between adjacent bins
    Note: Time complexity: O(N), Space complexity: O(1)
    
    Let N be Collections.get_size(spectrum)
    If N is less than 2:
        Throw Errors.ArgumentError with "Spectrum must have at least 2 points"
    
    Note: Compute total spectral energy
    Let total_energy be 0.0
    Let i be 0
    While i is less than N:
        Let power be Collections.get_item(spectrum, i)
        If power is less than 0.0:
            Throw Errors.ArgumentError with "Spectrum values must be non-negative"
        Let total_energy be total_energy plus power
        Let i be i plus 1
    
    If total_energy is less than or equal to 0.0:
        Return 0.0
    
    Note: Compute sum of absolute differences between adjacent bins
    Let variation_sum be 0.0
    Let j be 0
    While j is less than N minus 1:
        Let current_power be Collections.get_item(spectrum, j)
        Let next_power be Collections.get_item(spectrum, j plus 1)
        Let difference be MathCore.absolute(next_power minus current_power)
        Let variation_sum be variation_sum plus difference
        Let j be j plus 1
    
    Note: Normalize by total energy to get irregularity measure
    Let irregularity be variation_sum / total_energy
    
    Return irregularity

Note: ========================================================================
Note: ADAPTIVE SPECTRAL ANALYSIS
Note: ========================================================================

Process called "adaptive_line_enhancement" that takes signal as List[Float], reference_frequency as Float, adaptation_rate as Float returns List[Float]:
    Note: Adaptive line enhancer for narrow-band signals using adaptive filtering
    Note: Enhances sinusoidal components at reference frequency while suppressing noise
    Note: Time complexity: O(N), Space complexity: O(1)
    
    Let N be Collections.get_size(signal)
    If N is less than or equal to 1:
        Throw Errors.ArgumentError with "Signal must have at least 2 samples"
    
    If reference_frequency is less than or equal to 0.0 or reference_frequency is greater than or equal to DEFAULT_SAMPLING_RATE / 2.0:
        Throw Errors.ArgumentError with "Reference frequency must be positive and within Nyquist limit"
    
    If adaptation_rate is less than or equal to 0.0 or adaptation_rate is greater than or equal to 1.0:
        Throw Errors.ArgumentError with "Adaptation rate must be between 0.0 and 1.0"
    
    Note: Initialize adaptive filter parameters
    Let enhanced_signal be Collections.create_list()
    Let omega be 2.0 multiplied by 3.14159265359 multiplied by reference_frequency / DEFAULT_SAMPLING_RATE
    
    Note: Adaptive filter weights (sine and cosine components)
    Let weight_cos be 0.0
    Let weight_sin be 0.0
    
    Note: Previous samples for filtering
    Let prev_cos_ref be 1.0
    Let prev_sin_ref be 0.0
    
    Let n be 0
    While n is less than N:
        Let input_sample be Collections.get_item(signal, n)
        
        Note: Generate reference signals at target frequency
        Let cos_ref be MathCore.cosine(omega multiplied by Float(n))
        Let sin_ref be MathCore.sine(omega multiplied by Float(n))
        
        Note: Compute filter output (enhanced signal estimate)
        Let enhanced_output be (weight_cos multiplied by cos_ref) plus (weight_sin multiplied by sin_ref)
        Collections.append(enhanced_signal, enhanced_output)
        
        Note: Compute error signal (difference between input and enhanced)
        Let error be input_sample minus enhanced_output
        
        Note: Update adaptive weights using LMS algorithm
        Let weight_cos be weight_cos plus (adaptation_rate multiplied by error multiplied by cos_ref)
        Let weight_sin be weight_sin plus (adaptation_rate multiplied by error multiplied by sin_ref)
        
        Note: Optional: Apply weight decay for stability
        Let decay_factor be 0.999
        Let weight_cos be weight_cos multiplied by decay_factor
        Let weight_sin be weight_sin multiplied by decay_factor
        
        Let n be n plus 1
    
    Return enhanced_signal

Process called "least_mean_squares_spectrum" that takes signal as List[Float], reference as List[Float], step_size as Float returns SpectralEstimate:
    Note: LMS-based adaptive spectral estimation using adaptive filtering principles
    Note: Estimates spectrum by adaptively filtering signal based on reference
    Note: Time complexity: O(N^2), Space complexity: O(N)
    
    Let N be Collections.get_size(signal)
    Let ref_N be Collections.get_size(reference)
    
    If N is less than or equal to 1:
        Throw Errors.ArgumentError with "Signal must have at least 2 samples"
    
    If ref_N does not equal N:
        Throw Errors.ArgumentError with "Signal and reference must have same length"
    
    If step_size is less than or equal to 0.0 or step_size is greater than or equal to 1.0:
        Throw Errors.ArgumentError with "Step size must be between 0.0 and 1.0"
    
    Note: Initialize adaptive filter weights (simple FIR approach)
    Let filter_order be 16
    If filter_order is greater than N:
        Let filter_order be N / 2
    
    Let weights be Collections.create_list()
    Let i be 0
    While i is less than filter_order:
        Collections.append(weights, 0.0)
        Let i be i plus 1
    
    Note: Adaptive filtering using LMS algorithm
    Let filtered_signal be Collections.create_list()
    Let error_signal be Collections.create_list()
    
    Let n be 0
    While n is less than N:
        Let input_sample be Collections.get_item(signal, n)
        Let reference_sample be Collections.get_item(reference, n)
        
        Note: Compute filter output
        Let filter_output be 0.0
        Let tap be 0
        While tap is less than filter_order:
            If n is greater than or equal to tap:
                Let delayed_input be Collections.get_item(signal, n minus tap)
                Let weight be Collections.get_item(weights, tap)
                Let filter_output be filter_output plus (weight multiplied by delayed_input)
            Let tap be tap plus 1
        
        Collections.append(filtered_signal, filter_output)
        
        Note: Compute error
        Let error be reference_sample minus filter_output
        Collections.append(error_signal, error)
        
        Note: Update weights using LMS
        Let tap be 0
        While tap is less than filter_order:
            If n is greater than or equal to tap:
                Let delayed_input be Collections.get_item(signal, n minus tap)
                Let current_weight be Collections.get_item(weights, tap)
                Let weight_update be current_weight plus (step_size multiplied by error multiplied by delayed_input)
                Collections.set_item(weights, tap, weight_update)
            Let tap be tap plus 1
        
        Let n be n plus 1
    
    Note: Compute spectrum from adapted filter
    Let windowed_signal be apply_window_function(filtered_signal, "hanning")
    
    Let complex_signal be Collections.create_list()
    Let i be 0
    While i is less than N:
        Let real_part be Collections.get_item(windowed_signal, i)
        Let complex_sample be Complex
        Let complex_sample.real be real_part
        Let complex_sample.imag be 0.0
        Collections.append(complex_signal, complex_sample)
        Let i be i plus 1
    
    Let dft_result be DFT.dft_direct(complex_signal)
    
    Let psd be Collections.create_list()
    Let frequencies be Collections.create_list()
    Let k be 0
    While k is less than or equal to N / 2:
        Let dft_sample be Collections.get_item(dft_result, k)
        Let magnitude_squared be (dft_sample.real multiplied by dft_sample.real) plus (dft_sample.imag multiplied by dft_sample.imag)
        Let psd_value be magnitude_squared / DEFAULT_SAMPLING_RATE
        
        Collections.append(psd, psd_value)
        Collections.append(frequencies, Float(k) multiplied by DEFAULT_SAMPLING_RATE / Float(N))
        Let k be k plus 1
    
    Let estimate be SpectralEstimate
    Let estimate.frequencies be frequencies
    Let estimate.power_spectral_density be psd
    Let estimate.confidence_intervals be Collections.create_list()
    Let estimate.method be "lms_adaptive"
    Let parameters be Collections.create_dictionary()
    Collections.set_item(parameters, "step_size", step_size)
    Collections.set_item(parameters, "filter_order", filter_order)
    Let estimate.parameters be parameters
    Let estimate.sampling_rate be DEFAULT_SAMPLING_RATE
    
    Return estimate

Process called "recursive_least_squares_spectrum" that takes signal as List[Float], forgetting_factor as Float returns SpectralEstimate:
    Note: RLS-based adaptive spectral estimation for time-varying spectra
    Note: Uses recursive least squares to track spectral components adaptively
    Note: Time complexity: O(N*M^2), Space complexity: O(M^2) where M is model order
    
    Let N be Collections.get_size(signal)
    If N is less than 4:
        Throw Errors.ArgumentError with "Signal must have at least 4 samples"
    
    If forgetting_factor is less than or equal to 0.0 or forgetting_factor is greater than 1.0:
        Throw Errors.ArgumentError with "Forgetting factor must be in range (0, 1]"
    
    Note: Set model order (number of spectral components to track)
    Let model_order be 8
    If N is less than model_order multiplied by 2:
        Let model_order be N / 2
    
    Note: Initialize RLS parameters
    Let regularization be 1e-6
    Let covariance_matrix be Collections.create_list()
    
    Note: Initialize covariance matrix as identity multiplied by regularization
    Let i be 0
    While i is less than model_order:
        Let row be Collections.create_list()
        Let j be 0
        While j is less than model_order:
            If i is equal to j:
                Collections.append(row, 1.0 / regularization)
            Otherwise:
                Collections.append(row, 0.0)
            Let j be j plus 1
        Collections.append(covariance_matrix, row)
        Let i be i plus 1
    
    Note: Initialize coefficient vector
    Let coefficients be Collections.create_list()
    Let k be 0
    While k is less than model_order:
        Collections.append(coefficients, 0.0)
        Let k be k plus 1
    
    Note: Process signal samples recursively
    Let adaptive_spectrum be Collections.create_list()
    Let sample_idx be model_order
    
    While sample_idx is less than N:
        Note: Create input vector from past samples
        Let input_vector be Collections.create_list()
        Let lag be 0
        While lag is less than model_order:
            Let signal_idx be sample_idx minus lag minus 1
            Collections.append(input_vector, Collections.get_item(signal, signal_idx))
            Let lag be lag plus 1
        
        Let current_sample be Collections.get_item(signal, sample_idx)
        
        Note: Compute gain vector: K is equal to P multiplied by x / (λ plus x^T multiplied by P multiplied by x)
        Let gain_vector be Collections.create_list()
        
        Note: First compute P multiplied by x
        Let P_times_x be Collections.create_list()
        Let row_idx be 0
        While row_idx is less than model_order:
            Let dot_product be 0.0
            Let col_idx be 0
            While col_idx is less than model_order:
                Let P_val be Collections.get_item(Collections.get_item(covariance_matrix, row_idx), col_idx)
                Let x_val be Collections.get_item(input_vector, col_idx)
                Let dot_product be dot_product plus P_val multiplied by x_val
                Let col_idx be col_idx plus 1
            Collections.append(P_times_x, dot_product)
            Let row_idx be row_idx plus 1
        
        Note: Compute denominator: λ plus x^T multiplied by P multiplied by x
        Let denominator be forgetting_factor
        Let p_idx be 0
        While p_idx is less than model_order:
            Let P_x_val be Collections.get_item(P_times_x, p_idx)
            Let x_val be Collections.get_item(input_vector, p_idx)
            Let denominator be denominator plus x_val multiplied by P_x_val
            Let p_idx be p_idx plus 1
        
        Note: Compute gain vector
        Let g_idx be 0
        While g_idx is less than model_order:
            Let gain_val be Collections.get_item(P_times_x, g_idx) / denominator
            Collections.append(gain_vector, gain_val)
            Let g_idx be g_idx plus 1
        
        Note: Compute prediction error
        Let prediction be 0.0
        Let c_idx be 0
        While c_idx is less than model_order:
            Let coeff be Collections.get_item(coefficients, c_idx)
            Let input be Collections.get_item(input_vector, c_idx)
            Let prediction be prediction plus coeff multiplied by input
            Let c_idx be c_idx plus 1
        
        Let error be current_sample minus prediction
        
        Note: Update coefficients: w is equal to w plus K multiplied by error
        Let coeff_idx be 0
        While coeff_idx is less than model_order:
            Let old_coeff be Collections.get_item(coefficients, coeff_idx)
            Let gain be Collections.get_item(gain_vector, coeff_idx)
            Let new_coeff be old_coeff plus gain multiplied by error
            Collections.set_item(coefficients, coeff_idx, new_coeff)
            Let coeff_idx be coeff_idx plus 1
        
        Note: Update covariance matrix: P is equal to (P minus K multiplied by x^T multiplied by P) / λ
        Let new_covariance be Collections.create_list()
        Let r_idx be 0
        While r_idx is less than model_order:
            Let new_row be Collections.create_list()
            Let c_idx be 0
            While c_idx is less than model_order:
                Let P_old be Collections.get_item(Collections.get_item(covariance_matrix, r_idx), c_idx)
                Let K_val be Collections.get_item(gain_vector, r_idx)
                Let x_val be Collections.get_item(input_vector, c_idx)
                Let P_new be (P_old minus K_val multiplied by x_val) / forgetting_factor
                Collections.append(new_row, P_new)
                Let c_idx be c_idx plus 1
            Collections.append(new_covariance, new_row)
            Let r_idx be r_idx plus 1
        Let covariance_matrix be new_covariance
        
        Let sample_idx be sample_idx plus 1
    
    Note: Convert AR coefficients to power spectrum using FFT
    Let spectrum_length be 128
    Let ar_response be Collections.create_list()
    
    Note: Create impulse response from AR coefficients
    Collections.append(ar_response, 1.0)
    Let ar_idx be 0
    While ar_idx is less than model_order and ar_idx is less than spectrum_length minus 1:
        Let coeff be Collections.get_item(coefficients, ar_idx)
        Collections.append(ar_response, -coeff)
        Let ar_idx be ar_idx plus 1
    
    Note: Zero-pad to desired spectrum length
    While Collections.get_size(ar_response) is less than spectrum_length:
        Collections.append(ar_response, 0.0)
    
    Note: Convert to complex for FFT
    Let complex_response be Collections.create_list()
    Let resp_idx be 0
    While resp_idx is less than spectrum_length:
        Let real_val be Collections.get_item(ar_response, resp_idx)
        Let complex_val be Complex
        Let complex_val.real be real_val
        Let complex_val.imaginary be 0.0
        Collections.append(complex_response, complex_val)
        Let resp_idx be resp_idx plus 1
    
    Note: Compute FFT and convert to power spectrum
    Let fft_result be DFT.fft_direct(complex_response)
    Let power_spectrum be Collections.create_list()
    
    Let freq_idx be 0
    While freq_idx is less than spectrum_length / 2:
        Let X be Collections.get_item(fft_result, freq_idx)
        Let magnitude_squared be X.real multiplied by X.real plus X.imaginary multiplied by X.imaginary
        
        Note: Power spectrum is 1 / |H(ω)|²
        If magnitude_squared is greater than 1e-12:
            Collections.append(power_spectrum, 1.0 / magnitude_squared)
        Otherwise:
            Collections.append(power_spectrum, 1e12)
        Let freq_idx be freq_idx plus 1
    
    Note: Create frequency axis
    Let frequencies be Collections.create_list()
    Let f_idx be 0
    While f_idx is less than spectrum_length / 2:
        Let frequency be Float(f_idx) / Float(spectrum_length)
        Collections.append(frequencies, frequency)
        Let f_idx be f_idx plus 1
    
    Let estimate be SpectralEstimate
    Let estimate.power_spectrum be power_spectrum
    Let estimate.frequencies be frequencies
    Let estimate.method_name be "Recursive Least Squares"
    Let estimate.confidence_intervals be Collections.create_list()
    Let estimate.sampling_rate be DEFAULT_SAMPLING_RATE
    
    Return estimate

Process called "kalman_filter_spectrum" that takes signal as List[Float], process_noise as Float, measurement_noise as Float returns SpectralEstimate:
    Note: Kalman filter-based spectral estimation for adaptive frequency tracking
    Note: Models signal as sum of sinusoids with time-varying amplitudes and frequencies
    Note: Time complexity: O(N*M^2), Space complexity: O(M^2) where M is number of frequencies
    
    Let N be Collections.get_size(signal)
    If N is less than 8:
        Throw Errors.ArgumentError with "Signal must have at least 8 samples"
    
    If process_noise is less than or equal to 0.0 or measurement_noise is less than or equal to 0.0:
        Throw Errors.ArgumentError with "Noise parameters must be positive"
    
    Note: Set number of frequency components to track
    Let num_freqs be 16
    If N is less than num_freqs multiplied by 4:
        Let num_freqs be N / 4
    
    Note: Initialize state vector [real_amplitudes, imag_amplitudes, frequencies]
    Let state_size be num_freqs multiplied by 3  Note: 3 parameters per frequency component
    Let state_vector be Collections.create_list()
    Let state_covariance be Collections.create_list()
    
    Note: Initialize state with small random values and frequency grid
    Let state_idx be 0
    While state_idx is less than state_size:
        If state_idx is less than num_freqs:
            Note: Real amplitude components
            Collections.append(state_vector, 0.01)
        Otherwise:
            If state_idx is less than num_freqs multiplied by 2:
                Note: Imaginary amplitude components
                Collections.append(state_vector, 0.01)
            Otherwise:
                Note: Frequency components (normalized 0 to 0.5)
                Let freq_idx be state_idx minus num_freqs multiplied by 2
                Let initial_freq be Float(freq_idx plus 1) / Float(num_freqs multiplied by 2)
                Collections.append(state_vector, initial_freq)
        Let state_idx be state_idx plus 1
    
    Note: Initialize state covariance matrix
    Let cov_i be 0
    While cov_i is less than state_size:
        Let cov_row be Collections.create_list()
        Let cov_j be 0
        While cov_j is less than state_size:
            If cov_i is equal to cov_j:
                Collections.append(cov_row, process_noise)
            Otherwise:
                Collections.append(cov_row, 0.0)
            Let cov_j be cov_j plus 1
        Collections.append(state_covariance, cov_row)
        Let cov_i be cov_i plus 1
    
    Note: Process signal samples with Kalman filter
    Let sample_idx be 0
    While sample_idx is less than N:
        Let measurement be Collections.get_item(signal, sample_idx)
        Let time_sample be Float(sample_idx) / Float(N)
        
        Note: Prediction step: x_k|k-1 is equal to F multiplied by x_k-1|k-1
        Note: For simplicity, use identity transition (frequencies evolve slowly)
        
        Note: Update covariance: P_k|k-1 is equal to F multiplied by P_k-1|k-1 multiplied by F^T plus Q
        Let pred_covariance be Collections.create_list()
        Let p_i be 0
        While p_i is less than state_size:
            Let p_row be Collections.create_list()
            Let p_j be 0
            While p_j is less than state_size:
                Let old_cov be Collections.get_item(Collections.get_item(state_covariance, p_i), p_j)
                If p_i is equal to p_j:
                    Collections.append(p_row, old_cov plus process_noise)
                Otherwise:
                    Collections.append(p_row, old_cov)
                Let p_j be p_j plus 1
            Collections.append(pred_covariance, p_row)
            Let p_i be p_i plus 1
        
        Note: Compute observation vector H (measurement model)
        Let observation_vector be Collections.create_list()
        Let freq_comp be 0
        While freq_comp is less than num_freqs:
            Let real_amp_idx be freq_comp
            Let imag_amp_idx be freq_comp plus num_freqs
            Let freq_idx be freq_comp plus num_freqs multiplied by 2
            
            Let frequency be Collections.get_item(state_vector, freq_idx)
            Let phase be 2.0 multiplied by 3.14159265359 multiplied by frequency multiplied by time_sample
            Let cos_component be MathCore.cosine(phase)
            Let sin_component be MathCore.sine(phase)
            
            Collections.append(observation_vector, cos_component)  Note: Real part contribution
            Collections.append(observation_vector, sin_component)  Note: Imaginary part contribution
            Collections.append(observation_vector, 0.0)           Note: Frequency doesn't directly contribute to measurement
            Let freq_comp be freq_comp plus 1
        
        Note: Predicted measurement: h is equal to H^T multiplied by x
        Let predicted_measurement be 0.0
        Let obs_idx be 0
        While obs_idx is less than state_size:
            Let h_val be Collections.get_item(observation_vector, obs_idx)
            Let x_val be Collections.get_item(state_vector, obs_idx)
            Let predicted_measurement be predicted_measurement plus h_val multiplied by x_val
            Let obs_idx be obs_idx plus 1
        
        Note: Innovation (measurement residual)
        Let innovation be measurement minus predicted_measurement
        
        Note: Innovation covariance: S is equal to H^T multiplied by P multiplied by H plus R
        Let innovation_covariance be measurement_noise
        Let inn_i be 0
        While inn_i is less than state_size:
            Let inn_j be 0
            While inn_j is less than state_size:
                Let P_val be Collections.get_item(Collections.get_item(pred_covariance, inn_i), inn_j)
                Let H_i be Collections.get_item(observation_vector, inn_i)
                Let H_j be Collections.get_item(observation_vector, inn_j)
                Let innovation_covariance be innovation_covariance plus H_i multiplied by P_val multiplied by H_j
                Let inn_j be inn_j plus 1
            Let inn_i be inn_i plus 1
        
        Note: Kalman gain: K is equal to P multiplied by H / S
        Let kalman_gain be Collections.create_list()
        If innovation_covariance is greater than 1e-12:
            Let gain_idx be 0
            While gain_idx is less than state_size:
                Let gain_numerator be 0.0
                Let gain_j be 0
                While gain_j is less than state_size:
                    Let P_val be Collections.get_item(Collections.get_item(pred_covariance, gain_idx), gain_j)
                    Let H_val be Collections.get_item(observation_vector, gain_j)
                    Let gain_numerator be gain_numerator plus P_val multiplied by H_val
                    Let gain_j be gain_j plus 1
                Collections.append(kalman_gain, gain_numerator / innovation_covariance)
                Let gain_idx be gain_idx plus 1
        Otherwise:
            Let zero_idx be 0
            While zero_idx is less than state_size:
                Collections.append(kalman_gain, 0.0)
                Let zero_idx be zero_idx plus 1
        
        Note: State update: x is equal to x plus K multiplied by innovation
        Let upd_idx be 0
        While upd_idx is less than state_size:
            Let old_state be Collections.get_item(state_vector, upd_idx)
            Let gain be Collections.get_item(kalman_gain, upd_idx)
            Let new_state be old_state plus gain multiplied by innovation
            Collections.set_item(state_vector, upd_idx, new_state)
            Let upd_idx be upd_idx plus 1
        
        Note: Covariance update: P is equal to P minus K multiplied by H^T multiplied by P
        Let new_covariance be Collections.create_list()
        Let nc_i be 0
        While nc_i is less than state_size:
            Let nc_row be Collections.create_list()
            Let nc_j be 0
            While nc_j is less than state_size:
                Let P_old be Collections.get_item(Collections.get_item(pred_covariance, nc_i), nc_j)
                Let correction be 0.0
                Let corr_k be 0
                While corr_k is less than state_size:
                    Let K_val be Collections.get_item(kalman_gain, nc_i)
                    Let H_val be Collections.get_item(observation_vector, corr_k)
                    Let P_kj be Collections.get_item(Collections.get_item(pred_covariance, corr_k), nc_j)
                    Let correction be correction plus K_val multiplied by H_val multiplied by P_kj
                    Let corr_k be corr_k plus 1
                Collections.append(nc_row, P_old minus correction)
                Let nc_j be nc_j plus 1
            Collections.append(new_covariance, nc_row)
            Let nc_i be nc_i plus 1
        Let state_covariance be new_covariance
        
        Let sample_idx be sample_idx plus 1
    
    Note: Extract final spectrum from state estimates
    Let spectrum_length be 64
    Let power_spectrum be Collections.create_list()
    Let frequencies be Collections.create_list()
    
    Note: Create spectrum by placing frequency components
    Let spec_idx be 0
    While spec_idx is less than spectrum_length:
        Let frequency be Float(spec_idx) / Float(spectrum_length multiplied by 2)
        Collections.append(frequencies, frequency)
        
        Let total_power be 0.0
        Let comp_idx be 0
        While comp_idx is less than num_freqs:
            Let real_amp be Collections.get_item(state_vector, comp_idx)
            Let imag_amp be Collections.get_item(state_vector, comp_idx plus num_freqs)
            Let comp_freq be Collections.get_item(state_vector, comp_idx plus num_freqs multiplied by 2)
            
            Note: Add contribution if frequency component is close
            Let freq_diff be MathCore.absolute(comp_freq minus frequency)
            If freq_diff is less than 0.02:  Note: Within frequency resolution
                Let amplitude_squared be real_amp multiplied by real_amp plus imag_amp multiplied by imag_amp
                Let total_power be total_power plus amplitude_squared
            Let comp_idx be comp_idx plus 1
        
        Collections.append(power_spectrum, total_power)
        Let spec_idx be spec_idx plus 1
    
    Let estimate be SpectralEstimate
    Let estimate.power_spectrum be power_spectrum
    Let estimate.frequencies be frequencies
    Let estimate.method_name be "Kalman Filter"
    Let estimate.confidence_intervals be Collections.create_list()
    Let estimate.sampling_rate be DEFAULT_SAMPLING_RATE
    
    Return estimate

Note: ========================================================================
Note: UTILITY FUNCTIONS
Note: ========================================================================

Process called "db_scale" that takes linear_spectrum as List[Float], reference as Float returns List[Float]:
    Note: Convert linear spectrum to dB scale using 10*log10(spectrum/reference)
    Note: Handles zero and negative values by applying small offset
    Note: Time complexity: O(N), Space complexity: O(N)
    
    Let N be Collections.get_size(linear_spectrum)
    If N is equal to 0:
        Return Collections.create_list()
    
    If reference is less than or equal to 0.0:
        Throw Errors.ArgumentError with "Reference value must be positive"
    
    Let db_spectrum be Collections.create_list()
    Let epsilon be 1e-12
    
    Let i be 0
    While i is less than N:
        Let linear_value be Collections.get_item(linear_spectrum, i)
        
        Note: Handle non-positive values by adding small epsilon
        If linear_value is less than or equal to 0.0:
            Let linear_value be epsilon
        
        Note: Convert to dB: 10 multiplied by log10(value / reference)
        Let ratio be linear_value / reference
        Let db_value be 10.0 multiplied by MathCore.logarithm_base10(ratio)
        
        Collections.append(db_spectrum, db_value)
        Let i be i plus 1
    
    Return db_spectrum

Process called "mel_scale_conversion" that takes frequencies as List[Float] returns List[Float]:
    Note: Convert frequencies to mel scale using standard mel formula
    Note: mel is equal to 2595 multiplied by log10(1 plus f/700) where f is frequency in Hz
    Note: Time complexity: O(N), Space complexity: O(N)
    
    Let N be Collections.get_size(frequencies)
    If N is equal to 0:
        Return Collections.create_list()
    
    Let mel_frequencies be Collections.create_list()
    
    Let i be 0
    While i is less than N:
        Let freq_hz be Collections.get_item(frequencies, i)
        
        Note: Handle negative frequencies
        If freq_hz is less than 0.0:
            Let freq_hz be 0.0
        
        Note: Convert to mel: 2595 multiplied by log10(1 plus f/700)
        Let mel_value be 2595.0 multiplied by MathCore.logarithm_base10(1.0 plus (freq_hz / 700.0))
        
        Collections.append(mel_frequencies, mel_value)
        Let i be i plus 1
    
    Return mel_frequencies

Process called "bark_scale_conversion" that takes frequencies as List[Float] returns List[Float]:
    Note: Convert frequencies to bark scale using Zwicker's formula
    Note: bark is equal to 13 multiplied by atan(0.00076 multiplied by f) plus 3.5 multiplied by atan((f/7500)^2)
    Note: Time complexity: O(N), Space complexity: O(N)
    
    Let N be Collections.get_size(frequencies)
    If N is equal to 0:
        Return Collections.create_list()
    
    Let bark_frequencies be Collections.create_list()
    
    Let i be 0
    While i is less than N:
        Let freq_hz be Collections.get_item(frequencies, i)
        
        Note: Handle negative frequencies
        If freq_hz is less than 0.0:
            Let freq_hz be 0.0
        
        Note: Zwicker's bark formula: 13 multiplied by atan(0.00076 multiplied by f) plus 3.5 multiplied by atan((f/7500)^2)
        Let term1 be 13.0 multiplied by MathCore.arctangent(0.00076 multiplied by freq_hz)
        Let ratio be freq_hz / 7500.0
        Let term2 be 3.5 multiplied by MathCore.arctangent(ratio multiplied by ratio)
        Let bark_value be term1 plus term2
        
        Collections.append(bark_frequencies, bark_value)
        Let i be i plus 1
    
    Return bark_frequencies

Process called "erb_scale_conversion" that takes frequencies as List[Float] returns List[Float]:
    Note: Convert frequencies to ERB (Equivalent Rectangular Bandwidth) scale
    Note: ERB is equal to 24.7 multiplied by (4.37 multiplied by f/1000 plus 1) where f is frequency in Hz
    Note: Time complexity: O(N), Space complexity: O(N)
    
    Let N be Collections.get_size(frequencies)
    If N is equal to 0:
        Return Collections.create_list()
    
    Let erb_frequencies be Collections.create_list()
    
    Let i be 0
    While i is less than N:
        Let freq_hz be Collections.get_item(frequencies, i)
        
        Note: Handle negative frequencies
        If freq_hz is less than 0.0:
            Let freq_hz be 0.0
        
        Note: ERB formula: 24.7 multiplied by (4.37 multiplied by f/1000 plus 1)
        Let erb_value be 24.7 multiplied by (4.37 multiplied by freq_hz / 1000.0 plus 1.0)
        
        Collections.append(erb_frequencies, erb_value)
        Let i be i plus 1
    
    Return erb_frequencies

Process called "frequency_warping" that takes spectrum as List[Float], source_frequencies as List[Float], target_frequencies as List[Float] returns List[Float]:
    Note: Warp spectrum from source frequency scale to target frequency scale
    Note: Uses linear interpolation to map spectral values to new frequency bins
    Note: Time complexity: O(M*N), Space complexity: O(M) where M is target length
    
    Let source_N be Collections.get_size(spectrum)
    Let source_freq_N be Collections.get_size(source_frequencies)
    Let target_N be Collections.get_size(target_frequencies)
    
    If source_N does not equal source_freq_N:
        Throw Errors.ArgumentError with "Spectrum and source frequencies must have same length"
    
    If source_N is equal to 0 or target_N is equal to 0:
        Return Collections.create_list()
    
    Let warped_spectrum be Collections.create_list()
    
    Note: For each target frequency, interpolate from source spectrum
    Let i be 0
    While i is less than target_N:
        Let target_freq be Collections.get_item(target_frequencies, i)
        Let interpolated_value be 0.0
        
        Note: Find bracketing indices in source frequencies
        Let found_bracket be false
        Let j be 0
        While j is less than source_freq_N minus 1 and not found_bracket:
            Let freq1 be Collections.get_item(source_frequencies, j)
            Let freq2 be Collections.get_item(source_frequencies, j plus 1)
            
            If target_freq is greater than or equal to freq1 and target_freq is less than or equal to freq2:
                Note: Linear interpolation
                Let spec1 be Collections.get_item(spectrum, j)
                Let spec2 be Collections.get_item(spectrum, j plus 1)
                
                If freq2 does not equal freq1:
                    Let alpha be (target_freq minus freq1) / (freq2 minus freq1)
                    Let interpolated_value be spec1 multiplied by (1.0 minus alpha) plus spec2 multiplied by alpha
                Otherwise:
                    Let interpolated_value be spec1
                
                Let found_bracket be true
            
            Let j be j plus 1
        
        Note: Handle extrapolation cases
        If not found_bracket:
            If target_freq is less than Collections.get_item(source_frequencies, 0):
                Let interpolated_value be Collections.get_item(spectrum, 0)
            Otherwise:
                Let interpolated_value be Collections.get_item(spectrum, source_N minus 1)
        
        Collections.append(warped_spectrum, interpolated_value)
        Let i be i plus 1
    
    Return warped_spectrum

Note: ========================================================================
Note: MISSING HELPER FUNCTIONS minus CRITICAL FOR COMPILATION
Note: ========================================================================

Process called "apply_window_function" that takes signal as List[Float], window_type as String returns List[Float]:
    Note: Apply windowing function to signal segment
    Let N be Collections.get_size(signal)
    If N is equal to 0:
        Return Collections.create_list()
    
    Let windowed_signal be Collections.create_list()
    Let i be 0
    While i is less than N:
        Let sample be Collections.get_item(signal, i)
        Let window_value be 1.0
        
        If window_type is equal to "rectangular":
            Set window_value to 1.0
        If window_type is equal to "hanning" or window_type is equal to "hann":
            Set window_value to 0.5 minus 0.5 multiplied by Math.cos(2.0 multiplied by Math.PI multiplied by Float(i) / Float(N minus 1))
        If window_type is equal to "hamming":
            Set window_value to 0.54 minus 0.46 multiplied by Math.cos(2.0 multiplied by Math.PI multiplied by Float(i) / Float(N minus 1))
        If window_type is equal to "blackman":
            Let a0 be 0.42659
            Let a1 be 0.49656
            Let a2 be 0.07685
            Set window_value to a0 minus a1 multiplied by Math.cos(2.0 multiplied by Math.PI multiplied by Float(i) / Float(N minus 1)) plus a2 multiplied by Math.cos(4.0 multiplied by Math.PI multiplied by Float(i) / Float(N minus 1))
        If window_type is equal to "bartlett":
            If i is less than or equal to N / 2:
                Set window_value to 2.0 multiplied by Float(i) / Float(N minus 1)
            Otherwise:
                Set window_value to 2.0 minus 2.0 multiplied by Float(i) / Float(N minus 1)
        
        Collections.append(windowed_signal, sample multiplied by window_value)
        Let i be i plus 1
    
    Return windowed_signal

Process called "compute_window_gain" that takes windowed_signal as List[Float] returns Float:
    Note: Compute the gain factor of the applied window for normalization
    Let N be Collections.get_size(windowed_signal)
    If N is equal to 0:
        Return 1.0
    
    Note: Compute the sum of window values squared for power correction
    Let window_power be 0.0
    Let signal_power be 0.0
    
    Let i be 0
    While i is less than N:
        Let windowed_val be Collections.get_item(windowed_signal, i)
        Set window_power to window_power plus windowed_val multiplied by windowed_val
        Let i be i plus 1
    
    Note: Return normalization factor (typically sqrt of mean window power)
    If window_power is greater than 0.0:
        Return Math.sqrt(window_power / Float(N))
    Otherwise:
        Return 1.0