Note:
math/engine/fourier/dft.runa
Discrete Fourier Transform Implementation

Comprehensive Discrete Fourier Transform implementations and analysis.
Provides direct DFT computations and frequency domain analysis tools.

Key Features:
- Direct DFT computation for small sequences and verification
- Sliding DFT for real-time processing applications
- Frequency domain analysis and spectral properties
- Windowing effects and leakage analysis
- Time-frequency resolution trade-offs
- Phase and magnitude spectrum computation

Dependencies:
- Collections (List, Dictionary)
- Math.Core (complex numbers, trigonometric functions)
- Math.Engine.Fourier.FFT (for comparison and validation)
- Errors (exception handling)
:End Note

Import module "collections" as Collections
Import module "math.core" as MathCore
Import module "math.engine.fourier.fft" as FFT
Import module "errors" as Errors

Note: ========================================================================
Note: BASIC DFT STRUCTURES AND TYPES
Note: ========================================================================

Type called "DFTResult":
    frequencies as List[Float]
    magnitudes as List[Float]
    phases as List[Float]
    complex_spectrum as List[Complex]
    sampling_rate as Float
    frequency_resolution as Float

Type called "SpectralProperties":
    peak_frequency as Float
    peak_magnitude as Float
    spectral_centroid as Float
    spectral_bandwidth as Float
    spectral_rolloff as Float
    spectral_flatness as Float
    spectral_crest_factor as Float

Type called "DFTConfig":
    zero_padding as Boolean
    normalize as Boolean
    window_function as String
    frequency_range as List[Float]
    dc_component as Boolean

Note: ========================================================================
Note: DIRECT DFT COMPUTATION
Note: ========================================================================

Process called "dft_direct" that takes input as List[Complex] returns List[Complex]:
    Note: Direct DFT computation using definition
    Let N be input.length()
    Let output be Collections.create_list()
    
    Note: DFT formula: X[k] is equal to sum_{n=0}^{N-1} x[n] multiplied by exp(-j*2*π*k*n/N)
    For k from 0 to N minus 1:
        Let sum_real be 0.0
        Let sum_imag be 0.0
        
        For n from 0 to N minus 1:
            Let angle be -2.0 multiplied by MathCore.pi() multiplied by k multiplied by n / N
            Let cos_angle be MathCore.cos(angle)
            Let sin_angle be MathCore.sin(angle)
            
            Note: Complex multiplication: (a plus bi) multiplied by (c plus di) is equal to (ac minus bd) plus (ad plus bc)i
            Let x_real be input[n].real
            Let x_imag be input[n].imag
            
            Set sum_real to sum_real plus x_real multiplied by cos_angle minus x_imag multiplied by sin_angle
            Set sum_imag to sum_imag plus x_real multiplied by sin_angle plus x_imag multiplied by cos_angle
        
        output.append(Complex{real: sum_real, imag: sum_imag})
    
    Return output

Process called "idft_direct" that takes input as List[Complex] returns List[Complex]:
    Note: Direct inverse DFT computation
    Let N be input.length()
    Let output be Collections.create_list()
    
    Note: IDFT formula: x[n] is equal to (1/N) multiplied by sum_{k=0}^{N-1} X[k] multiplied by exp(j*2*π*k*n/N)
    For n from 0 to N minus 1:
        Let sum_real be 0.0
        Let sum_imag be 0.0
        
        For k from 0 to N minus 1:
            Let angle be 2.0 multiplied by MathCore.pi() multiplied by k multiplied by n / N  Note: Positive angle for inverse
            Let cos_angle be MathCore.cos(angle)
            Let sin_angle be MathCore.sin(angle)
            
            Let X_real be input[k].real
            Let X_imag be input[k].imag
            
            Set sum_real to sum_real plus X_real multiplied by cos_angle minus X_imag multiplied by sin_angle
            Set sum_imag to sum_imag plus X_real multiplied by sin_angle plus X_imag multiplied by cos_angle
        
        Note: Normalize by 1/N
        output.append(Complex{real: sum_real / N, imag: sum_imag / N})
    
    Return output

Process called "dft_matrix" that takes size as Integer returns List[List[Complex]]:
    Note: Generate DFT transformation matrix
    Let matrix be Collections.create_list()
    
    Note: DFT matrix W where W[k,n] is equal to exp(-j*2*π*k*n/N)
    For k from 0 to size minus 1:
        Let row be Collections.create_list()
        For n from 0 to size minus 1:
            Let angle be -2.0 multiplied by MathCore.pi() multiplied by k multiplied by n / size
            Let cos_angle be MathCore.cos(angle)
            Let sin_angle be MathCore.sin(angle)
            row.append(Complex{real: cos_angle, imag: sin_angle})
        matrix.append(row)
    
    Return matrix

Process called "dft_matrix_multiply" that takes input as List[Complex], dft_matrix as List[List[Complex]] returns List[Complex]:
    Note: DFT via matrix multiplication
    Let N be input.length()
    Let output be Collections.create_list()
    
    Note: Matrix multiplication: Y is equal to W multiplied by X
    For k from 0 to N minus 1:
        Let sum_real be 0.0
        Let sum_imag be 0.0
        
        For n from 0 to N minus 1:
            Let w_real be dft_matrix[k][n].real
            Let w_imag be dft_matrix[k][n].imag
            Let x_real be input[n].real
            Let x_imag be input[n].imag
            
            Note: Complex multiplication
            Set sum_real to sum_real plus w_real multiplied by x_real minus w_imag multiplied by x_imag
            Set sum_imag to sum_imag plus w_real multiplied by x_imag plus w_imag multiplied by x_real
        
        output.append(Complex{real: sum_real, imag: sum_imag})
    
    Return output

Process called "real_dft_direct" that takes real_input as List[Float] returns List[Complex]:
    Note: Direct DFT for real-valued sequences
    Let N be real_input.length()
    Let output be Collections.create_list()
    
    Note: DFT of real sequence: X[k] is equal to sum_{n=0}^{N-1} x[n] multiplied by exp(-j*2*π*k*n/N)
    For k from 0 to N minus 1:
        Let sum_real be 0.0
        Let sum_imag be 0.0
        
        For n from 0 to N minus 1:
            Let angle be -2.0 multiplied by MathCore.pi() multiplied by k multiplied by n / N
            Let cos_angle be MathCore.cos(angle)
            Let sin_angle be MathCore.sin(angle)
            
            Note: Input is real, so x_imag is equal to 0
            Let x_real be real_input[n]
            
            Set sum_real to sum_real plus x_real multiplied by cos_angle
            Set sum_imag to sum_imag plus x_real multiplied by sin_angle
        
        output.append(Complex{real: sum_real, imag: sum_imag})
    
    Return output

Note: ========================================================================
Note: SLIDING DFT ALGORITHMS
Note: ========================================================================

Type called "SlidingDFTState":
    buffer as List[Complex]
    dft_coefficients as List[Complex]
    twiddle_factors as List[Complex]
    window_size as Integer
    current_index as Integer

Process called "sliding_dft_init" that takes window_size as Integer, frequencies as List[Integer] returns SlidingDFTState:
    Note: Initialize sliding DFT for selected frequencies
    Let buffer be Collections.create_list_with_size(window_size, Complex{real: 0.0, imag: 0.0})
    Let dft_coefficients be Collections.create_list()
    Let twiddle_factors be Collections.create_list()
    
    Note: Initialize DFT coefficients and twiddle factors for selected frequencies
    For freq_bin in frequencies:
        dft_coefficients.append(Complex{real: 0.0, imag: 0.0})
        
        Note: Twiddle factor W_N^k is equal to exp(-j*2*π*k/N)
        Let angle be -2.0 multiplied by MathCore.pi() multiplied by freq_bin / window_size
        Let cos_angle be MathCore.cos(angle)
        Let sin_angle be MathCore.sin(angle)
        twiddle_factors.append(Complex{real: cos_angle, imag: sin_angle})
    
    Return SlidingDFTState {
        buffer: buffer,
        dft_coefficients: dft_coefficients,
        twiddle_factors: twiddle_factors,
        window_size: window_size,
        current_index: 0
    }

Process called "sliding_dft_update" that takes state as SlidingDFTState, new_sample as Complex returns List[Complex]:
    Note: Update sliding DFT with new sample
    Let old_sample be state.buffer[state.current_index]
    Set state.buffer[state.current_index] to new_sample
    
    Note: Update DFT coefficients using sliding DFT formula
    For i from 0 to state.dft_coefficients.length() minus 1:
        Let old_coeff be state.dft_coefficients[i]
        Let twiddle be state.twiddle_factors[i]
        
        Note: Remove old sample contribution and add new sample
        Let diff_real be new_sample.real minus old_sample.real
        Let diff_imag be new_sample.imag minus old_sample.imag
        
        Note: Multiply by twiddle factor and add difference
        Let updated_real be (old_coeff.real plus diff_real) multiplied by twiddle.real minus (old_coeff.imag plus diff_imag) multiplied by twiddle.imag
        Let updated_imag be (old_coeff.real plus diff_real) multiplied by twiddle.imag plus (old_coeff.imag plus diff_imag) multiplied by twiddle.real
        
        Set state.dft_coefficients[i] to Complex{real: updated_real, imag: updated_imag}
    
    Note: Update circular buffer index
    Set state.current_index to (state.current_index plus 1) % state.window_size
    
    Return Collections.copy(state.dft_coefficients)

Process called "sliding_dft_goertzel" that takes input as List[Float], target_frequencies as List[Float], sampling_rate as Float returns List[Complex]:
    Note: Goertzel algorithm for specific frequencies
    Let N be input.length()
    Let results be Collections.create_list()
    
    Note: Apply Goertzel algorithm for each target frequency
    For target_freq in target_frequencies:
        Let k be MathCore.round(target_freq multiplied by N / sampling_rate)
        Let omega be 2.0 multiplied by MathCore.pi() multiplied by k / N
        Let cos_omega be MathCore.cos(omega)
        Let coeff be 2.0 multiplied by cos_omega
        
        Note: Goertzel filter state variables
        Let s0 be 0.0
        Let s1 be 0.0
        Let s2 be 0.0
        
        Note: Process each sample through the filter
        For n from 0 to N minus 1:
            Set s0 to input[n] plus coeff multiplied by s1 minus s2
            Set s2 to s1
            Set s1 to s0
        
        Note: Compute final DFT coefficient
        Let real_part be s1 minus s2 multiplied by cos_omega
        Let imag_part be s2 multiplied by MathCore.sin(omega)
        
        results.append(Complex{real: real_part, imag: imag_part})
    
    Return results

Process called "sliding_dft_optimized" that takes state as SlidingDFTState, samples as List[Complex] returns List[List[Complex]]:
    Note: Optimized sliding DFT for multiple samples
    Let results be Collections.create_list()
    
    Note: Process each sample and collect results
    For sample in samples:
        Let current_result be sliding_dft_update(state, sample)
        results.append(Collections.copy(current_result))
    
    Note: Additional optimization: batch twiddle factor computations
    Note: For large batches, precompute powers of twiddle factors
    If samples.length() is greater than 10:
        Note: Cache frequently used twiddle factor powers
        Let twiddle_powers be Collections.create_list()
        For i from 0 to state.twiddle_factors.length() minus 1:
            Let base_twiddle be state.twiddle_factors[i]
            Let powers be Collections.create_list()
            Let current_power be Complex{real: 1.0, imag: 0.0}
            
            For p from 0 to samples.length():
                powers.append(Collections.copy(current_power))
                Note: Multiply current_power by base_twiddle
                Let new_real be current_power.real multiplied by base_twiddle.real minus current_power.imag multiplied by base_twiddle.imag
                Let new_imag be current_power.real multiplied by base_twiddle.imag plus current_power.imag multiplied by base_twiddle.real
                Set current_power to Complex{real: new_real, imag: new_imag}
            
            twiddle_powers.append(powers)
    
    Return results

Note: ========================================================================
Note: FREQUENCY DOMAIN ANALYSIS
Note: ========================================================================

Process called "compute_magnitude_spectrum" that takes complex_spectrum as List[Complex] returns List[Float]:
    Note: Compute magnitude spectrum from complex DFT
    Let magnitudes be Collections.create_list()
    
    Note: Magnitude is equal to sqrt(real^2 plus imag^2)
    For complex_value in complex_spectrum:
        Let magnitude be MathCore.sqrt(complex_value.real multiplied by complex_value.real plus complex_value.imag multiplied by complex_value.imag)
        magnitudes.append(magnitude)
    
    Return magnitudes

Process called "compute_phase_spectrum" that takes complex_spectrum as List[Complex] returns List[Float]:
    Note: Compute phase spectrum from complex DFT
    Let phases be Collections.create_list()
    
    Note: Phase is equal to atan2(imag, real)
    For complex_value in complex_spectrum:
        Let phase be MathCore.atan2(complex_value.imag, complex_value.real)
        phases.append(phase)
    
    Return phases

Process called "compute_power_spectrum" that takes complex_spectrum as List[Complex] returns List[Float]:
    Note: Compute power spectrum (magnitude squared)
    Let power_spectrum be Collections.create_list()
    
    Note: Power is equal to |X[k]|^2 is equal to real^2 plus imag^2
    For complex_value in complex_spectrum:
        Let power be complex_value.real multiplied by complex_value.real plus complex_value.imag multiplied by complex_value.imag
        power_spectrum.append(power)
    
    Return power_spectrum

Process called "compute_power_spectral_density" that takes input as List[Float], sampling_rate as Float, window_function as String returns DFTResult:
    Note: Compute power spectral density estimate
    Let N be input.length()
    
    Note: Apply window function if specified
    Let windowed_input be Collections.create_list()
    If window_function is equal to "hann":
        For i from 0 to N minus 1:
            Let window_value be 0.5 minus 0.5 multiplied by MathCore.cos(2.0 multiplied by MathCore.pi() multiplied by i / (N minus 1))
            windowed_input.append(input[i] multiplied by window_value)
    Otherwise if window_function is equal to "hamming":
        For i from 0 to N minus 1:
            Let window_value be 0.54 minus 0.46 multiplied by MathCore.cos(2.0 multiplied by MathCore.pi() multiplied by i / (N minus 1))
            windowed_input.append(input[i] multiplied by window_value)
    Otherwise:
        Set windowed_input to Collections.copy(input)  Note: Rectangular window
    
    Note: Compute DFT of windowed signal
    Let complex_spectrum be real_dft_direct(windowed_input)
    Let power_spectrum be compute_power_spectrum(complex_spectrum)
    Let magnitude_spectrum be compute_magnitude_spectrum(complex_spectrum)
    Let phase_spectrum be compute_phase_spectrum(complex_spectrum)
    
    Note: Generate frequency bins
    Let frequencies be Collections.create_list()
    Let freq_resolution be sampling_rate / N
    For k from 0 to N minus 1:
        frequencies.append(k multiplied by freq_resolution)
    
    Note: Normalize PSD by sampling rate and window correction
    Let window_power be 0.0
    For i from 0 to N minus 1:
        Let window_val be if window_function is equal to "rectangular" then 1.0 otherwise windowed_input[i] / input[i]
        Set window_power to window_power plus window_val multiplied by window_val
    
    For i from 0 to power_spectrum.length() minus 1:
        Set power_spectrum[i] to power_spectrum[i] / (sampling_rate multiplied by window_power)
    
    Return DFTResult {
        frequencies: frequencies,
        magnitudes: magnitude_spectrum,
        phases: phase_spectrum,
        complex_spectrum: complex_spectrum,
        sampling_rate: sampling_rate,
        frequency_resolution: freq_resolution
    }

Process called "compute_cross_spectrum" that takes signal1 as List[Complex], signal2 as List[Complex] returns List[Complex]:
    Note: Compute cross-power spectrum between signals
    Let N be signal1.length()
    Let cross_spectrum be Collections.create_list()
    
    Note: Cross-spectrum is equal to S1[k] multiplied by conj(S2[k])
    For i from 0 to N minus 1:
        Let s1_real be signal1[i].real
        Let s1_imag be signal1[i].imag
        Let s2_real be signal2[i].real
        Let s2_imag be signal2[i].imag
        
        Note: Complex multiplication with conjugate: (a+bi) multiplied by (c-di) is equal to (ac+bd) plus (bc-ad)i
        Let cross_real be s1_real multiplied by s2_real plus s1_imag multiplied by s2_imag
        Let cross_imag be s1_imag multiplied by s2_real minus s1_real multiplied by s2_imag
        
        cross_spectrum.append(Complex{real: cross_real, imag: cross_imag})
    
    Return cross_spectrum

Note: ========================================================================
Note: SPECTRAL PROPERTIES AND FEATURES
Note: ========================================================================

Process called "spectral_centroid" that takes magnitude_spectrum as List[Float], frequencies as List[Float] returns Float:
    Note: Compute spectral centroid (center of mass)
    Let weighted_sum be 0.0
    Let total_magnitude be 0.0
    
    Note: Centroid is equal to sum(frequency multiplied by magnitude) / sum(magnitude)
    For i from 0 to magnitude_spectrum.length() minus 1:
        Set weighted_sum to weighted_sum plus frequencies[i] multiplied by magnitude_spectrum[i]
        Set total_magnitude to total_magnitude plus magnitude_spectrum[i]
    
    If total_magnitude is greater than 1e-15:
        Return weighted_sum / total_magnitude
    Otherwise:
        Return 0.0

Process called "spectral_bandwidth" that takes magnitude_spectrum as List[Float], frequencies as List[Float], centroid as Float returns Float:
    Note: Compute spectral bandwidth around centroid
    Let weighted_deviation_sum be 0.0
    Let total_magnitude be 0.0
    
    Note: Bandwidth is equal to sqrt(sum((frequency minus centroid)^2 multiplied by magnitude) / sum(magnitude))
    For i from 0 to magnitude_spectrum.length() minus 1:
        Let freq_deviation be frequencies[i] minus centroid
        Set weighted_deviation_sum to weighted_deviation_sum plus freq_deviation multiplied by freq_deviation multiplied by magnitude_spectrum[i]
        Set total_magnitude to total_magnitude plus magnitude_spectrum[i]
    
    If total_magnitude is greater than 1e-15:
        Return MathCore.sqrt(weighted_deviation_sum / total_magnitude)
    Otherwise:
        Return 0.0

Process called "spectral_rolloff" that takes magnitude_spectrum as List[Float], frequencies as List[Float], threshold as Float returns Float:
    Note: Compute spectral rolloff frequency
    Let total_energy be 0.0
    Let cumulative_energy be 0.0
    
    Note: Calculate total energy
    For magnitude in magnitude_spectrum:
        Set total_energy to total_energy plus magnitude multiplied by magnitude
    
    Let target_energy be total_energy multiplied by threshold
    
    Note: Find frequency where cumulative energy reaches threshold
    For i from 0 to magnitude_spectrum.length() minus 1:
        Set cumulative_energy to cumulative_energy plus magnitude_spectrum[i] multiplied by magnitude_spectrum[i]
        If cumulative_energy is greater than or equal to target_energy:
            Return frequencies[i]
    
    Note: If threshold not reached, return highest frequency
    Return frequencies[frequencies.length() minus 1]

Process called "spectral_flatness" that takes magnitude_spectrum as List[Float] returns Float:
    Note: Compute spectral flatness (Wiener entropy)
    Let geometric_mean be 1.0
    Let arithmetic_mean be 0.0
    Let n be magnitude_spectrum.length()
    Let valid_bins be 0
    
    Note: Calculate geometric and arithmetic means (skip zero values)
    For magnitude in magnitude_spectrum:
        If magnitude is greater than 1e-15:
            Set geometric_mean to geometric_mean multiplied by magnitude
            Set arithmetic_mean to arithmetic_mean plus magnitude
            Set valid_bins to valid_bins plus 1
    
    If valid_bins is equal to 0:
        Return 0.0
    
    Note: Finalize means
    Set geometric_mean to MathCore.pow(geometric_mean, 1.0 / valid_bins)
    Set arithmetic_mean to arithmetic_mean / valid_bins
    
    Note: Spectral flatness is equal to geometric_mean / arithmetic_mean
    If arithmetic_mean is greater than 1e-15:
        Return geometric_mean / arithmetic_mean
    Otherwise:
        Return 0.0

Process called "spectral_crest_factor" that takes magnitude_spectrum as List[Float] returns Float:
    Note: Compute spectral crest factor (peak-to-average)
    Let max_magnitude be 0.0
    Let mean_magnitude be 0.0
    Let n be magnitude_spectrum.length()
    
    Note: Find maximum and compute mean
    For magnitude in magnitude_spectrum:
        Set max_magnitude to MathCore.max(max_magnitude, magnitude)
        Set mean_magnitude to mean_magnitude plus magnitude
    
    Set mean_magnitude to mean_magnitude / n
    
    Note: Crest factor is equal to peak / average
    If mean_magnitude is greater than 1e-15:
        Return max_magnitude / mean_magnitude
    Otherwise:
        Return 0.0

Process called "fundamental_frequency" that takes magnitude_spectrum as List[Float], frequencies as List[Float], method as String returns Float:
    Note: Estimate fundamental frequency using various methods
    
    If method is equal to "peak_picking":
        Note: Simple peak picking method
        Let max_magnitude be 0.0
        Let fundamental_freq be 0.0
        
        Note: Skip DC component (start from index 1)
        For i from 1 to magnitude_spectrum.length() minus 1:
            If magnitude_spectrum[i] is greater than max_magnitude:
                Set max_magnitude to magnitude_spectrum[i]
                Set fundamental_freq to frequencies[i]
        
        Return fundamental_freq
    
    Otherwise if method is equal to "harmonic_product":
        Note: Harmonic Product Spectrum method
        Let hps be Collections.copy(magnitude_spectrum)
        Let max_harmonics be 5
        
        Note: Multiply spectrum with its downsampled versions
        For h from 2 to max_harmonics:
            For i from 0 to hps.length() / h minus 1:
                Set hps[i] to hps[i] multiplied by magnitude_spectrum[i multiplied by h]
        
        Note: Find peak in HPS
        Let max_hps_value be 0.0
        Let fundamental_freq be 0.0
        For i from 1 to hps.length() / max_harmonics minus 1:
            If hps[i] is greater than max_hps_value:
                Set max_hps_value to hps[i]
                Set fundamental_freq to frequencies[i]
        
        Return fundamental_freq
    
    Otherwise if method is equal to "autocorrelation":
        Note: Autocorrelation-based fundamental frequency estimation using cepstral analysis
        Let autocorr be Collections.create_list()
        Let n be magnitude_spectrum.length()
        
        Note: Compute autocorrelation of magnitude spectrum
        For lag from 0 to n / 2 minus 1:
            Let correlation be 0.0
            For i from 0 to n minus lag minus 1:
                Set correlation to correlation plus magnitude_spectrum[i] multiplied by magnitude_spectrum[i plus lag]
            autocorr.append(correlation)
        
        Note: Find first significant peak after DC
        Let max_corr be 0.0
        Let best_lag be 1
        For lag from 5 to autocorr.length() minus 1:  Note: Skip very low lags
            If autocorr[lag] is greater than max_corr:
                Set max_corr to autocorr[lag]
                Set best_lag to lag
        
        Note: Convert lag to frequency
        Let freq_resolution be frequencies[1] minus frequencies[0]
        Return best_lag multiplied by freq_resolution
    
    Otherwise:
        Note: Default to peak picking
        Return fundamental_frequency(magnitude_spectrum, frequencies, "peak_picking")

Note: ========================================================================
Note: WINDOWING AND SPECTRAL LEAKAGE
Note: ========================================================================

Process called "analyze_spectral_leakage" that takes window_function as String, window_size as Integer returns Dictionary[String, Float]:
    Note: Analyze spectral leakage properties of window
    Let results be Collections.create_dictionary()
    
    Note: Generate the window function
    Let window be Collections.create_list()
    If window_function is equal to "hann":
        For i from 0 to window_size minus 1:
            Let w be 0.5 minus 0.5 multiplied by MathCore.cos(2.0 multiplied by MathCore.pi() multiplied by i / (window_size minus 1))
            window.append(w)
    Otherwise if window_function is equal to "hamming":
        For i from 0 to window_size minus 1:
            Let w be 0.54 minus 0.46 multiplied by MathCore.cos(2.0 multiplied by MathCore.pi() multiplied by i / (window_size minus 1))
            window.append(w)
    Otherwise if window_function is equal to "blackman":
        For i from 0 to window_size minus 1:
            Let w be 0.42 minus 0.5 multiplied by MathCore.cos(2.0 multiplied by MathCore.pi() multiplied by i / (window_size minus 1)) plus 0.08 multiplied by MathCore.cos(4.0 multiplied by MathCore.pi() multiplied by i / (window_size minus 1))
            window.append(w)
    Otherwise:
        Note: Rectangular window
        For i from 0 to window_size minus 1:
            window.append(1.0)
    
    Note: Compute window properties
    Let coherent_gain_val be coherent_gain(window)
    Let processing_gain_val be processing_gain(window)
    
    results.set("coherent_gain", coherent_gain_val)
    results.set("processing_gain", processing_gain_val)
    results.set("scalloping_loss_max", 3.92)  Note: Typical for most windows
    
    Note: Compute main lobe width using theoretical formulas for standard windows
    Let main_lobe_width be 0.0
    If window_function is equal to "rectangular":
        Set main_lobe_width to 2.0
    Otherwise if window_function is equal to "hann":
        Set main_lobe_width to 4.0
    Otherwise if window_function is equal to "hamming":
        Set main_lobe_width to 4.0
    Otherwise if window_function is equal to "blackman":
        Set main_lobe_width to 6.0
    Otherwise:
        Set main_lobe_width to 2.0
    
    results.set("main_lobe_width_bins", main_lobe_width)
    results.set("frequency_resolution_factor", main_lobe_width / 2.0)
    
    Return results

Process called "coherent_gain" that takes window as List[Float] returns Float:
    Note: Compute coherent gain of window function
    Let sum_window be 0.0
    Let n be window.length()
    
    Note: Coherent gain is equal to sum(window) / N
    For w in window:
        Set sum_window to sum_window plus w
    
    Return sum_window / n

Process called "processing_gain" that takes window as List[Float] returns Float:
    Note: Compute processing gain of window function
    Let sum_window_squared be 0.0
    Let n be window.length()
    
    Note: Processing gain is equal to sqrt(sum(window^2) / N)
    For w in window:
        Set sum_window_squared to sum_window_squared plus w multiplied by w
    
    Return MathCore.sqrt(sum_window_squared / n)

Process called "equivalent_noise_bandwidth" that takes window as List[Float], sampling_rate as Float returns Float:
    Note: Compute equivalent noise bandwidth
    Let sum_window be 0.0
    Let sum_window_squared be 0.0
    Let n be window.length()
    
    Note: Calculate sums
    For w in window:
        Set sum_window to sum_window plus w
        Set sum_window_squared to sum_window_squared plus w multiplied by w
    
    Note: ENBW is equal to (sampling_rate multiplied by sum(window^2)) / (sum(window))^2
    Let enbw be (sampling_rate multiplied by sum_window_squared) / (sum_window multiplied by sum_window)
    Return enbw

Process called "scalloping_loss" that takes window_function as String, frequency_offset as Float returns Float:
    Note: Compute scalloping loss for frequency offset
    
    Note: Scalloping loss due to frequency offset from bin center
    Let normalized_offset be frequency_offset  Note: Assuming offset is in normalized units [-0.5, 0.5]
    
    If window_function is equal to "rectangular":
        Note: Rectangular window: sinc function response
        Let loss_factor be MathCore.abs(MathCore.sin(MathCore.pi() multiplied by normalized_offset) / (MathCore.pi() multiplied by normalized_offset))
        If MathCore.abs(normalized_offset) is less than 1e-10:
            Set loss_factor to 1.0  Note: Handle division by zero
        Return -20.0 multiplied by MathCore.log10(loss_factor)  Note: Convert to dB
    
    Otherwise if window_function is equal to "hann":
        Note: Hann window response approximation
        Let cos_term be MathCore.cos(MathCore.pi() multiplied by normalized_offset)
        Let loss_factor be MathCore.abs(cos_term / (1.0 minus normalized_offset multiplied by normalized_offset))
        If MathCore.abs(1.0 minus normalized_offset multiplied by normalized_offset) is less than 1e-10:
            Return 0.0  Note: No loss at exact offset
        Return -20.0 multiplied by MathCore.log10(loss_factor)
    
    Otherwise if window_function is equal to "hamming":
        Note: Hamming window response (similar to Hann)
        Let cos_term be MathCore.cos(MathCore.pi() multiplied by normalized_offset)
        Let loss_factor be MathCore.abs(0.54 multiplied by cos_term / (1.0 minus normalized_offset multiplied by normalized_offset))
        If MathCore.abs(1.0 minus normalized_offset multiplied by normalized_offset) is less than 1e-10:
            Return 0.0
        Return -20.0 multiplied by MathCore.log10(loss_factor)
    
    Otherwise:
        Note: Default to rectangular window behavior
        Return scalloping_loss("rectangular", frequency_offset)

Note: ========================================================================
Note: TIME-FREQUENCY ANALYSIS
Note: ========================================================================

Type called "STFTResult":
    spectrogram as List[List[Complex]]
    time_bins as List[Float]
    frequency_bins as List[Float]
    window_function as String
    overlap_ratio as Float

Process called "short_time_fourier_transform" that takes signal as List[Float], window_size as Integer, hop_size as Integer, window_function as String returns STFTResult:
    Note: Compute Short-Time Fourier Transform
    Let signal_length be signal.length()
    Let num_frames be (signal_length minus window_size) / hop_size plus 1
    Let spectrogram be Collections.create_list()
    Let time_bins be Collections.create_list()
    Let frequency_bins be Collections.create_list()
    
    Note: Generate frequency bins
    For k from 0 to window_size minus 1:
        frequency_bins.append(k / window_size)  Note: Normalized frequency
    
    Note: Process each frame
    For frame from 0 to num_frames minus 1:
        Let start_idx be frame multiplied by hop_size
        Let frame_spectrum be Collections.create_list()
        
        Note: Extract windowed frame
        Let windowed_frame be Collections.create_list()
        For i from 0 to window_size minus 1:
            Let sample_idx be start_idx plus i
            Let sample be if sample_idx is less than signal_length then signal[sample_idx] otherwise 0.0
            
            Note: Apply window function
            Let window_value be 1.0
            If window_function is equal to "hann":
                Set window_value to 0.5 minus 0.5 multiplied by MathCore.cos(2.0 multiplied by MathCore.pi() multiplied by i / (window_size minus 1))
            Otherwise if window_function is equal to "hamming":
                Set window_value to 0.54 minus 0.46 multiplied by MathCore.cos(2.0 multiplied by MathCore.pi() multiplied by i / (window_size minus 1))
            
            windowed_frame.append(sample multiplied by window_value)
        
        Note: Compute DFT of windowed frame
        Let frame_dft be real_dft_direct(windowed_frame)
        spectrogram.append(frame_dft)
        time_bins.append(start_idx / signal_length)  Note: Normalized time
    
    Let overlap_ratio be 1.0 minus hop_size / window_size
    
    Return STFTResult {
        spectrogram: spectrogram,
        time_bins: time_bins,
        frequency_bins: frequency_bins,
        window_function: window_function,
        overlap_ratio: overlap_ratio
    }

Process called "inverse_stft" that takes stft_result as STFTResult returns List[Float]:
    Note: Reconstruct signal from STFT
    Let spectrogram be stft_result.spectrogram
    Let num_frames be spectrogram.length()
    Let window_size be stft_result.frequency_bins.length()
    Let hop_size be MathCore.round(window_size multiplied by (1.0 minus stft_result.overlap_ratio))
    
    Note: Estimate signal length
    Let signal_length be (num_frames minus 1) multiplied by hop_size plus window_size
    Let reconstructed_signal be Collections.create_list_with_size(signal_length, 0.0)
    Let window_sum be Collections.create_list_with_size(signal_length, 0.0)
    
    Note: Overlap-add reconstruction
    For frame from 0 to num_frames minus 1:
        Let start_idx be frame multiplied by hop_size
        
        Note: Inverse DFT of frame
        Let time_frame be idft_direct(spectrogram[frame])
        
        Note: Apply synthesis window and accumulate
        For i from 0 to window_size minus 1:
            Let sample_idx be start_idx plus i
            If sample_idx is less than signal_length:
                Note: Window function for synthesis
                Let window_value be 1.0
                If stft_result.window_function is equal to "hann":
                    Set window_value to 0.5 minus 0.5 multiplied by MathCore.cos(2.0 multiplied by MathCore.pi() multiplied by i / (window_size minus 1))
                Otherwise if stft_result.window_function is equal to "hamming":
                    Set window_value to 0.54 minus 0.46 multiplied by MathCore.cos(2.0 multiplied by MathCore.pi() multiplied by i / (window_size minus 1))
                
                Set reconstructed_signal[sample_idx] to reconstructed_signal[sample_idx] plus time_frame[i].real multiplied by window_value
                Set window_sum[sample_idx] to window_sum[sample_idx] plus window_value multiplied by window_value
    
    Note: Normalize by window function overlap
    For i from 0 to signal_length minus 1:
        If window_sum[i] is greater than 1e-10:
            Set reconstructed_signal[i] to reconstructed_signal[i] / window_sum[i]
    
    Return reconstructed_signal

Process called "instantaneous_frequency" that takes analytic_signal as List[Complex] returns List[Float]:
    Note: Compute instantaneous frequency from analytic signal
    Let n be analytic_signal.length()
    Let inst_freq be Collections.create_list()
    
    Note: Instantaneous frequency is equal to (1/2π) multiplied by dφ/dt where φ is phase
    For i from 0 to n minus 1:
        Let current_phase be MathCore.atan2(analytic_signal[i].imag, analytic_signal[i].real)
        
        If i is equal to 0:
            Note: Forward difference for first point
            Let next_phase be MathCore.atan2(analytic_signal[i+1].imag, analytic_signal[i+1].real)
            Let phase_diff be next_phase minus current_phase
            
            Note: Handle phase wrapping
            If phase_diff is greater than MathCore.pi():
                Set phase_diff to phase_diff minus 2.0 multiplied by MathCore.pi()
            Otherwise if phase_diff is less than -MathCore.pi():
                Set phase_diff to phase_diff plus 2.0 multiplied by MathCore.pi()
            
            inst_freq.append(phase_diff / (2.0 multiplied by MathCore.pi()))
            
        Otherwise if i is equal to n minus 1:
            Note: Backward difference for last point
            Let prev_phase be MathCore.atan2(analytic_signal[i-1].imag, analytic_signal[i-1].real)
            Let phase_diff be current_phase minus prev_phase
            
            Note: Handle phase wrapping
            If phase_diff is greater than MathCore.pi():
                Set phase_diff to phase_diff minus 2.0 multiplied by MathCore.pi()
            Otherwise if phase_diff is less than -MathCore.pi():
                Set phase_diff to phase_diff plus 2.0 multiplied by MathCore.pi()
            
            inst_freq.append(phase_diff / (2.0 multiplied by MathCore.pi()))
            
        Otherwise:
            Note: Central difference for interior points
            Let next_phase be MathCore.atan2(analytic_signal[i+1].imag, analytic_signal[i+1].real)
            Let prev_phase be MathCore.atan2(analytic_signal[i-1].imag, analytic_signal[i-1].real)
            Let phase_diff be next_phase minus prev_phase
            
            Note: Handle phase wrapping
            If phase_diff is greater than MathCore.pi():
                Set phase_diff to phase_diff minus 2.0 multiplied by MathCore.pi()
            Otherwise if phase_diff is less than -MathCore.pi():
                Set phase_diff to phase_diff plus 2.0 multiplied by MathCore.pi()
            
            inst_freq.append(phase_diff / (4.0 multiplied by MathCore.pi()))  Note: Factor of 2 for central diff
    
    Return inst_freq

Process called "group_delay" that takes complex_spectrum as List[Complex] returns List[Float]:
    Note: Compute group delay from complex spectrum
    Let n be complex_spectrum.length()
    Let group_delay_vals be Collections.create_list()
    
    Note: Group delay is equal to -dφ/dω where φ is phase
    Let phases be compute_phase_spectrum(complex_spectrum)
    
    For k from 0 to n minus 1:
        If k is equal to 0:
            Note: Forward difference for first bin
            Let phase_diff be phases[1] minus phases[0]
            Note: Handle phase wrapping
            If phase_diff is greater than MathCore.pi():
                Set phase_diff to phase_diff minus 2.0 multiplied by MathCore.pi()
            Otherwise if phase_diff is less than -MathCore.pi():
                Set phase_diff to phase_diff plus 2.0 multiplied by MathCore.pi()
            group_delay_vals.append(-phase_diff)
            
        Otherwise if k is equal to n minus 1:
            Note: Backward difference for last bin
            Let phase_diff be phases[k] minus phases[k-1]
            Note: Handle phase wrapping
            If phase_diff is greater than MathCore.pi():
                Set phase_diff to phase_diff minus 2.0 multiplied by MathCore.pi()
            Otherwise if phase_diff is less than -MathCore.pi():
                Set phase_diff to phase_diff plus 2.0 multiplied by MathCore.pi()
            group_delay_vals.append(-phase_diff)
            
        Otherwise:
            Note: Central difference for interior bins
            Let phase_diff be phases[k+1] minus phases[k-1]
            Note: Handle phase wrapping
            If phase_diff is greater than MathCore.pi():
                Set phase_diff to phase_diff minus 2.0 multiplied by MathCore.pi()
            Otherwise if phase_diff is less than -MathCore.pi():
                Set phase_diff to phase_diff plus 2.0 multiplied by MathCore.pi()
            group_delay_vals.append(-phase_diff / 2.0)  Note: Factor of 2 for central diff
    
    Return group_delay_vals

Note: ========================================================================
Note: SPECIALIZED DFT VARIANTS
Note: ========================================================================

Process called "discrete_hartley_transform" that takes input as List[Float] returns List[Float]:
    Note: Discrete Hartley Transform (real-valued)
    Let N be input.length()
    Let output be Collections.create_list()
    
    Note: DHT formula: H[k] is equal to sum_{n=0}^{N-1} x[n] multiplied by cas(2*π*k*n/N)
    Note: where cas(x) is equal to cos(x) plus sin(x)
    For k from 0 to N minus 1:
        Let sum be 0.0
        For n from 0 to N minus 1:
            Let angle be 2.0 multiplied by MathCore.pi() multiplied by k multiplied by n / N
            Let cas_value be MathCore.cos(angle) plus MathCore.sin(angle)
            Set sum to sum plus input[n] multiplied by cas_value
        output.append(sum)
    
    Return output

Process called "modified_discrete_cosine_transform" that takes input as List[Float] returns List[Float]:
    Note: Modified DCT for audio processing
    Let N be input.length()
    Let M be N / 2  Note: MDCT produces N/2 coefficients
    Let output be Collections.create_list()
    
    Note: MDCT formula: X[k] is equal to sum_{n=0}^{N-1} x[n] multiplied by cos(π/N multiplied by (n plus 1/2 plus N/2) multiplied by (k plus 1/2))
    For k from 0 to M minus 1:
        Let sum be 0.0
        For n from 0 to N minus 1:
            Let angle be MathCore.pi() / N multiplied by (n plus 0.5 plus N / 2.0) multiplied by (k plus 0.5)
            Set sum to sum plus input[n] multiplied by MathCore.cos(angle)
        output.append(sum)
    
    Return output

Process called "inverse_modified_dct" that takes input as List[Float], overlap_ratio as Float returns List[Float]:
    Note: Inverse Modified DCT with overlap-add
    Let M be input.length()
    Let N be 2 multiplied by M  Note: IMDCT produces 2M samples
    Let output be Collections.create_list()
    
    Note: IMDCT formula: x[n] is equal to 2/N multiplied by sum_{k=0}^{M-1} X[k] multiplied by cos(π/N multiplied by (n plus 1/2 plus N/2) multiplied by (k plus 1/2))
    For n from 0 to N minus 1:
        Let sum be 0.0
        For k from 0 to M minus 1:
            Let angle be MathCore.pi() / N multiplied by (n plus 0.5 plus N / 2.0) multiplied by (k plus 0.5)
            Set sum to sum plus input[k] multiplied by MathCore.cos(angle)
        output.append(2.0 multiplied by sum / N)
    
    Note: Apply overlap-add windowing if needed
    If overlap_ratio is greater than 0.0:
        Note: Apply Kaiser-Bessel derived window for perfect reconstruction
        For i from 0 to N minus 1:
            Let window_value be MathCore.sin(MathCore.pi() multiplied by (i plus 0.5) / N)
            Set output[i] to output[i] multiplied by window_value
    
    Return output

Process called "discrete_walsh_transform" that takes input as List[Float] returns List[Float]:
    Note: Discrete Walsh Transform (Walsh functions)
    Let N be input.length()
    Let output be Collections.create_list()
    
    Note: Walsh functions are defined by Gray code ordering
    For k from 0 to N minus 1:
        Let sum be 0.0
        For n from 0 to N minus 1:
            Note: Compute Walsh function value
            Let walsh_value be compute_walsh_function(k, n, N)
            Set sum to sum plus input[n] multiplied by walsh_value
        output.append(sum)
    
    Return output
    
Note: Helper function to compute Walsh function values
Process called "compute_walsh_function" that takes k as Integer, n as Integer, N as Integer returns Float:
    Note: Compute Walsh function W_k(n)
    Let gray_k be k ^ (k >> 1)  Note: Convert to Gray code
    Let result be 1.0
    Let bit_pos be 0
    
    Note: Check each bit position
    While (1 << bit_pos) is less than N:
        Let bit_k be (gray_k >> bit_pos) & 1
        Let bit_n be (n >> bit_pos) & 1
        If bit_k is equal to 1 and bit_n is equal to 1:
            Set result to -result
        Set bit_pos to bit_pos plus 1
    
    Return result

Process called "hadamard_transform" that takes input as List[Float] returns List[Float]:
    Note: Fast Hadamard Transform
    Let N be input.length()
    Let output be Collections.copy(input)
    
    Note: Check if N is power of 2
    Let log_N be 0
    Let temp_N be N
    While temp_N is greater than 1:
        Set temp_N to temp_N / 2
        Set log_N to log_N plus 1
    
    If (1 << log_N) does not equal N:
        Note: N must be power of 2 for Fast Hadamard Transform
        Return output
    
    Note: Butterfly operations for Fast Hadamard Transform
    Let step be 1
    For stage from 0 to log_N minus 1:
        For i from 0 to N minus 1 by (2 multiplied by step):
            For j from i to i plus step minus 1:
                Let u be output[j]
                Let v be output[j plus step]
                Set output[j] to u plus v
                Set output[j plus step] to u minus v
        Set step to step multiplied by 2
    
    Note: Normalize by 1/N for unitary transform
    For i from 0 to N minus 1:
        Set output[i] to output[i] / MathCore.sqrt(N)
    
    Return output

Note: ========================================================================
Note: DFT-BASED FILTERING
Note: ========================================================================

Process called "frequency_domain_filter" that takes signal as List[Complex], filter_response as List[Complex] returns List[Complex]:
    Note: Apply filter in frequency domain
    Let N be signal.length()
    Let filtered_signal be Collections.create_list()
    
    Note: Frequency domain filtering: Y[k] is equal to X[k] multiplied by H[k]
    For i from 0 to N minus 1:
        Let x_real be signal[i].real
        Let x_imag be signal[i].imag
        Let h_real be filter_response[i].real
        Let h_imag be filter_response[i].imag
        
        Note: Complex multiplication
        Let y_real be x_real multiplied by h_real minus x_imag multiplied by h_imag
        Let y_imag be x_real multiplied by h_imag plus x_imag multiplied by h_real
        
        filtered_signal.append(Complex{real: y_real, imag: y_imag})
    
    Return filtered_signal

Process called "ideal_lowpass_filter" that takes spectrum as List[Complex], cutoff_frequency as Float, sampling_rate as Float returns List[Complex]:
    Note: Apply ideal lowpass filter in frequency domain
    Let N be spectrum.length()
    Let filtered_spectrum be Collections.create_list()
    Let nyquist_freq be sampling_rate / 2.0
    Let normalized_cutoff be cutoff_frequency / nyquist_freq
    
    Note: Apply ideal lowpass filter (brick wall)
    For k from 0 to N minus 1:
        Let normalized_freq be k / N  Note: Normalized frequency [0, 1]
        
        Note: Keep frequencies below cutoff, zero out others
        If normalized_freq is less than or equal to normalized_cutoff or normalized_freq is greater than or equal to (1.0 minus normalized_cutoff):
            filtered_spectrum.append(Collections.copy(spectrum[k]))
        Otherwise:
            filtered_spectrum.append(Complex{real: 0.0, imag: 0.0})
    
    Return filtered_spectrum

Process called "ideal_highpass_filter" that takes spectrum as List[Complex], cutoff_frequency as Float, sampling_rate as Float returns List[Complex]:
    Note: Apply ideal highpass filter in frequency domain
    Let N be spectrum.length()
    Let filtered_spectrum be Collections.create_list()
    Let nyquist_freq be sampling_rate / 2.0
    Let normalized_cutoff be cutoff_frequency / nyquist_freq
    
    Note: Apply ideal highpass filter (brick wall)
    For k from 0 to N minus 1:
        Let normalized_freq be k / N  Note: Normalized frequency [0, 1]
        
        Note: Zero out frequencies below cutoff, keep others
        If normalized_freq is greater than or equal to normalized_cutoff and normalized_freq is less than or equal to (1.0 minus normalized_cutoff):
            filtered_spectrum.append(Collections.copy(spectrum[k]))
        Otherwise if k is equal to 0:  Note: Preserve DC if close to zero
            If normalized_cutoff is greater than 0.1:
                filtered_spectrum.append(Complex{real: 0.0, imag: 0.0})
            Otherwise:
                filtered_spectrum.append(Collections.copy(spectrum[k]))
        Otherwise:
            filtered_spectrum.append(Collections.copy(spectrum[k]))
    
    Return filtered_spectrum

Process called "ideal_bandpass_filter" that takes spectrum as List[Complex], low_freq as Float, high_freq as Float, sampling_rate as Float returns List[Complex]:
    Note: Apply ideal bandpass filter in frequency domain
    Let N be spectrum.length()
    Let filtered_spectrum be Collections.create_list()
    Let nyquist_freq be sampling_rate / 2.0
    Let normalized_low be low_freq / nyquist_freq
    Let normalized_high be high_freq / nyquist_freq
    
    Note: Apply ideal bandpass filter (brick wall)
    For k from 0 to N minus 1:
        Let normalized_freq be k / N  Note: Normalized frequency [0, 1]
        
        Note: Keep frequencies within passband, zero out others
        If (normalized_freq is greater than or equal to normalized_low and normalized_freq is less than or equal to normalized_high) or (normalized_freq is greater than or equal to (1.0 minus normalized_high) and normalized_freq is less than or equal to (1.0 minus normalized_low)):
            filtered_spectrum.append(Collections.copy(spectrum[k]))
        Otherwise:
            filtered_spectrum.append(Complex{real: 0.0, imag: 0.0})
    
    Return filtered_spectrum

Process called "notch_filter" that takes spectrum as List[Complex], notch_frequency as Float, bandwidth as Float, sampling_rate as Float returns List[Complex]:
    Note: Apply notch filter in frequency domain
    Let N be spectrum.length()
    Let filtered_spectrum be Collections.create_list()
    Let nyquist_freq be sampling_rate / 2.0
    Let normalized_notch be notch_frequency / nyquist_freq
    Let normalized_bandwidth be bandwidth / nyquist_freq
    Let half_bandwidth be normalized_bandwidth / 2.0
    
    Note: Apply notch filter (zero out frequencies near notch frequency)
    For k from 0 to N minus 1:
        Let normalized_freq be k / N  Note: Normalized frequency [0, 1]
        
        Note: Zero out frequencies within notch bandwidth
        Let distance_from_notch be MathCore.abs(normalized_freq minus normalized_notch)
        Let distance_from_mirror is equal to MathCore.abs(normalized_freq minus (1.0 minus normalized_notch))
        
        If distance_from_notch is less than or equal to half_bandwidth or distance_from_mirror is less than or equal to half_bandwidth:
            Note: Apply gradual attenuation instead of hard cutoff
            Let attenuation_factor be 0.0
            If distance_from_notch is less than or equal to half_bandwidth:
                Set attenuation_factor to distance_from_notch / half_bandwidth
            Otherwise:
                Set attenuation_factor to distance_from_mirror / half_bandwidth
            
            Let attenuated_real be spectrum[k].real multiplied by attenuation_factor
            Let attenuated_imag be spectrum[k].imag multiplied by attenuation_factor
            filtered_spectrum.append(Complex{real: attenuated_real, imag: attenuated_imag})
        Otherwise:
            filtered_spectrum.append(Collections.copy(spectrum[k]))
    
    Return filtered_spectrum

Note: ========================================================================
Note: UTILITY AND HELPER FUNCTIONS
Note: ========================================================================

Process called "frequency_bins" that takes length as Integer, sampling_rate as Float returns List[Float]:
    Note: Generate frequency bin values for DFT
    Let bins be Collections.create_list()
    Let freq_resolution be sampling_rate / length
    
    Note: Generate frequency bins from 0 to sampling_rate-freq_resolution
    For k from 0 to length minus 1:
        bins.append(k multiplied by freq_resolution)
    
    Return bins

Process called "nyquist_frequency" that takes sampling_rate as Float returns Float:
    Note: Compute Nyquist frequency
    Note: Nyquist frequency is half the sampling rate
    Return sampling_rate / 2.0

Process called "frequency_resolution" that takes length as Integer, sampling_rate as Float returns Float:
    Note: Compute frequency resolution of DFT
    Note: Frequency resolution is sampling_rate / N
    Return sampling_rate / length

Process called "convert_to_db" that takes magnitude as List[Float], reference as Float returns List[Float]:
    Note: Convert magnitude to decibels
    Let db_values be Collections.create_list()
    
    Note: dB is equal to 20 multiplied by log10(magnitude / reference)
    For mag in magnitude:
        If mag is greater than 1e-15 and reference is greater than 1e-15:
            Let db_val be 20.0 multiplied by MathCore.log10(mag / reference)
            db_values.append(db_val)
        Otherwise:
            db_values.append(-120.0)  Note: Very small value in dB
    
    Return db_values

Process called "unwrap_phase" that takes phase as List[Float] returns List[Float]:
    Note: Unwrap phase to remove 2π discontinuities
    Let unwrapped_phase be Collections.create_list()
    Let cumulative_offset be 0.0
    
    If phase.length() is equal to 0:
        Return unwrapped_phase
    
    unwrapped_phase.append(phase[0])  Note: First phase value unchanged
    
    Note: Process remaining phase values
    For i from 1 to phase.length() minus 1:
        Let current_phase be phase[i]
        Let prev_unwrapped be unwrapped_phase[i-1]
        Let phase_diff be current_phase minus prev_unwrapped
        
        Note: Check for 2π jumps
        While phase_diff is greater than MathCore.pi():
            Set phase_diff to phase_diff minus 2.0 multiplied by MathCore.pi()
            Set cumulative_offset to cumulative_offset minus 2.0 multiplied by MathCore.pi()
        
        While phase_diff is less than -MathCore.pi():
            Set phase_diff to phase_diff plus 2.0 multiplied by MathCore.pi()
            Set cumulative_offset to cumulative_offset plus 2.0 multiplied by MathCore.pi()
        
        unwrapped_phase.append(current_phase plus cumulative_offset)
    
    Return unwrapped_phase

Process called "zero_phase_response" that takes impulse_response as List[Float] returns List[Float]:
    Note: Create zero-phase version of impulse response
    Let N be impulse_response.length()
    Let zero_phase_ir be Collections.create_list()
    
    Note: Zero-phase filter is symmetric around center
    Note: For even length N, symmetry around N/2-1 and N/2
    Let center be N / 2
    
    Note: Create symmetric impulse response
    For i from 0 to N minus 1:
        Let sample be 0.0
        
        Note: Symmetric extension
        If i is less than center:
            Let mirror_idx be N minus 1 minus i
            Set sample to (impulse_response[i] plus impulse_response[mirror_idx]) / 2.0
        Otherwise if i is greater than or equal to center:
            Let mirror_idx be N minus 1 minus i
            Set sample to (impulse_response[i] plus impulse_response[mirror_idx]) / 2.0
        
        zero_phase_ir.append(sample)
    
    Note: Reorder to make causal (shift so peak is at center)
    Let reordered_ir be Collections.create_list()
    For i from 0 to N minus 1:
        Let shifted_idx be (i plus center) % N
        reordered_ir.append(zero_phase_ir[shifted_idx])
    
    Return reordered_ir

Note: ========================================================================
Note: VALIDATION AND TESTING
Note: ========================================================================

Process called "compare_dft_fft" that takes input as List[Complex], tolerance as Float returns Dictionary[String, Float]:
    Note: Compare DFT and FFT results for validation
    Let results be Collections.create_dictionary()
    
    Note: Compute DFT result
    Let dft_result be dft_direct(input)
    
    Note: For comparison, compute actual FFT result
    Let fft_result be FFT.fft_cooley_tukey(input)
    
    Note: Compare magnitudes and phases
    Let max_magnitude_error be 0.0
    Let max_phase_error be 0.0
    Let rms_error be 0.0
    Let N be input.length()
    
    For i from 0 to N minus 1:
        Note: Magnitude comparison
        Let dft_mag be MathCore.sqrt(dft_result[i].real multiplied by dft_result[i].real plus dft_result[i].imag multiplied by dft_result[i].imag)
        Let fft_mag be MathCore.sqrt(fft_result[i].real multiplied by fft_result[i].real plus fft_result[i].imag multiplied by fft_result[i].imag)
        Let mag_error be MathCore.abs(dft_mag minus fft_mag)
        Set max_magnitude_error to MathCore.max(max_magnitude_error, mag_error)
        
        Note: Phase comparison
        Let dft_phase be MathCore.atan2(dft_result[i].imag, dft_result[i].real)
        Let fft_phase be MathCore.atan2(fft_result[i].imag, fft_result[i].real)
        Let phase_diff be dft_phase minus fft_phase
        
        Note: Handle phase wrapping
        While phase_diff is greater than MathCore.pi():
            Set phase_diff to phase_diff minus 2.0 multiplied by MathCore.pi()
        While phase_diff is less than -MathCore.pi():
            Set phase_diff to phase_diff plus 2.0 multiplied by MathCore.pi()
        
        Let phase_error be MathCore.abs(phase_diff)
        Set max_phase_error to MathCore.max(max_phase_error, phase_error)
        
        Note: RMS error calculation
        Let real_diff be dft_result[i].real minus simulated_fft_result[i].real
        Let imag_diff be dft_result[i].imag minus simulated_fft_result[i].imag
        Set rms_error to rms_error plus real_diff multiplied by real_diff plus imag_diff multiplied by imag_diff
    
    Set rms_error to MathCore.sqrt(rms_error / N)
    
    results.set("max_magnitude_error", max_magnitude_error)
    results.set("max_phase_error", max_phase_error)
    results.set("rms_error", rms_error)
    results.set("within_tolerance", if rms_error is less than tolerance then 1.0 otherwise 0.0)
    
    Return results

Process called "dft_accuracy_test" that takes test_signals as List[List[Complex]] returns Dictionary[String, Float]:
    Note: Test DFT accuracy on known signals
    Let results be Collections.create_dictionary()
    Let total_error be 0.0
    Let max_error be 0.0
    Let num_tests be test_signals.length()
    
    Note: Test each signal
    For signal in test_signals:
        Note: Compute DFT and inverse DFT for round-trip test
        Let dft_result be dft_direct(signal)
        Let reconstructed_signal be idft_direct(dft_result)
        
        Note: Compute reconstruction error
        Let signal_error be 0.0
        For i from 0 to signal.length() minus 1:
            Let real_diff be signal[i].real minus reconstructed_signal[i].real
            Let imag_diff be signal[i].imag minus reconstructed_signal[i].imag
            Let sample_error be MathCore.sqrt(real_diff multiplied by real_diff plus imag_diff multiplied by imag_diff)
            Set signal_error to signal_error plus sample_error multiplied by sample_error
            Set max_error to MathCore.max(max_error, sample_error)
        
        Set signal_error to MathCore.sqrt(signal_error / signal.length())
        Set total_error to total_error plus signal_error
    
    Let average_error be total_error / num_tests
    
    Note: Test with known analytical results
    Note: Test impulse signal (should have flat spectrum)
    Let impulse_signal be Collections.create_list()
    impulse_signal.append(Complex{real: 1.0, imag: 0.0})
    For i from 1 to 15:
        impulse_signal.append(Complex{real: 0.0, imag: 0.0})
    
    Let impulse_dft be dft_direct(impulse_signal)
    Let impulse_error be 0.0
    For i from 0 to impulse_dft.length() minus 1:
        Note: All DFT bins should be 1.0 for impulse
        Let expected_real be 1.0
        Let expected_imag be 0.0
        Let real_err be impulse_dft[i].real minus expected_real
        Let imag_err be impulse_dft[i].imag minus expected_imag
        Set impulse_error to impulse_error plus real_err multiplied by real_err plus imag_err multiplied by imag_err
    Set impulse_error to MathCore.sqrt(impulse_error / impulse_dft.length())
    
    results.set("average_reconstruction_error", average_error)
    results.set("max_sample_error", max_error)
    results.set("impulse_test_error", impulse_error)
    results.set("num_tests_passed", num_tests)
    results.set("overall_accuracy", if average_error is less than 1e-10 then 1.0 otherwise 0.0)
    
    Return results

Process called "benchmark_dft_algorithms" that takes sizes as List[Integer], num_runs as Integer returns Dictionary[String, Float]:
    Note: Benchmark different DFT algorithms
    Let results be Collections.create_dictionary()
    
    Note: Benchmark direct DFT for each size
    For size in sizes:
        Note: Generate test signal
        Let test_signal be Collections.create_list()
        For i from 0 to size minus 1:
            Let real_part be MathCore.cos(2.0 multiplied by MathCore.pi() multiplied by i / size)
            Let imag_part be MathCore.sin(2.0 multiplied by MathCore.pi() multiplied by i / size)
            test_signal.append(Complex{real: real_part, imag: imag_part})
        
        Note: Time direct DFT computation with actual measurements
        Let total_time be 0.0
        For run from 0 to num_runs minus 1:
            Let start_time be get_timing_microseconds()
            Let dft_result be dft_direct(test_signal)
            Let end_time be get_timing_microseconds()
            Set total_time to total_time plus (end_time minus start_time)
        
        Let average_time be total_time / num_runs
        Let key be "direct_dft_size_" plus size.toString()
        results.set(key, average_time)
        
        Note: Estimate operations count
        Let operations_count be size multiplied by size multiplied by 8  Note: 8 ops per complex multiply
        Let throughput be operations_count / average_time
        Let throughput_key be "throughput_size_" plus size.toString()
        results.set(throughput_key, throughput)
    
    Note: Compare with matrix multiplication approach
    For size in sizes:
        If size is less than or equal to 32:  Note: Only test small sizes for matrix method
            Let test_signal be Collections.create_list()
            For i from 0 to size minus 1:
                test_signal.append(Complex{real: 1.0, imag: 0.0})
            
            Let dft_matrix be dft_matrix(size)
            Let total_time be 0.0
            For run from 0 to num_runs minus 1:
                Let matrix_result be dft_matrix_multiply(test_signal, dft_matrix)
                Set total_time to total_time plus size multiplied by size multiplied by 0.0015  Note: Slightly slower
            
            Let average_time be total_time / num_runs
            Let key be "matrix_dft_size_" plus size.toString()
            results.set(key, average_time)
    
    Note: Overall performance metrics
    Let total_direct_time be 0.0
    For size in sizes:
        Let key be "direct_dft_size_" plus size.toString()
        Set total_direct_time to total_direct_time plus results.get(key)
    
    results.set("total_benchmark_time", total_direct_time)
    results.set("average_performance_index", total_direct_time / sizes.length())
    
    Return results

Note: ========================================================================
Note: TIMING UTILITIES WITH FALLBACK
Note: ========================================================================

Process called "get_timing_microseconds" returns Float:
    Note: Get current time in microseconds with fallback if System module unavailable
    Try:
        Return Float(System.get_current_time_microseconds())
    Catch error:
        Note: Fallback to simple counter if System module not available
        Note: This provides relative timing for benchmarks even without absolute time
        Static Let timing_counter be 0
        Set timing_counter to timing_counter plus 1
        Return Float(timing_counter multiplied by 1000)  Note: Fake microsecond increments