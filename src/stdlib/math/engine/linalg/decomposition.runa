Note:
math/engine/linalg/decomposition.runa
Matrix Decomposition and Factorization Engine

This module provides comprehensive matrix decomposition algorithms including:
- LU decomposition with partial and complete pivoting
- QR decomposition using Householder reflections and Givens rotations
- SVD (Singular Value Decomposition) with various algorithms
- Cholesky decomposition for positive definite matrices
- Eigenvalue decomposition for symmetric and general matrices
- Schur decomposition and real Schur form
- Jordan canonical form decomposition
- Polar decomposition into orthogonal and positive definite parts
- Hessenberg reduction for eigenvalue algorithms
- Tridiagonal reduction for symmetric matrices
- Bidiagonal reduction for SVD algorithms
- Matrix exponential and logarithm computations
- Condition number estimation and error analysis
- Iterative refinement for improved accuracy
- Block-wise decompositions for large matrices
:End Note

Import module "dev/debug/errors/core" as Errors
Import module "math/engine/linalg/core" as LinAlgCore

Note: =====================================================================
Note: DECOMPOSITION DATA STRUCTURES
Note: =====================================================================

Type called "LUDecomposition":
    lower_matrix as Matrix
    upper_matrix as Matrix
    permutation_matrix as Matrix
    pivot_vector as List[Integer]
    decomposition_rank as Integer
    numerical_stability as String

Type called "QRDecomposition":
    orthogonal_matrix as Matrix
    upper_triangular as Matrix
    householder_vectors as List[Vector]
    tau_coefficients as List[String]
    algorithm_used as String

Type called "SVDResult":
    left_singular_vectors as Matrix
    singular_values as List[String]
    right_singular_vectors as Matrix
    rank as Integer
    condition_number as String
    numerical_tolerance as Float

Type called "EigenDecomposition":
    eigenvalues as List[String]
    eigenvectors as Matrix
    is_real as Boolean
    is_symmetric as Boolean
    convergence_info as Dictionary[String, String]

Type called "CholeskyDecomposition":
    lower_triangular as Matrix
    is_positive_definite as Boolean
    pivot_used as Boolean
    rank_deficiency as Integer

Type called "SchurDecomposition":
    orthogonal_matrix as Matrix
    schur_matrix as Matrix
    eigenvalues as List[String]
    is_real_schur as Boolean

Note: =====================================================================
Note: LU DECOMPOSITION OPERATIONS
Note: =====================================================================

Process called "lu_decomposition" that takes matrix as Matrix, pivoting_strategy as String returns LUDecomposition:
    Note: Perform LU decomposition with specified pivoting strategy
    Note: Dispatches to appropriate pivoting method based on strategy
    
    If pivoting_strategy is equal to "partial":
        Return lu_with_partial_pivoting(matrix)
    Otherwise if pivoting_strategy is equal to "complete":
        Return lu_with_complete_pivoting(matrix)
    Otherwise if pivoting_strategy is equal to "none":
        Return lu_without_pivoting(matrix)
    Otherwise:
        Throw Errors.InvalidArgument with "Unknown pivoting strategy: " plus pivoting_strategy

Process called "lu_with_partial_pivoting" that takes matrix as Matrix returns LUDecomposition:
    Note: LU decomposition with partial (row) pivoting
    Note: Implements PA is equal to LU where P is permutation matrix, L is lower triangular, U is upper triangular
    
    If matrix.rows does not equal matrix.columns:
        Throw Errors.InvalidMatrix with "LU decomposition requires square matrix"
    
    Let n be matrix.rows
    
    Note: Copy matrix entries for working matrix
    Let working_entries be List[List[String]]()
    Let i be 0
    While i is less than n:
        Let row be List[String]()
        Let j be 0
        While j is less than n:
            Call row.add(matrix.entries.get(i).get(j))
            Set j to j plus 1
        Call working_entries.add(row)
        Set i to i plus 1
    
    Note: Initialize lower triangular matrix as identity
    Let lower_entries be List[List[String]]()
    Set i to 0
    While i is less than n:
        Let row be List[String]()
        Let j be 0
        While j is less than n:
            If i is equal to j:
                Call row.add("1.0")
            Otherwise:
                Call row.add("0.0")
            Set j to j plus 1
        Call lower_entries.add(row)
        Set i to i plus 1
    
    Note: Initialize permutation matrix as identity
    Let perm_entries be List[List[String]]()
    Set i to 0
    While i is less than n:
        Let row be List[String]()
        Let j be 0
        While j is less than n:
            If i is equal to j:
                Call row.add("1.0")
            Otherwise:
                Call row.add("0.0")
            Set j to j plus 1
        Call perm_entries.add(row)
        Set i to i plus 1
    
    Note: Initialize pivot vector
    Let pivot_list be List[String]()
    Set i to 0
    While i is less than n:
        Call pivot_list.add(i.to_string())
        Set i to i plus 1
    
    Note: Main LU decomposition loop with partial pivoting
    Let k be 0
    While k is less than n minus 1:
        Note: Find pivot element minus maximum absolute value in column k from row k onwards
        Let max_value be LinAlgCore.absolute_value with LinAlgCore.get_matrix_element with working_matrix and k and k
        Let max_row be k
        
        Let i be k plus 1
        While i is less than n:
            Let current_value be LinAlgCore.absolute_value with LinAlgCore.get_matrix_element with working_matrix and i and k
            If LinAlgCore.is_greater_than with current_value and max_value:
                Let max_value be current_value
                Let max_row be i
            Let i be i plus 1
        
        Note: Check for numerical singularity
        If LinAlgCore.is_approximately_zero with max_value and 1e-14:
            Throw Errors.SingularMatrix with "Matrix is numerically singular"
        
        Note: Perform row interchange if necessary
        If max_row does not equal k:
            Let working_matrix be LinAlgCore.swap_matrix_rows with working_matrix and k and max_row
            Let lower_matrix be LinAlgCore.swap_matrix_rows_partial with lower_matrix and k and max_row and k
            Let permutation_matrix be LinAlgCore.swap_matrix_rows with permutation_matrix and k and max_row
            Let pivot_vector be LinAlgCore.swap_vector_elements with pivot_vector and k and max_row
            Let pivot_sign be -pivot_sign
        
        Note: Gaussian elimination step minus compute multipliers and update matrix
        Let pivot_element be LinAlgCore.get_matrix_element with working_matrix and k and k
        
        Let i be k plus 1
        While i is less than n:
            Let multiplier be LinAlgCore.divide with LinAlgCore.get_matrix_element with working_matrix and i and k and pivot_element
            Let lower_matrix be LinAlgCore.set_matrix_element with lower_matrix and i and k and multiplier
            
            Note: Update row i by subtracting multiplier multiplied by row k
            Let j be k plus 1
            While j is less than n:
                Let current_element be LinAlgCore.get_matrix_element with working_matrix and i and j
                Let pivot_row_element be LinAlgCore.get_matrix_element with working_matrix and k and j
                Let update_value be LinAlgCore.multiply with multiplier and pivot_row_element
                Let new_value be LinAlgCore.subtract with current_element and update_value
                Let working_matrix be LinAlgCore.set_matrix_element with working_matrix and i and j and new_value
                Let j be j plus 1
            
            Note: Zero out the eliminated element
            Let working_matrix be LinAlgCore.set_matrix_element with working_matrix and i and k and 0.0
            Let i be i plus 1
        
        Let k be k plus 1
    
    Note: Extract upper triangular matrix from working matrix
    Let upper_matrix be LinAlgCore.create_matrix with n and n
    Let i be 0
    While i is less than n:
        Let j be i
        While j is less than n:
            Let element be LinAlgCore.get_matrix_element with working_matrix and i and j
            Let upper_matrix be LinAlgCore.set_matrix_element with upper_matrix and i and j and element
            Let j be j plus 1
        Let i be i plus 1
    
    Note: Determine numerical stability assessment
    Let min_diagonal be LinAlgCore.get_matrix_element with upper_matrix and 0 and 0
    Let max_diagonal be min_diagonal
    Let i be 1
    While i is less than n:
        Let diagonal_element be LinAlgCore.get_matrix_element with upper_matrix and i and i
        If LinAlgCore.is_less_than with diagonal_element and min_diagonal:
            Let min_diagonal be diagonal_element
        If LinAlgCore.is_greater_than with diagonal_element and max_diagonal:
            Let max_diagonal be diagonal_element
        Let i be i plus 1
    
    Let condition_estimate be LinAlgCore.divide with LinAlgCore.absolute_value with max_diagonal and LinAlgCore.absolute_value with min_diagonal
    Let stability_assessment be "stable"
    If LinAlgCore.is_greater_than with condition_estimate and 1e12:
        Let stability_assessment be "ill_conditioned"
    Otherwise:
        If LinAlgCore.is_greater_than with condition_estimate and 1e8:
            Let stability_assessment be "moderately_conditioned"
    
    Note: Construct and return LU decomposition result
    Let decomposition_result be LUDecomposition with:
        lower_matrix is equal to lower_matrix
        upper_matrix is equal to upper_matrix
        permutation_matrix is equal to permutation_matrix
        pivot_vector is equal to pivot_vector
        decomposition_rank is equal to n
        numerical_stability is equal to stability_assessment
    
    Return decomposition_result

Process called "lu_with_complete_pivoting" that takes matrix as Matrix returns LUDecomposition:
    Note: LU decomposition with complete (row and column) pivoting
    Note: Implements PAQ is equal to LU where P, Q are permutation matrices for maximum numerical stability
    
    Let rows be LinAlgCore.get_matrix_rows with matrix
    Let cols be LinAlgCore.get_matrix_cols with matrix
    
    If rows does not equal cols:
        Throw Errors.InvalidMatrix with "Complete pivoting LU decomposition requires square matrix"
    
    Let n be rows
    Let working_matrix be LinAlgCore.copy_matrix with matrix
    Let lower_matrix be LinAlgCore.create_identity_matrix with n
    Let row_permutation be LinAlgCore.create_identity_matrix with n
    Let col_permutation be LinAlgCore.create_identity_matrix with n
    
    Let row_pivot_vector be LinAlgCore.create_vector with n
    Let col_pivot_vector be LinAlgCore.create_vector with n
    
    Note: Initialize permutation vectors to identity
    Let i be 0
    While i is less than n:
        Let row_pivot_vector be LinAlgCore.set_vector_element with row_pivot_vector and i and i
        Let col_pivot_vector be LinAlgCore.set_vector_element with col_pivot_vector and i and i
        Let i be i plus 1
    
    Note: Main LU decomposition loop with complete pivoting
    Let k be 0
    While k is less than n minus 1:
        Note: Find pivot element minus maximum absolute value in remaining submatrix
        Let max_value be 0.0
        Let max_row be k
        Let max_col be k
        
        Let i be k
        While i is less than n:
            Let j be k
            While j is less than n:
                Let current_value be LinAlgCore.absolute_value with LinAlgCore.get_matrix_element with working_matrix and i and j
                If LinAlgCore.is_greater_than with current_value and max_value:
                    Let max_value be current_value
                    Let max_row be i
                    Let max_col be j
                Let j be j plus 1
            Let i be i plus 1
        
        Note: Check for numerical singularity
        If LinAlgCore.is_approximately_zero with max_value and 1e-14:
            Throw Errors.SingularMatrix with "Matrix is numerically singular in complete pivoting"
        
        Note: Perform row interchange if necessary
        If max_row does not equal k:
            Let working_matrix be LinAlgCore.swap_matrix_rows with working_matrix and k and max_row
            Let lower_matrix be LinAlgCore.swap_matrix_rows_partial with lower_matrix and k and max_row and k
            Let row_permutation be LinAlgCore.swap_matrix_rows with row_permutation and k and max_row
            Let row_pivot_vector be LinAlgCore.swap_vector_elements with row_pivot_vector and k and max_row
        
        Note: Perform column interchange if necessary
        If max_col does not equal k:
            Let working_matrix be LinAlgCore.swap_matrix_cols with working_matrix and k and max_col
            Let col_permutation be LinAlgCore.swap_matrix_cols with col_permutation and k and max_col
            Let col_pivot_vector be LinAlgCore.swap_vector_elements with col_pivot_vector and k and max_col
        
        Note: Gaussian elimination step
        Let pivot_element be LinAlgCore.get_matrix_element with working_matrix and k and k
        
        Let i be k plus 1
        While i is less than n:
            Let multiplier be LinAlgCore.divide with LinAlgCore.get_matrix_element with working_matrix and i and k and pivot_element
            Let lower_matrix be LinAlgCore.set_matrix_element with lower_matrix and i and k and multiplier
            
            Note: Update row i by subtracting multiplier multiplied by row k
            Let j be k plus 1
            While j is less than n:
                Let current_element be LinAlgCore.get_matrix_element with working_matrix and i and j
                Let pivot_row_element be LinAlgCore.get_matrix_element with working_matrix and k and j
                Let update_value be LinAlgCore.multiply with multiplier and pivot_row_element
                Let new_value be LinAlgCore.subtract with current_element and update_value
                Let working_matrix be LinAlgCore.set_matrix_element with working_matrix and i and j and new_value
                Let j be j plus 1
            
            Note: Zero out the eliminated element
            Let working_matrix be LinAlgCore.set_matrix_element with working_matrix and i and k and 0.0
            Let i be i plus 1
        
        Let k be k plus 1
    
    Note: Extract upper triangular matrix
    Let upper_matrix be LinAlgCore.create_matrix with n and n
    Let i be 0
    While i is less than n:
        Let j be i
        While j is less than n:
            Let element be LinAlgCore.get_matrix_element with working_matrix and i and j
            Let upper_matrix be LinAlgCore.set_matrix_element with upper_matrix and i and j and element
            Let j be j plus 1
        Let i be i plus 1
    
    Note: Compute growth factor for numerical stability assessment
    Let original_max be 0.0
    Let i be 0
    While i is less than n:
        Let j be 0
        While j is less than n:
            Let element be LinAlgCore.absolute_value with LinAlgCore.get_matrix_element with matrix and i and j
            If LinAlgCore.is_greater_than with element and original_max:
                Let original_max be element
            Let j be j plus 1
        Let i be i plus 1
    
    Let final_max be 0.0
    Let i be 0
    While i is less than n:
        Let j be 0
        While j is less than n:
            Let l_element be LinAlgCore.absolute_value with LinAlgCore.get_matrix_element with lower_matrix and i and j
            Let u_element be LinAlgCore.absolute_value with LinAlgCore.get_matrix_element with upper_matrix and i and j
            
            If LinAlgCore.is_greater_than with l_element and final_max:
                Let final_max be l_element
            If LinAlgCore.is_greater_than with u_element and final_max:
                Let final_max be u_element
            Let j be j plus 1
        Let i be i plus 1
    
    Let growth_factor be LinAlgCore.divide with final_max and original_max
    
    Note: Determine numerical stability assessment
    Let stability_assessment be "stable"
    If LinAlgCore.is_greater_than with growth_factor and 1000.0:
        Let stability_assessment be "unstable"
    Otherwise:
        If LinAlgCore.is_greater_than with growth_factor and 100.0:
            Let stability_assessment be "moderately_stable"
    
    Note: Create combined permutation matrix P for row pivoting
    Let combined_permutation be row_permutation
    
    Note: Construct and return LU decomposition result
    Let decomposition_result be LUDecomposition with:
        lower_matrix is equal to lower_matrix
        upper_matrix is equal to upper_matrix
        permutation_matrix is equal to combined_permutation
        pivot_vector is equal to row_pivot_vector
        decomposition_rank is equal to n
        numerical_stability is equal to stability_assessment
    
    Return decomposition_result

Process called "block_lu_decomposition" that takes matrix as Matrix, block_size as Integer returns LUDecomposition:
    Note: Block-wise LU decomposition for large matrices
    Note: Partitions matrix into blocks and performs LU decomposition recursively
    
    Let rows be LinAlgCore.get_matrix_rows with matrix
    Let cols be LinAlgCore.get_matrix_cols with matrix
    
    If rows does not equal cols:
        Throw Errors.InvalidArgument with "Block LU requires square matrix"
    
    If block_size is less than or equal to 0 or block_size is greater than or equal to rows:
        Note: Fall back to regular LU decomposition
        Return lu_decomposition(matrix)
    
    Note: Initialize result matrices
    Let lower_matrix be LinAlgCore.create_matrix with rows and cols
    Let upper_matrix be LinAlgCore.create_matrix with rows and cols
    Let permutation_matrix be LinAlgCore.create_identity_matrix with rows
    
    Note: Process matrix in blocks
    Let block_row be 0
    While block_row is less than rows:
        Let current_block_size be block_size
        If block_row plus block_size is greater than rows:
            Set current_block_size to rows minus block_row
        
        Note: Extract diagonal block
        Let diagonal_block be LinAlgCore.extract_submatrix with matrix and block_row and block_row and current_block_size and current_block_size
        
        Note: Decompose diagonal block
        Let block_lu be lu_decomposition(diagonal_block)
        
        Note: Store L and U blocks
        Call LinAlgCore.set_submatrix with lower_matrix and block_row and block_row and block_lu.lower_matrix
        Call LinAlgCore.set_submatrix with upper_matrix and block_row and block_row and block_lu.upper_matrix
        
        Note: Update remaining blocks using forward and backward substitution
        Let remaining_start be block_row plus current_block_size
        If remaining_start is less than rows:
            Note: Solve for L blocks below diagonal
            Let below_block be LinAlgCore.extract_submatrix with matrix and remaining_start and block_row and (rows minus remaining_start) and current_block_size
            Let solved_l_block be LinAlgCore.solve_triangular_system with block_lu.upper_matrix and below_block and "lower"
            Call LinAlgCore.set_submatrix with lower_matrix and remaining_start and block_row and solved_l_block
            
            Note: Solve for U blocks to the right of diagonal
            Let right_block be LinAlgCore.extract_submatrix with matrix and block_row and remaining_start and current_block_size and (cols minus remaining_start)
            Let solved_u_block be LinAlgCore.solve_triangular_system with block_lu.lower_matrix and right_block and "upper"
            Call LinAlgCore.set_submatrix with upper_matrix and block_row and remaining_start and solved_u_block
        
        Set block_row to block_row plus current_block_size
    
    Note: Compute determinant as product of diagonal elements
    Let det be 1.0
    Let i be 0
    While i is less than rows:
        Let diagonal_element be LinAlgCore.get_matrix_element with upper_matrix and i and i
        Set det to LinAlgCore.multiply with det and diagonal_element
        Set i to i plus 1
    
    Return LUDecomposition with lower_matrix: lower_matrix, upper_matrix: upper_matrix, permutation_matrix: permutation_matrix, determinant: det, is_singular: (det is equal to 0.0)

Process called "solve_with_lu" that takes lu_result as LUDecomposition, right_hand_side as Vector returns Vector:
    Note: Solve linear system using precomputed LU decomposition
    Note: Solves PA*x is equal to b using forward and backward substitution
    
    Let lower_matrix be lu_result.lower_matrix
    Let upper_matrix be lu_result.upper_matrix
    Let permutation_matrix be lu_result.permutation_matrix
    Let n be LinAlgCore.get_matrix_rows with lower_matrix
    Let rhs_size be LinAlgCore.get_vector_size with right_hand_side
    
    If n does not equal rhs_size:
        Throw Errors.DimensionMismatch with "LU decomposition dimension does not match RHS vector size"
    
    Note: Apply permutation to right-hand side: P*b
    Let permuted_rhs be LinAlgCore.multiply_matrix_vector with permutation_matrix and right_hand_side
    
    Note: Forward substitution: L*y is equal to P*b
    Let y_vector be LinAlgCore.create_vector with n
    Let i be 0
    While i is less than n:
        Let sum be 0.0
        Let j be 0
        While j is less than i:
            Let l_element be LinAlgCore.get_matrix_element with lower_matrix and i and j
            Let y_element be LinAlgCore.get_vector_element with y_vector and j
            Let sum be LinAlgCore.add with sum and LinAlgCore.multiply with l_element and y_element
            Let j be j plus 1
        
        Let b_element be LinAlgCore.get_vector_element with permuted_rhs and i
        Let l_diagonal be LinAlgCore.get_matrix_element with lower_matrix and i and i
        
        If LinAlgCore.is_approximately_zero with l_diagonal and 1e-14:
            Throw Errors.SingularMatrix with "Singular matrix in forward substitution"
        
        Let y_value be LinAlgCore.divide with LinAlgCore.subtract with b_element and sum and l_diagonal
        Let y_vector be LinAlgCore.set_vector_element with y_vector and i and y_value
        Let i be i plus 1
    
    Note: Backward substitution: U*x is equal to y
    Let solution_vector be LinAlgCore.create_vector with n
    Let i be n minus 1
    While i is greater than or equal to 0:
        Let sum be 0.0
        Let j be i plus 1
        While j is less than n:
            Let u_element be LinAlgCore.get_matrix_element with upper_matrix and i and j
            Let x_element be LinAlgCore.get_vector_element with solution_vector and j
            Let sum be LinAlgCore.add with sum and LinAlgCore.multiply with u_element and x_element
            Let j be j plus 1
        
        Let y_element be LinAlgCore.get_vector_element with y_vector and i
        Let u_diagonal be LinAlgCore.get_matrix_element with upper_matrix and i and i
        
        If LinAlgCore.is_approximately_zero with u_diagonal and 1e-14:
            Throw Errors.SingularMatrix with "Singular matrix in backward substitution"
        
        Let x_value be LinAlgCore.divide with LinAlgCore.subtract with y_element and sum and u_diagonal
        Let solution_vector be LinAlgCore.set_vector_element with solution_vector and i and x_value
        Let i be i minus 1
    
    Return solution_vector

Note: =====================================================================
Note: QR DECOMPOSITION OPERATIONS
Note: =====================================================================

Process called "qr_decomposition" that takes matrix as Matrix, method as String returns QRDecomposition:
    Note: Perform QR decomposition using specified method
    Note: Factorizes matrix A is equal to QR where Q is orthogonal, R is upper triangular
    
    If method is equal to "householder":
        Return householder_qr(matrix)
    Otherwise if method is equal to "gram_schmidt":
        Return gram_schmidt_qr(matrix)
    Otherwise if method is equal to "givens":
        Return givens_qr(matrix)
    Otherwise:
        Note: Default to Householder method for stability
        Return householder_qr(matrix)

Process called "householder_qr" that takes matrix as Matrix returns QRDecomposition:
    Note: QR decomposition using Householder reflections
    Note: Implements A is equal to QR where Q is orthogonal, R is upper triangular
    
    Let m be LinAlgCore.get_matrix_rows with matrix
    Let n be LinAlgCore.get_matrix_cols with matrix
    
    If m is less than n:
        Throw Errors.InvalidMatrix with "QR decomposition requires m is greater than or equal to n (tall or square matrix)"
    
    Let working_matrix be LinAlgCore.copy_matrix with matrix
    Let householder_vectors be LinAlgCore.create_list with
    Let tau_coefficients be LinAlgCore.create_list with
    Let orthogonal_matrix be LinAlgCore.create_identity_matrix with m
    
    Note: Main QR decomposition loop using Householder reflections
    Let k be 0
    While k is less than n:
        Note: Extract column k from row k onwards for Householder vector computation
        Let column_vector be LinAlgCore.create_vector with m minus k
        Let i be 0
        While i is less than m minus k:
            Let element be LinAlgCore.get_matrix_element with working_matrix and (k plus i) and k
            Let column_vector be LinAlgCore.set_vector_element with column_vector and i and element
            Let i be i plus 1
        
        Note: Compute Householder vector and reflection coefficient
        Let column_norm be LinAlgCore.vector_norm with column_vector
        
        If LinAlgCore.is_approximately_zero with column_norm and 1e-14:
            Note: Column is already zero, skip reflection
            Let householder_vector be LinAlgCore.create_zero_vector with m minus k
            Let tau be 0.0
        Otherwise:
            Note: Standard Householder vector computation
            Let first_element be LinAlgCore.get_vector_element with column_vector and 0
            Let sigma be LinAlgCore.sign with first_element
            Let alpha be LinAlgCore.multiply with sigma and column_norm
            
            Let householder_vector be LinAlgCore.copy_vector with column_vector
            Let new_first be LinAlgCore.add with first_element and alpha
            Let householder_vector be LinAlgCore.set_vector_element with householder_vector and 0 and new_first
            
            Let householder_norm be LinAlgCore.vector_norm with householder_vector
            Let householder_vector be LinAlgCore.scale_vector with householder_vector and LinAlgCore.divide with 1.0 and householder_norm
            
            Note: Compute tau coefficient for efficient application
            Let tau be LinAlgCore.divide with LinAlgCore.multiply with 2.0 and new_first and LinAlgCore.add with LinAlgCore.multiply with new_first and new_first and LinAlgCore.multiply with column_norm and column_norm
        
        Let householder_vectors be LinAlgCore.append_to_list with householder_vectors and householder_vector
        Let tau_coefficients be LinAlgCore.append_to_list with tau_coefficients and LinAlgCore.float_to_string with tau
        
        Note: Apply Householder reflection to remaining columns
        Let j be k
        While j is less than n:
            Note: Compute H multiplied by column_j where H is equal to I minus tau multiplied by v multiplied by v^T
            Let column_j be LinAlgCore.create_vector with m minus k
            Let i be 0
            While i is less than m minus k:
                Let element be LinAlgCore.get_matrix_element with working_matrix and (k plus i) and j
                Let column_j be LinAlgCore.set_vector_element with column_j and i and element
                Let i be i plus 1
            
            Note: Compute v^T multiplied by column_j
            Let dot_product be LinAlgCore.vector_dot_product with householder_vector and column_j
            Let scaled_dot be LinAlgCore.multiply with tau and dot_product
            
            Note: Apply reflection: column_j is equal to column_j minus tau multiplied by (v^T multiplied by column_j) multiplied by v
            Let i be 0
            While i is less than m minus k:
                Let current_element be LinAlgCore.get_vector_element with column_j and i
                Let householder_element be LinAlgCore.get_vector_element with householder_vector and i
                Let update_value be LinAlgCore.multiply with scaled_dot and householder_element
                Let new_element be LinAlgCore.subtract with current_element and update_value
                Let working_matrix be LinAlgCore.set_matrix_element with working_matrix and (k plus i) and j and new_element
                Let i be i plus 1
            
            Let j be j plus 1
        
        Let k be k plus 1
    
    Note: Extract R matrix (upper triangular part)
    Let upper_triangular be LinAlgCore.create_matrix with m and n
    Let i be 0
    While i is less than m:
        Let j be 0
        While j is less than n:
            If i is less than or equal to j:
                Let element be LinAlgCore.get_matrix_element with working_matrix and i and j
                Let upper_triangular be LinAlgCore.set_matrix_element with upper_triangular and i and j and element
            Otherwise:
                Let upper_triangular be LinAlgCore.set_matrix_element with upper_triangular and i and j and 0.0
            Let j be j plus 1
        Let i be i plus 1
    
    Note: Construct Q matrix by applying Householder reflections in reverse order
    Let k be n minus 1
    While k is greater than or equal to 0:
        Let householder_vector be LinAlgCore.get_list_element with householder_vectors and k
        Let tau_str be LinAlgCore.get_list_element with tau_coefficients and k
        Let tau be LinAlgCore.string_to_float with tau_str
        
        Note: Apply H_k is equal to I minus tau multiplied by v_k multiplied by v_k^T to Q matrix columns
        Let j be k
        While j is less than m:
            Let column_j be LinAlgCore.create_vector with m minus k
            Let i be 0
            While i is less than m minus k:
                Let element be LinAlgCore.get_matrix_element with orthogonal_matrix and (k plus i) and j
                Let column_j be LinAlgCore.set_vector_element with column_j and i and element
                Let i be i plus 1
            
            Let dot_product be LinAlgCore.vector_dot_product with householder_vector and column_j
            Let scaled_dot be LinAlgCore.multiply with tau and dot_product
            
            Let i be 0
            While i is less than m minus k:
                Let current_element be LinAlgCore.get_vector_element with column_j and i
                Let householder_element be LinAlgCore.get_vector_element with householder_vector and i
                Let update_value be LinAlgCore.multiply with scaled_dot and householder_element
                Let new_element be LinAlgCore.subtract with current_element and update_value
                Let orthogonal_matrix be LinAlgCore.set_matrix_element with orthogonal_matrix and (k plus i) and j and new_element
                Let i be i plus 1
            
            Let j be j plus 1
        
        Let k be k minus 1
    
    Note: Construct and return QR decomposition result
    Let decomposition_result be QRDecomposition with:
        orthogonal_matrix is equal to orthogonal_matrix
        upper_triangular is equal to upper_triangular
        householder_vectors is equal to householder_vectors
        tau_coefficients is equal to tau_coefficients
        algorithm_used is equal to "householder_reflections"
    
    Return decomposition_result

Process called "givens_qr" that takes matrix as Matrix returns QRDecomposition:
    Note: QR decomposition using Givens rotations
    Note: Applies sequence of Givens rotations to zero out subdiagonal elements
    
    Let m be LinAlgCore.get_matrix_rows with matrix
    Let n be LinAlgCore.get_matrix_cols with matrix
    
    If m is less than n:
        Throw Errors.InvalidMatrix with "Givens QR decomposition requires m is greater than or equal to n (tall or square matrix)"
    
    Let working_matrix be LinAlgCore.copy_matrix with matrix
    Let orthogonal_matrix be LinAlgCore.create_identity_matrix with m
    Let rotation_count be 0
    
    Note: Apply Givens rotations column by column
    Let j be 0
    While j is less than n:
        Note: Zero out elements below diagonal in column j
        Let i be m minus 1
        While i is greater than j:
            Let a_ij be LinAlgCore.get_matrix_element with working_matrix and i and j
            Let a_i_minus_1_j be LinAlgCore.get_matrix_element with working_matrix and (i minus 1) and j
            
            Note: Skip if element is already effectively zero
            If LinAlgCore.is_greater_than with LinAlgCore.absolute_value with a_ij and 1e-14:
                Note: Compute Givens rotation parameters
                Let rotation_params be LinAlgCore.compute_givens_rotation with a_i_minus_1_j and a_ij
                Let cosine be LinAlgCore.get_rotation_cosine with rotation_params
                Let sine be LinAlgCore.get_rotation_sine with rotation_params
                Let radius be LinAlgCore.get_rotation_radius with rotation_params
                
                Note: Apply Givens rotation to working matrix (rows i-1 and i)
                Let k be j
                While k is less than n:
                    Let a_i_minus_1_k be LinAlgCore.get_matrix_element with working_matrix and (i minus 1) and k
                    Let a_i_k be LinAlgCore.get_matrix_element with working_matrix and i and k
                    
                    Let new_a_i_minus_1_k be LinAlgCore.add with 
                        LinAlgCore.multiply with cosine and a_i_minus_1_k
                        LinAlgCore.multiply with sine and a_i_k
                    
                    Let new_a_i_k be LinAlgCore.subtract with
                        LinAlgCore.multiply with cosine and a_i_k
                        LinAlgCore.multiply with sine and a_i_minus_1_k
                    
                    Let working_matrix be LinAlgCore.set_matrix_element with working_matrix and (i minus 1) and k and new_a_i_minus_1_k
                    Let working_matrix be LinAlgCore.set_matrix_element with working_matrix and i and k and new_a_i_k
                    Let k be k plus 1
                
                Note: Apply Givens rotation to orthogonal matrix Q is equal to Q multiplied by G^T
                Let k be 0
                While k is less than m:
                    Let q_k_i_minus_1 be LinAlgCore.get_matrix_element with orthogonal_matrix and k and (i minus 1)
                    Let q_k_i be LinAlgCore.get_matrix_element with orthogonal_matrix and k and i
                    
                    Let new_q_k_i_minus_1 be LinAlgCore.add with
                        LinAlgCore.multiply with cosine and q_k_i_minus_1
                        LinAlgCore.multiply with sine and q_k_i
                    
                    Let new_q_k_i be LinAlgCore.subtract with
                        LinAlgCore.multiply with cosine and q_k_i
                        LinAlgCore.multiply with sine and q_k_i_minus_1
                    
                    Let orthogonal_matrix be LinAlgCore.set_matrix_element with orthogonal_matrix and k and (i minus 1) and new_q_k_i_minus_1
                    Let orthogonal_matrix be LinAlgCore.set_matrix_element with orthogonal_matrix and k and i and new_q_k_i
                    Let k be k plus 1
                
                Let rotation_count be rotation_count plus 1
            
            Let i be i minus 1
        Let j be j plus 1
    
    Note: Extract R matrix (upper triangular part)
    Let upper_triangular be LinAlgCore.create_matrix with m and n
    Let i be 0
    While i is less than m:
        Let j be 0
        While j is less than n:
            If i is less than or equal to j:
                Let element be LinAlgCore.get_matrix_element with working_matrix and i and j
                Let upper_triangular be LinAlgCore.set_matrix_element with upper_triangular and i and j and element
            Otherwise:
                Let upper_triangular be LinAlgCore.set_matrix_element with upper_triangular and i and j and 0.0
            Let j be j plus 1
        Let i be i plus 1
    
    Note: Verify orthogonality of Q matrix
    Let q_transpose be LinAlgCore.matrix_transpose with orthogonal_matrix
    Let qtq_matrix be LinAlgCore.multiply_matrices with q_transpose and orthogonal_matrix
    Let identity_matrix be LinAlgCore.create_identity_matrix with m
    Let orthogonality_error be LinAlgCore.matrix_frobenius_norm with LinAlgCore.subtract_matrices with qtq_matrix and identity_matrix
    
    If LinAlgCore.is_greater_than with orthogonality_error and 1e-10:
        Throw Errors.NumericalError with "Givens QR orthogonality verification failed"
    
    Note: Verify QR reconstruction
    let qr_reconstruction be LinAlgCore.multiply_matrices with orthogonal_matrix and upper_triangular
    Let reconstruction_error be LinAlgCore.matrix_frobenius_norm with LinAlgCore.subtract_matrices with matrix and qr_reconstruction
    
    If LinAlgCore.is_greater_than with reconstruction_error and 1e-10:
        Throw Errors.NumericalError with "Givens QR reconstruction verification failed"
    
    Note: Create empty lists for Householder-style storage (not applicable for Givens)
    Let householder_vectors be LinAlgCore.create_list with
    Let tau_coefficients be LinAlgCore.create_list with
    
    Note: Store rotation count as string in tau coefficients for information
    Let rotation_count_str be LinAlgCore.integer_to_string with rotation_count
    Let tau_coefficients be LinAlgCore.append_to_list with tau_coefficients and rotation_count_str
    
    Note: Construct and return QR decomposition result
    Let decomposition_result be QRDecomposition with:
        orthogonal_matrix is equal to orthogonal_matrix
        upper_triangular is equal to upper_triangular
        householder_vectors is equal to householder_vectors
        tau_coefficients is equal to tau_coefficients
        algorithm_used is equal to "givens_rotations"
    
    Return decomposition_result

Process called "modified_gram_schmidt_qr" that takes matrix as Matrix returns QRDecomposition:
    Note: QR decomposition using modified Gram-Schmidt process
    Note: More numerically stable than classical Gram-Schmidt
    
    Let m be LinAlgCore.get_matrix_rows with matrix
    Let n be LinAlgCore.get_matrix_cols with matrix
    
    If m is less than n:
        Throw Errors.InvalidMatrix with "Modified Gram-Schmidt QR requires m is greater than or equal to n (tall or square matrix)"
    
    Note: Initialize Q and R matrices
    Let q_matrix be LinAlgCore.copy_matrix with matrix
    Let r_matrix be LinAlgCore.create_matrix with n and n
    
    Note: Modified Gram-Schmidt orthogonalization
    Let j be 0
    While j is less than n:
        Note: Extract column j
        Let column_j be LinAlgCore.create_vector with m
        Let i be 0
        While i is less than m:
            Let element be LinAlgCore.get_matrix_element with q_matrix and i and j
            Let column_j be LinAlgCore.set_vector_element with column_j and i and element
            Let i be i plus 1
        
        Note: Compute R[j,j] is equal to ||q[:,j]||
        Let column_norm be LinAlgCore.vector_norm with column_j
        
        If LinAlgCore.is_approximately_zero with column_norm and 1e-14:
            Throw Errors.SingularMatrix with "Matrix is rank deficient minus column has zero norm"
        
        Let r_matrix be LinAlgCore.set_matrix_element with r_matrix and j and j and column_norm
        
        Note: Normalize column j: q[:,j] is equal to q[:,j] / R[j,j]
        Let i be 0
        While i is less than m:
            Let element be LinAlgCore.get_matrix_element with q_matrix and i and j
            Let normalized_element be LinAlgCore.divide with element and column_norm
            Let q_matrix be LinAlgCore.set_matrix_element with q_matrix and i and j and normalized_element
            Let i be i plus 1
        
        Note: Orthogonalize remaining columns against column j
        Let k be j plus 1
        While k is less than n:
            Note: Compute R[j,k] is equal to q[:,j]^T multiplied by q[:,k]
            Let dot_product be 0.0
            Let i be 0
            While i is less than m:
                Let q_ij be LinAlgCore.get_matrix_element with q_matrix and i and j
                Let q_ik be LinAlgCore.get_matrix_element with q_matrix and i and k
                Let dot_product be LinAlgCore.add with dot_product and LinAlgCore.multiply with q_ij and q_ik
                Let i be i plus 1
            
            Let r_matrix be LinAlgCore.set_matrix_element with r_matrix and j and k and dot_product
            
            Note: Update column k: q[:,k] is equal to q[:,k] minus R[j,k] multiplied by q[:,j]
            Let i be 0
            While i is less than m:
                Let q_ij be LinAlgCore.get_matrix_element with q_matrix and i and j
                Let q_ik be LinAlgCore.get_matrix_element with q_matrix and i and k
                Let update_value be LinAlgCore.multiply with dot_product and q_ij
                Let new_element be LinAlgCore.subtract with q_ik and update_value
                Let q_matrix be LinAlgCore.set_matrix_element with q_matrix and i and k and new_element
                Let i be i plus 1
            
            Let k be k plus 1
        
        Let j be j plus 1
    
    Note: Create full Q matrix for overdetermined case (m is greater than n)
    Let full_q_matrix be LinAlgCore.create_matrix with m and m
    
    Note: Copy computed Q columns
    Let i be 0
    While i is less than m:
        Let j be 0
        While j is less than n:
            Let element be LinAlgCore.get_matrix_element with q_matrix and i and j
            Let full_q_matrix be LinAlgCore.set_matrix_element with full_q_matrix and i and j and element
            Let j be j plus 1
        Let i be i plus 1
    
    Note: Complete Q to orthogonal matrix if m is greater than n using QR of random matrix
    If m is greater than n:
        Let remaining_cols be m minus n
        Let random_matrix be LinAlgCore.create_random_matrix with m and remaining_cols
        
        Note: Orthogonalize random columns against existing Q columns
        Let k be n
        While k is less than m:
            Note: Generate random column
            Let random_column be LinAlgCore.create_random_vector with m
            
            Note: Orthogonalize against all previous columns
            Let j be 0
            While j is less than k:
                Let q_column_j be LinAlgCore.create_vector with m
                Let i be 0
                While i is less than m:
                    Let element be LinAlgCore.get_matrix_element with full_q_matrix and i and j
                    Let q_column_j be LinAlgCore.set_vector_element with q_column_j and i and element
                    Let i be i plus 1
                
                Let dot_product be LinAlgCore.vector_dot_product with q_column_j and random_column
                
                Let i be 0
                While i is less than m:
                    Let q_element be LinAlgCore.get_vector_element with q_column_j and i
                    Let r_element be LinAlgCore.get_vector_element with random_column and i
                    Let new_element be LinAlgCore.subtract with r_element and LinAlgCore.multiply with dot_product and q_element
                    Let random_column be LinAlgCore.set_vector_element with random_column and i and new_element
                    Let i be i plus 1
                
                Let j be j plus 1
            
            Note: Normalize the orthogonalized column
            Let column_norm be LinAlgCore.vector_norm with random_column
            If LinAlgCore.is_greater_than with column_norm and 1e-14:
                Let i be 0
                While i is less than m:
                    Let element be LinAlgCore.get_vector_element with random_column and i
                    Let normalized_element be LinAlgCore.divide with element and column_norm
                    Let full_q_matrix be LinAlgCore.set_matrix_element with full_q_matrix and i and k and normalized_element
                    Let i be i plus 1
            
            Let k be k plus 1
    
    Note: Extend R matrix to full size for completeness
    Let full_r_matrix be LinAlgCore.create_matrix with m and n
    Let i be 0
    While i is less than n:
        Let j be 0
        While j is less than n:
            Let element be LinAlgCore.get_matrix_element with r_matrix and i and j
            Let full_r_matrix be LinAlgCore.set_matrix_element with full_r_matrix and i and j and element
            Let j be j plus 1
        Let i be i plus 1
    
    Note: Verify orthogonality of Q matrix
    Let q_transpose be LinAlgCore.matrix_transpose with full_q_matrix
    Let qtq_matrix be LinAlgCore.multiply_matrices with q_transpose and full_q_matrix
    Let identity_matrix be LinAlgCore.create_identity_matrix with m
    Let orthogonality_error be LinAlgCore.matrix_frobenius_norm with LinAlgCore.subtract_matrices with qtq_matrix and identity_matrix
    
    If LinAlgCore.is_greater_than with orthogonality_error and 1e-10:
        Throw Errors.NumericalError with "Modified Gram-Schmidt orthogonality verification failed"
    
    Note: Verify QR reconstruction
    Let qr_reconstruction be LinAlgCore.multiply_matrices with full_q_matrix and full_r_matrix
    Let reconstruction_error be LinAlgCore.matrix_frobenius_norm with LinAlgCore.subtract_matrices with matrix and qr_reconstruction
    
    If LinAlgCore.is_greater_than with reconstruction_error and 1e-10:
        Throw Errors.NumericalError with "Modified Gram-Schmidt reconstruction verification failed"
    
    Note: Create empty lists for Householder-style storage (not applicable for Gram-Schmidt)
    Let householder_vectors be LinAlgCore.create_list with
    Let tau_coefficients be LinAlgCore.create_list with
    
    Note: Store orthogonalization count in tau coefficients for information
    Let orthogonalization_count be LinAlgCore.multiply with n and LinAlgCore.subtract with n and 1
    Let orthogonalization_count be LinAlgCore.divide with orthogonalization_count and 2
    Let count_str be LinAlgCore.integer_to_string with orthogonalization_count
    Let tau_coefficients be LinAlgCore.append_to_list with tau_coefficients and count_str
    
    Note: Construct and return QR decomposition result
    Let decomposition_result be QRDecomposition with:
        orthogonal_matrix is equal to full_q_matrix
        upper_triangular is equal to full_r_matrix
        householder_vectors is equal to householder_vectors
        tau_coefficients is equal to tau_coefficients
        algorithm_used is equal to "modified_gram_schmidt"
    
    Return decomposition_result

Process called "column_pivoting_qr" that takes matrix as Matrix returns QRDecomposition:
    Note: QR decomposition with column pivoting for rank-deficient matrices
    Note: Computes A*P is equal to Q*R where P is permutation matrix for numerical stability
    
    Let rows be LinAlgCore.get_matrix_rows with matrix
    Let cols be LinAlgCore.get_matrix_cols with matrix
    
    Note: Start with standard QR decomposition
    Let qr_result be householder_qr(matrix)
    
    Note: Create column permutation matrix using column pivoting strategy
    Let permutation_indices be LinAlgCore.create_vector with cols
    Let i be 0
    While i is less than cols:
        Set permutation_indices to LinAlgCore.set_vector_element with permutation_indices and i and i
        Set i to i plus 1
    
    Note: Compute column norms for pivoting strategy
    Let column_norms be LinAlgCore.create_vector with cols
    Let j be 0
    While j is less than cols:
        Let col_vector be LinAlgCore.extract_column with matrix and j
        Let norm be LinAlgCore.vector_l2_norm with col_vector
        Set column_norms to LinAlgCore.set_vector_element with column_norms and j and norm
        Set j to j plus 1
    
    Note: Apply column pivoting using maximum norm strategy
    Let k be 0
    While k is less than cols:
        Note: Find column with maximum remaining norm
        Let max_norm be "0"
        Let max_col_idx be k
        Let j be k
        While j is less than cols:
            Let current_norm be LinAlgCore.get_vector_element with column_norms and j
            If LinAlgCore.compare_numbers with current_norm and max_norm is "greater":
                Set max_norm to current_norm
                Set max_col_idx to j
            Set j to j plus 1
        
        Note: Swap columns k and max_col_idx if needed
        If max_col_idx does not equal k:
            Note: Update permutation indices
            Let temp_idx be LinAlgCore.get_vector_element with permutation_indices and k
            Let max_idx_value be LinAlgCore.get_vector_element with permutation_indices and max_col_idx
            Set permutation_indices to LinAlgCore.set_vector_element with permutation_indices and k and max_idx_value
            Set permutation_indices to LinAlgCore.set_vector_element with permutation_indices and max_col_idx and temp_idx
            
            Note: Swap column norms
            Let temp_norm be LinAlgCore.get_vector_element with column_norms and k
            Set column_norms to LinAlgCore.set_vector_element with column_norms and k and max_norm
            Set column_norms to LinAlgCore.set_vector_element with column_norms and max_col_idx and temp_norm
        
        Set k to k plus 1
    
    Note: Build permutation matrix from indices
    Let permutation_matrix be LinAlgCore.create_zero_matrix with cols and cols
    Set i to 0
    While i is less than cols:
        Let perm_col be LinAlgCore.get_vector_element with permutation_indices and i
        Set permutation_matrix to LinAlgCore.set_matrix_element with permutation_matrix and perm_col and i and "1.0"
        Set i to i plus 1
    Let pivoted_matrix be matrix
    Let current_col be 0
    While current_col is less than cols minus 1:
        Note: Find column with largest norm
        Let max_norm_col be current_col
        Let max_norm be LinAlgCore.get_vector_element with column_norms and current_col
        
        Let search_col be current_col plus 1
        While search_col is less than cols:
            Let search_norm be LinAlgCore.get_vector_element with column_norms and search_col
            If LinAlgCore.is_greater_than with search_norm and max_norm:
                Set max_norm_col to search_col
                Set max_norm to search_norm
            Set search_col to search_col plus 1
        
        Note: Swap columns if needed
        If max_norm_col does not equal current_col:
            Set pivoted_matrix to LinAlgCore.swap_matrix_columns with pivoted_matrix and current_col and max_norm_col
            Set permutation_matrix to LinAlgCore.swap_matrix_columns with permutation_matrix and current_col and max_norm_col
        
        Set current_col to current_col plus 1
    
    Note: Perform QR on pivoted matrix
    Let final_qr be householder_qr(pivoted_matrix)
    
    Return QRDecomposition with orthogonal_matrix: final_qr.orthogonal_matrix, upper_triangular: final_qr.upper_triangular, permutation_matrix: permutation_matrix, is_full_rank: final_qr.is_full_rank

Process called "solve_with_qr" that takes qr_result as QRDecomposition, right_hand_side as Vector returns Vector:
    Note: Solve linear system using precomputed QR decomposition
    Note: Solves A*x is equal to b where A is equal to Q*R using Q^T*b then R*x is equal to Q^T*b
    
    Let q_matrix be qr_result.orthogonal_matrix
    Let r_matrix be qr_result.upper_triangular
    
    Let m be LinAlgCore.get_matrix_rows with q_matrix
    Let n be LinAlgCore.get_matrix_cols with r_matrix
    Let rhs_size be LinAlgCore.get_vector_size with right_hand_side
    
    If m does not equal rhs_size:
        Throw Errors.DimensionMismatch with "QR decomposition dimension does not match RHS vector size"
    
    Note: Step 1: Compute Q^T multiplied by b
    Let q_transpose be LinAlgCore.matrix_transpose with q_matrix
    Let qtb_vector be LinAlgCore.multiply_matrix_vector with q_transpose and right_hand_side
    
    Note: Step 2: Extract the first n components (since R is n×n)
    Let truncated_qtb be LinAlgCore.create_vector with n
    Let i be 0
    While i is less than n:
        Let element be LinAlgCore.get_vector_element with qtb_vector and i
        Let truncated_qtb be LinAlgCore.set_vector_element with truncated_qtb and i and element
        Let i be i plus 1
    
    Note: Step 3: Solve R*x is equal to truncated_Q^T*b using backward substitution
    Let solution_vector be LinAlgCore.create_vector with n
    Let i be n minus 1
    While i is greater than or equal to 0:
        Let sum be 0.0
        Let j be i plus 1
        While j is less than n:
            Let r_element be LinAlgCore.get_matrix_element with r_matrix and i and j
            Let x_element be LinAlgCore.get_vector_element with solution_vector and j
            Let sum be LinAlgCore.add with sum and LinAlgCore.multiply with r_element and x_element
            Let j be j plus 1
        
        Let qtb_element be LinAlgCore.get_vector_element with truncated_qtb and i
        Let r_diagonal be LinAlgCore.get_matrix_element with r_matrix and i and i
        
        If LinAlgCore.is_approximately_zero with r_diagonal and 1e-14:
            Throw Errors.SingularMatrix with "Singular R matrix in QR solve"
        
        Let x_value be LinAlgCore.divide with LinAlgCore.subtract with qtb_element and sum and r_diagonal
        Let solution_vector be LinAlgCore.set_vector_element with solution_vector and i and x_value
        Let i be i minus 1
    
    Note: Verify the solution by computing residual ||A*x minus b||
    If m is equal to n:
        Note: For square systems, verify exact solution
        Let reconstruction be LinAlgCore.multiply_matrices with q_matrix and r_matrix
        Let ax_vector be LinAlgCore.multiply_matrix_vector with reconstruction and solution_vector
        Let residual_vector be LinAlgCore.subtract_vectors with right_hand_side and ax_vector
        Let residual_norm be LinAlgCore.vector_norm with residual_vector
        
        If LinAlgCore.is_greater_than with residual_norm and 1e-10:
            Throw Errors.NumericalError with "QR solve verification failed minus large residual detected"
    Otherwise:
        Note: For overdetermined systems, check if solution minimizes ||A*x minus b||
        Let qr_reconstruction be LinAlgCore.multiply_matrices with q_matrix and r_matrix
        
        Note: Extract the n×n part for square solve verification
        Let square_r be LinAlgCore.create_matrix with n and n
        Let i be 0
        While i is less than n:
            Let j be 0
            While j is less than n:
                Let element be LinAlgCore.get_matrix_element with r_matrix and i and j
                Let square_r be LinAlgCore.set_matrix_element with square_r and i and j and element
                Let j be j plus 1
            Let i be i plus 1
        
        Let square_q be LinAlgCore.create_matrix with n and n
        Let i be 0
        While i is less than n:
            Let j be 0
            While j is less than n:
                Let element be LinAlgCore.get_matrix_element with q_matrix and i and j
                Let square_q be LinAlgCore.set_matrix_element with square_q and i and j and element
                Let j be j plus 1
            Let i be i plus 1
        
        Let square_reconstruction be LinAlgCore.multiply_matrices with square_q and square_r
        Let truncated_rhs be LinAlgCore.create_vector with n
        Let i be 0
        While i is less than n:
            Let element be LinAlgCore.get_vector_element with right_hand_side and i
            Let truncated_rhs be LinAlgCore.set_vector_element with truncated_rhs and i and element
            Let i be i plus 1
        
        Let verification_vector be LinAlgCore.multiply_matrix_vector with square_reconstruction and solution_vector
        Let verification_residual be LinAlgCore.subtract_vectors with truncated_rhs and verification_vector
        Let verification_norm be LinAlgCore.vector_norm with verification_residual
        
        If LinAlgCore.is_greater_than with verification_norm and 1e-10:
            Throw Errors.NumericalError with "QR solve verification failed for overdetermined system"
    
    Return solution_vector

Note: =====================================================================
Note: SINGULAR VALUE DECOMPOSITION OPERATIONS
Note: =====================================================================

Process called "singular_value_decomposition" that takes matrix as Matrix, algorithm as String returns SVDResult:
    Note: Compute SVD using specified algorithm
    Note: Factorizes matrix A is equal to U*Σ*V^T where U,V orthogonal, Σ diagonal
    
    If algorithm is equal to "jacobi":
        Return jacobi_svd(matrix, 1e-10)
    Otherwise if algorithm is equal to "divide_conquer":
        Return divide_conquer_svd(matrix)
    Otherwise if algorithm is equal to "randomized":
        Return randomized_svd(matrix, 0)
    Otherwise if algorithm is equal to "truncated":
        Return truncated_svd(matrix, 10)
    Otherwise:
        Note: Default to power iteration method for stability
        Return power_iteration_svd(matrix, 1e-10)

Process called "jacobi_svd" that takes matrix as Matrix, tolerance as Float returns SVDResult:
    Note: SVD using Jacobi eigenvalue algorithm
    Note: Iterative method using Jacobi rotations to diagonalize A^T*A
    
    Let rows be LinAlgCore.get_matrix_rows with matrix
    Let cols be LinAlgCore.get_matrix_cols with matrix
    Let min_dim be rows
    If cols is less than min_dim:
        Set min_dim to cols
    
    Note: Form A^T*A for eigenvalue decomposition
    Let transpose_a be LinAlgCore.transpose_matrix with matrix
    Let ata_matrix be LinAlgCore.multiply_matrices with transpose_a and matrix
    
    Note: Use Jacobi eigenvalue algorithm on A^T*A
    Let eigendecomp be jacobi_eigenvalues(ata_matrix, tolerance)
    
    Note: Extract singular values as sqrt of eigenvalues
    Let singular_values be LinAlgCore.create_vector with min_dim
    Let i be 0
    While i is less than min_dim:
        Let eigenvalue be LinAlgCore.get_vector_element with eigendecomp.eigenvalues and i
        Let singular_value be LinAlgCore.sqrt with eigenvalue
        Set singular_values to LinAlgCore.set_vector_element with singular_values and i and singular_value
        Set i to i plus 1
    
    Note: Compute U is equal to A*V*Σ^(-1)
    Let u_matrix be LinAlgCore.multiply_matrices with matrix and eigendecomp.eigenvectors
    Let normalized_u be LinAlgCore.normalize_matrix_columns with u_matrix
    
    Return SVDResult with left_singular_vectors: normalized_u, singular_values: singular_values, right_singular_vectors: eigendecomp.eigenvectors, rank: min_dim, condition_number: 1.0

Process called "bidiagonal_svd" that takes matrix as Matrix returns SVDResult:
    Note: SVD via bidiagonalization and iterative algorithm
    Note: Implements A is equal to U multiplied by Σ multiplied by V^T using Golub-Reinsch algorithm
    
    Let m be LinAlgCore.get_matrix_rows with matrix
    Let n be LinAlgCore.get_matrix_cols with matrix
    Let min_dim be LinAlgCore.minimum with m and n
    
    Note: Step 1: Reduce to bidiagonal form
    Let bidiag_data be bidiagonal_reduction with matrix
    Let bidiagonal_matrix be LinAlgCore.get_dictionary_matrix with bidiag_data and "bidiagonal_matrix"
    Let left_householder be LinAlgCore.get_dictionary_matrix with bidiag_data and "left_orthogonal"
    Let right_householder be LinAlgCore.get_dictionary_matrix with bidiag_data and "right_orthogonal"
    
    Note: Extract bidiagonal elements
    Let diagonal_elements be LinAlgCore.create_vector with min_dim
    Let superdiagonal_elements be LinAlgCore.create_vector with min_dim minus 1
    
    Let i be 0
    While i is less than min_dim:
        Let diagonal_value be LinAlgCore.get_matrix_element with bidiagonal_matrix and i and i
        Let diagonal_elements be LinAlgCore.set_vector_element with diagonal_elements and i and diagonal_value
        
        If i is less than min_dim minus 1:
            Let superdiag_value be LinAlgCore.get_matrix_element with bidiagonal_matrix and i and (i plus 1)
            Let superdiagonal_elements be LinAlgCore.set_vector_element with superdiagonal_elements and i and superdiag_value
        
        Let i be i plus 1
    
    Note: Step 2: Apply implicit shift QR algorithm to bidiagonal matrix
    Let max_iterations be 100
    Let convergence_tolerance be 1e-15
    Let iteration be 0
    Let has_converged be False
    
    Let left_rotations be LinAlgCore.create_identity_matrix with min_dim
    Let right_rotations be LinAlgCore.create_identity_matrix with min_dim
    
    While iteration is less than max_iterations and not has_converged:
        Note: Check for convergence minus small superdiagonal elements
        Let max_superdiag be 0.0
        Let i be 0
        While i is less than min_dim minus 1:
            Let superdiag_element be LinAlgCore.absolute_value with LinAlgCore.get_vector_element with superdiagonal_elements and i
            If LinAlgCore.is_greater_than with superdiag_element and max_superdiag:
                Let max_superdiag be superdiag_element
            Let i be i plus 1
        
        If LinAlgCore.is_less_than with max_superdiag and convergence_tolerance:
            Let has_converged be True
        Otherwise:
            Note: Apply implicit shift strategy
            Let n_active be min_dim
            
            Note: Find active subproblem by deflating small superdiagonal elements
            Let i be min_dim minus 2
            While i is greater than or equal to 0:
                Let superdiag_val be LinAlgCore.absolute_value with LinAlgCore.get_vector_element with superdiagonal_elements and i
                If LinAlgCore.is_less_than with superdiag_val and convergence_tolerance:
                    Let n_active be i plus 1
                    Break
                Let i be i minus 1
            
            If n_active is greater than 1:
                Note: Apply one step of implicit shift QR to active part
                Let last_diag be LinAlgCore.get_vector_element with diagonal_elements and (n_active minus 1)
                Let last_superdiag be LinAlgCore.get_vector_element with superdiagonal_elements and (n_active minus 2)
                
                Note: Compute Wilkinson shift
                Let shift be LinAlgCore.compute_wilkinson_shift with last_diag and last_superdiag
                
                Note: Apply Givens rotations to chase bulge
                Let i be 0
                While i is less than n_active minus 1:
                    Note: Compute Givens rotation parameters
                    Let diag_shifted be LinAlgCore.subtract with LinAlgCore.get_vector_element with diagonal_elements and i and shift
                    Let superdiag be LinAlgCore.get_vector_element with superdiagonal_elements and i
                    
                    Let rotation_params be LinAlgCore.compute_givens_rotation with diag_shifted and superdiag
                    Let cosine be LinAlgCore.get_givens_cosine with rotation_params
                    Let sine be LinAlgCore.get_givens_sine with rotation_params
                    
                    Note: Apply rotation to bidiagonal elements
                    Let new_diag be LinAlgCore.add with LinAlgCore.multiply with cosine and diag_shifted and LinAlgCore.multiply with sine and superdiag
                    Let diagonal_elements be LinAlgCore.set_vector_element with diagonal_elements and i and LinAlgCore.add with new_diag and shift
                    
                    If i is less than n_active minus 2:
                        Let next_superdiag be LinAlgCore.get_vector_element with superdiagonal_elements and (i plus 1)
                        Let new_superdiag be LinAlgCore.subtract with LinAlgCore.multiply with cosine and next_superdiag and LinAlgCore.multiply with sine and 0.0
                        Let superdiagonal_elements be LinAlgCore.set_vector_element with superdiagonal_elements and (i plus 1) and new_superdiag
                    
                    Note: Update rotation matrices
                    Let left_rotations be LinAlgCore.apply_givens_left with left_rotations and i and (i plus 1) and cosine and sine
                    
                    Let i be i plus 1
        
        Let iteration be iteration plus 1
    
    Note: Step 3: Ensure all singular values are positive
    Let singular_values be LinAlgCore.create_list with
    Let i be 0
    While i is less than min_dim:
        Let diagonal_value be LinAlgCore.get_vector_element with diagonal_elements and i
        If LinAlgCore.is_less_than with diagonal_value and 0.0:
            Let diagonal_value be LinAlgCore.negate with diagonal_value
            Note: Negate corresponding column in left matrix
            Let j be 0
            While j is less than m:
                Let element be LinAlgCore.get_matrix_element with left_rotations and j and i
                Let left_rotations be LinAlgCore.set_matrix_element with left_rotations and j and i and LinAlgCore.negate with element
                Let j be j plus 1
        
        Let singular_value_str be LinAlgCore.float_to_string with diagonal_value
        Let singular_values be LinAlgCore.append_to_list with singular_values and singular_value_str
        Let i be i plus 1
    
    Note: Step 4: Construct final U and V matrices
    Let u_matrix be LinAlgCore.multiply_matrices with left_householder and left_rotations
    Let v_matrix be LinAlgCore.multiply_matrices with right_householder and right_rotations
    
    Note: Sort singular values in descending order
    Let sorted_indices be LinAlgCore.sort_indices_descending with singular_values
    Let sorted_singular_values be LinAlgCore.reorder_list with singular_values and sorted_indices
    Let sorted_u_matrix be LinAlgCore.reorder_matrix_columns with u_matrix and sorted_indices
    Let sorted_v_matrix be LinAlgCore.reorder_matrix_columns with v_matrix and sorted_indices
    
    Note: Compute condition number and numerical rank
    Let max_singular_value be LinAlgCore.string_to_float with LinAlgCore.get_list_element with sorted_singular_values and 0
    Let min_singular_value be LinAlgCore.string_to_float with LinAlgCore.get_list_element with sorted_singular_values and (min_dim minus 1)
    
    Let condition_number be LinAlgCore.float_to_string with LinAlgCore.divide with max_singular_value and min_singular_value
    
    Let numerical_rank be 0
    Let rank_tolerance be LinAlgCore.multiply with max_singular_value and 1e-14
    Let i be 0
    While i is less than min_dim:
        Let singular_value be LinAlgCore.string_to_float with LinAlgCore.get_list_element with sorted_singular_values and i
        If LinAlgCore.is_greater_than with singular_value and rank_tolerance:
            Let numerical_rank be numerical_rank plus 1
        Let i be i plus 1
    
    Note: Construct and return SVD result
    Let svd_result be SVDResult with:
        left_singular_vectors is equal to sorted_u_matrix
        singular_values is equal to sorted_singular_values
        right_singular_vectors is equal to sorted_v_matrix
        rank is equal to numerical_rank
        condition_number is equal to condition_number
        numerical_tolerance is equal to 1e-15
    
    Return svd_result

Process called "divide_and_conquer_svd" that takes matrix as Matrix returns SVDResult:
    Note: SVD using divide-and-conquer algorithm
    Note: Recursive algorithm that divides matrix into smaller subproblems
    
    Let rows be LinAlgCore.get_matrix_rows with matrix
    Let cols be LinAlgCore.get_matrix_cols with matrix
    
    Note: Base case minus use direct method for small matrices
    If rows is less than or equal to 32 or cols is less than or equal to 32:
        Return jacobi_svd(matrix, 1e-10)
    
    Note: Divide matrix into top and bottom halves
    Let mid_row be rows / 2
    Let top_half be LinAlgCore.extract_submatrix with matrix and 0 and 0 and mid_row and cols
    Let bottom_half be LinAlgCore.extract_submatrix with matrix and mid_row and 0 and (rows minus mid_row) and cols
    
    Note: Recursively compute SVD of each half
    Let top_svd be divide_conquer_svd(top_half)
    Let bottom_svd be divide_conquer_svd(bottom_half)
    
    Note: Combine results (simplified merging)
    Let combined_u be LinAlgCore.vertically_concatenate_matrices with top_svd.left_singular_vectors and bottom_svd.left_singular_vectors
    
    Note: Merge singular values by taking average
    Let top_values be top_svd.singular_values
    Let bottom_values be bottom_svd.singular_values
    Let min_values be LinAlgCore.get_vector_size with top_values
    Let bottom_size be LinAlgCore.get_vector_size with bottom_values
    If bottom_size is less than min_values:
        Set min_values to bottom_size
    
    Let merged_values be LinAlgCore.create_vector with min_values
    Let i be 0
    While i is less than min_values:
        Let top_val be LinAlgCore.get_vector_element with top_values and i
        Let bottom_val be LinAlgCore.get_vector_element with bottom_values and i
        Let avg_val be LinAlgCore.divide with LinAlgCore.add with top_val and bottom_val and 2.0
        Set merged_values to LinAlgCore.set_vector_element with merged_values and i and avg_val
        Set i to i plus 1
    
    Return SVDResult with left_singular_vectors: combined_u, singular_values: merged_values, right_singular_vectors: top_svd.right_singular_vectors, rank: min_values, condition_number: 1.0

Process called "randomized_svd" that takes matrix as Matrix, target_rank as Integer, oversampling as Integer returns SVDResult:
    Note: Randomized SVD for large matrices with low-rank approximation
    Note: Uses random projection to reduce computational complexity
    
    Let rows be LinAlgCore.get_matrix_rows with matrix
    Let cols be LinAlgCore.get_matrix_cols with matrix
    
    Note: Determine effective rank
    Let effective_rank be target_rank
    If effective_rank is less than or equal to 0:
        Set effective_rank to LinAlgCore.min with rows and cols / 4
    
    Let oversampling_param be oversampling
    If oversampling_param is less than or equal to 0:
        Set oversampling_param to 10
    
    Let total_rank be effective_rank plus oversampling_param
    If total_rank is greater than cols:
        Set total_rank to cols
    
    Note: Generate random matrix for projection
    Let random_matrix be LinAlgCore.create_random_matrix with cols and total_rank
    
    Note: Compute range matrix Y is equal to A multiplied by Omega
    Let range_matrix be LinAlgCore.multiply_matrices with matrix and random_matrix
    
    Note: Orthogonalize range matrix using QR
    Let range_qr be householder_qr(range_matrix)
    Let q_matrix be range_qr.orthogonal_matrix
    
    Note: Project original matrix onto range: B is equal to Q^T multiplied by A
    Let q_transpose be LinAlgCore.transpose_matrix with q_matrix
    Let projected_matrix be LinAlgCore.multiply_matrices with q_transpose and matrix
    
    Note: Compute SVD of smaller projected matrix
    Let projected_svd be jacobi_svd(projected_matrix, 1e-10)
    
    Note: Reconstruct U is equal to Q multiplied by U_tilde
    Let final_u be LinAlgCore.multiply_matrices with q_matrix and projected_svd.left_singular_vectors
    
    Note: Truncate to target rank
    Let truncated_u be LinAlgCore.extract_submatrix with final_u and 0 and 0 and rows and effective_rank
    Let truncated_values be LinAlgCore.extract_subvector with projected_svd.singular_values and 0 and effective_rank
    Let truncated_v be LinAlgCore.extract_submatrix with projected_svd.right_singular_vectors and 0 and 0 and cols and effective_rank
    
    Return SVDResult with left_singular_vectors: truncated_u, singular_values: truncated_values, right_singular_vectors: truncated_v, rank: effective_rank, condition_number: 1.0

Process called "truncated_svd" that takes matrix as Matrix, num_components as Integer returns SVDResult:
    Note: Compute truncated SVD for dimensionality reduction
    Note: Computes only the largest num_components singular values and vectors
    
    Let rows be LinAlgCore.get_matrix_rows with matrix
    Let cols be LinAlgCore.get_matrix_cols with matrix
    Let max_components be LinAlgCore.min with rows and cols
    
    Let target_components be num_components
    If target_components is less than or equal to 0 or target_components is greater than max_components:
        Set target_components to max_components
    
    Note: Use randomized SVD for efficiency on large matrices
    If rows is greater than 100 and cols is greater than 100:
        Return randomized_svd(matrix, target_components, 5)
    
    Note: For smaller matrices, use full SVD then truncate
    Let full_svd be jacobi_svd(matrix, 1e-10)
    
    Note: Extract top components
    Let truncated_u be LinAlgCore.extract_submatrix with full_svd.left_singular_vectors and 0 and 0 and rows and target_components
    Let truncated_s be LinAlgCore.extract_subvector with full_svd.singular_values and 0 and target_components
    Let truncated_v be LinAlgCore.extract_submatrix with full_svd.right_singular_vectors and 0 and 0 and cols and target_components
    
    Note: Compute explained variance ratio
    Let total_variance be LinAlgCore.vector_sum_of_squares with full_svd.singular_values
    Let truncated_variance be LinAlgCore.vector_sum_of_squares with truncated_s
    Let explained_ratio be LinAlgCore.divide with truncated_variance and total_variance
    
    Return SVDResult with left_singular_vectors: truncated_u, singular_values: truncated_s, right_singular_vectors: truncated_v, rank: target_components, condition_number: explained_ratio

Note: =====================================================================
Note: CHOLESKY DECOMPOSITION OPERATIONS
Note: =====================================================================

Process called "cholesky_decomposition" that takes matrix as Matrix returns CholeskyDecomposition:
    Note: Perform Cholesky decomposition for positive definite matrices
    Note: Implements A is equal to L*L^T where L is lower triangular
    
    Let rows be LinAlgCore.get_matrix_rows with matrix
    Let cols be LinAlgCore.get_matrix_cols with matrix
    
    If rows does not equal cols:
        Throw Errors.InvalidMatrix with "Cholesky decomposition requires square matrix"
    
    Let n be rows
    Let lower_triangular be LinAlgCore.create_matrix with n and n
    Let is_positive_definite be True
    Let rank_deficiency be 0
    
    Note: Main Cholesky decomposition algorithm
    Let i be 0
    While i is less than n:
        Note: Compute diagonal element L[i,i] is equal to sqrt(A[i,i] minus sum(L[i,k]^2 for k is less than i))
        Let diagonal_sum be 0.0
        Let k be 0
        While k is less than i:
            Let l_ik be LinAlgCore.get_matrix_element with lower_triangular and i and k
            Let diagonal_sum be LinAlgCore.add with diagonal_sum and LinAlgCore.multiply with l_ik and l_ik
            Let k be k plus 1
        
        Let a_ii be LinAlgCore.get_matrix_element with matrix and i and i
        Let diagonal_value be LinAlgCore.subtract with a_ii and diagonal_sum
        
        Note: Check for positive definiteness
        If LinAlgCore.is_less_than_or_equal with diagonal_value and 0.0:
            Let is_positive_definite be False
            If LinAlgCore.is_approximately_zero with diagonal_value and 1e-14:
                Let rank_deficiency be rank_deficiency plus 1
                Let lower_triangular be LinAlgCore.set_matrix_element with lower_triangular and i and i and 0.0
            Otherwise:
                Throw Errors.NotPositiveDefinite with "Matrix is not positive definite minus negative diagonal element encountered"
        Otherwise:
            Let l_ii be LinAlgCore.square_root with diagonal_value
            Let lower_triangular be LinAlgCore.set_matrix_element with lower_triangular and i and i and l_ii
        
        Note: Compute below-diagonal elements L[j,i] for j is greater than i
        Let j be i plus 1
        While j is less than n:
            If is_positive_definite:
                Note: L[j,i] is equal to (A[j,i] minus sum(L[j,k]*L[i,k] for k is less than i)) / L[i,i]
                Let off_diagonal_sum be 0.0
                Let k be 0
                While k is less than i:
                    Let l_jk be LinAlgCore.get_matrix_element with lower_triangular and j and k
                    Let l_ik be LinAlgCore.get_matrix_element with lower_triangular and i and k
                    Let product be LinAlgCore.multiply with l_jk and l_ik
                    Let off_diagonal_sum be LinAlgCore.add with off_diagonal_sum and product
                    Let k be k plus 1
                
                Let a_ji be LinAlgCore.get_matrix_element with matrix and j and i
                Let numerator be LinAlgCore.subtract with a_ji and off_diagonal_sum
                Let l_ii be LinAlgCore.get_matrix_element with lower_triangular and i and i
                
                If LinAlgCore.is_approximately_zero with l_ii and 1e-14:
                    Let lower_triangular be LinAlgCore.set_matrix_element with lower_triangular and j and i and 0.0
                Otherwise:
                    Let l_ji be LinAlgCore.divide with numerator and l_ii
                    Let lower_triangular be LinAlgCore.set_matrix_element with lower_triangular and j and i and l_ji
            Otherwise:
                Let lower_triangular be LinAlgCore.set_matrix_element with lower_triangular and j and i and 0.0
            
            Let j be j plus 1
        
        Let i be i plus 1
    
    Note: Verify symmetry of input matrix for additional validation
    Let symmetry_error be 0.0
    Let i be 0
    While i is less than n:
        Let j be i plus 1
        While j is less than n:
            Let a_ij be LinAlgCore.get_matrix_element with matrix and i and j
            Let a_ji be LinAlgCore.get_matrix_element with matrix and j and i
            Let difference be LinAlgCore.absolute_value with LinAlgCore.subtract with a_ij and a_ji
            If LinAlgCore.is_greater_than with difference and symmetry_error:
                Let symmetry_error be difference
            Let j be j plus 1
        Let i be i plus 1
    
    If LinAlgCore.is_greater_than with symmetry_error and 1e-12:
        Throw Errors.InvalidMatrix with "Input matrix is not symmetric within tolerance"
    
    Note: Verify Cholesky decomposition by computing L*L^T and comparing with original
    If is_positive_definite:
        Let verification_error be 0.0
        Let i be 0
        While i is less than n:
            Let j be 0
            While j is less than n:
                Note: Compute (L*L^T)[i,j] is equal to sum(L[i,k] multiplied by L[j,k] for k in range(min(i,j)+1))
                Let reconstructed_element be 0.0
                Let k be 0
                Let max_k be LinAlgCore.minimum with i and j
                While k is less than or equal to max_k:
                    Let l_ik be LinAlgCore.get_matrix_element with lower_triangular and i and k
                    Let l_jk be LinAlgCore.get_matrix_element with lower_triangular and j and k
                    Let product be LinAlgCore.multiply with l_ik and l_jk
                    Let reconstructed_element be LinAlgCore.add with reconstructed_element and product
                    Let k be k plus 1
                
                Let original_element be LinAlgCore.get_matrix_element with matrix and i and j
                Let error be LinAlgCore.absolute_value with LinAlgCore.subtract with original_element and reconstructed_element
                If LinAlgCore.is_greater_than with error and verification_error:
                    Let verification_error be error
                Let j be j plus 1
            Let i be i plus 1
        
        If LinAlgCore.is_greater_than with verification_error and 1e-10:
            Throw Errors.NumericalError with "Cholesky decomposition verification failed minus numerical instability detected"
    
    Note: Construct and return Cholesky decomposition result
    Let decomposition_result be CholeskyDecomposition with:
        lower_triangular is equal to lower_triangular
        is_positive_definite is equal to is_positive_definite
        pivot_used is equal to False
        rank_deficiency is equal to rank_deficiency
    
    Return decomposition_result

Process called "ldlt_decomposition" that takes matrix as Matrix returns Dictionary[String, Matrix]:
    Note: LDLT decomposition for symmetric matrices
    Note: Factorizes A is equal to L*D*L^T where L is unit lower triangular, D is diagonal
    
    Let n be LinAlgCore.get_matrix_rows with matrix
    If n does not equal LinAlgCore.get_matrix_cols with matrix:
        Throw Errors.InvalidArgument with "LDLT requires square matrix"
    
    Note: Initialize L as identity and D as zero
    Let l_matrix be LinAlgCore.create_identity_matrix with n
    Let d_matrix be LinAlgCore.create_matrix with n and n
    
    Note: LDLT decomposition algorithm
    Let i be 0
    While i is less than n:
        Note: Compute diagonal element D[i,i]
        Let sum be 0.0
        Let k be 0
        While k is less than i:
            Let l_ik be LinAlgCore.get_matrix_element with l_matrix and i and k
            Let d_kk be LinAlgCore.get_matrix_element with d_matrix and k and k
            Let sum be LinAlgCore.add with sum and LinAlgCore.multiply with LinAlgCore.multiply with l_ik and l_ik and d_kk
            Set k to k plus 1
        
        Let a_ii be LinAlgCore.get_matrix_element with matrix and i and i
        Let d_ii be LinAlgCore.subtract with a_ii and sum
        Set d_matrix to LinAlgCore.set_matrix_element with d_matrix and i and i and d_ii
        
        Note: Compute lower triangular elements L[j,i] for j is greater than i
        Let j be i plus 1
        While j is less than n:
            Let sum_j be 0.0
            Set k to 0
            While k is less than i:
                Let l_jk be LinAlgCore.get_matrix_element with l_matrix and j and k
                Let l_ik be LinAlgCore.get_matrix_element with l_matrix and i and k
                Let d_kk be LinAlgCore.get_matrix_element with d_matrix and k and k
                Let sum_j be LinAlgCore.add with sum_j and LinAlgCore.multiply with LinAlgCore.multiply with l_jk and l_ik and d_kk
                Set k to k plus 1
            
            Let a_ji be LinAlgCore.get_matrix_element with matrix and j and i
            If LinAlgCore.is_approximately_zero with d_ii and 1e-14:
                Throw Errors.SingularMatrix with "Zero diagonal element in LDLT decomposition"
            
            Let l_ji be LinAlgCore.divide with LinAlgCore.subtract with a_ji and sum_j and d_ii
            Set l_matrix to LinAlgCore.set_matrix_element with l_matrix and j and i and l_ji
            Set j to j plus 1
        
        Set i to i plus 1
    
    Note: Compute determinant as product of diagonal elements
    Let det be 1.0
    Set i to 0
    While i is less than n:
        Let d_ii be LinAlgCore.get_matrix_element with d_matrix and i and i
        Set det to LinAlgCore.multiply with det and d_ii
        Set i to i plus 1
    
    Return LDLTDecomposition with lower_matrix: l_matrix, diagonal_matrix: d_matrix, determinant: det, is_positive_definite: (det is greater than 0.0)

Process called "pivoted_cholesky" that takes matrix as Matrix, tolerance as Float returns CholeskyDecomposition:
    Note: Cholesky decomposition with pivoting for rank-deficient matrices
    Note: Computes P*A*P^T is equal to L*L^T where P is permutation matrix
    
    Let n be LinAlgCore.get_matrix_rows with matrix
    If n does not equal LinAlgCore.get_matrix_cols with matrix:
        Throw Errors.InvalidArgument with "Pivoted Cholesky requires square matrix"
    
    Note: Initialize permutation matrix and working matrix
    Let permutation_matrix be LinAlgCore.create_identity_matrix with n
    Let working_matrix be LinAlgCore.copy_matrix with matrix
    Let l_matrix be LinAlgCore.create_matrix with n and n
    
    Note: Pivoted Cholesky algorithm
    Let rank be 0
    Let i be 0
    While i is less than n:
        Note: Find diagonal element with largest value for pivoting
        Let max_diag be LinAlgCore.get_matrix_element with working_matrix and i and i
        Let max_idx be i
        
        Let j be i plus 1
        While j is less than n:
            Let diag_elem be LinAlgCore.get_matrix_element with working_matrix and j and j
            If LinAlgCore.is_greater_than with diag_elem and max_diag:
                Set max_diag to diag_elem
                Set max_idx to j
            Set j to j plus 1
        
        Note: Check if diagonal element is sufficiently large
        If LinAlgCore.is_less_than with max_diag and tolerance:
            Note: Matrix is rank deficient, stop decomposition
            Break
        
        Note: Swap rows and columns if needed
        If max_idx does not equal i:
            Set working_matrix to LinAlgCore.swap_matrix_rows with working_matrix and i and max_idx
            Set working_matrix to LinAlgCore.swap_matrix_cols with working_matrix and i and max_idx
            Set permutation_matrix to LinAlgCore.swap_matrix_rows with permutation_matrix and i and max_idx
        
        Note: Compute Cholesky factor for current column
        Let l_ii be LinAlgCore.sqrt with max_diag
        Set l_matrix to LinAlgCore.set_matrix_element with l_matrix and i and i and l_ii
        
        Note: Update column below diagonal
        Set j to i plus 1
        While j is less than n:
            Let a_ji be LinAlgCore.get_matrix_element with working_matrix and j and i
            Let l_ji be LinAlgCore.divide with a_ji and l_ii
            Set l_matrix to LinAlgCore.set_matrix_element with l_matrix and j and i and l_ji
            Set j to j plus 1
        
        Note: Update remaining submatrix
        Set j to i plus 1
        While j is less than n:
            Let k be i plus 1
            While k is less than or equal to j:
                Let l_ji be LinAlgCore.get_matrix_element with l_matrix and j and i
                Let l_ki be LinAlgCore.get_matrix_element with l_matrix and k and i
                Let old_elem be LinAlgCore.get_matrix_element with working_matrix and j and k
                Let new_elem be LinAlgCore.subtract with old_elem and LinAlgCore.multiply with l_ji and l_ki
                Set working_matrix to LinAlgCore.set_matrix_element with working_matrix and j and k and new_elem
                Set working_matrix to LinAlgCore.set_matrix_element with working_matrix and k and j and new_elem
                Set k to k plus 1
            Set j to j plus 1
        
        Set rank to rank plus 1
        Set i to i plus 1
    
    Return CholeskyDecomposition with lower_triangular: l_matrix, permutation_matrix: permutation_matrix, is_positive_definite: (rank is equal to n), rank: rank

Process called "block_cholesky" that takes matrix as Matrix, block_size as Integer returns CholeskyDecomposition:
    Note: Block-wise Cholesky decomposition for large matrices
    Note: Partitions matrix into blocks for improved cache performance
    
    Let n be LinAlgCore.get_matrix_rows with matrix
    If n does not equal LinAlgCore.get_matrix_cols with matrix:
        Throw Errors.InvalidArgument with "Block Cholesky requires square matrix"
    
    If block_size is less than or equal to 0 or block_size is greater than or equal to n:
        Note: Fall back to standard Cholesky decomposition
        Return cholesky_decomposition(matrix)
    
    Let l_matrix be LinAlgCore.create_matrix with n and n
    
    Note: Block Cholesky algorithm
    Let block_row be 0
    While block_row is less than n:
        Let current_block_size be block_size
        If block_row plus block_size is greater than n:
            Set current_block_size to n minus block_row
        
        Note: Extract diagonal block
        Let diagonal_block be LinAlgCore.extract_submatrix with matrix and block_row and block_row and current_block_size and current_block_size
        
        Note: Subtract contribution from previous blocks
        If block_row is greater than 0:
            Let left_block be LinAlgCore.extract_submatrix with l_matrix and block_row and 0 and current_block_size and block_row
            Let left_transpose be LinAlgCore.transpose_matrix with left_block
            Let contribution be LinAlgCore.multiply_matrices with left_block and left_transpose
            Set diagonal_block to LinAlgCore.subtract_matrices with diagonal_block and contribution
        
        Note: Decompose diagonal block
        Let block_chol be cholesky_decomposition(diagonal_block)
        If not block_chol.is_positive_definite:
            Throw Errors.NotPositiveDefinite with "Matrix is not positive definite for block Cholesky"
        
        Note: Store diagonal block result
        Call LinAlgCore.set_submatrix with l_matrix and block_row and block_row and block_chol.lower_triangular
        
        Note: Update blocks below diagonal
        Let below_start be block_row plus current_block_size
        If below_start is less than n:
            Let below_block be LinAlgCore.extract_submatrix with matrix and below_start and block_row and (n minus below_start) and current_block_size
            
            Note: Subtract contribution from previous L blocks
            If block_row is greater than 0:
                Let below_left be LinAlgCore.extract_submatrix with l_matrix and below_start and 0 and (n minus below_start) and block_row
                Let diag_left be LinAlgCore.extract_submatrix with l_matrix and block_row and 0 and current_block_size and block_row
                Let diag_left_transpose be LinAlgCore.transpose_matrix with diag_left
                Let below_contribution be LinAlgCore.multiply_matrices with below_left and diag_left_transpose
                Set below_block to LinAlgCore.subtract_matrices with below_block and below_contribution
            
            Note: Solve triangular system for below blocks
            Let solved_below be LinAlgCore.solve_triangular_system with block_chol.lower_triangular and below_block and "lower"
            Call LinAlgCore.set_submatrix with l_matrix and below_start and block_row and solved_below
        
        Set block_row to block_row plus current_block_size
    
    Note: Compute determinant as product of diagonal elements
    Let det be 1.0
    Let i be 0
    While i is less than n:
        Let diag_elem be LinAlgCore.get_matrix_element with l_matrix and i and i
        Set det to LinAlgCore.multiply with det and LinAlgCore.multiply with diag_elem and diag_elem
        Set i to i plus 1
    
    Return CholeskyDecomposition with lower_triangular: l_matrix, permutation_matrix: LinAlgCore.create_identity_matrix with n, is_positive_definite: true, rank: n

Process called "solve_with_cholesky" that takes cholesky_result as CholeskyDecomposition, right_hand_side as Vector returns Vector:
    Note: Solve linear system using precomputed Cholesky decomposition
    Note: Solves A*x is equal to b where A is equal to L*L^T using forward and backward substitution
    
    Let lower_matrix be cholesky_result.lower_triangular
    Let is_positive_definite be cholesky_result.is_positive_definite
    
    If not is_positive_definite:
        Throw Errors.NotPositiveDefinite with "Cannot solve with non-positive definite Cholesky decomposition"
    
    Let n be LinAlgCore.get_matrix_rows with lower_matrix
    Let rhs_size be LinAlgCore.get_vector_size with right_hand_side
    
    If n does not equal rhs_size:
        Throw Errors.DimensionMismatch with "Cholesky decomposition dimension does not match RHS vector size"
    
    Note: Forward substitution: L*y is equal to b
    Let y_vector be LinAlgCore.create_vector with n
    Let i be 0
    While i is less than n:
        Let sum be 0.0
        Let j be 0
        While j is less than i:
            Let l_element be LinAlgCore.get_matrix_element with lower_matrix and i and j
            Let y_element be LinAlgCore.get_vector_element with y_vector and j
            Let sum be LinAlgCore.add with sum and LinAlgCore.multiply with l_element and y_element
            Let j be j plus 1
        
        Let b_element be LinAlgCore.get_vector_element with right_hand_side and i
        Let l_diagonal be LinAlgCore.get_matrix_element with lower_matrix and i and i
        
        If LinAlgCore.is_approximately_zero with l_diagonal and 1e-14:
            Throw Errors.SingularMatrix with "Singular matrix in Cholesky forward substitution"
        
        Let y_value be LinAlgCore.divide with LinAlgCore.subtract with b_element and sum and l_diagonal
        Let y_vector be LinAlgCore.set_vector_element with y_vector and i and y_value
        Let i be i plus 1
    
    Note: Backward substitution: L^T*x is equal to y
    Let solution_vector be LinAlgCore.create_vector with n
    Let i be n minus 1
    While i is greater than or equal to 0:
        Let sum be 0.0
        Let j be i plus 1
        While j is less than n:
            Note: Use L^T[i,j] is equal to L[j,i]
            Let l_transpose_element be LinAlgCore.get_matrix_element with lower_matrix and j and i
            Let x_element be LinAlgCore.get_vector_element with solution_vector and j
            Let sum be LinAlgCore.add with sum and LinAlgCore.multiply with l_transpose_element and x_element
            Let j be j plus 1
        
        Let y_element be LinAlgCore.get_vector_element with y_vector and i
        Let l_diagonal be LinAlgCore.get_matrix_element with lower_matrix and i and i
        
        If LinAlgCore.is_approximately_zero with l_diagonal and 1e-14:
            Throw Errors.SingularMatrix with "Singular matrix in Cholesky backward substitution"
        
        Let x_value be LinAlgCore.divide with LinAlgCore.subtract with y_element and sum and l_diagonal
        Let solution_vector be LinAlgCore.set_vector_element with solution_vector and i and x_value
        Let i be i minus 1
    
    Return solution_vector

Note: =====================================================================
Note: EIGENVALUE DECOMPOSITION OPERATIONS
Note: =====================================================================

Process called "eigenvalue_decomposition" that takes matrix as Matrix, algorithm as String returns EigenDecomposition:
    Note: Compute eigenvalues and eigenvectors using specified algorithm
    Note: Supports "qr_algorithm", "power_iteration", and "jacobi" methods
    
    Let rows be LinAlgCore.get_matrix_rows with matrix
    Let cols be LinAlgCore.get_matrix_cols with matrix
    
    If rows does not equal cols:
        Throw Errors.InvalidMatrix with "Eigenvalue decomposition requires square matrix"
    
    If algorithm is equal to "qr_algorithm":
        Let result be qr_algorithm_eigenvalues with matrix and 1000
        Return result
    Otherwise:
        If algorithm is equal to "power_iteration":
            Let result be power_iteration_eigenvalues with matrix and 100 and 1e-10
            Return result
        Otherwise:
            If algorithm is equal to "jacobi":
                Note: Check if matrix is symmetric for Jacobi method
                Let is_symmetric be LinAlgCore.is_symmetric_matrix with matrix and 1e-12
                If is_symmetric:
                    Let result be jacobi_eigenvalue_algorithm with matrix and 1e-10
                    Return result
                Otherwise:
                    Throw Errors.InvalidAlgorithm with "Jacobi method requires symmetric matrix"
            Otherwise:
                Throw Errors.InvalidAlgorithm with "Unknown eigenvalue algorithm specified"

Process called "symmetric_eigendecomposition" that takes symmetric_matrix as Matrix returns EigenDecomposition:
    Note: Eigendecomposition for symmetric matrices using optimized algorithms
    Note: Uses Jacobi method for symmetric matrices with guaranteed convergence
    
    Let n be LinAlgCore.get_matrix_rows with matrix
    If n does not equal LinAlgCore.get_matrix_cols with matrix:
        Throw Errors.InvalidArgument with "Symmetric eigendecomposition requires square matrix"
    
    Note: Verify matrix is symmetric
    Let is_symmetric be true
    Let i be 0
    While i is less than n and is_symmetric:
        Let j be 0
        While j is less than n and is_symmetric:
            Let a_ij be LinAlgCore.get_matrix_element with matrix and i and j
            Let a_ji be LinAlgCore.get_matrix_element with matrix and j and i
            If not LinAlgCore.is_approximately_equal with a_ij and a_ji and 1e-12:
                Set is_symmetric to false
            Set j to j plus 1
        Set i to i plus 1
    
    If not is_symmetric:
        Note: Fall back to general eigendecomposition
        Return jacobi_eigenvalues(matrix, tolerance)
    
    Note: Use specialized symmetric Jacobi method
    Let working_matrix be LinAlgCore.copy_matrix with matrix
    Let eigenvectors be LinAlgCore.create_identity_matrix with n
    
    Note: Jacobi iterations for symmetric matrix
    Let max_iterations be 50
    Let iteration be 0
    Let converged be false
    
    While iteration is less than max_iterations and not converged:
        Let max_off_diagonal be 0.0
        Let best_p be 0
        Let best_q be 1
        
        Note: Find largest off-diagonal element
        Set i to 0
        While i is less than n:
            Let j be i plus 1
            While j is less than n:
                Let elem be LinAlgCore.abs with LinAlgCore.get_matrix_element with working_matrix and i and j
                If LinAlgCore.is_greater_than with elem and max_off_diagonal:
                    Set max_off_diagonal to elem
                    Set best_p to i
                    Set best_q to j
                Set j to j plus 1
            Set i to i plus 1
        
        Note: Check convergence
        If LinAlgCore.is_less_than with max_off_diagonal and tolerance:
            Set converged to true
        Otherwise:
            Note: Apply Jacobi rotation
            Let app be LinAlgCore.get_matrix_element with working_matrix and best_p and best_p
            Let aqq be LinAlgCore.get_matrix_element with working_matrix and best_q and best_q
            Let apq be LinAlgCore.get_matrix_element with working_matrix and best_p and best_q
            
            Note: Compute rotation angle
            Let theta be LinAlgCore.divide with LinAlgCore.subtract with aqq and app and LinAlgCore.multiply with 2.0 and apq
            Let t be LinAlgCore.divide with 1.0 and LinAlgCore.add with theta and LinAlgCore.sqrt with LinAlgCore.add with LinAlgCore.multiply with theta and theta and 1.0
            Let c be LinAlgCore.divide with 1.0 and LinAlgCore.sqrt with LinAlgCore.add with LinAlgCore.multiply with t and t and 1.0
            Let s be LinAlgCore.multiply with c and t
            
            Note: Apply rotation to working matrix and eigenvectors
            Set working_matrix to apply_jacobi_rotation(working_matrix, best_p, best_q, c, s)
            Set eigenvectors to apply_jacobi_rotation(eigenvectors, best_p, best_q, c, s)
        
        Set iteration to iteration plus 1
    
    Note: Extract eigenvalues from diagonal
    Let eigenvalues be LinAlgCore.create_vector with n
    Set i to 0
    While i is less than n:
        Let eigenvalue be LinAlgCore.get_matrix_element with working_matrix and i and i
        Set eigenvalues to LinAlgCore.set_vector_element with eigenvalues and i and eigenvalue
        Set i to i plus 1
    
    Note: Sort eigenvalues and eigenvectors in descending order
    Let sorted_result be sort_eigen_pairs(eigenvalues, eigenvectors)
    
    Return EigenDecomposition with eigenvalues: sorted_result.eigenvalues, eigenvectors: sorted_result.eigenvectors, is_real: true, condition_number: 1.0

Process called "power_iteration_eigenvalues" that takes matrix as Matrix, num_iterations as Integer, tolerance as Float returns EigenDecomposition:
    Note: Find dominant eigenvalues using power iteration
    Note: Computes the largest eigenvalue and corresponding eigenvector
    
    Let n be LinAlgCore.get_matrix_rows with matrix
    Let cols be LinAlgCore.get_matrix_cols with matrix
    
    If n does not equal cols:
        Throw Errors.InvalidMatrix with "Power iteration requires square matrix"
    
    Note: Initialize random starting vector
    Let current_vector be LinAlgCore.create_random_vector with n
    Let current_vector be LinAlgCore.normalize_vector with current_vector
    
    Let dominant_eigenvalue be 0.0
    Let iteration be 0
    Let has_converged be False
    
    Note: Power iteration main loop
    While iteration is less than num_iterations and not has_converged:
        Note: Apply matrix multiplication: v_new is equal to A multiplied by v_old
        Let new_vector be LinAlgCore.multiply_matrix_vector with matrix and current_vector
        
        Note: Compute Rayleigh quotient: λ is equal to v^T multiplied by A multiplied by v / v^T multiplied by v
        Let numerator be LinAlgCore.vector_dot_product with current_vector and new_vector
        Let denominator be LinAlgCore.vector_dot_product with current_vector and current_vector
        
        If LinAlgCore.is_approximately_zero with denominator and 1e-14:
            Throw Errors.NumericalError with "Zero vector encountered in power iteration"
        
        Let new_eigenvalue be LinAlgCore.divide with numerator and denominator
        
        Note: Normalize the new vector
        Let new_vector_norm be LinAlgCore.vector_norm with new_vector
        If LinAlgCore.is_approximately_zero with new_vector_norm and 1e-14:
            Throw Errors.NumericalError with "Vector became zero during power iteration"
        
        Let new_vector be LinAlgCore.scale_vector with new_vector and LinAlgCore.divide with 1.0 and new_vector_norm
        
        Note: Check for convergence
        If iteration is greater than 0:
            Let eigenvalue_change be LinAlgCore.absolute_value with LinAlgCore.subtract with new_eigenvalue and dominant_eigenvalue
            If LinAlgCore.is_less_than with eigenvalue_change and tolerance:
                Let has_converged be True
        
        Let dominant_eigenvalue be new_eigenvalue
        Let current_vector be new_vector
        Let iteration be iteration plus 1
    
    Note: Create eigenvector matrix (single column)
    Let eigenvector_matrix be LinAlgCore.create_matrix with n and 1
    Let i be 0
    While i is less than n:
        Let element be LinAlgCore.get_vector_element with current_vector and i
        Let eigenvector_matrix be LinAlgCore.set_matrix_element with eigenvector_matrix and i and 0 and element
        Let i be i plus 1
    
    Note: Create eigenvalue list
    Let eigenvalues be LinAlgCore.create_list with
    Let eigenvalue_str be LinAlgCore.complex_to_string with dominant_eigenvalue and 0.0
    Let eigenvalues be LinAlgCore.append_to_list with eigenvalues and eigenvalue_str
    
    Note: Prepare convergence information
    Let convergence_info be LinAlgCore.create_dictionary with
    Let convergence_info be LinAlgCore.set_dictionary_value with convergence_info and "iterations" and LinAlgCore.integer_to_string with iteration
    Let convergence_info be LinAlgCore.set_dictionary_value with convergence_info and "converged" and LinAlgCore.boolean_to_string with has_converged
    Let convergence_info be LinAlgCore.set_dictionary_value with convergence_info and "final_eigenvalue" and LinAlgCore.float_to_string with dominant_eigenvalue
    Let convergence_info be LinAlgCore.set_dictionary_value with convergence_info and "method" and "power_iteration"
    
    Note: Check if result is real (power iteration always gives real eigenvalue for real matrix)
    Let is_real be LinAlgCore.is_real_number with dominant_eigenvalue
    
    Note: Construct and return eigenvalue decomposition result
    Let decomposition_result be EigenDecomposition with:
        eigenvalues is equal to eigenvalues
        eigenvectors is equal to eigenvector_matrix
        is_real is equal to is_real
        is_symmetric is equal to False
        convergence_info is equal to convergence_info
    
    Return decomposition_result

Process called "qr_algorithm_eigenvalues" that takes matrix as Matrix, max_iterations as Integer returns EigenDecomposition:
    Note: QR algorithm for computing all eigenvalues
    Note: Iteratively applies QR decomposition: A_k+1 is equal to R_k multiplied by Q_k
    
    Let n be LinAlgCore.get_matrix_rows with matrix
    Let working_matrix be LinAlgCore.copy_matrix with matrix
    Let eigenvectors be LinAlgCore.create_identity_matrix with n
    Let is_symmetric be LinAlgCore.is_symmetric_matrix with matrix and 1e-12
    Let convergence_tolerance be 1e-10
    Let iteration be 0
    Let has_converged be False
    
    Note: First reduce to Hessenberg form for efficiency
    Let hessenberg_data be hessenberg_reduction with working_matrix
    Let working_matrix be LinAlgCore.get_dictionary_matrix with hessenberg_data and "hessenberg_matrix"
    Let hessenberg_q be LinAlgCore.get_dictionary_matrix with hessenberg_data and "orthogonal_matrix"
    Let eigenvectors be LinAlgCore.multiply_matrices with eigenvectors and hessenberg_q
    
    Note: Main QR iteration loop
    While iteration is less than max_iterations and not has_converged:
        Note: Apply QR decomposition to current matrix
        Let qr_result be householder_qr with working_matrix
        Let q_matrix be qr_result.orthogonal_matrix
        Let r_matrix be qr_result.upper_triangular
        
        Note: Form A_k+1 is equal to R_k multiplied by Q_k
        Let new_matrix be LinAlgCore.multiply_matrices with r_matrix and q_matrix
        
        Note: Update eigenvectors: V is equal to V multiplied by Q_k
        Let eigenvectors be LinAlgCore.multiply_matrices with eigenvectors and q_matrix
        
        Note: Check for convergence by examining subdiagonal elements
        Let max_subdiagonal be 0.0
        Let i be 1
        While i is less than n:
            Let j be 0
            While j is less than i:
                Let element be LinAlgCore.absolute_value with LinAlgCore.get_matrix_element with new_matrix and i and j
                If LinAlgCore.is_greater_than with element and max_subdiagonal:
                    Let max_subdiagonal be element
                Let j be j plus 1
            Let i be i plus 1
        
        If LinAlgCore.is_less_than with max_subdiagonal and convergence_tolerance:
            Let has_converged be True
        
        Let working_matrix be new_matrix
        Let iteration be iteration plus 1
    
    Note: Extract eigenvalues from diagonal
    Let eigenvalues be LinAlgCore.create_list with
    Let i be 0
    While i is less than n:
        Let diagonal_element be LinAlgCore.get_matrix_element with working_matrix and i and i
        Let eigenvalue_str be LinAlgCore.complex_to_string with diagonal_element and 0.0
        Let eigenvalues be LinAlgCore.append_to_list with eigenvalues and eigenvalue_str
        Let i be i plus 1
    
    Note: Handle 2x2 blocks on diagonal for complex eigenvalues
    Let refined_eigenvalues be LinAlgCore.create_list with
    Let refined_eigenvectors be LinAlgCore.copy_matrix with eigenvectors
    Let i be 0
    While i is less than n:
        If i is less than n minus 1:
            Let subdiagonal be LinAlgCore.absolute_value with LinAlgCore.get_matrix_element with working_matrix and (i plus 1) and i
            If LinAlgCore.is_greater_than with subdiagonal and convergence_tolerance:
                Note: Found 2x2 block indicating complex eigenvalues
                Let a11 be LinAlgCore.get_matrix_element with working_matrix and i and i
                Let a12 be LinAlgCore.get_matrix_element with working_matrix and i and (i plus 1)
                Let a21 be LinAlgCore.get_matrix_element with working_matrix and (i plus 1) and i
                Let a22 be LinAlgCore.get_matrix_element with working_matrix and (i plus 1) and (i plus 1)
                
                Note: Solve characteristic polynomial of 2x2 block
                Let trace be LinAlgCore.add with a11 and a22
                Let determinant be LinAlgCore.subtract with LinAlgCore.multiply with a11 and a22 and LinAlgCore.multiply with a12 and a21
                Let discriminant be LinAlgCore.subtract with LinAlgCore.multiply with trace and trace and LinAlgCore.multiply with 4.0 and determinant
                
                If LinAlgCore.is_less_than with discriminant and 0.0:
                    Note: Complex eigenvalues
                    Let real_part be LinAlgCore.divide with trace and 2.0
                    Let imag_part be LinAlgCore.divide with LinAlgCore.square_root with LinAlgCore.negate with discriminant and 2.0
                    Let eigenvalue1_str be LinAlgCore.complex_to_string with real_part and imag_part
                    Let eigenvalue2_str be LinAlgCore.complex_to_string with real_part and LinAlgCore.negate with imag_part
                    Let refined_eigenvalues be LinAlgCore.append_to_list with refined_eigenvalues and eigenvalue1_str
                    Let refined_eigenvalues be LinAlgCore.append_to_list with refined_eigenvalues and eigenvalue2_str
                Otherwise:
                    Note: Real eigenvalues
                    Let sqrt_discriminant be LinAlgCore.square_root with discriminant
                    Let eigenvalue1 be LinAlgCore.divide with LinAlgCore.add with trace and sqrt_discriminant and 2.0
                    Let eigenvalue2 be LinAlgCore.divide with LinAlgCore.subtract with trace and sqrt_discriminant and 2.0
                    Let eigenvalue1_str be LinAlgCore.complex_to_string with eigenvalue1 and 0.0
                    Let eigenvalue2_str be LinAlgCore.complex_to_string with eigenvalue2 and 0.0
                    Let refined_eigenvalues be LinAlgCore.append_to_list with refined_eigenvalues and eigenvalue1_str
                    Let refined_eigenvalues be LinAlgCore.append_to_list with refined_eigenvalues and eigenvalue2_str
                
                Let i be i plus 2
            Otherwise:
                Note: Real eigenvalue on diagonal
                Let diagonal_element be LinAlgCore.get_matrix_element with working_matrix and i and i
                Let eigenvalue_str be LinAlgCore.complex_to_string with diagonal_element and 0.0
                Let refined_eigenvalues be LinAlgCore.append_to_list with refined_eigenvalues and eigenvalue_str
                Let i be i plus 1
        Otherwise:
            Note: Last element minus must be real eigenvalue
            Let diagonal_element be LinAlgCore.get_matrix_element with working_matrix and i and i
            Let eigenvalue_str be LinAlgCore.complex_to_string with diagonal_element and 0.0
            Let refined_eigenvalues be LinAlgCore.append_to_list with refined_eigenvalues and eigenvalue_str
            Let i be i plus 1
    
    Note: Prepare convergence information
    Let convergence_info be LinAlgCore.create_dictionary with
    Let convergence_info be LinAlgCore.set_dictionary_value with convergence_info and "iterations" and LinAlgCore.integer_to_string with iteration
    Let convergence_info be LinAlgCore.set_dictionary_value with convergence_info and "converged" and LinAlgCore.boolean_to_string with has_converged
    Let convergence_info be LinAlgCore.set_dictionary_value with convergence_info and "final_subdiagonal_norm" and LinAlgCore.float_to_string with max_subdiagonal
    
    Note: Construct and return eigenvalue decomposition result
    Let decomposition_result be EigenDecomposition with:
        eigenvalues is equal to refined_eigenvalues
        eigenvectors is equal to refined_eigenvectors
        is_real is equal to not LinAlgCore.list_contains_complex with refined_eigenvalues
        is_symmetric is equal to is_symmetric
        convergence_info is equal to convergence_info
    
    Return decomposition_result

Process called "jacobi_eigenvalue_algorithm" that takes symmetric_matrix as Matrix, tolerance as Float returns EigenDecomposition:
    Note: Jacobi method for symmetric eigenvalue problems
    Note: Iteratively applies Givens rotations to diagonalize symmetric matrix
    
    Let n be LinAlgCore.get_matrix_rows with symmetric_matrix
    Let cols be LinAlgCore.get_matrix_cols with symmetric_matrix
    
    If n does not equal cols:
        Throw Errors.InvalidMatrix with "Jacobi algorithm requires square matrix"
    
    Note: Verify matrix is symmetric
    Let symmetry_error be 0.0
    Let i be 0
    While i is less than n:
        Let j be i plus 1
        While j is less than n:
            Let a_ij be LinAlgCore.get_matrix_element with symmetric_matrix and i and j
            Let a_ji be LinAlgCore.get_matrix_element with symmetric_matrix and j and i
            Let difference be LinAlgCore.absolute_value with LinAlgCore.subtract with a_ij and a_ji
            If LinAlgCore.is_greater_than with difference and symmetry_error:
                Let symmetry_error be difference
            Let j be j plus 1
        Let i be i plus 1
    
    If LinAlgCore.is_greater_than with symmetry_error and 1e-12:
        Throw Errors.InvalidMatrix with "Matrix is not symmetric within tolerance"
    
    Let working_matrix be LinAlgCore.copy_matrix with symmetric_matrix
    Let eigenvectors be LinAlgCore.create_identity_matrix with n
    Let max_iterations be 50
    Let iteration be 0
    Let has_converged be False
    
    Note: Main Jacobi iteration loop
    While iteration is less than max_iterations and not has_converged:
        Note: Find largest off-diagonal element
        Let max_off_diagonal be 0.0
        Let max_i be 0
        Let max_j be 1
        
        Let i be 0
        While i is less than n:
            Let j be i plus 1
            While j is less than n:
                Let element be LinAlgCore.absolute_value with LinAlgCore.get_matrix_element with working_matrix and i and j
                If LinAlgCore.is_greater_than with element and max_off_diagonal:
                    Let max_off_diagonal be element
                    Let max_i be i
                    Let max_j be j
                Let j be j plus 1
            Let i be i plus 1
        
        Note: Check for convergence
        If LinAlgCore.is_less_than with max_off_diagonal and tolerance:
            Let has_converged be True
        Otherwise:
            Note: Compute Jacobi rotation parameters
            Let a_ii be LinAlgCore.get_matrix_element with working_matrix and max_i and max_i
            Let a_jj be LinAlgCore.get_matrix_element with working_matrix and max_j and max_j
            Let a_ij be LinAlgCore.get_matrix_element with working_matrix and max_i and max_j
            
            Note: Compute rotation angle using standard Jacobi formula
            Let theta be 0.0
            If LinAlgCore.is_approximately_zero with a_ij and 1e-15:
                Let theta be 0.0
            Otherwise:
                Let tau be LinAlgCore.divide with LinAlgCore.subtract with a_jj and a_ii and LinAlgCore.multiply with 2.0 and a_ij
                Let t be 0.0
                
                If LinAlgCore.is_approximately_zero with tau and 1e-15:
                    Let t be 1.0
                Otherwise:
                    Let abs_tau be LinAlgCore.absolute_value with tau
                    Let sign_tau be LinAlgCore.sign with tau
                    Let t be LinAlgCore.divide with sign_tau and LinAlgCore.add with abs_tau and LinAlgCore.square_root with LinAlgCore.add with 1.0 and LinAlgCore.multiply with tau and tau
                
                Let cosine be LinAlgCore.divide with 1.0 and LinAlgCore.square_root with LinAlgCore.add with 1.0 and LinAlgCore.multiply with t and t
                Let sine be LinAlgCore.multiply with t and cosine
            
            Note: Apply Jacobi rotation to matrix A is equal to G^T multiplied by A multiplied by G
            Note: Update diagonal elements
            Let new_a_ii be LinAlgCore.add with LinAlgCore.subtract with a_ii and LinAlgCore.multiply with t and a_ij and LinAlgCore.multiply with LinAlgCore.multiply with t and t and LinAlgCore.subtract with a_jj and a_ii
            Let new_a_jj be LinAlgCore.add with LinAlgCore.subtract with a_jj and LinAlgCore.multiply with t and a_ij and LinAlgCore.multiply with LinAlgCore.multiply with t and t and LinAlgCore.subtract with a_ii and a_jj
            
            Let working_matrix be LinAlgCore.set_matrix_element with working_matrix and max_i and max_i and new_a_ii
            Let working_matrix be LinAlgCore.set_matrix_element with working_matrix and max_j and max_j and new_a_jj
            Let working_matrix be LinAlgCore.set_matrix_element with working_matrix and max_i and max_j and 0.0
            Let working_matrix be LinAlgCore.set_matrix_element with working_matrix and max_j and max_i and 0.0
            
            Note: Update other matrix elements affected by rotation
            Let k be 0
            While k is less than n:
                If k does not equal max_i and k does not equal max_j:
                    Note: Update row/column k
                    Let a_ik be LinAlgCore.get_matrix_element with working_matrix and max_i and k
                    Let a_jk be LinAlgCore.get_matrix_element with working_matrix and max_j and k
                    
                    Let new_a_ik be LinAlgCore.subtract with LinAlgCore.multiply with cosine and a_ik and LinAlgCore.multiply with sine and a_jk
                    Let new_a_jk be LinAlgCore.add with LinAlgCore.multiply with sine and a_ik and LinAlgCore.multiply with cosine and a_jk
                    
                    Let working_matrix be LinAlgCore.set_matrix_element with working_matrix and max_i and k and new_a_ik
                    Let working_matrix be LinAlgCore.set_matrix_element with working_matrix and k and max_i and new_a_ik
                    Let working_matrix be LinAlgCore.set_matrix_element with working_matrix and max_j and k and new_a_jk
                    Let working_matrix be LinAlgCore.set_matrix_element with working_matrix and k and max_j and new_a_jk
                Let k be k plus 1
            
            Note: Update eigenvectors V is equal to V multiplied by G
            Let k be 0
            While k is less than n:
                Let v_ki be LinAlgCore.get_matrix_element with eigenvectors and k and max_i
                Let v_kj be LinAlgCore.get_matrix_element with eigenvectors and k and max_j
                
                Let new_v_ki be LinAlgCore.subtract with LinAlgCore.multiply with cosine and v_ki and LinAlgCore.multiply with sine and v_kj
                Let new_v_kj be LinAlgCore.add with LinAlgCore.multiply with sine and v_ki and LinAlgCore.multiply with cosine and v_kj
                
                Let eigenvectors be LinAlgCore.set_matrix_element with eigenvectors and k and max_i and new_v_ki
                Let eigenvectors be LinAlgCore.set_matrix_element with eigenvectors and k and max_j and new_v_kj
                Let k be k plus 1
        
        Let iteration be iteration plus 1
    
    Note: Extract eigenvalues from diagonal
    Let eigenvalues be LinAlgCore.create_list with
    Let i be 0
    While i is less than n:
        Let diagonal_element be LinAlgCore.get_matrix_element with working_matrix and i and i
        Let eigenvalue_str be LinAlgCore.complex_to_string with diagonal_element and 0.0
        Let eigenvalues be LinAlgCore.append_to_list with eigenvalues and eigenvalue_str
        Let i be i plus 1
    
    Note: Sort eigenvalues and eigenvectors in descending order
    Let sorted_indices be LinAlgCore.sort_indices_descending_real with eigenvalues
    Let sorted_eigenvalues be LinAlgCore.reorder_list with eigenvalues and sorted_indices
    Let sorted_eigenvectors be LinAlgCore.reorder_matrix_columns with eigenvectors and sorted_indices
    
    Note: Prepare convergence information
    Let convergence_info be LinAlgCore.create_dictionary with
    Let convergence_info be LinAlgCore.set_dictionary_value with convergence_info and "iterations" and LinAlgCore.integer_to_string with iteration
    Let convergence_info be LinAlgCore.set_dictionary_value with convergence_info and "converged" and LinAlgCore.boolean_to_string with has_converged
    Let convergence_info be LinAlgCore.set_dictionary_value with convergence_info and "final_off_diagonal_norm" and LinAlgCore.float_to_string with max_off_diagonal
    Let convergence_info be LinAlgCore.set_dictionary_value with convergence_info and "method" and "jacobi"
    
    Note: Construct and return eigenvalue decomposition result
    Let decomposition_result be EigenDecomposition with:
        eigenvalues is equal to sorted_eigenvalues
        eigenvectors is equal to sorted_eigenvectors
        is_real is equal to True
        is_symmetric is equal to True
        convergence_info is equal to convergence_info
    
    Return decomposition_result

Process called "lanczos_eigenvalues" that takes matrix as Matrix, num_eigenvalues as Integer returns EigenDecomposition:
    Note: Lanczos algorithm for sparse symmetric eigenvalue problems
    Note: Iterative method for computing a few eigenvalues of large sparse matrices
    
    Let n be LinAlgCore.get_matrix_rows with matrix
    If n does not equal LinAlgCore.get_matrix_cols with matrix:
        Throw Errors.InvalidArgument with "Lanczos requires square matrix"
    
    If num_eigenvalues is less than or equal to 0 or num_eigenvalues is greater than n:
        Set num_eigenvalues to LinAlgCore.min with n and 6
    
    Note: Initialize Lanczos vectors
    Let lanczos_vectors be LinAlgCore.create_matrix with n and (num_eigenvalues plus 1)
    Let alpha_values be LinAlgCore.create_vector with num_eigenvalues
    Let beta_values be LinAlgCore.create_vector with (num_eigenvalues minus 1)
    
    Note: Random initial vector
    Let initial_vector be LinAlgCore.create_random_vector with n
    Let normalized_initial be LinAlgCore.normalize_vector with initial_vector
    Call LinAlgCore.set_matrix_column with lanczos_vectors and 0 and normalized_initial
    
    Note: Lanczos iteration
    Let k be 0
    While k is less than num_eigenvalues:
        Note: Get current Lanczos vector
        Let v_k be LinAlgCore.get_matrix_column with lanczos_vectors and k
        
        Note: Compute w is equal to A multiplied by v_k
        Let w_k be LinAlgCore.multiply_matrix_vector with matrix and v_k
        
        Note: Compute alpha_k is equal to v_k^T multiplied by w_k
        Let alpha_k be LinAlgCore.dot_product with v_k and w_k
        Set alpha_values to LinAlgCore.set_vector_element with alpha_values and k and alpha_k
        
        Note: Orthogonalize against current vector: w is equal to w minus alpha_k multiplied by v_k
        Let scaled_v_k be LinAlgCore.scale_vector with v_k and alpha_k
        Set w_k to LinAlgCore.subtract_vectors with w_k and scaled_v_k
        
        Note: Orthogonalize against previous vector if exists
        If k is greater than 0:
            Let beta_prev be LinAlgCore.get_vector_element with beta_values and (k minus 1)
            Let v_prev be LinAlgCore.get_matrix_column with lanczos_vectors and (k minus 1)
            Let scaled_v_prev be LinAlgCore.scale_vector with v_prev and beta_prev
            Set w_k to LinAlgCore.subtract_vectors with w_k and scaled_v_prev
        
        Note: Compute beta and next Lanczos vector
        If k is less than num_eigenvalues minus 1:
            Let beta_k be LinAlgCore.vector_l2_norm with w_k
            
            If LinAlgCore.is_greater_than with beta_k and tolerance:
                Set beta_values to LinAlgCore.set_vector_element with beta_values and k and beta_k
                Let v_next be LinAlgCore.normalize_vector with w_k
                Call LinAlgCore.set_matrix_column with lanczos_vectors and (k plus 1) and v_next
            Otherwise:
                Note: Lanczos breakdown, stop iteration
                Break
        
        Set k to k plus 1
    
    Note: Form tridiagonal matrix T from alpha and beta values
    Let tridiag_matrix be LinAlgCore.create_matrix with k and k
    Let i be 0
    While i is less than k:
        Let alpha_i be LinAlgCore.get_vector_element with alpha_values and i
        Set tridiag_matrix to LinAlgCore.set_matrix_element with tridiag_matrix and i and i and alpha_i
        
        If i is less than k minus 1:
            Let beta_i be LinAlgCore.get_vector_element with beta_values and i
            Set tridiag_matrix to LinAlgCore.set_matrix_element with tridiag_matrix and i and (i plus 1) and beta_i
            Set tridiag_matrix to LinAlgCore.set_matrix_element with tridiag_matrix and (i plus 1) and i and beta_i
        
        Set i to i plus 1
    
    Note: Compute eigenvalues of tridiagonal matrix
    Let tridiag_eigen be symmetric_eigendecomposition(tridiag_matrix, tolerance)
    
    Note: Transform eigenvectors back to original space
    Let reduced_lanczos be LinAlgCore.extract_submatrix with lanczos_vectors and 0 and 0 and n and k
    Let final_eigenvectors be LinAlgCore.multiply_matrices with reduced_lanczos and tridiag_eigen.eigenvectors
    
    Return EigenDecomposition with eigenvalues: tridiag_eigen.eigenvalues, eigenvectors: final_eigenvectors, is_real: true, condition_number: 1.0

Note: =====================================================================
Note: SCHUR DECOMPOSITION OPERATIONS
Note: =====================================================================

Process called "schur_decomposition" that takes matrix as Matrix returns SchurDecomposition:
    Note: Compute Schur decomposition of general matrix
    Note: Implements A is equal to Q multiplied by T multiplied by Q^H where Q is orthogonal, T is upper triangular (Schur form)
    
    Let n be LinAlgCore.get_matrix_rows with matrix
    Let cols be LinAlgCore.get_matrix_cols with matrix
    
    If n does not equal cols:
        Throw Errors.InvalidMatrix with "Schur decomposition requires square matrix"
    
    Note: Step 1: Reduce to Hessenberg form
    Let hessenberg_data be hessenberg_reduction with matrix
    Let schur_matrix be LinAlgCore.get_dictionary_matrix with hessenberg_data and "hessenberg_matrix"
    Let orthogonal_matrix be LinAlgCore.get_dictionary_matrix with hessenberg_data and "orthogonal_matrix"
    
    Note: Step 2: Apply QR algorithm to Hessenberg matrix
    Let max_iterations be 1000
    Let convergence_tolerance be 1e-12
    Let iteration be 0
    Let has_converged be False
    
    Note: Main iteration loop for Schur form
    While iteration is less than max_iterations and not has_converged:
        Note: Check for convergence by examining subdiagonal elements
        Let max_subdiagonal be 0.0
        Let i be 1
        While i is less than n:
            Let subdiag_element be LinAlgCore.absolute_value with LinAlgCore.get_matrix_element with schur_matrix and i and (i minus 1)
            If LinAlgCore.is_greater_than with subdiag_element and max_subdiagonal:
                Let max_subdiagonal be subdiag_element
            Let i be i plus 1
        
        If LinAlgCore.is_less_than with max_subdiagonal and convergence_tolerance:
            Let has_converged be True
        Otherwise:
            Note: Find active submatrix by deflating converged eigenvalues
            Let n_active be n
            Let deflation_found be True
            
            While deflation_found and n_active is greater than 1:
                Let deflation_found be False
                Let i be n_active minus 1
                While i is greater than 0:
                    Let subdiag_val be LinAlgCore.absolute_value with LinAlgCore.get_matrix_element with schur_matrix and i and (i minus 1)
                    If LinAlgCore.is_less_than with subdiag_val and convergence_tolerance:
                        Let schur_matrix be LinAlgCore.set_matrix_element with schur_matrix and i and (i minus 1) and 0.0
                        If i is equal to n_active minus 1:
                            Let n_active be n_active minus 1
                            Let deflation_found be True
                        Let i be 0
                    Otherwise:
                        Let i be i minus 1
            
            Note: Apply shifted QR step to active submatrix
            If n_active is greater than 1:
                Note: Compute Wilkinson shift from 2x2 block at bottom-right
                Let a_nn_1 be LinAlgCore.get_matrix_element with schur_matrix and (n_active minus 2) and (n_active minus 2)
                Let a_nn be LinAlgCore.get_matrix_element with schur_matrix and (n_active minus 1) and (n_active minus 1)
                Let a_n_1n be LinAlgCore.get_matrix_element with schur_matrix and (n_active minus 2) and (n_active minus 1)
                Let a_nn_1 be LinAlgCore.get_matrix_element with schur_matrix and (n_active minus 1) and (n_active minus 2)
                
                Let trace be LinAlgCore.add with a_nn_1 and a_nn
                Let determinant be LinAlgCore.subtract with LinAlgCore.multiply with a_nn_1 and a_nn and LinAlgCore.multiply with a_n_1n and a_nn_1
                Let discriminant be LinAlgCore.subtract with LinAlgCore.multiply with trace and trace and LinAlgCore.multiply with 4.0 and determinant
                
                Let shift be a_nn
                If LinAlgCore.is_greater_than_or_equal with discriminant and 0.0:
                    Note: Real eigenvalues minus choose closer to a_nn
                    Let sqrt_discriminant be LinAlgCore.square_root with discriminant
                    Let eigenvalue1 be LinAlgCore.divide with LinAlgCore.add with trace and sqrt_discriminant and 2.0
                    Let eigenvalue2 be LinAlgCore.divide with LinAlgCore.subtract with trace and sqrt_discriminant and 2.0
                    
                    Let diff1 be LinAlgCore.absolute_value with LinAlgCore.subtract with eigenvalue1 and a_nn
                    Let diff2 be LinAlgCore.absolute_value with LinAlgCore.subtract with eigenvalue2 and a_nn
                    
                    If LinAlgCore.is_less_than with diff2 and diff1:
                        Let shift be eigenvalue2
                    Otherwise:
                        Let shift be eigenvalue1
                
                Note: Apply shifted QR step: (A minus shift*I) is equal to QR, then A is equal to RQ plus shift*I
                Let shifted_matrix be LinAlgCore.copy_matrix with schur_matrix
                Let i be 0
                While i is less than n_active:
                    Let diagonal_element be LinAlgCore.get_matrix_element with shifted_matrix and i and i
                    Let new_diagonal be LinAlgCore.subtract with diagonal_element and shift
                    Let shifted_matrix be LinAlgCore.set_matrix_element with shifted_matrix and i and i and new_diagonal
                    Let i be i plus 1
                
                Note: Extract active submatrix
                Let active_matrix be LinAlgCore.extract_submatrix with shifted_matrix and 0 and 0 and n_active and n_active
                
                Note: Apply QR decomposition to active submatrix
                Let qr_result be householder_qr with active_matrix
                Let q_active be qr_result.orthogonal_matrix
                Let r_active be qr_result.upper_triangular
                
                Note: Form RQ plus shift*I for active part
                Let rq_matrix be LinAlgCore.multiply_matrices with r_active and q_active
                Let i be 0
                While i is less than n_active:
                    Let diagonal_element be LinAlgCore.get_matrix_element with rq_matrix and i and i
                    Let new_diagonal be LinAlgCore.add with diagonal_element and shift
                    Let rq_matrix be LinAlgCore.set_matrix_element with rq_matrix and i and i and new_diagonal
                    Let i be i plus 1
                
                Note: Update full Schur matrix with active part
                Let i be 0
                While i is less than n_active:
                    Let j be 0
                    While j is less than n_active:
                        Let element be LinAlgCore.get_matrix_element with rq_matrix and i and j
                        Let schur_matrix be LinAlgCore.set_matrix_element with schur_matrix and i and j and element
                        Let j be j plus 1
                    Let i be i plus 1
                
                Note: Update full orthogonal matrix Q is equal to Q multiplied by [Q_active, 0; 0, I]
                Let full_q be LinAlgCore.create_identity_matrix with n
                Let i be 0
                While i is less than n_active:
                    Let j be 0
                    While j is less than n_active:
                        Let element be LinAlgCore.get_matrix_element with q_active and i and j
                        Let full_q be LinAlgCore.set_matrix_element with full_q and i and j and element
                        Let j be j plus 1
                    Let i be i plus 1
                
                Let orthogonal_matrix be LinAlgCore.multiply_matrices with orthogonal_matrix and full_q
        
        Let iteration be iteration plus 1
    
    Note: Extract eigenvalues from diagonal and 2x2 blocks
    Let eigenvalues be LinAlgCore.create_list with
    Let i be 0
    While i is less than n:
        If i is less than n minus 1:
            Let subdiag be LinAlgCore.absolute_value with LinAlgCore.get_matrix_element with schur_matrix and (i plus 1) and i
            If LinAlgCore.is_greater_than with subdiag and convergence_tolerance:
                Note: 2x2 block minus extract complex eigenvalues
                Let a11 be LinAlgCore.get_matrix_element with schur_matrix and i and i
                Let a12 be LinAlgCore.get_matrix_element with schur_matrix and i and (i plus 1)
                Let a21 be LinAlgCore.get_matrix_element with schur_matrix and (i plus 1) and i
                Let a22 be LinAlgCore.get_matrix_element with schur_matrix and (i plus 1) and (i plus 1)
                
                Let trace be LinAlgCore.add with a11 and a22
                Let determinant be LinAlgCore.subtract with LinAlgCore.multiply with a11 and a22 and LinAlgCore.multiply with a12 and a21
                Let discriminant be LinAlgCore.subtract with LinAlgCore.multiply with trace and trace and LinAlgCore.multiply with 4.0 and determinant
                
                If LinAlgCore.is_less_than with discriminant and 0.0:
                    Let real_part be LinAlgCore.divide with trace and 2.0
                    Let imag_part be LinAlgCore.divide with LinAlgCore.square_root with LinAlgCore.negate with discriminant and 2.0
                    Let eigenvalue1_str be LinAlgCore.complex_to_string with real_part and imag_part
                    Let eigenvalue2_str be LinAlgCore.complex_to_string with real_part and LinAlgCore.negate with imag_part
                    Let eigenvalues be LinAlgCore.append_to_list with eigenvalues and eigenvalue1_str
                    Let eigenvalues be LinAlgCore.append_to_list with eigenvalues and eigenvalue2_str
                Otherwise:
                    Let sqrt_discriminant be LinAlgCore.square_root with discriminant
                    Let eigenvalue1 be LinAlgCore.divide with LinAlgCore.add with trace and sqrt_discriminant and 2.0
                    Let eigenvalue2 be LinAlgCore.divide with LinAlgCore.subtract with trace and sqrt_discriminant and 2.0
                    Let eigenvalue1_str be LinAlgCore.complex_to_string with eigenvalue1 and 0.0
                    Let eigenvalue2_str be LinAlgCore.complex_to_string with eigenvalue2 and 0.0
                    Let eigenvalues be LinAlgCore.append_to_list with eigenvalues and eigenvalue1_str
                    Let eigenvalues be LinAlgCore.append_to_list with eigenvalues and eigenvalue2_str
                
                Let i be i plus 2
            Otherwise:
                Let diagonal_element be LinAlgCore.get_matrix_element with schur_matrix and i and i
                Let eigenvalue_str be LinAlgCore.complex_to_string with diagonal_element and 0.0
                Let eigenvalues be LinAlgCore.append_to_list with eigenvalues and eigenvalue_str
                Let i be i plus 1
        Otherwise:
            Let diagonal_element be LinAlgCore.get_matrix_element with schur_matrix and i and i
            Let eigenvalue_str be LinAlgCore.complex_to_string with diagonal_element and 0.0
            Let eigenvalues be LinAlgCore.append_to_list with eigenvalues and eigenvalue_str
            Let i be i plus 1
    
    Note: Determine if result is real Schur form
    Let is_real_schur be True
    Let i be 0
    While i is less than LinAlgCore.get_list_length with eigenvalues:
        Let eigenvalue_str be LinAlgCore.get_list_element with eigenvalues and i
        If LinAlgCore.contains_imaginary_part with eigenvalue_str:
            Let is_real_schur be False
            Break
        Let i be i plus 1
    
    Note: Construct and return Schur decomposition result
    Let decomposition_result be SchurDecomposition with:
        orthogonal_matrix is equal to orthogonal_matrix
        schur_matrix is equal to schur_matrix
        eigenvalues is equal to eigenvalues
        is_real_schur is equal to is_real_schur
    
    Return decomposition_result

Process called "real_schur_decomposition" that takes matrix as Matrix returns SchurDecomposition:
    Note: Real Schur decomposition avoiding complex arithmetic
    Note: Real Schur decomposition using QR algorithm with shifts
    Note: Computes A is equal to Q*T*Q^T where T is quasi-upper triangular (real Schur form)
    
    Let n be LinAlgCore.get_matrix_rows with matrix
    If n does not equal LinAlgCore.get_matrix_cols with matrix:
        Throw Errors.InvalidArgument with "Real Schur decomposition requires square matrix"
    
    Note: Start with Hessenberg reduction for efficiency
    Let hessenberg_result be upper_hessenberg(matrix)
    Let h_matrix be hessenberg_result.hessenberg_matrix
    Let q_matrix be hessenberg_result.orthogonal_matrix
    
    Note: QR algorithm with double shift for real matrices
    Let max_iterations be 30 multiplied by n
    Let iteration be 0
    Let converged be false
    
    While iteration is less than max_iterations and not converged:
        Note: Check for convergence of subdiagonal elements
        Let all_converged be true
        Let i be 0
        While i is less than n minus 1 and all_converged:
            Let subdiag_elem be LinAlgCore.abs with LinAlgCore.get_matrix_element with h_matrix and (i plus 1) and i
            Let diag_elem be LinAlgCore.abs with LinAlgCore.get_matrix_element with h_matrix and i and i
            Let next_diag_elem be LinAlgCore.abs with LinAlgCore.get_matrix_element with h_matrix and (i plus 1) and (i plus 1)
            Let threshold be LinAlgCore.multiply with tolerance and LinAlgCore.add with diag_elem and next_diag_elem
            
            If LinAlgCore.is_greater_than with subdiag_elem and threshold:
                Set all_converged to false
            Set i to i plus 1
        
        If all_converged:
            Set converged to true
        Otherwise:
            Note: Apply QR step with Wilkinson shift
            Let shift be compute_wilkinson_shift(h_matrix, n minus 1)
            
            Note: Shift matrix: H is equal to H minus shift*I
            Set i to 0
            While i is less than n:
                Let diag_elem be LinAlgCore.get_matrix_element with h_matrix and i and i
                Let shifted_elem be LinAlgCore.subtract with diag_elem and shift
                Set h_matrix to LinAlgCore.set_matrix_element with h_matrix and i and i and shifted_elem
                Set i to i plus 1
            
            Note: QR factorization
            Let qr_result be householder_qr(h_matrix)
            Let q_step be qr_result.orthogonal_matrix
            Let r_step be qr_result.upper_triangular
            
            Note: Form H is equal to R*Q plus shift*I
            Set h_matrix to LinAlgCore.multiply_matrices with r_step and q_step
            Set i to 0
            While i is less than n:
                Let diag_elem be LinAlgCore.get_matrix_element with h_matrix and i and i
                Let unshifted_elem be LinAlgCore.add with diag_elem and shift
                Set h_matrix to LinAlgCore.set_matrix_element with h_matrix and i and i and unshifted_elem
                Set i to i plus 1
            
            Note: Accumulate orthogonal transformations
            Set q_matrix to LinAlgCore.multiply_matrices with q_matrix and q_step
        
        Set iteration to iteration plus 1
    
    Return SchurDecomposition with orthogonal_matrix: q_matrix, schur_form: h_matrix, eigenvalues: extract_schur_eigenvalues(h_matrix), is_real: true

Process called "ordered_schur_decomposition" that takes matrix as Matrix, eigenvalue_ordering as String returns SchurDecomposition:
    Note: Schur decomposition with specified eigenvalue ordering
    Note: Ordered Schur decomposition with eigenvalue reordering
    Note: Reorders eigenvalues according to selection criteria
    
    Note: Start with standard Schur decomposition
    Let schur_result be real_schur_decomposition(matrix, tolerance)
    Let q_matrix be schur_result.orthogonal_matrix
    Let t_matrix be schur_result.schur_form
    Let eigenvals be schur_result.eigenvalues
    
    Note: Apply eigenvalue selection and reordering
    Let n be LinAlgCore.get_matrix_rows with matrix
    Let reordered_q be q_matrix
    Let reordered_t be t_matrix
    
    Note: Simple reordering by magnitude (largest first)
    Let sorted_indices be sort_eigenvalues_by_magnitude(eigenvals)
    
    Note: Apply permutation swaps to reorder Schur form
    Let i be 0
    While i is less than n minus 1:
        Let target_index be sorted_indices.get(i)
        If target_index does not equal i:
            Note: Swap eigenvalue blocks in Schur form
            Let swap_result be swap_schur_blocks(reordered_t, reordered_q, i, target_index)
            Set reordered_t to swap_result.schur_form
            Set reordered_q to swap_result.orthogonal_matrix
            
            Note: Update remaining indices
            Call update_sorted_indices with sorted_indices and i and target_index
        Set i to i plus 1
    
    Let reordered_eigenvals be extract_schur_eigenvalues(reordered_t)
    
    Return SchurDecomposition with orthogonal_matrix: reordered_q, schur_form: reordered_t, eigenvalues: reordered_eigenvals, is_real: true

Process called "generalized_schur_decomposition" that takes matrix_a as Matrix, matrix_b as Matrix returns Dictionary[String, Matrix]:
    Note: Generalized Schur decomposition for matrix pairs
    Note: Generalized Schur decomposition for matrix pencil A minus λB
    Note: Computes A is equal to Q*S*Z^T, B is equal to Q*T*Z^T where S,T are upper triangular
    
    Let n be LinAlgCore.get_matrix_rows with matrix_a
    If n does not equal LinAlgCore.get_matrix_cols with matrix_a or n does not equal LinAlgCore.get_matrix_rows with matrix_b or n does not equal LinAlgCore.get_matrix_cols with matrix_b:
        Throw Errors.InvalidArgument with "Generalized Schur requires square matrices of same size"
    
    Note: Check if B is singular
    Let b_det be LinAlgCore.compute_determinant with matrix_b
    If LinAlgCore.is_approximately_zero with b_det and 1e-12:
        Throw Errors.SingularMatrix with "Matrix B is singular in generalized Schur decomposition"
    
    Note: Transform to standard eigenvalue problem: C is equal to B^(-1)*A
    Let b_inverse be LinAlgCore.matrix_inverse with matrix_b
    Let transformed_matrix be LinAlgCore.multiply_matrices with b_inverse and matrix_a
    
    Note: Compute standard Schur decomposition of transformed problem
    Let schur_result be real_schur_decomposition(transformed_matrix, tolerance)
    
    Note: Transform back to generalized form
    Let q_matrix be schur_result.orthogonal_matrix
    Let z_matrix be q_matrix Note: For simplicity, assume Q is equal to Z
    
    Note: Compute generalized Schur matrices
    Let q_transpose be LinAlgCore.transpose_matrix with q_matrix
    let z_transpose be LinAlgCore.transpose_matrix with z_matrix
    
    Note: S is equal to Q^T multiplied by A multiplied by Z
    Let temp_s be LinAlgCore.multiply_matrices with q_transpose and matrix_a
    Let s_matrix be LinAlgCore.multiply_matrices with temp_s and z_matrix
    
    Note: T is equal to Q^T multiplied by B multiplied by Z
    Let temp_t be LinAlgCore.multiply_matrices with q_transpose and matrix_b
    Let t_matrix be LinAlgCore.multiply_matrices with temp_t and z_matrix
    
    Note: Extract generalized eigenvalues
    Let generalized_eigenvals be LinAlgCore.create_vector with n
    Let i be 0
    While i is less than n:
        Let s_ii be LinAlgCore.get_matrix_element with s_matrix and i and i
        Let t_ii be LinAlgCore.get_matrix_element with t_matrix and i and i
        
        If not LinAlgCore.is_approximately_zero with t_ii and 1e-14:
            Let eigenval be LinAlgCore.divide with s_ii and t_ii
            Set generalized_eigenvals to LinAlgCore.set_vector_element with generalized_eigenvals and i and eigenval
        Otherwise:
            Note: Infinite eigenvalue
            Set generalized_eigenvals to LinAlgCore.set_vector_element with generalized_eigenvals and i and Float.positive_infinity()
        Set i to i plus 1
    
    Return GeneralizedSchurDecomposition with left_orthogonal: q_matrix, right_orthogonal: z_matrix, upper_triangular_s: s_matrix, upper_triangular_t: t_matrix, eigenvalues: generalized_eigenvals

Note: =====================================================================
Note: SPECIALIZED DECOMPOSITIONS
Note: =====================================================================

Process called "jordan_canonical_form" that takes matrix as Matrix, tolerance as Float returns Dictionary[String, Matrix]:
    Note: Compute Jordan canonical form decomposition
    Note: Jordan canonical form (Jordan normal form) decomposition
    Note: Computes P^(-1)*A*P is equal to J where J contains Jordan blocks
    
    Let n be LinAlgCore.get_matrix_rows with matrix
    If n does not equal LinAlgCore.get_matrix_cols with matrix:
        Throw Errors.InvalidArgument with "Jordan canonical form requires square matrix"
    
    Note: Start with eigendecomposition to find eigenvalues
    Let eigen_result be jacobi_eigenvalues(matrix, tolerance)
    Let eigenvalues be eigen_result.eigenvalues
    Let eigenvectors be eigen_result.eigenvectors
    
    Note: Initialize Jordan form matrix
    Let jordan_matrix be LinAlgCore.create_matrix with n and n
    Let transformation_matrix be LinAlgCore.create_matrix with n and n
    
    Note: Process each distinct eigenvalue
    Let processed_cols be 0
    Let eigenval_idx be 0
    
    While eigenval_idx is less than n:
        Let current_eigenval be LinAlgCore.get_vector_element with eigenvalues and eigenval_idx
        
        Note: Find all occurrences of this eigenvalue (including multiplicity)
        Let multiplicity be 1
        Let search_idx be eigenval_idx plus 1
        While search_idx is less than n:
            Let search_eigenval be LinAlgCore.get_vector_element with eigenvalues and search_idx
            If LinAlgCore.is_approximately_equal with current_eigenval and search_eigenval and tolerance:
                Set multiplicity to multiplicity plus 1
            Set search_idx to search_idx plus 1
        
        Note: Compute Jordan blocks for this eigenvalue
        Let block_start be processed_cols
        
        Note: Simple Jordan block construction (assume one block per eigenvalue)
        Let block_size be multiplicity
        Let i be 0
        While i is less than block_size:
            Note: Set diagonal element
            Let row be block_start plus i
            Let col be block_start plus i
            Set jordan_matrix to LinAlgCore.set_matrix_element with jordan_matrix and row and col and current_eigenval
            
            Note: Set super-diagonal element (Jordan block structure)
            If i is less than block_size minus 1:
                Set jordan_matrix to LinAlgCore.set_matrix_element with jordan_matrix and row and (col plus 1) and 1.0
            
            Note: Set transformation matrix column (generalized eigenvector)
            If i is less than eigenvectors.shape.get(1):
                Let eigenvec_col be LinAlgCore.get_matrix_column with eigenvectors and (eigenval_idx plus i)
                Call LinAlgCore.set_matrix_column with transformation_matrix and row and eigenvec_col
            Otherwise:
                Note: Use unit vector as fallback
                Let unit_vector be LinAlgCore.create_unit_vector with n and row
                Call LinAlgCore.set_matrix_column with transformation_matrix and row and unit_vector
            
            Set i to i plus 1
        
        Set processed_cols to processed_cols plus block_size
        Set eigenval_idx to eigenval_idx plus multiplicity
    
    Note: Compute transformation matrix inverse
    Let transformation_inverse be LinAlgCore.matrix_inverse with transformation_matrix
    
    Note: Verify Jordan form: P^(-1)*A*P is equal to J
    Let temp_product be LinAlgCore.multiply_matrices with transformation_inverse and matrix
    Let computed_jordan be LinAlgCore.multiply_matrices with temp_product and transformation_matrix
    
    Note: Compute condition number for numerical stability
    Let cond_number be LinAlgCore.matrix_condition_number with transformation_matrix
    
    Return JordanDecomposition with jordan_form: jordan_matrix, transformation_matrix: transformation_matrix, transformation_inverse: transformation_inverse, eigenvalues: eigenvalues, condition_number: cond_number

Process called "polar_decomposition" that takes matrix as Matrix returns Dictionary[String, Matrix]:
    Note: Decompose matrix into orthogonal and positive definite parts
    Note: Computes A is equal to U multiplied by P where U is orthogonal and P is positive semidefinite using SVD
    
    Let m be LinAlgCore.get_matrix_rows with matrix
    Let n be LinAlgCore.get_matrix_cols with matrix
    
    Note: Use SVD to compute polar decomposition: A is equal to (U multiplied by V^T) multiplied by (V multiplied by Σ multiplied by V^T)
    Let svd_result be bidiagonal_svd with matrix
    Let u_svd be svd_result.left_singular_vectors
    Let singular_values be svd_result.singular_values
    Let v_svd be svd_result.right_singular_vectors
    
    Note: Construct orthogonal factor U is equal to U_svd multiplied by V_svd^T
    Let v_transpose be LinAlgCore.matrix_transpose with v_svd
    Let orthogonal_factor be LinAlgCore.multiply_matrices with u_svd and v_transpose
    
    Note: Construct positive semidefinite factor P is equal to V multiplied by Σ multiplied by V^T
    Note: Create diagonal matrix from singular values
    Let min_dim be LinAlgCore.minimum with m and n
    Let sigma_matrix be LinAlgCore.create_matrix with n and n
    
    Let i be 0
    While i is less than min_dim:
        Let singular_value_str be LinAlgCore.get_list_element with singular_values and i
        Let singular_value be LinAlgCore.string_to_float with singular_value_str
        Let sigma_matrix be LinAlgCore.set_matrix_element with sigma_matrix and i and i and singular_value
        Let i be i plus 1
    
    Note: If m is greater than n, we need to handle rectangular case
    If m is greater than n:
        Note: For tall matrices, P is equal to V multiplied by Σ multiplied by V^T is n×n
        Let v_sigma be LinAlgCore.multiply_matrices with v_svd and sigma_matrix
        Let positive_factor be LinAlgCore.multiply_matrices with v_sigma and v_transpose
    Otherwise:
        Note: For wide or square matrices
        If n is greater than m:
            Note: For wide matrices, extend Σ to n×n
            Let extended_sigma be LinAlgCore.create_matrix with n and n
            Let i be 0
            While i is less than m:
                Let singular_value_str be LinAlgCore.get_list_element with singular_values and i
                Let singular_value be LinAlgCore.string_to_float with singular_value_str
                Let extended_sigma be LinAlgCore.set_matrix_element with extended_sigma and i and i and singular_value
                Let i be i plus 1
            Let v_sigma be LinAlgCore.multiply_matrices with v_svd and extended_sigma
            Let positive_factor be LinAlgCore.multiply_matrices with v_sigma and v_transpose
        Otherwise:
            Note: Square matrix case
            Let v_sigma be LinAlgCore.multiply_matrices with v_svd and sigma_matrix
            Let positive_factor be LinAlgCore.multiply_matrices with v_sigma and v_transpose
    
    Note: Verify decomposition: A should equal U multiplied by P
    Let reconstructed_matrix be LinAlgCore.multiply_matrices with orthogonal_factor and positive_factor
    Let reconstruction_error be LinAlgCore.matrix_frobenius_norm with LinAlgCore.subtract_matrices with matrix and reconstructed_matrix
    
    If LinAlgCore.is_greater_than with reconstruction_error and 1e-10:
        Throw Errors.NumericalError with "Polar decomposition reconstruction failed minus numerical instability"
    
    Note: Verify U is orthogonal: U^T multiplied by U is equal to I (for square case)
    Let verification_passed be True
    If m is equal to n:
        Let u_transpose be LinAlgCore.matrix_transpose with orthogonal_factor
        Let utu_matrix be LinAlgCore.multiply_matrices with u_transpose and orthogonal_factor
        Let identity_matrix be LinAlgCore.create_identity_matrix with n
        Let orthogonality_error be LinAlgCore.matrix_frobenius_norm with LinAlgCore.subtract_matrices with utu_matrix and identity_matrix
        
        If LinAlgCore.is_greater_than with orthogonality_error and 1e-10:
            Let verification_passed be False
    
    Note: Verify P is positive semidefinite by checking eigenvalues
    If m is less than or equal to n:
        Let p_eigenvalues be eigenvalue_decomposition with positive_factor and "qr_algorithm"
        Let eigenvalue_list be p_eigenvalues.eigenvalues
        
        Let i be 0
        While i is less than LinAlgCore.get_list_length with eigenvalue_list:
            Let eigenvalue_str be LinAlgCore.get_list_element with eigenvalue_list and i
            Let eigenvalue_real be LinAlgCore.extract_real_part with eigenvalue_str
            
            If LinAlgCore.is_less_than with eigenvalue_real and -1e-12:
                Let verification_passed be False
                Break
            Let i be i plus 1
    
    If not verification_passed:
        Throw Errors.NumericalError with "Polar decomposition verification failed minus factors do not satisfy required properties"
    
    Note: Compute condition number of the decomposition
    Let max_singular_value be LinAlgCore.string_to_float with LinAlgCore.get_list_element with singular_values and 0
    Let min_singular_value be LinAlgCore.string_to_float with LinAlgCore.get_list_element with singular_values and (min_dim minus 1)
    Let condition_number be LinAlgCore.divide with max_singular_value and min_singular_value
    
    Note: Create result dictionary
    Let result_dict be LinAlgCore.create_dictionary with
    Let result_dict be LinAlgCore.set_dictionary_matrix with result_dict and "orthogonal_factor" and orthogonal_factor
    Let result_dict be LinAlgCore.set_dictionary_matrix with result_dict and "positive_factor" and positive_factor
    Let result_dict be LinAlgCore.set_dictionary_value with result_dict and "condition_number" and LinAlgCore.float_to_string with condition_number
    Let result_dict be LinAlgCore.set_dictionary_value with result_dict and "reconstruction_error" and LinAlgCore.float_to_string with reconstruction_error
    Let result_dict be LinAlgCore.set_dictionary_value with result_dict and "verification_passed" and LinAlgCore.boolean_to_string with verification_passed
    
    Return result_dict

Process called "hessenberg_reduction" that takes matrix as Matrix returns Dictionary[String, Matrix]:
    Note: Reduce matrix to Hessenberg form
    Note: Uses Householder reflections to reduce A to H is equal to Q^T multiplied by A multiplied by Q where H is upper Hessenberg
    
    Let n be LinAlgCore.get_matrix_rows with matrix
    Let cols be LinAlgCore.get_matrix_cols with matrix
    
    If n does not equal cols:
        Throw Errors.InvalidMatrix with "Hessenberg reduction requires square matrix"
    
    Let working_matrix be LinAlgCore.copy_matrix with matrix
    Let orthogonal_matrix be LinAlgCore.create_identity_matrix with n
    
    Note: Apply Householder reflections to columns 0 to n-3
    Let k be 0
    While k is less than n minus 2:
        Note: Extract subdiagonal part of column k starting from row k+1
        Let col_size be n minus k minus 1
        Let column_vector be LinAlgCore.create_vector with col_size
        
        Let i be 0
        While i is less than col_size:
            Let element be LinAlgCore.get_matrix_element with working_matrix and (k plus 1 plus i) and k
            Let column_vector be LinAlgCore.set_vector_element with column_vector and i and element
            Let i be i plus 1
        
        Note: Compute Householder vector
        Let column_norm be LinAlgCore.vector_norm with column_vector
        
        If LinAlgCore.is_greater_than with column_norm and 1e-14:
            Let first_element be LinAlgCore.get_vector_element with column_vector and 0
            Let sigma be LinAlgCore.sign with first_element
            Let alpha be LinAlgCore.multiply with sigma and column_norm
            
            Let householder_vector be LinAlgCore.copy_vector with column_vector
            Let new_first be LinAlgCore.add with first_element and alpha
            Let householder_vector be LinAlgCore.set_vector_element with householder_vector and 0 and new_first
            
            Let householder_norm be LinAlgCore.vector_norm with householder_vector
            If LinAlgCore.is_greater_than with householder_norm and 1e-14:
                Let householder_vector be LinAlgCore.scale_vector with householder_vector and LinAlgCore.divide with 1.0 and householder_norm
                
                Note: Compute tau coefficient
                Let tau be LinAlgCore.divide with LinAlgCore.multiply with 2.0 and new_first and LinAlgCore.add with LinAlgCore.multiply with new_first and new_first and LinAlgCore.multiply with column_norm and column_norm
                
                Note: Apply left multiplication: H is equal to (I minus tau*v*v^T) multiplied by A
                Let j be k
                While j is less than n:
                    Let column_j be LinAlgCore.create_vector with col_size
                    Let i be 0
                    While i is less than col_size:
                        Let element be LinAlgCore.get_matrix_element with working_matrix and (k plus 1 plus i) and j
                        Let column_j be LinAlgCore.set_vector_element with column_j and i and element
                        Let i be i plus 1
                    
                    Let dot_product be LinAlgCore.vector_dot_product with householder_vector and column_j
                    Let scaled_dot be LinAlgCore.multiply with tau and dot_product
                    
                    Let i be 0
                    While i is less than col_size:
                        Let current_element be LinAlgCore.get_vector_element with column_j and i
                        Let householder_element be LinAlgCore.get_vector_element with householder_vector and i
                        Let update_value be LinAlgCore.multiply with scaled_dot and householder_element
                        Let new_element be LinAlgCore.subtract with current_element and update_value
                        Let working_matrix be LinAlgCore.set_matrix_element with working_matrix and (k plus 1 plus i) and j and new_element
                        Let i be i plus 1
                    Let j be j plus 1
                
                Note: Apply right multiplication: H is equal to A multiplied by (I minus tau*v*v^T)
                Let i be 0
                While i is less than n:
                    Let row_i be LinAlgCore.create_vector with col_size
                    Let j be 0
                    While j is less than col_size:
                        Let element be LinAlgCore.get_matrix_element with working_matrix and i and (k plus 1 plus j)
                        Let row_i be LinAlgCore.set_vector_element with row_i and j and element
                        Let j be j plus 1
                    
                    Let dot_product be LinAlgCore.vector_dot_product with row_i and householder_vector
                    Let scaled_dot be LinAlgCore.multiply with tau and dot_product
                    
                    Let j be 0
                    While j is less than col_size:
                        Let current_element be LinAlgCore.get_vector_element with row_i and j
                        Let householder_element be LinAlgCore.get_vector_element with householder_vector and j
                        Let update_value be LinAlgCore.multiply with scaled_dot and householder_element
                        Let new_element be LinAlgCore.subtract with current_element and update_value
                        Let working_matrix be LinAlgCore.set_matrix_element with working_matrix and i and (k plus 1 plus j) and new_element
                        Let j be j plus 1
                    Let i be i plus 1
                
                Note: Update orthogonal matrix Q is equal to Q multiplied by H_k
                Let i be 0
                While i is less than n:
                    Let q_column_i be LinAlgCore.create_vector with col_size
                    Let j be 0
                    While j is less than col_size:
                        Let element be LinAlgCore.get_matrix_element with orthogonal_matrix and i and (k plus 1 plus j)
                        Let q_column_i be LinAlgCore.set_vector_element with q_column_i and j and element
                        Let j be j plus 1
                    
                    Let dot_product be LinAlgCore.vector_dot_product with q_column_i and householder_vector
                    Let scaled_dot be LinAlgCore.multiply with tau and dot_product
                    
                    Let j be 0
                    While j is less than col_size:
                        Let current_element be LinAlgCore.get_vector_element with q_column_i and j
                        Let householder_element be LinAlgCore.get_vector_element with householder_vector and j
                        Let update_value be LinAlgCore.multiply with scaled_dot and householder_element
                        Let new_element be LinAlgCore.subtract with current_element and update_value
                        Let orthogonal_matrix be LinAlgCore.set_matrix_element with orthogonal_matrix and i and (k plus 1 plus j) and new_element
                        Let j be j plus 1
                    Let i be i plus 1
        
        Let k be k plus 1
    
    Note: Zero out elements below first subdiagonal for clean Hessenberg form
    Let i be 2
    While i is less than n:
        Let j be 0
        While j is less than i minus 1:
            Let working_matrix be LinAlgCore.set_matrix_element with working_matrix and i and j and 0.0
            Let j be j plus 1
        Let i be i plus 1
    
    Note: Create result dictionary
    Let result_dict be LinAlgCore.create_dictionary with
    Let result_dict be LinAlgCore.set_dictionary_matrix with result_dict and "hessenberg_matrix" and working_matrix
    Let result_dict be LinAlgCore.set_dictionary_matrix with result_dict and "orthogonal_matrix" and orthogonal_matrix
    
    Return result_dict

Process called "tridiagonal_reduction" that takes symmetric_matrix as Matrix returns Dictionary[String, Matrix]:
    Note: Reduce symmetric matrix to tridiagonal form
    Note: Uses Householder reflections to reduce symmetric A to T is equal to Q^T multiplied by A multiplied by Q where T is tridiagonal
    
    Let n be LinAlgCore.get_matrix_rows with symmetric_matrix
    Let cols be LinAlgCore.get_matrix_cols with symmetric_matrix
    
    If n does not equal cols:
        Throw Errors.InvalidMatrix with "Tridiagonal reduction requires square matrix"
    
    Note: Verify matrix is symmetric
    Let symmetry_error be 0.0
    Let i be 0
    While i is less than n:
        Let j be i plus 1
        While j is less than n:
            Let a_ij be LinAlgCore.get_matrix_element with symmetric_matrix and i and j
            Let a_ji be LinAlgCore.get_matrix_element with symmetric_matrix and j and i
            Let difference be LinAlgCore.absolute_value with LinAlgCore.subtract with a_ij and a_ji
            If LinAlgCore.is_greater_than with difference and symmetry_error:
                Let symmetry_error be difference
            Let j be j plus 1
        Let i be i plus 1
    
    If LinAlgCore.is_greater_than with symmetry_error and 1e-12:
        Throw Errors.InvalidMatrix with "Matrix is not symmetric within tolerance"
    
    Let working_matrix be LinAlgCore.copy_matrix with symmetric_matrix
    Let orthogonal_matrix be LinAlgCore.create_identity_matrix with n
    
    Note: Apply Householder reflections to reduce to tridiagonal form
    Let k be 0
    While k is less than n minus 2:
        Note: Extract subdiagonal part of column k starting from row k+1
        Let col_size be n minus k minus 1
        Let column_vector be LinAlgCore.create_vector with col_size
        
        Let i be 0
        While i is less than col_size:
            Let element be LinAlgCore.get_matrix_element with working_matrix and (k plus 1 plus i) and k
            Let column_vector be LinAlgCore.set_vector_element with column_vector and i and element
            Let i be i plus 1
        
        Note: Compute Householder vector
        Let column_norm be LinAlgCore.vector_norm with column_vector
        
        If LinAlgCore.is_greater_than with column_norm and 1e-14:
            Let first_element be LinAlgCore.get_vector_element with column_vector and 0
            Let sigma be LinAlgCore.sign with first_element
            Let alpha be LinAlgCore.multiply with sigma and column_norm
            
            Let householder_vector be LinAlgCore.copy_vector with column_vector
            Let new_first be LinAlgCore.add with first_element and alpha
            Let householder_vector be LinAlgCore.set_vector_element with householder_vector and 0 and new_first
            
            Let householder_norm be LinAlgCore.vector_norm with householder_vector
            If LinAlgCore.is_greater_than with householder_norm and 1e-14:
                Let householder_vector be LinAlgCore.scale_vector with householder_vector and LinAlgCore.divide with 1.0 and householder_norm
                
                Note: Compute tau coefficient
                Let tau be LinAlgCore.divide with LinAlgCore.multiply with 2.0 and new_first and LinAlgCore.add with LinAlgCore.multiply with new_first and new_first and LinAlgCore.multiply with column_norm and column_norm
                
                Note: Compute p is equal to tau multiplied by A multiplied by v (submatrix operation)
                Let p_vector be LinAlgCore.create_vector with col_size
                Let i be 0
                While i is less than col_size:
                    Let sum be 0.0
                    Let j be 0
                    While j is less than col_size:
                        Let a_element be LinAlgCore.get_matrix_element with working_matrix and (k plus 1 plus i) and (k plus 1 plus j)
                        Let v_element be LinAlgCore.get_vector_element with householder_vector and j
                        Let sum be LinAlgCore.add with sum and LinAlgCore.multiply with a_element and v_element
                        Let j be j plus 1
                    Let p_value be LinAlgCore.multiply with tau and sum
                    Let p_vector be LinAlgCore.set_vector_element with p_vector and i and p_value
                    Let i be i plus 1
                
                Note: Compute K is equal to (1/2) multiplied by tau multiplied by (v^T multiplied by p)
                Let vt_p be LinAlgCore.vector_dot_product with householder_vector and p_vector
                Let K be LinAlgCore.multiply with 0.5 and LinAlgCore.multiply with tau and vt_p
                
                Note: Compute w is equal to p minus K multiplied by v
                Let w_vector be LinAlgCore.create_vector with col_size
                Let i be 0
                While i is less than col_size:
                    Let p_element be LinAlgCore.get_vector_element with p_vector and i
                    Let v_element be LinAlgCore.get_vector_element with householder_vector and i
                    let w_value be LinAlgCore.subtract with p_element and LinAlgCore.multiply with K and v_element
                    Let w_vector be LinAlgCore.set_vector_element with w_vector and i and w_value
                    Let i be i plus 1
                
                Note: Update submatrix: A is equal to A minus v*w^T minus w*v^T
                Let i be 0
                While i is less than col_size:
                    Let j be 0
                    While j is less than col_size:
                        Let current_element be LinAlgCore.get_matrix_element with working_matrix and (k plus 1 plus i) and (k plus 1 plus j)
                        
                        Let v_i be LinAlgCore.get_vector_element with householder_vector and i
                        Let w_j be LinAlgCore.get_vector_element with w_vector and j
                        Let v_j be LinAlgCore.get_vector_element with householder_vector and j
                        Let w_i be LinAlgCore.get_vector_element with w_vector and i
                        
                        Let update_value be LinAlgCore.add with
                            LinAlgCore.multiply with v_i and w_j
                            LinAlgCore.multiply with w_i and v_j
                        
                        Let new_element be LinAlgCore.subtract with current_element and update_value
                        Let working_matrix be LinAlgCore.set_matrix_element with working_matrix and (k plus 1 plus i) and (k plus 1 plus j) and new_element
                        Let j be j plus 1
                    Let i be i plus 1
                
                Note: Zero out the column and row elements (except tridiagonal)
                Let i be k plus 2
                While i is less than n:
                    Let working_matrix be LinAlgCore.set_matrix_element with working_matrix and i and k and 0.0
                    Let working_matrix be LinAlgCore.set_matrix_element with working_matrix and k and i and 0.0
                    Let i be i plus 1
                
                Note: Update diagonal element
                Let new_diagonal be LinAlgCore.multiply with -1.0 and LinAlgCore.multiply with sigma and column_norm
                Let working_matrix be LinAlgCore.set_matrix_element with working_matrix and (k plus 1) and k and new_diagonal
                Let working_matrix be LinAlgCore.set_matrix_element with working_matrix and k and (k plus 1) and new_diagonal
                
                Note: Update orthogonal matrix Q is equal to Q multiplied by H_k
                Let i be 0
                While i is less than n:
                    Let q_column_i be LinAlgCore.create_vector with col_size
                    Let j be 0
                    While j is less than col_size:
                        Let element be LinAlgCore.get_matrix_element with orthogonal_matrix and i and (k plus 1 plus j)
                        Let q_column_i be LinAlgCore.set_vector_element with q_column_i and j and element
                        Let j be j plus 1
                    
                    Let dot_product be LinAlgCore.vector_dot_product with q_column_i and householder_vector
                    Let scaled_dot be LinAlgCore.multiply with tau and dot_product
                    
                    Let j be 0
                    While j is less than col_size:
                        Let current_element be LinAlgCore.get_vector_element with q_column_i and j
                        Let householder_element be LinAlgCore.get_vector_element with householder_vector and j
                        Let update_value be LinAlgCore.multiply with scaled_dot and householder_element
                        Let new_element be LinAlgCore.subtract with current_element and update_value
                        Let orthogonal_matrix be LinAlgCore.set_matrix_element with orthogonal_matrix and i and (k plus 1 plus j) and new_element
                        Let j be j plus 1
                    Let i be i plus 1
        
        Let k be k plus 1
    
    Note: Clean up minus ensure exact tridiagonal form
    Let i be 0
    While i is less than n:
        Let j be 0
        While j is less than n:
            If LinAlgCore.absolute_value with LinAlgCore.subtract with i and j is greater than 1:
                Let working_matrix be LinAlgCore.set_matrix_element with working_matrix and i and j and 0.0
            Let j be j plus 1
        Let i be i plus 1
    
    Note: Extract diagonal and superdiagonal elements
    Let diagonal_elements be LinAlgCore.create_vector with n
    Let superdiagonal_elements be LinAlgCore.create_vector with n minus 1
    
    Let i be 0
    While i is less than n:
        Let diagonal_value be LinAlgCore.get_matrix_element with working_matrix and i and i
        Let diagonal_elements be LinAlgCore.set_vector_element with diagonal_elements and i and diagonal_value
        
        If i is less than n minus 1:
            Let superdiag_value be LinAlgCore.get_matrix_element with working_matrix and i and (i plus 1)
            Let superdiagonal_elements be LinAlgCore.set_vector_element with superdiagonal_elements and i and superdiag_value
        
        Let i be i plus 1
    
    Note: Create result dictionary
    Let result_dict be LinAlgCore.create_dictionary with
    Let result_dict be LinAlgCore.set_dictionary_matrix with result_dict and "tridiagonal_matrix" and working_matrix
    Let result_dict be LinAlgCore.set_dictionary_matrix with result_dict and "orthogonal_matrix" and orthogonal_matrix
    Let result_dict be LinAlgCore.set_dictionary_vector with result_dict and "diagonal_elements" and diagonal_elements
    Let result_dict be LinAlgCore.set_dictionary_vector with result_dict and "superdiagonal_elements" and superdiagonal_elements
    
    Return result_dict

Process called "bidiagonal_reduction" that takes matrix as Matrix returns Dictionary[String, Matrix]:
    Note: Reduce matrix to bidiagonal form for SVD
    Note: Uses Householder reflections to reduce A to B is equal to U^T multiplied by A multiplied by V where B is bidiagonal
    
    Let m be LinAlgCore.get_matrix_rows with matrix
    Let n be LinAlgCore.get_matrix_cols with matrix
    Let min_dim be LinAlgCore.minimum with m and n
    
    Let working_matrix be LinAlgCore.copy_matrix with matrix
    Let left_orthogonal be LinAlgCore.create_identity_matrix with m
    Let right_orthogonal be LinAlgCore.create_identity_matrix with n
    
    Note: Main bidiagonalization loop
    Let k be 0
    While k is less than min_dim:
        Note: Left Householder reflection to zero column k below diagonal
        If k is less than m:
            Let col_size be m minus k
            Let column_vector be LinAlgCore.create_vector with col_size
            
            Let i be 0
            While i is less than col_size:
                Let element be LinAlgCore.get_matrix_element with working_matrix and (k plus i) and k
                Let column_vector be LinAlgCore.set_vector_element with column_vector and i and element
                Let i be i plus 1
            
            Let column_norm be LinAlgCore.vector_norm with column_vector
            
            If LinAlgCore.is_greater_than with column_norm and 1e-14:
                Let first_element be LinAlgCore.get_vector_element with column_vector and 0
                Let sigma be LinAlgCore.sign with first_element
                Let alpha be LinAlgCore.multiply with sigma and column_norm
                
                Let householder_vector be LinAlgCore.copy_vector with column_vector
                Let new_first be LinAlgCore.add with first_element and alpha
                Let householder_vector be LinAlgCore.set_vector_element with householder_vector and 0 and new_first
                
                Let householder_norm be LinAlgCore.vector_norm with householder_vector
                If LinAlgCore.is_greater_than with householder_norm and 1e-14:
                    Let householder_vector be LinAlgCore.scale_vector with householder_vector and LinAlgCore.divide with 1.0 and householder_norm
                    
                    Let tau be LinAlgCore.divide with LinAlgCore.multiply with 2.0 and new_first and LinAlgCore.add with LinAlgCore.multiply with new_first and new_first and LinAlgCore.multiply with column_norm and column_norm
                    
                    Note: Apply left reflection to A
                    Let j be k
                    While j is less than n:
                        Let column_j be LinAlgCore.create_vector with col_size
                        Let i be 0
                        While i is less than col_size:
                            Let element be LinAlgCore.get_matrix_element with working_matrix and (k plus i) and j
                            Let column_j be LinAlgCore.set_vector_element with column_j and i and element
                            Let i be i plus 1
                        
                        Let dot_product be LinAlgCore.vector_dot_product with householder_vector and column_j
                        Let scaled_dot be LinAlgCore.multiply with tau and dot_product
                        
                        Let i be 0
                        While i is less than col_size:
                            Let current_element be LinAlgCore.get_vector_element with column_j and i
                            Let householder_element be LinAlgCore.get_vector_element with householder_vector and i
                            Let update_value be LinAlgCore.multiply with scaled_dot and householder_element
                            Let new_element be LinAlgCore.subtract with current_element and update_value
                            Let working_matrix be LinAlgCore.set_matrix_element with working_matrix and (k plus i) and j and new_element
                            Let i be i plus 1
                        Let j be j plus 1
                    
                    Note: Update left orthogonal matrix U is equal to U multiplied by H_k
                    Let i be 0
                    While i is less than m:
                        Let u_row_i be LinAlgCore.create_vector with col_size
                        Let j be 0
                        While j is less than col_size:
                            Let element be LinAlgCore.get_matrix_element with left_orthogonal and i and (k plus j)
                            Let u_row_i be LinAlgCore.set_vector_element with u_row_i and j and element
                            Let j be j plus 1
                        
                        Let dot_product be LinAlgCore.vector_dot_product with u_row_i and householder_vector
                        Let scaled_dot be LinAlgCore.multiply with tau and dot_product
                        
                        Let j be 0
                        While j is less than col_size:
                            Let current_element be LinAlgCore.get_vector_element with u_row_i and j
                            Let householder_element be LinAlgCore.get_vector_element with householder_vector and j
                            Let update_value be LinAlgCore.multiply with scaled_dot and householder_element
                            Let new_element be LinAlgCore.subtract with current_element and update_value
                            Let left_orthogonal be LinAlgCore.set_matrix_element with left_orthogonal and i and (k plus j) and new_element
                            Let j be j plus 1
                        Let i be i plus 1
        
        Note: Right Householder reflection to zero row k to the right of superdiagonal
        If k is less than n minus 1:
            Let row_size be n minus k minus 1
            Let row_vector be LinAlgCore.create_vector with row_size
            
            Let j be 0
            While j is less than row_size:
                Let element be LinAlgCore.get_matrix_element with working_matrix and k and (k plus 1 plus j)
                Let row_vector be LinAlgCore.set_vector_element with row_vector and j and element
                Let j be j plus 1
            
            Let row_norm be LinAlgCore.vector_norm with row_vector
            
            If LinAlgCore.is_greater_than with row_norm and 1e-14:
                Let first_element be LinAlgCore.get_vector_element with row_vector and 0
                Let sigma be LinAlgCore.sign with first_element
                Let alpha be LinAlgCore.multiply with sigma and row_norm
                
                Let householder_vector be LinAlgCore.copy_vector with row_vector
                Let new_first be LinAlgCore.add with first_element and alpha
                Let householder_vector be LinAlgCore.set_vector_element with householder_vector and 0 and new_first
                
                Let householder_norm be LinAlgCore.vector_norm with householder_vector
                If LinAlgCore.is_greater_than with householder_norm and 1e-14:
                    Let householder_vector be LinAlgCore.scale_vector with householder_vector and LinAlgCore.divide with 1.0 and householder_norm
                    
                    Let tau be LinAlgCore.divide with LinAlgCore.multiply with 2.0 and new_first and LinAlgCore.add with LinAlgCore.multiply with new_first and new_first and LinAlgCore.multiply with row_norm and row_norm
                    
                    Note: Apply right reflection to A
                    Let i be k
                    While i is less than m:
                        Let row_i be LinAlgCore.create_vector with row_size
                        Let j be 0
                        While j is less than row_size:
                            Let element be LinAlgCore.get_matrix_element with working_matrix and i and (k plus 1 plus j)
                            Let row_i be LinAlgCore.set_vector_element with row_i and j and element
                            Let j be j plus 1
                        
                        Let dot_product be LinAlgCore.vector_dot_product with row_i and householder_vector
                        Let scaled_dot be LinAlgCore.multiply with tau and dot_product
                        
                        Let j be 0
                        While j is less than row_size:
                            Let current_element be LinAlgCore.get_vector_element with row_i and j
                            Let householder_element be LinAlgCore.get_vector_element with householder_vector and j
                            Let update_value be LinAlgCore.multiply with scaled_dot and householder_element
                            Let new_element be LinAlgCore.subtract with current_element and update_value
                            Let working_matrix be LinAlgCore.set_matrix_element with working_matrix and i and (k plus 1 plus j) and new_element
                            Let j be j plus 1
                        Let i be i plus 1
                    
                    Note: Update right orthogonal matrix V is equal to V multiplied by H_k
                    Let i be 0
                    While i is less than n:
                        Let v_column_i be LinAlgCore.create_vector with row_size
                        Let j be 0
                        While j is less than row_size:
                            Let element be LinAlgCore.get_matrix_element with right_orthogonal and i and (k plus 1 plus j)
                            Let v_column_i be LinAlgCore.set_vector_element with v_column_i and j and element
                            Let j be j plus 1
                        
                        Let dot_product be LinAlgCore.vector_dot_product with v_column_i and householder_vector
                        Let scaled_dot be LinAlgCore.multiply with tau and dot_product
                        
                        Let j be 0
                        While j is less than row_size:
                            Let current_element be LinAlgCore.get_vector_element with v_column_i and j
                            Let householder_element be LinAlgCore.get_vector_element with householder_vector and j
                            Let update_value be LinAlgCore.multiply with scaled_dot and householder_element
                            Let new_element be LinAlgCore.subtract with current_element and update_value
                            Let right_orthogonal be LinAlgCore.set_matrix_element with right_orthogonal and i and (k plus 1 plus j) and new_element
                            Let j be j plus 1
                        Let i be i plus 1
        
        Let k be k plus 1
    
    Note: Clean up bidiagonal matrix minus zero out unwanted elements
    Let i be 0
    While i is less than m:
        Let j be 0
        While j is less than n:
            If i is greater than j or (i is less than j and j is greater than i plus 1):
                Let working_matrix be LinAlgCore.set_matrix_element with working_matrix and i and j and 0.0
            Let j be j plus 1
        Let i be i plus 1
    
    Note: Create result dictionary
    Let result_dict be LinAlgCore.create_dictionary with
    Let result_dict be LinAlgCore.set_dictionary_matrix with result_dict and "bidiagonal_matrix" and working_matrix
    Let result_dict be LinAlgCore.set_dictionary_matrix with result_dict and "left_orthogonal" and left_orthogonal
    Let result_dict be LinAlgCore.set_dictionary_matrix with result_dict and "right_orthogonal" and right_orthogonal
    
    Return result_dict

Note: =====================================================================
Note: MATRIX FUNCTIONS VIA DECOMPOSITION
Note: =====================================================================

Process called "matrix_exponential" that takes matrix as Matrix, method as String returns Matrix:
    Note: Compute matrix exponential using decomposition methods
    Note: Supports "pade_approximation", "schur_decomposition", and "taylor_series" methods
    
    Let n be LinAlgCore.get_matrix_rows with matrix
    Let cols be LinAlgCore.get_matrix_cols with matrix
    
    If n does not equal cols:
        Throw Errors.InvalidMatrix with "Matrix exponential requires square matrix"
    
    If method is equal to "schur_decomposition":
        Note: Use Schur decomposition method exp(A) is equal to Q multiplied by exp(T) multiplied by Q^T
        Let schur_result be schur_decomposition with matrix
        Let q_matrix be schur_result.orthogonal_matrix
        Let t_matrix be schur_result.schur_matrix
        
        Note: Compute exponential of upper triangular Schur matrix
        Let exp_t_matrix be LinAlgCore.create_matrix with n and n
        
        Note: Diagonal elements: exp(T[i,i])
        Let i be 0
        While i is less than n:
            Let diagonal_element be LinAlgCore.get_matrix_element with t_matrix and i and i
            Let exp_diagonal be LinAlgCore.exponential with diagonal_element
            Let exp_t_matrix be LinAlgCore.set_matrix_element with exp_t_matrix and i and i and exp_diagonal
            Let i be i plus 1
        
        Note: Upper triangular elements using recurrence relation
        Let j be 1
        While j is less than n:
            Let i be 0
            While i is less than n minus j:
                Let t_ii be LinAlgCore.get_matrix_element with t_matrix and i and i
                Let t_jj be LinAlgCore.get_matrix_element with t_matrix and (i plus j) and (i plus j)
                Let t_ij be LinAlgCore.get_matrix_element with t_matrix and i and (i plus j)
                
                Let exp_ii be LinAlgCore.get_matrix_element with exp_t_matrix and i and i
                Let exp_jj be LinAlgCore.get_matrix_element with exp_t_matrix and (i plus j) and (i plus j)
                
                Note: Compute sum term for off-diagonal element
                Let sum_term be 0.0
                Let k be 1
                While k is less than j:
                    Let t_ik_element be LinAlgCore.get_matrix_element with t_matrix and i and (i plus k)
                    Let exp_kj_element be LinAlgCore.get_matrix_element with exp_t_matrix and (i plus k) and (i plus j)
                    Let product be LinAlgCore.multiply with t_ik_element and exp_kj_element
                    Let sum_term be LinAlgCore.add with sum_term and product
                    Let k be k plus 1
                
                Note: Apply recurrence formula
                Let numerator be LinAlgCore.subtract with LinAlgCore.multiply with t_ij and LinAlgCore.add with exp_ii and exp_jj and LinAlgCore.multiply with 2.0 and sum_term
                Let denominator be LinAlgCore.subtract with t_jj and t_ii
                
                Let exp_element be 0.0
                If LinAlgCore.is_approximately_zero with denominator and 1e-14:
                    Note: Special case when t_jj ≈ t_ii
                    Let exp_element be LinAlgCore.multiply with t_ij and exp_ii
                Otherwise:
                    Let exp_element be LinAlgCore.divide with numerator and denominator
                
                Let exp_t_matrix be LinAlgCore.set_matrix_element with exp_t_matrix and i and (i plus j) and exp_element
                Let i be i plus 1
            Let j be j plus 1
        
        Note: Reconstruct: exp(A) is equal to Q multiplied by exp(T) multiplied by Q^T
        Let q_transpose be LinAlgCore.matrix_transpose with q_matrix
        Let temp_result be LinAlgCore.multiply_matrices with q_matrix and exp_t_matrix
        Let final_result be LinAlgCore.multiply_matrices with temp_result and q_transpose
        Return final_result
    
    Otherwise:
        If method is equal to "pade_approximation":
            Note: Use Padé approximation with scaling and squaring
            Let matrix_norm be LinAlgCore.matrix_norm_1 with matrix
            
            Note: Determine scaling factor
            Let scaling_factor be 0
            Let scaled_matrix be LinAlgCore.copy_matrix with matrix
            
            While LinAlgCore.is_greater_than with matrix_norm and 1.0:
                Let scaling_factor be scaling_factor plus 1
                Let scaled_matrix be LinAlgCore.scale_matrix with scaled_matrix and 0.5
                Let matrix_norm be LinAlgCore.multiply with matrix_norm and 0.5
            
            Note: Apply Padé(6,6) approximation
            Let identity be LinAlgCore.create_identity_matrix with n
            
            Note: Compute powers of scaled matrix
            Let a2 be LinAlgCore.multiply_matrices with scaled_matrix and scaled_matrix
            Let a3 be LinAlgCore.multiply_matrices with a2 and scaled_matrix
            Let a4 be LinAlgCore.multiply_matrices with a3 and scaled_matrix
            Let a5 be LinAlgCore.multiply_matrices with a4 and scaled_matrix
            Let a6 be LinAlgCore.multiply_matrices with a5 and scaled_matrix
            
            Note: Numerator coefficients for Padé(6,6)
            Let u_term be LinAlgCore.add_matrices with 
                LinAlgCore.add_matrices with 
                    LinAlgCore.scale_matrix with a6 and 1.0
                    LinAlgCore.scale_matrix with a4 and 42.0
                LinAlgCore.add_matrices with 
                    LinAlgCore.scale_matrix with a2 and 840.0
                    LinAlgCore.scale_matrix with identity and 30240.0
            
            Let numerator be LinAlgCore.multiply_matrices with scaled_matrix and u_term
            
            Note: Denominator coefficients for Padé(6,6)  
            Let v_term be LinAlgCore.subtract_matrices with
                LinAlgCore.add_matrices with
                    LinAlgCore.add_matrices with
                        LinAlgCore.scale_matrix with a6 and 1.0
                        LinAlgCore.scale_matrix with a4 and 42.0
                    LinAlgCore.add_matrices with
                        LinAlgCore.scale_matrix with a2 and 840.0
                        LinAlgCore.scale_matrix with identity and 30240.0
                numerator
            
            Let denominator be LinAlgCore.add_matrices with v_term and numerator
            
            Note: Solve denominator multiplied by result is equal to numerator
            Let lu_decomp be lu_with_partial_pivoting with denominator
            Let pade_result be solve_with_lu with lu_decomp and numerator
            
            Note: Apply squaring to reverse scaling
            Let result_matrix be pade_result
            Let square_count be 0
            While square_count is less than scaling_factor:
                Let result_matrix be LinAlgCore.multiply_matrices with result_matrix and result_matrix
                Let square_count be square_count plus 1
            
            Return result_matrix
        
        Otherwise:
            If method is equal to "taylor_series":
                Note: Use Taylor series expansion with adaptive number of terms
                Let identity be LinAlgCore.create_identity_matrix with n
                Let result_matrix be LinAlgCore.copy_matrix with identity
                Let power_matrix be LinAlgCore.copy_matrix with identity
                Let factorial be 1.0
                Let max_terms be 50
                Let tolerance be 1e-15
                
                Let k be 1
                While k is less than or equal to max_terms:
                    Let power_matrix be LinAlgCore.multiply_matrices with power_matrix and matrix
                    Let factorial be LinAlgCore.multiply with factorial and LinAlgCore.integer_to_float with k
                    Let term_matrix be LinAlgCore.scale_matrix with power_matrix and LinAlgCore.divide with 1.0 and factorial
                    
                    Note: Check convergence
                    Let term_norm be LinAlgCore.matrix_frobenius_norm with term_matrix
                    If LinAlgCore.is_less_than with term_norm and tolerance:
                        Break
                    
                    Let result_matrix be LinAlgCore.add_matrices with result_matrix and term_matrix
                    Let k be k plus 1
                
                Return result_matrix
            
            Otherwise:
                Throw Errors.InvalidMethod with "Unknown matrix exponential method specified"

Process called "matrix_logarithm" that takes matrix as Matrix returns Matrix:
    Note: Compute matrix logarithm using eigendecomposition
    Note: Uses the fact that log(A) is equal to V multiplied by log(Λ) multiplied by V^(-1) where A is equal to V multiplied by Λ multiplied by V^(-1)
    
    Let n be LinAlgCore.get_matrix_rows with matrix
    Let cols be LinAlgCore.get_matrix_cols with matrix
    
    If n does not equal cols:
        Throw Errors.InvalidMatrix with "Matrix logarithm requires square matrix"
    
    Note: Check if matrix is invertible (det ≠ 0)
    Let matrix_determinant be LinAlgCore.matrix_determinant with matrix
    If LinAlgCore.is_approximately_zero with matrix_determinant and 1e-14:
        Throw Errors.SingularMatrix with "Cannot compute logarithm of singular matrix"
    
    Note: Use Schur decomposition for numerical stability
    Let schur_result be schur_decomposition with matrix
    Let q_matrix be schur_result.orthogonal_matrix  
    Let t_matrix be schur_result.schur_matrix
    
    Note: Compute logarithm of upper triangular Schur matrix
    Let log_t_matrix be LinAlgCore.create_matrix with n and n
    
    Note: Diagonal elements: log(T[i,i])
    Let i be 0
    While i is less than n:
        Let diagonal_element be LinAlgCore.get_matrix_element with t_matrix and i and i
        
        Note: Check if diagonal element is positive (required for real logarithm)
        If LinAlgCore.is_less_than_or_equal with diagonal_element and 0.0:
            Throw Errors.ComplexResult with "Matrix has non-positive eigenvalues minus logarithm would be complex"
        
        Let log_diagonal be LinAlgCore.natural_logarithm with diagonal_element
        Let log_t_matrix be LinAlgCore.set_matrix_element with log_t_matrix and i and i and log_diagonal
        Let i be i plus 1
    
    Note: Upper triangular elements using inverse Parlett recurrence
    Let j be 1
    While j is less than n:
        Let i be 0
        While i is less than n minus j:
            Let t_ii be LinAlgCore.get_matrix_element with t_matrix and i and i
            Let t_jj be LinAlgCore.get_matrix_element with t_matrix and (i plus j) and (i plus j)
            Let t_ij be LinAlgCore.get_matrix_element with t_matrix and i and (i plus j)
            
            Note: Check if eigenvalues are distinct
            Let eigenvalue_diff be LinAlgCore.absolute_value with LinAlgCore.subtract with t_jj and t_ii
            
            If LinAlgCore.is_greater_than with eigenvalue_diff and 1e-12:
                Note: Standard case: distinct eigenvalues
                Note: Compute sum term for off-diagonal element
                Let sum_term be 0.0
                Let k be 1
                While k is less than j:
                    Let t_ik_element be LinAlgCore.get_matrix_element with t_matrix and i and (i plus k)
                    Let log_kj_element be LinAlgCore.get_matrix_element with log_t_matrix and (i plus k) and (i plus j)
                    
                    Let log_ii be LinAlgCore.get_matrix_element with log_t_matrix and (i plus k) and (i plus k)
                    Let log_jj be LinAlgCore.get_matrix_element with log_t_matrix and (i plus j) and (i plus j)
                    
                    Let weight be LinAlgCore.divide with 1.0 and LinAlgCore.subtract with log_jj and log_ii
                    Let product be LinAlgCore.multiply with t_ik_element and LinAlgCore.multiply with log_kj_element and weight
                    Let sum_term be LinAlgCore.add with sum_term and product
                    Let k be k plus 1
                
                Note: Apply Parlett recurrence formula
                Let log_ii be LinAlgCore.get_matrix_element with log_t_matrix and i and i
                Let log_jj be LinAlgCore.get_matrix_element with log_t_matrix and (i plus j) and (i plus j)
                
                Let numerator be LinAlgCore.subtract with t_ij and LinAlgCore.multiply with t_ii and sum_term
                Let denominator be LinAlgCore.subtract with t_jj and t_ii
                Let log_element be LinAlgCore.divide with numerator and denominator
                
                Let log_t_matrix be LinAlgCore.set_matrix_element with log_t_matrix and i and (i plus j) and log_element
            Otherwise:
                Note: Repeated eigenvalues case: use derivative formula
                Let log_diagonal be LinAlgCore.get_matrix_element with log_t_matrix and i and i
                Let derivative_term be LinAlgCore.divide with t_ij and t_ii
                
                Note: Add correction for sum of commutators
                Let commutator_sum be 0.0
                Let k be 1
                While k is less than j:
                    Let t_ik_element be LinAlgCore.get_matrix_element with t_matrix and i and (i plus k)
                    Let log_kj_element be LinAlgCore.get_matrix_element with log_t_matrix and (i plus k) and (i plus j)
                    Let log_ik_element be LinAlgCore.get_matrix_element with log_t_matrix and i and (i plus k)
                    Let t_kj_element be LinAlgCore.get_matrix_element with t_matrix and (i plus k) and (i plus j)
                    
                    Let commutator_term be LinAlgCore.subtract with 
                        LinAlgCore.multiply with t_ik_element and log_kj_element
                        LinAlgCore.multiply with log_ik_element and t_kj_element
                    Let commutator_sum be LinAlgCore.add with commutator_sum and commutator_term
                    Let k be k plus 1
                
                Let log_element be LinAlgCore.add with derivative_term and LinAlgCore.divide with commutator_sum and t_ii
                Let log_t_matrix be LinAlgCore.set_matrix_element with log_t_matrix and i and (i plus j) and log_element
            
            Let i be i plus 1
        Let j be j plus 1
    
    Note: Reconstruct: log(A) is equal to Q multiplied by log(T) multiplied by Q^T
    Let q_transpose be LinAlgCore.matrix_transpose with q_matrix
    Let temp_result be LinAlgCore.multiply_matrices with q_matrix and log_t_matrix
    Let final_result be LinAlgCore.multiply_matrices with temp_result and q_transpose
    
    Return final_result

Process called "matrix_square_root" that takes matrix as Matrix returns Matrix:
    Note: Compute matrix square root using decomposition
    Note: For positive definite matrices, uses Cholesky; otherwise uses Schur decomposition
    
    Let n be LinAlgCore.get_matrix_rows with matrix
    Let cols be LinAlgCore.get_matrix_cols with matrix
    
    If n does not equal cols:
        Throw Errors.InvalidMatrix with "Matrix square root requires square matrix"
    
    Note: Check if matrix is symmetric and positive definite
    Let is_symmetric be LinAlgCore.is_symmetric_matrix with matrix and 1e-12
    
    If is_symmetric:
        Note: Try Cholesky decomposition for symmetric positive definite case
        Let cholesky_result be cholesky_decomposition with matrix
        
        If cholesky_result.is_positive_definite:
            Note: For positive definite case: sqrt(A) is equal to L multiplied by sqrt(I) multiplied by L^T is equal to L multiplied by L^T is equal to A
            Note: Actually, sqrt(A) is equal to L where A is equal to L multiplied by L^T, so we need eigendecomposition
            Let eigen_result be eigenvalue_decomposition with matrix and "qr_algorithm"
            Let eigenvalues be eigen_result.eigenvalues
            Let eigenvectors be eigen_result.eigenvectors
            
            Note: Check all eigenvalues are non-negative
            Let i be 0
            While i is less than LinAlgCore.get_list_length with eigenvalues:
                Let eigenvalue_str be LinAlgCore.get_list_element with eigenvalues and i
                Let eigenvalue_real be LinAlgCore.extract_real_part with eigenvalue_str
                
                If LinAlgCore.is_less_than with eigenvalue_real and -1e-14:
                    Throw Errors.ComplexResult with "Matrix has negative eigenvalues minus square root would be complex"
                Let i be i plus 1
            
            Note: Compute sqrt(Λ)
            Let sqrt_eigenvalues_matrix be LinAlgCore.create_matrix with n and n
            Let i be 0
            While i is less than n:
                Let eigenvalue_str be LinAlgCore.get_list_element with eigenvalues and i
                Let eigenvalue_real be LinAlgCore.extract_real_part with eigenvalue_str
                Let sqrt_eigenvalue be LinAlgCore.square_root with LinAlgCore.maximum with eigenvalue_real and 0.0
                Let sqrt_eigenvalues_matrix be LinAlgCore.set_matrix_element with sqrt_eigenvalues_matrix and i and i and sqrt_eigenvalue
                Let i be i plus 1
            
            Note: Reconstruct: sqrt(A) is equal to V multiplied by sqrt(Λ) multiplied by V^T
            Let v_transpose be LinAlgCore.matrix_transpose with eigenvectors
            Let temp_matrix be LinAlgCore.multiply_matrices with eigenvectors and sqrt_eigenvalues_matrix
            Let result_matrix be LinAlgCore.multiply_matrices with temp_matrix and v_transpose
            
            Return result_matrix
    
    Note: General case: use Schur decomposition
    Let schur_result be schur_decomposition with matrix
    Let q_matrix be schur_result.orthogonal_matrix
    Let t_matrix be schur_result.schur_matrix
    
    Note: Compute square root of upper triangular Schur matrix
    Let sqrt_t_matrix be LinAlgCore.create_matrix with n and n
    
    Note: Diagonal elements: sqrt(T[i,i])
    Let i be 0
    While i is less than n:
        Let diagonal_element be LinAlgCore.get_matrix_element with t_matrix and i and i
        
        If LinAlgCore.is_less_than with diagonal_element and -1e-14:
            Throw Errors.ComplexResult with "Matrix has negative eigenvalues minus square root would be complex"
        
        Let sqrt_diagonal be LinAlgCore.square_root with LinAlgCore.maximum with diagonal_element and 0.0
        Let sqrt_t_matrix be LinAlgCore.set_matrix_element with sqrt_t_matrix and i and i and sqrt_diagonal
        Let i be i plus 1
    
    Note: Upper triangular elements using Parlett recurrence for square root
    Let j be 1
    While j is less than n:
        Let i be 0
        While i is less than n minus j:
            Let t_ii be LinAlgCore.get_matrix_element with t_matrix and i and i
            Let t_jj be LinAlgCore.get_matrix_element with t_matrix and (i plus j) and (i plus j)
            Let t_ij be LinAlgCore.get_matrix_element with t_matrix and i and (i plus j)
            
            Let sqrt_ii be LinAlgCore.get_matrix_element with sqrt_t_matrix and i and i
            Let sqrt_jj be LinAlgCore.get_matrix_element with sqrt_t_matrix and (i plus j) and (i plus j)
            
            Note: Check if denominators are non-zero
            Let denominator be LinAlgCore.add with sqrt_ii and sqrt_jj
            
            If LinAlgCore.is_approximately_zero with denominator and 1e-14:
                Note: Special case when sqrt(t_ii) plus sqrt(t_jj) ≈ 0
                Let sqrt_element be 0.0
            Otherwise:
                Note: Compute sum term for off-diagonal element
                Let sum_term be 0.0
                Let k be 1
                While k is less than j:
                    Let sqrt_ik_element be LinAlgCore.get_matrix_element with sqrt_t_matrix and i and (i plus k)
                    Let sqrt_kj_element be LinAlgCore.get_matrix_element with sqrt_t_matrix and (i plus k) and (i plus j)
                    Let product be LinAlgCore.multiply with sqrt_ik_element and sqrt_kj_element
                    Let sum_term be LinAlgCore.add with sum_term and product
                    Let k be k plus 1
                
                Note: Apply Parlett recurrence formula for square root
                Let numerator be LinAlgCore.subtract with t_ij and sum_term
                Let sqrt_element be LinAlgCore.divide with numerator and denominator
            
            Let sqrt_t_matrix be LinAlgCore.set_matrix_element with sqrt_t_matrix and i and (i plus j) and sqrt_element
            Let i be i plus 1
        Let j be j plus 1
    
    Note: Reconstruct: sqrt(A) is equal to Q multiplied by sqrt(T) multiplied by Q^T
    Let q_transpose be LinAlgCore.matrix_transpose with q_matrix
    Let temp_result be LinAlgCore.multiply_matrices with q_matrix and sqrt_t_matrix
    Let final_result be LinAlgCore.multiply_matrices with temp_result and q_transpose
    
    Note: Verify result by computing (sqrt(A))^2 and comparing with A
    Let verification_matrix be LinAlgCore.multiply_matrices with final_result and final_result
    Let verification_error be LinAlgCore.matrix_frobenius_norm with LinAlgCore.subtract_matrices with matrix and verification_matrix
    
    If LinAlgCore.is_greater_than with verification_error and 1e-10:
        Throw Errors.NumericalError with "Matrix square root verification failed minus numerical instability detected"
    
    Return final_result

Process called "matrix_power_fractional" that takes matrix as Matrix, exponent as String returns Matrix:
    Note: Compute matrix raised to fractional power
    Note: Uses eigendecomposition: A^p is equal to V multiplied by Λ^p multiplied by V^(-1) where p can be fractional
    
    Let n be LinAlgCore.get_matrix_rows with matrix
    Let cols be LinAlgCore.get_matrix_cols with matrix
    
    If n does not equal cols:
        Throw Errors.InvalidMatrix with "Fractional matrix power requires square matrix"
    
    Let exponent_value be LinAlgCore.string_to_float with exponent
    
    Note: Handle special cases
    If LinAlgCore.is_approximately_zero with exponent_value and 1e-14:
        Note: A^0 is equal to I
        Return LinAlgCore.create_identity_matrix with n
    
    If LinAlgCore.is_approximately_equal with exponent_value and 1.0 and 1e-14:
        Note: A^1 is equal to A
        Return LinAlgCore.copy_matrix with matrix
    
    Note: Use Schur decomposition for numerical stability
    Let schur_result be schur_decomposition with matrix
    Let q_matrix be schur_result.orthogonal_matrix
    Let t_matrix be schur_result.schur_matrix
    
    Note: Compute T^p using diagonal and off-diagonal elements
    Let power_t_matrix be LinAlgCore.create_matrix with n and n
    
    Note: Diagonal elements: T[i,i]^p
    Let i be 0
    While i is less than n:
        Let diagonal_element be LinAlgCore.get_matrix_element with t_matrix and i and i
        
        Note: Check for non-positive eigenvalues when exponent is not integer
        If LinAlgCore.is_less_than_or_equal with diagonal_element and 0.0:
            If not LinAlgCore.is_integer with exponent_value:
                Throw Errors.ComplexResult with "Matrix has non-positive eigenvalues minus fractional power would be complex"
        
        Let power_diagonal be LinAlgCore.power with diagonal_element and exponent_value
        Let power_t_matrix be LinAlgCore.set_matrix_element with power_t_matrix and i and i and power_diagonal
        Let i be i plus 1
    
    Note: Off-diagonal elements using Parlett recurrence for matrix functions
    Let j be 1
    While j is less than n:
        Let i be 0
        While i is less than n minus j:
            Let t_ii be LinAlgCore.get_matrix_element with t_matrix and i and i
            Let t_jj be LinAlgCore.get_matrix_element with t_matrix and (i plus j) and (i plus j)
            Let t_ij be LinAlgCore.get_matrix_element with t_matrix and i and (i plus j)
            
            Let power_ii be LinAlgCore.get_matrix_element with power_t_matrix and i and i
            Let power_jj be LinAlgCore.get_matrix_element with power_t_matrix and (i plus j) and (i plus j)
            
            Note: Check if eigenvalues are distinct enough for stable computation
            Let eigenvalue_diff be LinAlgCore.absolute_value with LinAlgCore.subtract with t_jj and t_ii
            
            If LinAlgCore.is_greater_than with eigenvalue_diff and 1e-12:
                Note: Standard case: distinct eigenvalues
                Note: Compute sum term for recurrence relation
                Let sum_term be 0.0
                Let k be 1
                While k is less than j:
                    Let t_ik_element be LinAlgCore.get_matrix_element with t_matrix and i and (i plus k)
                    Let power_kj_element be LinAlgCore.get_matrix_element with power_t_matrix and (i plus k) and (i plus j)
                    
                    Let t_kk be LinAlgCore.get_matrix_element with t_matrix and (i plus k) and (i plus k)
                    Let power_kk be LinAlgCore.get_matrix_element with power_t_matrix and (i plus k) and (i plus k)
                    
                    Note: Compute integral of t^(p-1) from t_ii to t_jj approximation
                    Let integral_approx be LinAlgCore.divide with LinAlgCore.subtract with power_jj and power_ii and LinAlgCore.subtract with t_jj and t_ii
                    Let weight be LinAlgCore.divide with power_kk and integral_approx
                    
                    Let product be LinAlgCore.multiply with t_ik_element and LinAlgCore.multiply with power_kj_element and weight
                    Let sum_term be LinAlgCore.add with sum_term and product
                    Let k be k plus 1
                
                Note: Apply generalized Parlett recurrence for arbitrary powers
                Let integral_factor be LinAlgCore.divide with LinAlgCore.subtract with power_jj and power_ii and LinAlgCore.subtract with t_jj and t_ii
                Let numerator be LinAlgCore.subtract with LinAlgCore.multiply with t_ij and integral_factor and sum_term
                Let power_element be numerator
            Otherwise:
                Note: Repeated eigenvalues case: use derivative approach
                If LinAlgCore.is_approximately_zero with exponent_value and 1e-14:
                    Let power_element be 0.0
                Otherwise:
                    Let derivative_factor be LinAlgCore.multiply with exponent_value and LinAlgCore.power with t_ii and LinAlgCore.subtract with exponent_value and 1.0
                    Let power_element be LinAlgCore.multiply with t_ij and derivative_factor
                    
                    Note: Add higher-order correction terms for repeated eigenvalues
                    Let correction_sum be 0.0
                    Let k be 1
                    While k is less than j:
                        Let t_ik_element be LinAlgCore.get_matrix_element with t_matrix and i and (i plus k)
                        Let power_kj_element be LinAlgCore.get_matrix_element with power_t_matrix and (i plus k) and (i plus j)
                        
                        Let correction_term be LinAlgCore.multiply with t_ik_element and power_kj_element
                        Let correction_sum be LinAlgCore.add with correction_sum and correction_term
                        Let k be k plus 1
                    
                    Let power_element be LinAlgCore.add with power_element and correction_sum
            
            Let power_t_matrix be LinAlgCore.set_matrix_element with power_t_matrix and i and (i plus j) and power_element
            Let i be i plus 1
        Let j be j plus 1
    
    Note: Reconstruct: A^p is equal to Q multiplied by T^p multiplied by Q^T
    Let q_transpose be LinAlgCore.matrix_transpose with q_matrix
    Let temp_result be LinAlgCore.multiply_matrices with q_matrix and power_t_matrix
    Let final_result be LinAlgCore.multiply_matrices with temp_result and q_transpose
    
    Note: Verify result for integer powers by repeated multiplication (when feasible)
    If LinAlgCore.is_integer with exponent_value and LinAlgCore.is_less_than with LinAlgCore.absolute_value with exponent_value and 5.0:
        Let integer_exponent be LinAlgCore.float_to_integer with exponent_value
        
        If integer_exponent is greater than 0:
            Let verification_matrix be LinAlgCore.copy_matrix with matrix
            Let count be 1
            While count is less than integer_exponent:
                Let verification_matrix be LinAlgCore.multiply_matrices with verification_matrix and matrix
                Let count be count plus 1
            
            Let verification_error be LinAlgCore.matrix_frobenius_norm with LinAlgCore.subtract_matrices with final_result and verification_matrix
            
            If LinAlgCore.is_greater_than with verification_error and 1e-10:
                Throw Errors.NumericalError with "Fractional matrix power verification failed for integer case"
    
    Return final_result

Process called "matrix_sine_cosine" that takes matrix as Matrix returns Dictionary[String, Matrix]:
    Note: Compute matrix sine and cosine simultaneously using Schur decomposition
    Note: For matrix A, computes sin(A) and cos(A) where sin(A) is equal to Σ((-1)^k multiplied by A^(2k+1) / (2k+1)!) and cos(A) is equal to Σ((-1)^k multiplied by A^(2k) / (2k)!)
    Note: Uses Schur decomposition and Parlett recurrence for numerical stability
    
    Let m be LinAlgCore.get_matrix_rows with matrix
    Let n be LinAlgCore.get_matrix_cols with matrix
    
    Note: Verify square matrix
    If m does not equal n:
        Throw Errors.MatrixNotSquare with "Matrix sine/cosine requires square matrix"
    
    Note: Handle small matrices directly
    If n is equal to 1:
        Let scalar be LinAlgCore.get_matrix_element with matrix and 0 and 0
        Let sine_val be Math.sin with scalar
        Let cosine_val be Math.cos with scalar
        Let sine_matrix be LinAlgCore.create_matrix with 1 and 1
        Let cosine_matrix be LinAlgCore.create_matrix with 1 and 1
        Set sine_matrix at 0 and 0 to sine_val
        Set cosine_matrix at 0 and 0 to cosine_val
        Let result be Dictionary.new
        Set result["sine"] to sine_matrix
        Set result["cosine"] to cosine_matrix
        Return result
    
    Note: Compute Schur decomposition for numerical stability
    Let schur_result be schur_decomposition with matrix
    Let q_matrix be LinAlgCore.get_dictionary_matrix with schur_result and "Q"
    Let t_matrix be LinAlgCore.get_dictionary_matrix with schur_result and "T"
    
    Note: Compute sine and cosine of upper triangular matrix T using Parlett recurrence
    Let t_sine be LinAlgCore.create_zero_matrix with n and n
    Let t_cosine be LinAlgCore.create_zero_matrix with n and n
    
    Note: Initialize diagonal elements
    Let i be 0
    While i is less than n:
        Let t_ii be LinAlgCore.get_matrix_element with t_matrix and i and i
        Let sine_diagonal be Math.sin with t_ii
        Let cosine_diagonal be Math.cos with t_ii
        Set t_sine at i and i to sine_diagonal
        Set t_cosine at i and i to cosine_diagonal
        Set i to i plus 1
    
    Note: Fill superdiagonal elements using Parlett recurrence
    Let k be 1
    While k is less than n:
        Let i be 0
        While i is less than n minus k:
            Let j be i plus k
            
            Note: Compute T[i,j] element for sine using Parlett recurrence
            Let sum_sine be 0.0
            Let sum_cosine be 0.0
            Let m_idx be i plus 1
            While m_idx is less than j:
                Let t_im be LinAlgCore.get_matrix_element with t_matrix and i and m_idx
                Let t_mj be LinAlgCore.get_matrix_element with t_matrix and m_idx and j
                Let sine_im be LinAlgCore.get_matrix_element with t_sine and i and m_idx
                Let sine_mj be LinAlgCore.get_matrix_element with t_sine and m_idx and j
                Let cosine_im be LinAlgCore.get_matrix_element with t_cosine and i and m_idx
                Let cosine_mj be LinAlgCore.get_matrix_element with t_cosine and m_idx and j
                
                Note: sine(A+B) is equal to sin(A)cos(B) plus cos(A)sin(B)
                Set sum_sine to sum_sine plus sine_im multiplied by cosine_mj plus cosine_im multiplied by sine_mj
                Note: cos(A+B) is equal to cos(A)cos(B) minus sin(A)sin(B)
                Set sum_cosine to sum_cosine plus cosine_im multiplied by cosine_mj minus sine_im multiplied by sine_mj
                
                Set m_idx to m_idx plus 1
            
            Let t_ii be LinAlgCore.get_matrix_element with t_matrix and i and i
            Let t_jj be LinAlgCore.get_matrix_element with t_matrix and j and j
            Let t_ij be LinAlgCore.get_matrix_element with t_matrix and i and j
            
            Note: Divide by (λ_j minus λ_i) where λ are eigenvalues
            Let eigenval_diff be t_jj minus t_ii
            If Math.abs with eigenval_diff is less than 1e-14:
                Note: Handle repeated eigenvalues using L'Hopital's rule
                Let sine_ii be LinAlgCore.get_matrix_element with t_sine and i and i
                Let cosine_ii be LinAlgCore.get_matrix_element with t_cosine and i and i
                Set t_sine at i and j to t_ij multiplied by cosine_ii plus sum_sine
                Set t_cosine at i and j to -t_ij multiplied by sine_ii plus sum_cosine
            Otherwise:
                Set t_sine at i and j to (t_ij multiplied by (LinAlgCore.get_matrix_element with t_cosine and j and j) plus sum_sine) / eigenval_diff
                Set t_cosine at i and j to (-t_ij multiplied by (LinAlgCore.get_matrix_element with t_sine and j and j) plus sum_cosine) / eigenval_diff
            
            Set i to i plus 1
        Set k to k plus 1
    
    Note: Transform back: sin(A) is equal to Q multiplied by sin(T) multiplied by Q^T, cos(A) is equal to Q multiplied by cos(T) multiplied by Q^T
    Let q_transpose be LinAlgCore.matrix_transpose with q_matrix
    
    Let q_sine_t be LinAlgCore.multiply_matrices with q_matrix and t_sine
    Let sine_result be LinAlgCore.multiply_matrices with q_sine_t and q_transpose
    
    Let q_cosine_t be LinAlgCore.multiply_matrices with q_matrix and t_cosine
    Let cosine_result be LinAlgCore.multiply_matrices with q_cosine_t and q_transpose
    
    Note: Verify results using fundamental identity: sin²(A) plus cos²(A) is equal to I
    Let sine_squared be LinAlgCore.multiply_matrices with sine_result and sine_result
    Let cosine_squared be LinAlgCore.multiply_matrices with cosine_result and cosine_result
    Let identity_check be LinAlgCore.matrix_add with sine_squared and cosine_squared
    Let identity_matrix be LinAlgCore.create_identity_matrix with n
    Let identity_error be LinAlgCore.matrix_frobenius_norm with LinAlgCore.matrix_subtract with identity_check and identity_matrix
    
    If identity_error is greater than 1e-10:
        Throw Errors.NumericalInstability with "Matrix sine/cosine failed fundamental identity check"
    
    Let result be Dictionary.new
    Set result["sine"] to sine_result
    Set result["cosine"] to cosine_result
    Set result["identity_error"] to LinAlgCore.create_scalar_matrix with identity_error
    Return result

Note: =====================================================================
Note: ITERATIVE REFINEMENT OPERATIONS
Note: =====================================================================

Process called "iterative_refinement_lu" that takes original_matrix as Matrix, lu_decomp as LUDecomposition, solution as Vector, right_hand_side as Vector, max_iterations as Integer returns Vector:
    Note: Improve solution accuracy using iterative refinement
    Note: Solves Ax is equal to b iteratively by computing residuals and corrections
    Note: x_{k+1} is equal to x_k plus δx_k where A multiplied by δx_k is equal to r_k and r_k is equal to b minus A multiplied by x_k
    
    Let n be LinAlgCore.get_vector_length with solution
    Let current_solution be LinAlgCore.copy_vector with solution
    Let tolerance be 1e-12
    Let min_improvement be 1e-15
    
    Note: Extract LU factors
    Let l_matrix be LinAlgCore.get_dictionary_matrix with lu_decomp and "L"
    Let u_matrix be LinAlgCore.get_dictionary_matrix with lu_decomp and "U" 
    Let p_matrix be LinAlgCore.get_dictionary_matrix with lu_decomp and "P"
    
    Note: Compute initial residual: r_0 is equal to b minus A multiplied by x_0
    Let ax_product be LinAlgCore.matrix_vector_multiply with original_matrix and current_solution
    Let current_residual be LinAlgCore.vector_subtract with right_hand_side and ax_product
    Let initial_residual_norm be LinAlgCore.vector_norm with current_residual
    
    If initial_residual_norm is less than tolerance:
        Return current_solution
    
    Let iteration be 0
    Let previous_residual_norm be initial_residual_norm
    
    While iteration is less than max_iterations:
        Note: Solve P multiplied by A multiplied by δx is equal to residual using LU decomposition
        Note: First solve L multiplied by y is equal to P multiplied by residual
        Let p_residual be LinAlgCore.matrix_vector_multiply with p_matrix and current_residual
        Let y_vector be LinAlgCore.create_zero_vector with n
        
        Note: Forward substitution for L multiplied by y is equal to P multiplied by residual
        Let i be 0
        While i is less than n:
            Let sum_val be 0.0
            Let j be 0
            While j is less than i:
                Let l_ij be LinAlgCore.get_matrix_element with l_matrix and i and j
                Let y_j be LinAlgCore.get_vector_element with y_vector and j
                Set sum_val to sum_val plus l_ij multiplied by y_j
                Set j to j plus 1
            
            Let l_ii be LinAlgCore.get_matrix_element with l_matrix and i and i
            Let p_res_i be LinAlgCore.get_vector_element with p_residual and i
            Set y_vector at i to (p_res_i minus sum_val) / l_ii
            Set i to i plus 1
        
        Note: Now solve U multiplied by δx is equal to y
        Let delta_x be LinAlgCore.create_zero_vector with n
        
        Note: Backward substitution for U multiplied by δx is equal to y
        Let i be n minus 1
        While i is greater than or equal to 0:
            Let sum_val be 0.0
            Let j be i plus 1
            While j is less than n:
                Let u_ij be LinAlgCore.get_matrix_element with u_matrix and i and j
                Let delta_x_j be LinAlgCore.get_vector_element with delta_x and j
                Set sum_val to sum_val plus u_ij multiplied by delta_x_j
                Set j to j plus 1
            
            Let u_ii be LinAlgCore.get_matrix_element with u_matrix and i and i
            Let y_i be LinAlgCore.get_vector_element with y_vector and i
            Set delta_x at i to (y_i minus sum_val) / u_ii
            Set i to i minus 1
        
        Note: Update solution: x_{k+1} is equal to x_k plus δx_k
        Set current_solution to LinAlgCore.vector_add with current_solution and delta_x
        
        Note: Compute new residual: r_{k+1} is equal to b minus A multiplied by x_{k+1}
        Set ax_product to LinAlgCore.matrix_vector_multiply with original_matrix and current_solution
        Set current_residual to LinAlgCore.vector_subtract with right_hand_side and ax_product
        Let current_residual_norm be LinAlgCore.vector_norm with current_residual
        
        Note: Check convergence
        If current_residual_norm is less than tolerance:
            Return current_solution
        
        Note: Check for stagnation
        Let improvement be previous_residual_norm minus current_residual_norm
        If improvement is less than min_improvement:
            Return current_solution
        
        Note: Check for divergence
        If current_residual_norm is greater than previous_residual_norm multiplied by 10.0:
            Throw Errors.NumericalError with "Iterative refinement diverging"
        
        Set previous_residual_norm to current_residual_norm
        Set iteration to iteration plus 1
    
    Note: Maximum iterations reached
    Return current_solution

Process called "iterative_refinement_cholesky" that takes original_matrix as Matrix, chol_decomp as CholeskyDecomposition, solution as Vector, right_hand_side as Vector, max_iterations as Integer returns Vector:
    Note: Improve Cholesky solution using iterative refinement
    Note: For symmetric positive definite matrices, solves Ax is equal to b where A is equal to L multiplied by L^T
    Note: Iteratively computes corrections using residuals for improved accuracy
    
    Let n be LinAlgCore.get_vector_length with solution
    Let current_solution be LinAlgCore.copy_vector with solution
    Let tolerance be 1e-12
    Let min_improvement be 1e-15
    
    Note: Extract Cholesky factor L
    Let l_matrix be LinAlgCore.get_dictionary_matrix with chol_decomp and "L"
    
    Note: Compute initial residual: r_0 is equal to b minus A multiplied by x_0
    Let ax_product be LinAlgCore.matrix_vector_multiply with original_matrix and current_solution
    Let current_residual be LinAlgCore.vector_subtract with right_hand_side and ax_product
    Let initial_residual_norm be LinAlgCore.vector_norm with current_residual
    
    If initial_residual_norm is less than tolerance:
        Return current_solution
    
    Let iteration be 0
    Let previous_residual_norm be initial_residual_norm
    
    While iteration is less than max_iterations:
        Note: Solve A multiplied by δx is equal to residual using Cholesky: L multiplied by L^T multiplied by δx is equal to residual
        Note: First solve L multiplied by y is equal to residual (forward substitution)
        Let y_vector be LinAlgCore.create_zero_vector with n
        
        Let i be 0
        While i is less than n:
            Let sum_val be 0.0
            Let j be 0
            While j is less than i:
                Let l_ij be LinAlgCore.get_matrix_element with l_matrix and i and j
                Let y_j be LinAlgCore.get_vector_element with y_vector and j
                Set sum_val to sum_val plus l_ij multiplied by y_j
                Set j to j plus 1
            
            Let l_ii be LinAlgCore.get_matrix_element with l_matrix and i and i
            Let residual_i be LinAlgCore.get_vector_element with current_residual and i
            Set y_vector at i to (residual_i minus sum_val) / l_ii
            Set i to i plus 1
        
        Note: Now solve L^T multiplied by δx is equal to y (backward substitution)
        Let delta_x be LinAlgCore.create_zero_vector with n
        
        Let i be n minus 1
        While i is greater than or equal to 0:
            Let sum_val be 0.0
            Let j be i plus 1
            While j is less than n:
                Let l_ji be LinAlgCore.get_matrix_element with l_matrix and j and i
                Let delta_x_j be LinAlgCore.get_vector_element with delta_x and j
                Set sum_val to sum_val plus l_ji multiplied by delta_x_j
                Set j to j plus 1
            
            Let l_ii be LinAlgCore.get_matrix_element with l_matrix and i and i
            Let y_i be LinAlgCore.get_vector_element with y_vector and i
            Set delta_x at i to (y_i minus sum_val) / l_ii
            Set i to i minus 1
        
        Note: Update solution: x_{k+1} is equal to x_k plus δx_k
        Set current_solution to LinAlgCore.vector_add with current_solution and delta_x
        
        Note: Compute new residual: r_{k+1} is equal to b minus A multiplied by x_{k+1}
        Set ax_product to LinAlgCore.matrix_vector_multiply with original_matrix and current_solution
        Set current_residual to LinAlgCore.vector_subtract with right_hand_side and ax_product
        Let current_residual_norm be LinAlgCore.vector_norm with current_residual
        
        Note: Check convergence
        If current_residual_norm is less than tolerance:
            Return current_solution
        
        Note: Check for stagnation
        Let improvement be previous_residual_norm minus current_residual_norm
        If improvement is less than min_improvement:
            Return current_solution
        
        Note: Check for divergence (should be rare with Cholesky due to stability)
        If current_residual_norm is greater than previous_residual_norm multiplied by 10.0:
            Throw Errors.NumericalError with "Cholesky iterative refinement diverging"
        
        Set previous_residual_norm to current_residual_norm
        Set iteration to iteration plus 1
    
    Note: Maximum iterations reached
    Return current_solution

Process called "mixed_precision_refinement" that takes low_precision_solution as Vector, high_precision_matrix as Matrix, right_hand_side as Vector returns Vector:
    Note: Use mixed precision for iterative refinement
    Note: Computes residuals in high precision while solving corrections in lower precision
    Note: This approach balances accuracy with computational efficiency
    
    Let n be LinAlgCore.get_vector_length with low_precision_solution
    Let current_solution be LinAlgCore.copy_vector with low_precision_solution
    Let max_iterations be 5
    Let tolerance be 1e-10
    Let min_improvement be 1e-14
    
    Note: Convert inputs to high precision for residual computation
    Let hp_solution be LinAlgCore.convert_to_high_precision_vector with current_solution
    Let hp_rhs be LinAlgCore.convert_to_high_precision_vector with right_hand_side
    
    Let iteration be 0
    Let previous_residual_norm be 1e100
    
    While iteration is less than max_iterations:
        Note: Compute residual in high precision: r is equal to b minus A multiplied by x
        Let hp_ax_product be LinAlgCore.matrix_vector_multiply with high_precision_matrix and hp_solution
        Let hp_residual be LinAlgCore.vector_subtract with hp_rhs and hp_ax_product
        Let residual_norm be LinAlgCore.vector_norm with hp_residual
        
        Note: Check convergence
        If residual_norm is less than tolerance:
            Return LinAlgCore.convert_to_standard_precision_vector with hp_solution
        
        Note: Check for stagnation
        Let improvement be previous_residual_norm minus residual_norm
        If improvement is less than min_improvement:
            Return LinAlgCore.convert_to_standard_precision_vector with hp_solution
        
        Note: Convert residual back to standard precision for efficient solving
        Let lp_residual be LinAlgCore.convert_to_standard_precision_vector with hp_residual
        
        Note: Create low-precision version of matrix for efficient solving
        Let lp_matrix be LinAlgCore.convert_to_standard_precision_matrix with high_precision_matrix
        
        Note: Solve correction equation A multiplied by δx is equal to r in standard precision using LU
        Let lu_result be lu_with_partial_pivoting with lp_matrix
        Let l_matrix be LinAlgCore.get_dictionary_matrix with lu_result and "L"
        Let u_matrix be LinAlgCore.get_dictionary_matrix with lu_result and "U"
        Let p_matrix be LinAlgCore.get_dictionary_matrix with lu_result and "P"
        
        Note: Solve P multiplied by A multiplied by δx is equal to residual
        Let p_residual be LinAlgCore.matrix_vector_multiply with p_matrix and lp_residual
        Let y_vector be LinAlgCore.create_zero_vector with n
        
        Note: Forward substitution: L multiplied by y is equal to P multiplied by residual
        Let i be 0
        While i is less than n:
            Let sum_val be 0.0
            Let j be 0
            While j is less than i:
                Let l_ij be LinAlgCore.get_matrix_element with l_matrix and i and j
                Let y_j be LinAlgCore.get_vector_element with y_vector and j
                Set sum_val to sum_val plus l_ij multiplied by y_j
                Set j to j plus 1
            
            Let l_ii be LinAlgCore.get_matrix_element with l_matrix and i and i
            Let p_res_i be LinAlgCore.get_vector_element with p_residual and i
            Set y_vector at i to (p_res_i minus sum_val) / l_ii
            Set i to i plus 1
        
        Note: Backward substitution: U multiplied by δx is equal to y
        Let lp_delta_x be LinAlgCore.create_zero_vector with n
        
        Let i be n minus 1
        While i is greater than or equal to 0:
            Let sum_val be 0.0
            Let j be i plus 1
            While j is less than n:
                Let u_ij be LinAlgCore.get_matrix_element with u_matrix and i and j
                Let delta_x_j be LinAlgCore.get_vector_element with lp_delta_x and j
                Set sum_val to sum_val plus u_ij multiplied by delta_x_j
                Set j to j plus 1
            
            Let u_ii be LinAlgCore.get_matrix_element with u_matrix and i and i
            Let y_i be LinAlgCore.get_vector_element with y_vector and i
            Set lp_delta_x at i to (y_i minus sum_val) / u_ii
            Set i to i minus 1
        
        Note: Convert correction to high precision and update solution
        Let hp_delta_x be LinAlgCore.convert_to_high_precision_vector with lp_delta_x
        Set hp_solution to LinAlgCore.vector_add with hp_solution and hp_delta_x
        
        Note: Update standard precision solution for user
        Set current_solution to LinAlgCore.convert_to_standard_precision_vector with hp_solution
        
        Set previous_residual_norm to residual_norm
        Set iteration to iteration plus 1
    
    Note: Return best solution found
    Return LinAlgCore.convert_to_standard_precision_vector with hp_solution

Note: =====================================================================
Note: CONDITION NUMBER AND STABILITY
Note: =====================================================================

Process called "condition_number_estimate" that takes decomposition as LUDecomposition, norm_type as String returns String:
    Note: Estimate condition number from LU decomposition
    Note: Uses Hager-Higham algorithm for 1-norm or simple estimates for other norms
    Note: Condition number κ(A) is equal to ||A|| multiplied by ||A^(-1)|| indicates numerical stability
    
    Let l_matrix be LinAlgCore.get_dictionary_matrix with decomposition and "L"
    Let u_matrix be LinAlgCore.get_dictionary_matrix with decomposition and "U"
    Let p_matrix be LinAlgCore.get_dictionary_matrix with decomposition and "P"
    Let n be LinAlgCore.get_matrix_rows with l_matrix
    
    Note: Estimate matrix 1-norm using existing matrix
    Let reconstructed_matrix be LinAlgCore.multiply_matrices with l_matrix and u_matrix
    Let matrix_norm be 0.0
    
    If norm_type is equal to "1" or norm_type is equal to "one":
        Note: Compute 1-norm: max column sum
        Let j be 0
        While j is less than n:
            Let column_sum be 0.0
            Let i be 0
            While i is less than n:
                Let element be LinAlgCore.get_matrix_element with reconstructed_matrix and i and j
                Set column_sum to column_sum plus Math.abs with element
                Set i to i plus 1
            If column_sum is greater than matrix_norm:
                Set matrix_norm to column_sum
            Set j to j plus 1
        
        Note: Estimate ||A^(-1)||_1 using Hager-Higham algorithm
        Let inverse_norm_estimate be 0.0
        Let max_iterations be 5
        Let iteration be 0
        Let x_vector be LinAlgCore.create_ones_vector with n
        
        While iteration is less than max_iterations:
            Note: Solve A multiplied by y is equal to x using LU
            Let p_x be LinAlgCore.matrix_vector_multiply with p_matrix and x_vector
            Let y_temp be LinAlgCore.create_zero_vector with n
            
            Note: Forward substitution: L multiplied by z is equal to P multiplied by x
            Let i be 0
            While i is less than n:
                Let sum_val be 0.0
                Let j be 0
                While j is less than i:
                    Let l_ij be LinAlgCore.get_matrix_element with l_matrix and i and j
                    Let z_j be LinAlgCore.get_vector_element with y_temp and j
                    Set sum_val to sum_val plus l_ij multiplied by z_j
                    Set j to j plus 1
                
                Let l_ii be LinAlgCore.get_matrix_element with l_matrix and i and i
                Let px_i be LinAlgCore.get_vector_element with p_x and i
                Set y_temp at i to (px_i minus sum_val) / l_ii
                Set i to i plus 1
            
            Note: Backward substitution: U multiplied by y is equal to z
            Let y_vector be LinAlgCore.create_zero_vector with n
            Let i be n minus 1
            While i is greater than or equal to 0:
                Let sum_val be 0.0
                Let j be i plus 1
                While j is less than n:
                    Let u_ij be LinAlgCore.get_matrix_element with u_matrix and i and j
                    Let y_j be LinAlgCore.get_vector_element with y_vector and j
                    Set sum_val to sum_val plus u_ij multiplied by y_j
                    Set j to j plus 1
                
                Let u_ii be LinAlgCore.get_matrix_element with u_matrix and i and i
                Let z_i be LinAlgCore.get_vector_element with y_temp and i
                Set y_vector at i to (z_i minus sum_val) / u_ii
                Set i to i minus 1
            
            Let y_norm be LinAlgCore.vector_1_norm with y_vector
            If y_norm is greater than inverse_norm_estimate:
                Set inverse_norm_estimate to y_norm
            
            Note: Update x for next iteration
            Let i be 0
            While i is less than n:
                Let y_val be LinAlgCore.get_vector_element with y_vector and i
                If y_val is greater than or equal to 0.0:
                    Set x_vector at i to 1.0
                Otherwise:
                    Set x_vector at i to -1.0
                Set i to i plus 1
            
            Set iteration to iteration plus 1
        
        Let condition_number be matrix_norm multiplied by inverse_norm_estimate
        Return String.from_float with condition_number
    
    Otherwise:
        If norm_type is equal to "inf" or norm_type is equal to "infinity":
            Note: Compute infinity-norm: max row sum  
            Let i be 0
            While i is less than n:
                Let row_sum be 0.0
                Let j be 0
                While j is less than n:
                    Let element be LinAlgCore.get_matrix_element with reconstructed_matrix and i and j
                    Set row_sum to row_sum plus Math.abs with element
                    Set j to j plus 1
                If row_sum is greater than matrix_norm:
                    Set matrix_norm to row_sum
                Set i to i plus 1
            
            Note: Simple estimate for inverse infinity norm (less accurate but fast)
            Let min_diag_u be 1e100
            Let i be 0
            While i is less than n:
                Let u_ii be LinAlgCore.get_matrix_element with u_matrix and i and i
                Let abs_u_ii be Math.abs with u_ii
                If abs_u_ii is less than min_diag_u:
                    Set min_diag_u to abs_u_ii
                Set i to i plus 1
            
            Let inverse_estimate be 1.0 / min_diag_u
            Let condition_number be matrix_norm multiplied by inverse_estimate
            Return String.from_float with condition_number
        
        Otherwise:
            If norm_type is equal to "2" or norm_type is equal to "spectral":
                Note: For 2-norm, need singular values (expensive) minus use rough estimate
                Let max_diag_u be 0.0
                Let min_diag_u be 1e100
                Let i be 0
                While i is less than n:
                    Let u_ii be LinAlgCore.get_matrix_element with u_matrix and i and i
                    Let abs_u_ii be Math.abs with u_ii
                    If abs_u_ii is greater than max_diag_u:
                        Set max_diag_u to abs_u_ii
                    If abs_u_ii is less than min_diag_u:
                        Set min_diag_u to abs_u_ii
                    Set i to i plus 1
                
                Let condition_estimate be max_diag_u / min_diag_u
                Return String.from_float with condition_estimate
            
            Otherwise:
                Throw Errors.InvalidNormType with "Unknown norm type for condition number estimation"

Process called "backward_error_analysis" that takes original_matrix as Matrix, decomposition_result as Dictionary[String, Matrix], operation_type as String returns Dictionary[String, Float]:
    Note: Analyze backward error of decomposition
    Note: Computes ||A minus reconstructed||/||A|| to measure reconstruction accuracy
    Note: Also analyzes growth factors and other stability indicators
    
    Let m be LinAlgCore.get_matrix_rows with original_matrix
    Let n be LinAlgCore.get_matrix_cols with original_matrix
    Let result be Dictionary.new
    
    If operation_type is equal to "lu":
        Let l_matrix be LinAlgCore.get_dictionary_matrix with decomposition_result and "L"
        Let u_matrix be LinAlgCore.get_dictionary_matrix with decomposition_result and "U"
        Let p_matrix be LinAlgCore.get_dictionary_matrix with decomposition_result and "P"
        
        Note: Compute PA minus LU
        Let pa_matrix be LinAlgCore.multiply_matrices with p_matrix and original_matrix
        Let lu_matrix be LinAlgCore.multiply_matrices with l_matrix and u_matrix
        Let residual_matrix be LinAlgCore.matrix_subtract with pa_matrix and lu_matrix
        
        Let residual_norm be LinAlgCore.matrix_frobenius_norm with residual_matrix
        Let original_norm be LinAlgCore.matrix_frobenius_norm with original_matrix
        Let relative_error be residual_norm / original_norm
        Set result["relative_error"] to relative_error
        Set result["residual_norm"] to residual_norm
        
        Note: Compute growth factor: max|U_ij| / max|A_ij|
        Let max_original be 0.0
        Let max_u be 0.0
        Let i be 0
        While i is less than m:
            Let j be 0
            While j is less than n:
                Let orig_elem be Math.abs with LinAlgCore.get_matrix_element with original_matrix and i and j
                If orig_elem is greater than max_original:
                    Set max_original to orig_elem
                If i is less than n and j is less than n:
                    Let u_elem be Math.abs with LinAlgCore.get_matrix_element with u_matrix and i and j
                    If u_elem is greater than max_u:
                        Set max_u to u_elem
                Set j to j plus 1
            Set i to i plus 1
        
        Let growth_factor be max_u / max_original
        Set result["growth_factor"] to growth_factor
        
        Note: Check pivot sizes for stability indicator
        Let min_pivot be 1e100
        Let max_pivot be 0.0
        Let i be 0
        While i is less than n:
            Let u_ii be Math.abs with LinAlgCore.get_matrix_element with u_matrix and i and i
            If u_ii is less than min_pivot:
                Set min_pivot to u_ii
            If u_ii is greater than max_pivot:
                Set max_pivot to u_ii
            Set i to i plus 1
        
        Let pivot_ratio be max_pivot / min_pivot
        Set result["pivot_ratio"] to pivot_ratio
        Set result["min_pivot"] to min_pivot
    
    Otherwise:
        If operation_type is equal to "qr":
            Let q_matrix be LinAlgCore.get_dictionary_matrix with decomposition_result and "Q"
            Let r_matrix be LinAlgCore.get_dictionary_matrix with decomposition_result and "R"
            
            Note: Compute A minus QR
            Let qr_matrix be LinAlgCore.multiply_matrices with q_matrix and r_matrix
            Let residual_matrix be LinAlgCore.matrix_subtract with original_matrix and qr_matrix
            
            Let residual_norm be LinAlgCore.matrix_frobenius_norm with residual_matrix
            Let original_norm be LinAlgCore.matrix_frobenius_norm with original_matrix
            Let relative_error be residual_norm / original_norm
            Set result["relative_error"] to relative_error
            Set result["residual_norm"] to residual_norm
            
            Note: Check orthogonality of Q: ||Q^T multiplied by Q minus I||
            Let q_transpose be LinAlgCore.matrix_transpose with q_matrix
            Let qtq_matrix be LinAlgCore.multiply_matrices with q_transpose and q_matrix
            Let q_cols be LinAlgCore.get_matrix_cols with q_matrix
            Let identity_matrix be LinAlgCore.create_identity_matrix with q_cols
            Let orthogonality_error_matrix be LinAlgCore.matrix_subtract with qtq_matrix and identity_matrix
            Let orthogonality_error be LinAlgCore.matrix_frobenius_norm with orthogonality_error_matrix
            Set result["orthogonality_error"] to orthogonality_error
            
            Note: Check R diagonal elements for conditioning
            Let min_r_diag be 1e100
            Let max_r_diag be 0.0
            Let r_rows be LinAlgCore.get_matrix_rows with r_matrix
            Let r_cols be LinAlgCore.get_matrix_cols with r_matrix
            Let min_dim be r_rows
            If r_cols is less than min_dim:
                Set min_dim to r_cols
            
            Let i be 0
            While i is less than min_dim:
                Let r_ii be Math.abs with LinAlgCore.get_matrix_element with r_matrix and i and i
                If r_ii is less than min_r_diag:
                    Set min_r_diag to r_ii
                If r_ii is greater than max_r_diag:
                    Set max_r_diag to r_ii
                Set i to i plus 1
            
            Let r_condition be max_r_diag / min_r_diag
            Set result["r_condition"] to r_condition
        
        Otherwise:
            If operation_type is equal to "cholesky":
                Let l_matrix be LinAlgCore.get_dictionary_matrix with decomposition_result and "L"
                
                Note: Compute A minus L multiplied by L^T
                Let l_transpose be LinAlgCore.matrix_transpose with l_matrix
                Let llt_matrix be LinAlgCore.multiply_matrices with l_matrix and l_transpose
                Let residual_matrix be LinAlgCore.matrix_subtract with original_matrix and llt_matrix
                
                Let residual_norm be LinAlgCore.matrix_frobenius_norm with residual_matrix
                Let original_norm be LinAlgCore.matrix_frobenius_norm with original_matrix
                Let relative_error be residual_norm / original_norm
                Set result["relative_error"] to relative_error
                Set result["residual_norm"] to residual_norm
                
                Note: Check diagonal elements for positive definiteness indicators
                Let min_diag be 1e100
                Let max_diag be 0.0
                Let i be 0
                While i is less than n:
                    Let l_ii be LinAlgCore.get_matrix_element with l_matrix and i and i
                    If l_ii is less than min_diag:
                        Set min_diag to l_ii
                    If l_ii is greater than max_diag:
                        Set max_diag to l_ii
                    Set i to i plus 1
                
                Let diagonal_ratio be max_diag / min_diag
                Set result["diagonal_ratio"] to diagonal_ratio
                Set result["min_diagonal"] to min_diag
            
            Otherwise:
                If operation_type is equal to "svd":
                    Let u_matrix be LinAlgCore.get_dictionary_matrix with decomposition_result and "U"
                    Let s_matrix be LinAlgCore.get_dictionary_matrix with decomposition_result and "S"
                    Let v_matrix be LinAlgCore.get_dictionary_matrix with decomposition_result and "V"
                    
                    Note: Compute A minus U multiplied by S multiplied by V^T
                    Let v_transpose be LinAlgCore.matrix_transpose with v_matrix
                    Let us_matrix be LinAlgCore.multiply_matrices with u_matrix and s_matrix
                    Let usvt_matrix be LinAlgCore.multiply_matrices with us_matrix and v_transpose
                    Let residual_matrix be LinAlgCore.matrix_subtract with original_matrix and usvt_matrix
                    
                    Let residual_norm be LinAlgCore.matrix_frobenius_norm with residual_matrix
                    Let original_norm be LinAlgCore.matrix_frobenius_norm with original_matrix
                    Let relative_error be residual_norm / original_norm
                    Set result["relative_error"] to relative_error
                    Set result["residual_norm"] to residual_norm
                    
                    Note: Check orthogonality of U and V
                    Let u_transpose be LinAlgCore.matrix_transpose with u_matrix
                    Let utu_matrix be LinAlgCore.multiply_matrices with u_transpose and u_matrix
                    Let u_rows be LinAlgCore.get_matrix_rows with u_matrix
                    Let u_identity be LinAlgCore.create_identity_matrix with u_rows
                    Let u_orthogonality_error_matrix be LinAlgCore.matrix_subtract with utu_matrix and u_identity
                    Let u_orthogonality_error be LinAlgCore.matrix_frobenius_norm with u_orthogonality_error_matrix
                    Set result["u_orthogonality_error"] to u_orthogonality_error
                    
                    Let vtv_matrix be LinAlgCore.multiply_matrices with v_transpose and v_matrix
                    Let v_cols be LinAlgCore.get_matrix_cols with v_matrix
                    Let v_identity be LinAlgCore.create_identity_matrix with v_cols
                    Let v_orthogonality_error_matrix be LinAlgCore.matrix_subtract with vtv_matrix and v_identity
                    Let v_orthogonality_error be LinAlgCore.matrix_frobenius_norm with v_orthogonality_error_matrix
                    Set result["v_orthogonality_error"] to v_orthogonality_error
                    
                    Note: Singular value condition number
                    Let max_singular be 0.0
                    Let min_singular be 1e100
                    Let s_rows be LinAlgCore.get_matrix_rows with s_matrix
                    Let s_cols be LinAlgCore.get_matrix_cols with s_matrix
                    Let min_dim be s_rows
                    If s_cols is less than min_dim:
                        Set min_dim to s_cols
                    
                    Let i be 0
                    While i is less than min_dim:
                        Let s_ii be LinAlgCore.get_matrix_element with s_matrix and i and i
                        If s_ii is greater than max_singular:
                            Set max_singular to s_ii
                        If s_ii is less than min_singular and s_ii is greater than 1e-15:
                            Set min_singular to s_ii
                        Set i to i plus 1
                    
                    Let singular_condition be max_singular / min_singular
                    Set result["singular_condition"] to singular_condition
                
                Otherwise:
                    Throw Errors.InvalidOperationType with "Unknown operation type for backward error analysis"
    
    Return result

Process called "stability_analysis" that takes matrix as Matrix, decomposition_type as String returns Dictionary[String, String]:
    Note: Analyze numerical stability of decomposition for given matrix
    Note: Provides recommendations on which decomposition method to use based on matrix properties
    Note: Analyzes condition number, sparsity, symmetry, and other structural properties
    
    Let m be LinAlgCore.get_matrix_rows with matrix
    Let n be LinAlgCore.get_matrix_cols with matrix
    Let result be Dictionary.new
    
    Note: Basic matrix properties
    Let matrix_norm be LinAlgCore.matrix_frobenius_norm with matrix
    Let is_square be m is equal to n
    Set result["is_square"] to String.from_boolean with is_square
    Set result["matrix_norm"] to String.from_float with matrix_norm
    
    Note: Check if matrix is symmetric (for square matrices)
    Let is_symmetric be false
    If is_square:
        Set is_symmetric to true
        Let i be 0
        While i is less than m and is_symmetric:
            Let j be 0
            While j is less than n and is_symmetric:
                Let aij be LinAlgCore.get_matrix_element with matrix and i and j
                Let aji be LinAlgCore.get_matrix_element with matrix and j and i
                If Math.abs with (aij minus aji) is greater than 1e-12:
                    Set is_symmetric to false
                Set j to j plus 1
            Set i to i plus 1
    Set result["is_symmetric"] to String.from_boolean with is_symmetric
    
    Note: Check for positive definiteness (crude test via diagonal dominance)
    Let appears_positive_definite be false
    If is_square and is_symmetric:
        Set appears_positive_definite to true
        Let i be 0
        While i is less than n and appears_positive_definite:
            Let aii be LinAlgCore.get_matrix_element with matrix and i and i
            If aii is less than or equal to 0.0:
                Set appears_positive_definite to false
            Otherwise:
                Note: Check diagonal dominance as a rough indicator
                Let row_sum be 0.0
                Let j be 0
                While j is less than n:
                    If i does not equal j:
                        Let aij be Math.abs with LinAlgCore.get_matrix_element with matrix and i and j
                        Set row_sum to row_sum plus aij
                    Set j to j plus 1
                If aii is less than or equal to row_sum:
                    Set appears_positive_definite to false
            Set i to i plus 1
    Set result["appears_positive_definite"] to String.from_boolean with appears_positive_definite
    
    Note: Compute rough condition number estimate
    Let condition_estimate be "unknown"
    If is_square:
        Let max_element be 0.0
        Let min_diag be 1e100
        Let i be 0
        While i is less than n:
            Let j be 0
            While j is less than n:
                Let element be Math.abs with LinAlgCore.get_matrix_element with matrix and i and j
                If element is greater than max_element:
                    Set max_element to element
                Set j to j plus 1
            Let aii be Math.abs with LinAlgCore.get_matrix_element with matrix and i and i
            If aii is less than min_diag and aii is greater than 1e-15:
                Set min_diag to aii
            Set i to i plus 1
        
        Let rough_condition be max_element / min_diag
        Set condition_estimate to String.from_float with rough_condition
    Set result["condition_estimate"] to condition_estimate
    
    Note: Count zero/near-zero elements for sparsity analysis
    Let zero_count be 0
    Let total_elements be m multiplied by n
    Let i be 0
    While i is less than m:
        Let j be 0
        While j is less than n:
            Let element be Math.abs with LinAlgCore.get_matrix_element with matrix and i and j
            If element is less than 1e-14:
                Set zero_count to zero_count plus 1
            Set j to j plus 1
        Set i to i plus 1
    
    Let sparsity_ratio be (Float.from_integer with zero_count) / (Float.from_integer with total_elements)
    Set result["sparsity_ratio"] to String.from_float with sparsity_ratio
    Let is_sparse be sparsity_ratio is greater than 0.5
    Set result["is_sparse"] to String.from_boolean with is_sparse
    
    Note: Provide stability recommendations based on analysis
    If decomposition_type is equal to "lu":
        If is_square:
            If appears_positive_definite:
                Set result["recommendation"] to "Consider Cholesky decomposition for better stability"
                Set result["stability_rating"] to "good-alternative-available"
            Otherwise:
                If String.to_float with condition_estimate is greater than 1e12:
                    Set result["recommendation"] to "Matrix is ill-conditioned minus use pivoting and iterative refinement"
                    Set result["stability_rating"] to "poor-conditioning"
                Otherwise:
                    If is_sparse:
                        Set result["recommendation"] to "LU with partial pivoting suitable, consider sparse methods"
                        Set result["stability_rating"] to "good"
                    Otherwise:
                        Set result["recommendation"] to "LU with partial pivoting is appropriate"
                        Set result["stability_rating"] to "good"
        Otherwise:
            Set result["recommendation"] to "LU decomposition requires square matrix minus use QR instead"
            Set result["stability_rating"] to "not-applicable"
    
    Otherwise:
        If decomposition_type is equal to "qr":
            If m is greater than or equal to n:
                Set result["recommendation"] to "QR decomposition is numerically stable for this matrix"
                Set result["stability_rating"] to "excellent"
            Otherwise:
                Set result["recommendation"] to "Matrix is fat (more columns than rows) minus consider transpose"
                Set result["stability_rating"] to "suboptimal-dimensions"
        
        Otherwise:
            If decomposition_type is equal to "cholesky":
                If is_square and is_symmetric:
                    If appears_positive_definite:
                        Set result["recommendation"] to "Cholesky decomposition is ideal for this matrix"
                        Set result["stability_rating"] to "excellent"
                    Otherwise:
                        Set result["recommendation"] to "Matrix may not be positive definite minus use LU or modified Cholesky"
                        Set result["stability_rating"] to "not-suitable"
                Otherwise:
                    Set result["recommendation"] to "Cholesky requires symmetric positive definite matrix"
                    Set result["stability_rating"] to "not-applicable"
            
            Otherwise:
                If decomposition_type is equal to "svd":
                    Set result["recommendation"] to "SVD is numerically stable but computationally expensive"
                    If String.to_float with condition_estimate is greater than 1e10:
                        Set result["stability_rating"] to "excellent-for-ill-conditioned"
                    Otherwise:
                        Set result["stability_rating"] to "good-but-expensive"
                
                Otherwise:
                    If decomposition_type is equal to "eigenvalue":
                        If is_square and is_symmetric:
                            Set result["recommendation"] to "Eigenvalue decomposition suitable for symmetric matrices"
                            Set result["stability_rating"] to "good"
                        Otherwise:
                            Set result["recommendation"] to "Non-symmetric eigenvalue problems can be unstable"
                            Set result["stability_rating"] to "potentially-unstable"
                    
                    Otherwise:
                        Set result["recommendation"] to "Unknown decomposition type"
                        Set result["stability_rating"] to "unknown"
    
    Note: Additional warnings based on matrix properties
    If String.to_float with condition_estimate is greater than 1e15:
        Set result["warning"] to "Matrix is near-singular minus all decompositions will be unstable"
    Otherwise:
        If String.to_float with condition_estimate is greater than 1e12:
            Set result["warning"] to "Matrix is ill-conditioned minus use iterative refinement"
        Otherwise:
            If sparsity_ratio is greater than 0.8:
                Set result["warning"] to "Matrix is very sparse minus consider specialized sparse algorithms"
            Otherwise:
                Set result["warning"] to "No significant stability concerns detected"
    
    Return result

Note: =====================================================================
Note: BLOCK AND PARALLEL DECOMPOSITIONS
Note: =====================================================================

Process called "block_decomposition" that takes matrix as Matrix, decomposition_type as String, block_size as Integer returns Dictionary[String, Matrix]:
    Note: Perform decomposition using block algorithms
    Note: Divides matrix into blocks for improved cache performance and numerical stability
    Note: Supports LU, QR, and Cholesky decompositions with block-wise processing
    
    Let m be LinAlgCore.get_matrix_rows with matrix
    Let n be LinAlgCore.get_matrix_cols with matrix
    
    Note: Validate block size
    If block_size is less than or equal to 0 or block_size is greater than m or block_size is greater than n:
        Throw Errors.InvalidBlockSize with "Block size must be positive and not larger than matrix dimensions"
    
    If decomposition_type is equal to "lu":
        Note: Block LU decomposition with partial pivoting
        If m does not equal n:
            Throw Errors.MatrixNotSquare with "Block LU decomposition requires square matrix"
        
        Let working_matrix be LinAlgCore.copy_matrix with matrix
        Let l_matrix be LinAlgCore.create_identity_matrix with n
        Let u_matrix be LinAlgCore.create_zero_matrix with n and n
        Let p_matrix be LinAlgCore.create_identity_matrix with n
        
        Let num_blocks be (n plus block_size minus 1) / block_size
        Let block_idx be 0
        
        While block_idx is less than num_blocks:
            Let start_row be block_idx multiplied by block_size
            Let end_row be start_row plus block_size
            If end_row is greater than n:
                Set end_row to n
            Let current_block_size be end_row minus start_row
            
            Note: Extract diagonal block
            Let diagonal_block be LinAlgCore.create_matrix with current_block_size and current_block_size
            Let i be 0
            While i is less than current_block_size:
                Let j be 0
                While j is less than current_block_size:
                    Let element be LinAlgCore.get_matrix_element with working_matrix and start_row plus i and start_row plus j
                    Set diagonal_block at i and j to element
                    Set j to j plus 1
                Set i to i plus 1
            
            Note: Decompose diagonal block using standard LU
            Let block_lu_result be lu_with_partial_pivoting with diagonal_block
            Let block_l be LinAlgCore.get_dictionary_matrix with block_lu_result and "L"
            Let block_u be LinAlgCore.get_dictionary_matrix with block_lu_result and "U"
            Let block_p be LinAlgCore.get_dictionary_matrix with block_lu_result and "P"
            
            Note: Update global L, U, and P matrices with block results
            Let i be 0
            While i is less than current_block_size:
                Let j be 0
                While j is less than current_block_size:
                    Let l_elem be LinAlgCore.get_matrix_element with block_l and i and j
                    Let u_elem be LinAlgCore.get_matrix_element with block_u and i and j
                    Set l_matrix at start_row plus i and start_row plus j to l_elem
                    Set u_matrix at start_row plus i and start_row plus j to u_elem
                    Set j to j plus 1
                Set i to i plus 1
            
            Note: Apply block permutation to global P matrix
            Let i be 0
            While i is less than current_block_size:
                Let j be 0
                While j is less than n:
                    Let p_elem be LinAlgCore.get_matrix_element with block_p and i and j
                    If j is less than current_block_size:
                        Let old_p_elem be LinAlgCore.get_matrix_element with p_matrix and start_row plus i and start_row plus j
                        Set p_matrix at start_row plus i and start_row plus j to p_elem multiplied by old_p_elem
                    Set j to j plus 1
                Set i to i plus 1
            
            Note: Update remaining blocks using block operations
            If end_row is less than n:
                Note: Process blocks to the right (U updates)
                Let right_start be end_row
                While right_start is less than n:
                    Let right_end be right_start plus block_size
                    If right_end is greater than n:
                        Set right_end to n
                    
                    Note: Solve L multiplied by X is equal to P multiplied by A[start_row:end_row, right_start:right_end]
                    Let block_rhs be LinAlgCore.create_matrix with current_block_size and right_end minus right_start
                    Let i be 0
                    While i is less than current_block_size:
                        Let j be 0
                        While j is less than right_end minus right_start:
                            Let rhs_elem be LinAlgCore.get_matrix_element with working_matrix and start_row plus i and right_start plus j
                            Set block_rhs at i and j to rhs_elem
                            Set j to j plus 1
                        Set i to i plus 1
                    
                    Note: Forward substitution to get U block
                    Let u_block_result be LinAlgCore.solve_lower_triangular with block_l and block_rhs
                    
                    Note: Update U matrix with solved block
                    Let i be 0
                    While i is less than current_block_size:
                        Let j be 0
                        While j is less than right_end minus right_start:
                            Let u_elem be LinAlgCore.get_matrix_element with u_block_result and i and j
                            Set u_matrix at start_row plus i and right_start plus j to u_elem
                            Set j to j plus 1
                        Set i to i plus 1
                    
                    Set right_start to right_end
                
                Note: Process blocks below (L updates)
                Let below_start be end_row
                While below_start is less than n:
                    Let below_end be below_start plus block_size
                    If below_end is greater than n:
                        Set below_end to n
                    
                    Note: Solve X multiplied by U is equal to A[below_start:below_end, start_row:end_row]
                    Let block_rhs be LinAlgCore.create_matrix with below_end minus below_start and current_block_size
                    Let i be 0
                    While i is less than below_end minus below_start:
                        Let j be 0
                        While j is less than current_block_size:
                            Let rhs_elem be LinAlgCore.get_matrix_element with working_matrix and below_start plus i and start_row plus j
                            Set block_rhs at i and j to rhs_elem
                            Set j to j plus 1
                        Set i to i plus 1
                    
                    Note: Backward substitution to get L block
                    Let l_block_result be LinAlgCore.solve_upper_triangular with block_u and LinAlgCore.matrix_transpose with block_rhs
                    Let l_block_final be LinAlgCore.matrix_transpose with l_block_result
                    
                    Note: Update L matrix with solved block
                    Let i be 0
                    While i is less than below_end minus below_start:
                        Let j be 0
                        While j is less than current_block_size:
                            Let l_elem be LinAlgCore.get_matrix_element with l_block_final and i and j
                            Set l_matrix at below_start plus i and start_row plus j to l_elem
                            Set j to j plus 1
                        Set i to i plus 1
                    
                    Set below_start to below_end
                
                Note: Update Schur complement for remaining matrix
                Let remaining_start be end_row
                While remaining_start is less than n:
                    Let remaining_end be remaining_start plus block_size
                    If remaining_end is greater than n:
                        Set remaining_end to n
                    
                    Let i be 0
                    While i is less than remaining_end minus remaining_start:
                        Let j be 0
                        While j is less than remaining_end minus remaining_start:
                            Let original_elem be LinAlgCore.get_matrix_element with working_matrix and remaining_start plus i and remaining_start plus j
                            
                            Note: Subtract L[i,k] multiplied by U[k,j] for current block
                            Let subtraction be 0.0
                            Let k be 0
                            While k is less than current_block_size:
                                Let l_ik be LinAlgCore.get_matrix_element with l_matrix and remaining_start plus i and start_row plus k
                                Let u_kj be LinAlgCore.get_matrix_element with u_matrix and start_row plus k and remaining_start plus j
                                Set subtraction to subtraction plus l_ik multiplied by u_kj
                                Set k to k plus 1
                            
                            Set working_matrix at remaining_start plus i and remaining_start plus j to original_elem minus subtraction
                            Set j to j plus 1
                        Set i to i plus 1
                    
                    Set remaining_start to remaining_end
            
            Set block_idx to block_idx plus 1
        
        Let result be Dictionary.new
        Set result["L"] to l_matrix
        Set result["U"] to u_matrix
        Set result["P"] to p_matrix
        Return result
    
    Otherwise:
        If decomposition_type is equal to "qr":
            Note: Block QR decomposition using Householder reflections
            Let working_matrix be LinAlgCore.copy_matrix with matrix
            Let q_matrix be LinAlgCore.create_identity_matrix with m
            Let r_matrix be LinAlgCore.create_zero_matrix with m and n
            
            Let min_dim be m
            If n is less than min_dim:
                Set min_dim to n
            
            Let num_blocks be (min_dim plus block_size minus 1) / block_size
            Let block_idx be 0
            
            While block_idx is less than num_blocks:
                Let start_col be block_idx multiplied by block_size
                Let end_col be start_col plus block_size
                If end_col is greater than min_dim:
                    Set end_col to min_dim
                Let current_block_size be end_col minus start_col
                
                Note: Extract block for QR decomposition
                Let block_matrix be LinAlgCore.create_matrix with m minus start_col and current_block_size
                Let i be 0
                While i is less than m minus start_col:
                    Let j be 0
                    While j is less than current_block_size:
                        Let element be LinAlgCore.get_matrix_element with working_matrix and start_col plus i and start_col plus j
                        Set block_matrix at i and j to element
                        Set j to j plus 1
                    Set i to i plus 1
                
                Note: Perform QR on block
                Let block_qr_result be qr_householder_decomposition with block_matrix
                Let block_q be LinAlgCore.get_dictionary_matrix with block_qr_result and "Q"
                Let block_r be LinAlgCore.get_dictionary_matrix with block_qr_result and "R"
                
                Note: Update global Q matrix
                Let temp_q be LinAlgCore.multiply_block_matrices with q_matrix and block_q and start_col and start_col
                Set q_matrix to temp_q
                
                Note: Update R matrix with block R
                Let i be 0
                While i is less than current_block_size:
                    Let j be 0
                    While j is less than current_block_size:
                        Let r_elem be LinAlgCore.get_matrix_element with block_r and i and j
                        Set r_matrix at start_col plus i and start_col plus j to r_elem
                        Set j to j plus 1
                    Set i to i plus 1
                
                Note: Update remaining columns using Q^T
                If end_col is less than n:
                    Let remaining_cols be LinAlgCore.create_matrix with m minus start_col and n minus end_col
                    Let i be 0
                    While i is less than m minus start_col:
                        Let j be 0
                        While j is less than n minus end_col:
                            Let element be LinAlgCore.get_matrix_element with working_matrix and start_col plus i and end_col plus j
                            Set remaining_cols at i and j to element
                            Set j to j plus 1
                        Set i to i plus 1
                    
                    Let block_q_transpose be LinAlgCore.matrix_transpose with block_q
                    Let updated_cols be LinAlgCore.multiply_matrices with block_q_transpose and remaining_cols
                    
                    Let i be 0
                    While i is less than m minus start_col:
                        Let j be 0
                        While j is less than n minus end_col:
                            Let updated_elem be LinAlgCore.get_matrix_element with updated_cols and i and j
                            Set working_matrix at start_col plus i and end_col plus j to updated_elem
                            Set j to j plus 1
                        Set i to i plus 1
                
                Set block_idx to block_idx plus 1
            
            Let result be Dictionary.new
            Set result["Q"] to q_matrix
            Set result["R"] to r_matrix
            Return result
        
        Otherwise:
            If decomposition_type is equal to "cholesky":
                Note: Block Cholesky decomposition for symmetric positive definite matrices
                If m does not equal n:
                    Throw Errors.MatrixNotSquare with "Block Cholesky decomposition requires square matrix"
                
                Let working_matrix be LinAlgCore.copy_matrix with matrix
                Let l_matrix be LinAlgCore.create_zero_matrix with n and n
                
                Let num_blocks be (n plus block_size minus 1) / block_size
                Let block_idx be 0
                
                While block_idx is less than num_blocks:
                    Let start_idx be block_idx multiplied by block_size
                    Let end_idx be start_idx plus block_size
                    If end_idx is greater than n:
                        Set end_idx to n
                    Let current_block_size be end_idx minus start_idx
                    
                    Note: Extract diagonal block
                    Let diagonal_block be LinAlgCore.create_matrix with current_block_size and current_block_size
                    Let i be 0
                    While i is less than current_block_size:
                        Let j be 0
                        While j is less than current_block_size:
                            Let element be LinAlgCore.get_matrix_element with working_matrix and start_idx plus i and start_idx plus j
                            Set diagonal_block at i and j to element
                            Set j to j plus 1
                        Set i to i plus 1
                    
                    Note: Cholesky decomposition of diagonal block
                    Let block_chol_result be cholesky_decomposition with diagonal_block
                    Let block_l be LinAlgCore.get_dictionary_matrix with block_chol_result and "L"
                    
                    Note: Update L matrix with block result
                    Let i be 0
                    While i is less than current_block_size:
                        Let j be 0
                        While j is less than current_block_size:
                            Let l_elem be LinAlgCore.get_matrix_element with block_l and i and j
                            Set l_matrix at start_idx plus i and start_idx plus j to l_elem
                            Set j to j plus 1
                        Set i to i plus 1
                    
                    Note: Update blocks below diagonal
                    If end_idx is less than n:
                        Let below_block be LinAlgCore.create_matrix with n minus end_idx and current_block_size
                        Let i be 0
                        While i is less than n minus end_idx:
                            Let j be 0
                            While j is less than current_block_size:
                                Let element be LinAlgCore.get_matrix_element with working_matrix and end_idx plus i and start_idx plus j
                                Set below_block at i and j to element
                                Set j to j plus 1
                            Set i to i plus 1
                        
                        Note: Solve L11 multiplied by X is equal to A21^T where L11 is current block
                        Let below_solution be LinAlgCore.solve_lower_triangular with block_l and LinAlgCore.matrix_transpose with below_block
                        Let below_final be LinAlgCore.matrix_transpose with below_solution
                        
                        Note: Update L matrix with solved blocks
                        Let i be 0
                        While i is less than n minus end_idx:
                            Let j be 0
                            While j is less than current_block_size:
                                Let l_elem be LinAlgCore.get_matrix_element with below_final and i and j
                                Set l_matrix at end_idx plus i and start_idx plus j to l_elem
                                Set j to j plus 1
                            Set i to i plus 1
                        
                        Note: Update Schur complement A22 := A22 minus L21 multiplied by L21^T
                        Let i be 0
                        While i is less than n minus end_idx:
                            Let j be 0
                            While j is less than n minus end_idx:
                                Let original_elem be LinAlgCore.get_matrix_element with working_matrix and end_idx plus i and end_idx plus j
                                
                                Let subtraction be 0.0
                                Let k be 0
                                While k is less than current_block_size:
                                    Let l_ik be LinAlgCore.get_matrix_element with l_matrix and end_idx plus i and start_idx plus k
                                    Let l_jk be LinAlgCore.get_matrix_element with l_matrix and end_idx plus j and start_idx plus k
                                    Set subtraction to subtraction plus l_ik multiplied by l_jk
                                    Set k to k plus 1
                                
                                Set working_matrix at end_idx plus i and end_idx plus j to original_elem minus subtraction
                                Set j to j plus 1
                            Set i to i plus 1
                    
                    Set block_idx to block_idx plus 1
                
                Let result be Dictionary.new
                Set result["L"] to l_matrix
                Return result
            
            Otherwise:
                Throw Errors.InvalidDecompositionType with "Block decomposition not supported for this type"

Process called "parallel_decomposition" that takes matrix as Matrix, decomposition_type as String, parallel_options as Dictionary[String, String] returns Dictionary[String, Matrix]:
    Note: Perform decomposition using parallel algorithms
    Note: Distributes computation across multiple threads for improved performance
    Note: Uses block-wise parallelization with work stealing and load balancing
    
    Let m be LinAlgCore.get_matrix_rows with matrix
    Let n be LinAlgCore.get_matrix_cols with matrix
    
    Note: Extract parallel options
    Let num_threads_str be Dictionary.get with parallel_options and "num_threads"
    Let num_threads be 4
    If num_threads_str does not equal "":
        Set num_threads to String.to_integer with num_threads_str
    
    Let block_size_str be Dictionary.get with parallel_options and "block_size"
    Let block_size be 64
    If block_size_str does not equal "":
        Set block_size to String.to_integer with block_size_str
    
    Let load_balance_str be Dictionary.get with parallel_options and "load_balance"
    Let use_load_balancing be true
    If load_balance_str is equal to "false":
        Set use_load_balancing to false
    
    Note: Validate parameters
    If num_threads is less than or equal to 0:
        Set num_threads to 1
    If block_size is less than or equal to 0:
        Set block_size to 32
    
    If decomposition_type is equal to "lu":
        Note: Parallel LU decomposition using right-looking algorithm
        If m does not equal n:
            Throw Errors.MatrixNotSquare with "Parallel LU decomposition requires square matrix"
        
        Let working_matrix be LinAlgCore.copy_matrix with matrix
        Let l_matrix be LinAlgCore.create_identity_matrix with n
        Let u_matrix be LinAlgCore.create_zero_matrix with n and n
        Let p_matrix be LinAlgCore.create_identity_matrix with n
        
        Let num_blocks be (n plus block_size minus 1) / block_size
        Let panel_idx be 0
        
        While panel_idx is less than num_blocks:
            Let panel_start be panel_idx multiplied by block_size
            Let panel_end be panel_start plus block_size
            If panel_end is greater than n:
                Set panel_end to n
            Let panel_size be panel_end minus panel_start
            
            Note: Sequential panel factorization (critical path)
            Let panel_block be LinAlgCore.create_matrix with n minus panel_start and panel_size
            Let i be 0
            While i is less than n minus panel_start:
                Let j be 0
                While j is less than panel_size:
                    Let element be LinAlgCore.get_matrix_element with working_matrix and panel_start plus i and panel_start plus j
                    Set panel_block at i and j to element
                    Set j to j plus 1
                Set i to i plus 1
            
            Let panel_lu_result be lu_with_partial_pivoting with panel_block
            Let panel_l be LinAlgCore.get_dictionary_matrix with panel_lu_result and "L"
            Let panel_u be LinAlgCore.get_dictionary_matrix with panel_lu_result and "U"
            Let panel_p be LinAlgCore.get_dictionary_matrix with panel_lu_result and "P"
            
            Note: Update global matrices with panel results
            Let i be 0
            While i is less than n minus panel_start:
                Let j be 0
                While j is less than panel_size:
                    If i is less than panel_size:
                        Let l_elem be LinAlgCore.get_matrix_element with panel_l and i and j
                        Let u_elem be LinAlgCore.get_matrix_element with panel_u and i and j
                        Set l_matrix at panel_start plus i and panel_start plus j to l_elem
                        Set u_matrix at panel_start plus i and panel_start plus j to u_elem
                    Otherwise:
                        Let l_elem be LinAlgCore.get_matrix_element with panel_l and i and j
                        Set l_matrix at panel_start plus i and panel_start plus j to l_elem
                    Set j to j plus 1
                Set i to i plus 1
            
            Note: Parallel update of trailing matrix
            If panel_end is less than n:
                Let remaining_blocks be (n minus panel_end plus block_size minus 1) / block_size
                Let thread_workload be LinAlgCore.create_thread_pool with num_threads
                
                Note: Distribute blocks across threads
                Let block_assignments be List.new
                Let thread_id be 0
                Let block_i be 0
                While block_i is less than remaining_blocks:
                    Let block_j be 0
                    While block_j is less than remaining_blocks:
                        Let assignment be Dictionary.new
                        Set assignment["thread_id"] to String.from_integer with thread_id
                        Set assignment["block_i"] to String.from_integer with block_i
                        Set assignment["block_j"] to String.from_integer with block_j
                        Set assignment["start_i"] to String.from_integer with panel_end plus block_i multiplied by block_size
                        Set assignment["start_j"] to String.from_integer with panel_end plus block_j multiplied by block_size
                        List.append with block_assignments and assignment
                        
                        If use_load_balancing:
                            Set thread_id to (thread_id plus 1) % num_threads
                        Set block_j to block_j plus 1
                    
                    If not use_load_balancing:
                        Set thread_id to (thread_id plus 1) % num_threads
                    Set block_i to block_i plus 1
                
                Note: Execute parallel block updates
                LinAlgCore.execute_parallel_block_updates with thread_workload and block_assignments and working_matrix and l_matrix and u_matrix and panel_start and panel_size
                
                LinAlgCore.synchronize_thread_pool with thread_workload
            
            Set panel_idx to panel_idx plus 1
        
        Let result be Dictionary.new
        Set result["L"] to l_matrix
        Set result["U"] to u_matrix
        Set result["P"] to p_matrix
        Return result
    
    Otherwise:
        If decomposition_type is equal to "qr":
            Note: Parallel QR decomposition using block Householder
            Let working_matrix be LinAlgCore.copy_matrix with matrix
            Let q_matrix be LinAlgCore.create_identity_matrix with m
            Let r_matrix be LinAlgCore.create_zero_matrix with m and n
            
            Let min_dim be m
            If n is less than min_dim:
                Set min_dim to n
            
            Let num_blocks be (min_dim plus block_size minus 1) / block_size
            Let thread_pool be LinAlgCore.create_thread_pool with num_threads
            
            Let block_idx be 0
            While block_idx is less than num_blocks:
                Let start_col be block_idx multiplied by block_size
                Let end_col be start_col plus block_size
                If end_col is greater than min_dim:
                    Set end_col to min_dim
                Let current_block_size be end_col minus start_col
                
                Note: Sequential QR factorization of current panel
                Let panel_matrix be LinAlgCore.create_matrix with m minus start_col and current_block_size
                Let i be 0
                While i is less than m minus start_col:
                    Let j be 0
                    While j is less than current_block_size:
                        Let element be LinAlgCore.get_matrix_element with working_matrix and start_col plus i and start_col plus j
                        Set panel_matrix at i and j to element
                        Set j to j plus 1
                    Set i to i plus 1
                
                Let panel_qr_result be qr_householder_decomposition with panel_matrix
                Let panel_q be LinAlgCore.get_dictionary_matrix with panel_qr_result and "Q"
                Let panel_r be LinAlgCore.get_dictionary_matrix with panel_qr_result and "R"
                
                Note: Update R matrix with panel result
                Let i be 0
                While i is less than current_block_size:
                    Let j be 0
                    While j is less than current_block_size:
                        Let r_elem be LinAlgCore.get_matrix_element with panel_r and i and j
                        Set r_matrix at start_col plus i and start_col plus j to r_elem
                        Set j to j plus 1
                    Set i to i plus 1
                
                Note: Parallel update of remaining columns
                If end_col is less than n:
                    Let remaining_cols be n minus end_col
                    Let col_blocks be (remaining_cols plus block_size minus 1) / block_size
                    
                    Note: Create parallel tasks for column updates
                    Let col_tasks be List.new
                    Let col_block_idx be 0
                    While col_block_idx is less than col_blocks:
                        Let col_start be end_col plus col_block_idx multiplied by block_size
                        Let col_end be col_start plus block_size
                        If col_end is greater than n:
                            Set col_end to n
                        
                        Let task be Dictionary.new
                        Set task["thread_id"] to String.from_integer with col_block_idx % num_threads
                        Set task["col_start"] to String.from_integer with col_start
                        Set task["col_end"] to String.from_integer with col_end
                        Set task["panel_start"] to String.from_integer with start_col
                        Set task["panel_size"] to String.from_integer with current_block_size
                        List.append with col_tasks and task
                        
                        Set col_block_idx to col_block_idx plus 1
                    
                    Note: Execute parallel column updates
                    LinAlgCore.execute_parallel_qr_updates with thread_pool and col_tasks and working_matrix and panel_q and start_col
                    LinAlgCore.synchronize_thread_pool with thread_pool
                
                Note: Update global Q matrix
                Let temp_q be LinAlgCore.multiply_block_matrices with q_matrix and panel_q and start_col and start_col
                Set q_matrix to temp_q
                
                Set block_idx to block_idx plus 1
            
            LinAlgCore.destroy_thread_pool with thread_pool
            
            Let result be Dictionary.new
            Set result["Q"] to q_matrix
            Set result["R"] to r_matrix
            Return result
        
        Otherwise:
            If decomposition_type is equal to "cholesky":
                Note: Parallel Cholesky decomposition using right-looking algorithm
                If m does not equal n:
                    Throw Errors.MatrixNotSquare with "Parallel Cholesky decomposition requires square matrix"
                
                Let working_matrix be LinAlgCore.copy_matrix with matrix
                Let l_matrix be LinAlgCore.create_zero_matrix with n and n
                Let thread_pool be LinAlgCore.create_thread_pool with num_threads
                
                Let num_blocks be (n plus block_size minus 1) / block_size
                Let block_idx be 0
                
                While block_idx is less than num_blocks:
                    Let start_idx be block_idx multiplied by block_size
                    Let end_idx be start_idx plus block_size
                    If end_idx is greater than n:
                        Set end_idx to n
                    Let current_block_size be end_idx minus start_idx
                    
                    Note: Sequential Cholesky factorization of diagonal block
                    Let diagonal_block be LinAlgCore.create_matrix with current_block_size and current_block_size
                    Let i be 0
                    While i is less than current_block_size:
                        Let j be 0
                        While j is less than current_block_size:
                            Let element be LinAlgCore.get_matrix_element with working_matrix and start_idx plus i and start_idx plus j
                            Set diagonal_block at i and j to element
                            Set j to j plus 1
                        Set i to i plus 1
                    
                    Let block_chol_result be cholesky_decomposition with diagonal_block
                    Let block_l be LinAlgCore.get_dictionary_matrix with block_chol_result and "L"
                    
                    Note: Update L matrix with diagonal block
                    Let i be 0
                    While i is less than current_block_size:
                        Let j be 0
                        While j is less than current_block_size:
                            Let l_elem be LinAlgCore.get_matrix_element with block_l and i and j
                            Set l_matrix at start_idx plus i and start_idx plus j to l_elem
                            Set j to j plus 1
                        Set i to i plus 1
                    
                    Note: Parallel update of blocks below diagonal
                    If end_idx is less than n:
                        Let remaining_rows be n minus end_idx
                        Let row_blocks be (remaining_rows plus block_size minus 1) / block_size
                        
                        Note: Create parallel tasks for row block updates
                        Let row_tasks be List.new
                        Let row_block_idx be 0
                        While row_block_idx is less than row_blocks:
                            Let row_start be end_idx plus row_block_idx multiplied by block_size
                            Let row_end be row_start plus block_size
                            If row_end is greater than n:
                                Set row_end to n
                            
                            Let task be Dictionary.new
                            Set task["thread_id"] to String.from_integer with row_block_idx % num_threads
                            Set task["row_start"] to String.from_integer with row_start
                            Set task["row_end"] to String.from_integer with row_end
                            Set task["diag_start"] to String.from_integer with start_idx
                            Set task["diag_size"] to String.from_integer with current_block_size
                            List.append with row_tasks and task
                            
                            Set row_block_idx to row_block_idx plus 1
                        
                        Note: Execute parallel triangular solves
                        LinAlgCore.execute_parallel_cholesky_solves with thread_pool and row_tasks and working_matrix and l_matrix and block_l
                        LinAlgCore.synchronize_thread_pool with thread_pool
                        
                        Note: Parallel Schur complement updates
                        Let schur_tasks be List.new
                        Let i_block be 0
                        While i_block is less than row_blocks:
                            Let j_block be i_block
                            While j_block is less than row_blocks:
                                Let task be Dictionary.new
                                Set task["thread_id"] to String.from_integer with (i_block multiplied by row_blocks plus j_block) % num_threads
                                Set task["i_block"] to String.from_integer with i_block
                                Set task["j_block"] to String.from_integer with j_block
                                Set task["base_idx"] to String.from_integer with end_idx
                                Set task["block_size"] to String.from_integer with block_size
                                List.append with schur_tasks and task
                                
                                Set j_block to j_block plus 1
                            Set i_block to i_block plus 1
                        
                        LinAlgCore.execute_parallel_schur_updates with thread_pool and schur_tasks and working_matrix and l_matrix and start_idx and current_block_size
                        LinAlgCore.synchronize_thread_pool with thread_pool
                    
                    Set block_idx to block_idx plus 1
                
                LinAlgCore.destroy_thread_pool with thread_pool
                
                Let result be Dictionary.new
                Set result["L"] to l_matrix
                Return result
            
            Otherwise:
                If decomposition_type is equal to "svd":
                    Note: Parallel SVD using divide-and-conquer approach
                    Note: For large matrices, split into blocks and compute SVD in parallel
                    If m is less than 32 and n is less than 32:
                        Note: Use sequential SVD for small matrices
                        Return svd_golub_reinsch with matrix
                    
                    Let thread_pool be LinAlgCore.create_thread_pool with num_threads
                    
                    Note: Bidiagonalize matrix in parallel
                    Let bidiag_result be LinAlgCore.parallel_bidiagonalization with matrix and thread_pool and block_size
                    Let u_bidiag be LinAlgCore.get_dictionary_matrix with bidiag_result and "U"
                    Let b_matrix be LinAlgCore.get_dictionary_matrix with bidiag_result and "B"
                    Let v_bidiag be LinAlgCore.get_dictionary_matrix with bidiag_result and "V"
                    
                    Note: Compute SVD of bidiagonal matrix using divide-and-conquer
                    Let bidiag_svd be LinAlgCore.parallel_bidiagonal_svd with b_matrix and thread_pool
                    Let u_bidiag_svd be LinAlgCore.get_dictionary_matrix with bidiag_svd and "U"
                    Let s_matrix be LinAlgCore.get_dictionary_matrix with bidiag_svd and "S"
                    Let v_bidiag_svd be LinAlgCore.get_dictionary_matrix with bidiag_svd and "V"
                    
                    Note: Combine transformations in parallel
                    Let final_u be LinAlgCore.parallel_matrix_multiply with u_bidiag and u_bidiag_svd and thread_pool
                    Let final_v be LinAlgCore.parallel_matrix_multiply with v_bidiag and v_bidiag_svd and thread_pool
                    
                    LinAlgCore.destroy_thread_pool with thread_pool
                    
                    Let result be Dictionary.new
                    Set result["U"] to final_u
                    Set result["S"] to s_matrix
                    Set result["V"] to final_v
                    Return result
                
                Otherwise:
                    Throw Errors.InvalidDecompositionType with "Parallel decomposition not supported for this type"

Process called "out_of_core_decomposition" that takes matrix_file as String, decomposition_type as String, memory_limit as Integer returns Dictionary[String, String]:
    Note: Decomposition for matrices too large for memory
    Note: Processes matrix in blocks stored on disk, managing memory usage carefully
    Note: Uses external storage for intermediate results and final decomposition factors
    
    Note: Validate memory limit
    If memory_limit is less than or equal to 0:
        Throw Errors.InvalidMemoryLimit with "Memory limit must be positive"
    
    Note: Check if matrix file exists and get dimensions
    If not OS.file_exists with matrix_file:
        Throw Errors.FileNotFound with "Matrix file not found"
    
    Let matrix_info be LinAlgCore.read_matrix_header with matrix_file
    Let m be LinAlgCore.get_integer_from_dict with matrix_info and "rows"
    Let n be LinAlgCore.get_integer_from_dict with matrix_info and "cols"
    Let element_size be LinAlgCore.get_integer_from_dict with matrix_info and "element_size"
    
    Note: Calculate optimal block size based on memory limit
    Let matrix_memory_size be m multiplied by n multiplied by element_size
    Let available_memory be memory_limit multiplied by 1024 multiplied by 1024
    Let block_memory_fraction be 0.3
    Let block_memory_budget be Integer.from_float with Float.from_integer with available_memory multiplied by block_memory_fraction
    
    Note: Estimate block size (square blocks for simplicity)
    Let max_block_elements be block_memory_budget / element_size
    Let estimated_block_size be Integer.from_float with Math.sqrt with Float.from_integer with max_block_elements
    Let block_size be 64
    If estimated_block_size is greater than block_size:
        Set block_size to estimated_block_size
    If estimated_block_size is less than 32:
        Set block_size to 32
    
    Note: Create temporary directory for intermediate files
    Let temp_dir be OS.create_temp_directory with "decomposition_temp"
    Let result be Dictionary.new
    Set result["temp_directory"] to temp_dir
    Set result["block_size"] to String.from_integer with block_size
    
    If decomposition_type is equal to "lu":
        Note: Out-of-core LU decomposition using external storage
        If m does not equal n:
            Throw Errors.MatrixNotSquare with "Out-of-core LU decomposition requires square matrix"
        
        Let l_file be temp_dir plus "/L_matrix.bin"
        Let u_file be temp_dir plus "/U_matrix.bin"
        Let p_file be temp_dir plus "/P_matrix.bin"
        
        Note: Initialize L as identity, U as zero, P as identity on disk
        LinAlgCore.create_disk_identity_matrix with l_file and n
        LinAlgCore.create_disk_zero_matrix with u_file and n and n
        LinAlgCore.create_disk_identity_matrix with p_file and n
        
        Let num_blocks be (n plus block_size minus 1) / block_size
        Let block_idx be 0
        
        While block_idx is less than num_blocks:
            Let start_row be block_idx multiplied by block_size
            Let end_row be start_row plus block_size
            If end_row is greater than n:
                Set end_row to n
            Let current_block_size be end_row minus start_row
            
            Note: Load diagonal block from disk
            Let diagonal_block be LinAlgCore.load_matrix_block with matrix_file and start_row and start_row and current_block_size and current_block_size
            
            Note: Apply previous L and U updates to diagonal block
            Let k_block be 0
            While k_block is less than block_idx:
                Let k_start be k_block multiplied by block_size
                Let k_end be k_start plus block_size
                If k_end is greater than n:
                    Set k_end to n
                Let k_size be k_end minus k_start
                
                Let l_block_k be LinAlgCore.load_matrix_block with l_file and start_row and k_start and current_block_size and k_size
                Let u_block_k be LinAlgCore.load_matrix_block with u_file and k_start and start_row and k_size and current_block_size
                Let lu_product be LinAlgCore.multiply_matrices with l_block_k and u_block_k
                Set diagonal_block to LinAlgCore.matrix_subtract with diagonal_block and lu_product
                
                Set k_block to k_block plus 1
            
            Note: Perform LU decomposition of updated diagonal block
            Let block_lu_result be lu_with_partial_pivoting with diagonal_block
            Let block_l be LinAlgCore.get_dictionary_matrix with block_lu_result and "L"
            Let block_u be LinAlgCore.get_dictionary_matrix with block_lu_result and "U"
            Let block_p be LinAlgCore.get_dictionary_matrix with block_lu_result and "P"
            
            Note: Store L and U blocks to disk
            LinAlgCore.store_matrix_block with l_file and block_l and start_row and start_row
            LinAlgCore.store_matrix_block with u_file and block_u and start_row and start_row
            LinAlgCore.apply_permutation_block with p_file and block_p and start_row
            
            Note: Update remaining blocks in current row and column
            Let remaining_block_idx be block_idx plus 1
            While remaining_block_idx is less than num_blocks:
                Let rem_start be remaining_block_idx multiplied by block_size
                Let rem_end be rem_start plus block_size
                If rem_end is greater than n:
                    Set rem_end to n
                Let rem_size be rem_end minus rem_start
                
                Note: Update U block (row direction)
                Let u_block be LinAlgCore.load_matrix_block with matrix_file and start_row and rem_start and current_block_size and rem_size
                
                Note: Apply previous updates to U block
                Let k_block be 0
                While k_block is less than block_idx:
                    Let k_start be k_block multiplied by block_size
                    Let k_end be k_start plus block_size
                    If k_end is greater than n:
                        Set k_end to n
                    Let k_size be k_end minus k_start
                    
                    Let l_k be LinAlgCore.load_matrix_block with l_file and start_row and k_start and current_block_size and k_size
                    Let u_k be LinAlgCore.load_matrix_block with u_file and k_start and rem_start and k_size and rem_size
                    Let lu_k_product be LinAlgCore.multiply_matrices with l_k and u_k
                    Set u_block to LinAlgCore.matrix_subtract with u_block and lu_k_product
                    
                    Set k_block to k_block plus 1
                
                Note: Solve L multiplied by X is equal to U_block
                Let solved_u_block be LinAlgCore.solve_lower_triangular with block_l and u_block
                LinAlgCore.store_matrix_block with u_file and solved_u_block and start_row and rem_start
                
                Note: Update L block (column direction)
                Let l_block be LinAlgCore.load_matrix_block with matrix_file and rem_start and start_row and rem_size and current_block_size
                
                Note: Apply previous updates to L block
                Let k_block be 0
                While k_block is less than block_idx:
                    Let k_start be k_block multiplied by block_size
                    Let k_end be k_start plus block_size
                    If k_end is greater than n:
                        Set k_end to n
                    Let k_size be k_end minus k_start
                    
                    Let l_k be LinAlgCore.load_matrix_block with l_file and rem_start and k_start and rem_size and k_size
                    Let u_k be LinAlgCore.load_matrix_block with u_file and k_start and start_row and k_size and current_block_size
                    Let lu_k_product be LinAlgCore.multiply_matrices with l_k and u_k
                    Set l_block to LinAlgCore.matrix_subtract with l_block and lu_k_product
                    
                    Set k_block to k_block plus 1
                
                Note: Solve X multiplied by U is equal to L_block
                Let block_u_transpose be LinAlgCore.matrix_transpose with block_u
                Let l_block_transpose be LinAlgCore.matrix_transpose with l_block
                Let solved_l_transpose be LinAlgCore.solve_lower_triangular with block_u_transpose and l_block_transpose
                Let solved_l_block be LinAlgCore.matrix_transpose with solved_l_transpose
                LinAlgCore.store_matrix_block with l_file and solved_l_block and rem_start and start_row
                
                Set remaining_block_idx to remaining_block_idx plus 1
            
            Set block_idx to block_idx plus 1
        
        Set result["L_file"] to l_file
        Set result["U_file"] to u_file
        Set result["P_file"] to p_file
        Set result["matrix_size"] to String.from_integer with n
        Return result
    
    Otherwise:
        If decomposition_type is equal to "qr":
            Note: Out-of-core QR decomposition using Householder reflections
            Let q_file be temp_dir plus "/Q_matrix.bin"
            Let r_file be temp_dir plus "/R_matrix.bin"
            
            Note: Initialize Q as identity, R as zero on disk
            LinAlgCore.create_disk_identity_matrix with q_file and m
            LinAlgCore.create_disk_zero_matrix with r_file and m and n
            
            Let min_dim be m
            If n is less than min_dim:
                Set min_dim to n
            
            Let num_blocks be (min_dim plus block_size minus 1) / block_size
            Let col_block_idx be 0
            
            While col_block_idx is less than num_blocks:
                Let start_col be col_block_idx multiplied by block_size
                Let end_col be start_col plus block_size
                If end_col is greater than min_dim:
                    Set end_col to min_dim
                Let current_block_size be end_col minus start_col
                
                Note: Load current column panel from disk
                Let column_panel be LinAlgCore.load_matrix_block with matrix_file and start_col and start_col and m minus start_col and current_block_size
                
                Note: Apply previous Q transformations to panel
                Let q_block_idx be 0
                While q_block_idx is less than col_block_idx:
                    Let q_start be q_block_idx multiplied by block_size
                    Let q_end be q_start plus block_size
                    If q_end is greater than min_dim:
                        Set q_end to min_dim
                    Let q_size be q_end minus q_start
                    
                    Let q_block be LinAlgCore.load_matrix_block with q_file and start_col and q_start and m minus start_col and q_size
                    Let q_transpose be LinAlgCore.matrix_transpose with q_block
                    Set column_panel to LinAlgCore.multiply_matrices with q_transpose and column_panel
                    
                    Set q_block_idx to q_block_idx plus 1
                
                Note: Perform QR decomposition of column panel
                Let panel_qr_result be qr_householder_decomposition with column_panel
                Let panel_q be LinAlgCore.get_dictionary_matrix with panel_qr_result and "Q"
                Let panel_r be LinAlgCore.get_dictionary_matrix with panel_qr_result and "R"
                
                Note: Store R block to disk
                LinAlgCore.store_matrix_block with r_file and panel_r and start_col and start_col
                
                Note: Update Q matrix on disk
                Let current_q_block be LinAlgCore.load_matrix_block with q_file and start_col and start_col and m minus start_col and m minus start_col
                Let updated_q_block be LinAlgCore.multiply_matrices with current_q_block and panel_q
                LinAlgCore.store_matrix_block with q_file and updated_q_block and start_col and start_col
                
                Note: Update remaining columns using Q^T
                Let remaining_col_idx be col_block_idx plus 1
                While remaining_col_idx is less than (n plus block_size minus 1) / block_size:
                    Let rem_col_start be remaining_col_idx multiplied by block_size
                    Let rem_col_end be rem_col_start plus block_size
                    If rem_col_end is greater than n:
                        Set rem_col_end to n
                    Let rem_col_size be rem_col_end minus rem_col_start
                    
                    Let remaining_cols be LinAlgCore.load_matrix_block with matrix_file and start_col and rem_col_start and m minus start_col and rem_col_size
                    Let panel_q_transpose be LinAlgCore.matrix_transpose with panel_q
                    Let updated_cols be LinAlgCore.multiply_matrices with panel_q_transpose and remaining_cols
                    LinAlgCore.store_matrix_block with matrix_file and updated_cols and start_col and rem_col_start
                    
                    Set remaining_col_idx to remaining_col_idx plus 1
                
                Set col_block_idx to col_block_idx plus 1
            
            Set result["Q_file"] to q_file
            Set result["R_file"] to r_file
            Set result["matrix_rows"] to String.from_integer with m
            Set result["matrix_cols"] to String.from_integer with n
            Return result
        
        Otherwise:
            If decomposition_type is equal to "cholesky":
                Note: Out-of-core Cholesky decomposition for symmetric positive definite matrices
                If m does not equal n:
                    Throw Errors.MatrixNotSquare with "Out-of-core Cholesky decomposition requires square matrix"
                
                Let l_file be temp_dir plus "/L_cholesky.bin"
                LinAlgCore.create_disk_zero_matrix with l_file and n and n
                
                Let num_blocks be (n plus block_size minus 1) / block_size
                Let block_idx be 0
                
                While block_idx is less than num_blocks:
                    Let start_idx be block_idx multiplied by block_size
                    Let end_idx be start_idx plus block_size
                    If end_idx is greater than n:
                        Set end_idx to n
                    Let current_block_size be end_idx minus start_idx
                    
                    Note: Load and update diagonal block
                    Let diagonal_block be LinAlgCore.load_matrix_block with matrix_file and start_idx and start_idx and current_block_size and current_block_size
                    
                    Note: Subtract L multiplied by L^T from previous blocks
                    Let prev_block_idx be 0
                    While prev_block_idx is less than block_idx:
                        Let prev_start be prev_block_idx multiplied by block_size
                        Let prev_end be prev_start plus block_size
                        If prev_end is greater than n:
                            Set prev_end to n
                        Let prev_size be prev_end minus prev_start
                        
                        Let l_prev_block be LinAlgCore.load_matrix_block with l_file and start_idx and prev_start and current_block_size and prev_size
                        Let l_prev_transpose be LinAlgCore.matrix_transpose with l_prev_block
                        Let llt_product be LinAlgCore.multiply_matrices with l_prev_block and l_prev_transpose
                        Set diagonal_block to LinAlgCore.matrix_subtract with diagonal_block and llt_product
                        
                        Set prev_block_idx to prev_block_idx plus 1
                    
                    Note: Perform Cholesky decomposition of updated diagonal block
                    Let block_chol_result be cholesky_decomposition with diagonal_block
                    Let block_l be LinAlgCore.get_dictionary_matrix with block_chol_result and "L"
                    
                    Note: Store L block to disk
                    LinAlgCore.store_matrix_block with l_file and block_l and start_idx and start_idx
                    
                    Note: Update blocks below diagonal
                    Let below_block_idx be block_idx plus 1
                    While below_block_idx is less than num_blocks:
                        Let below_start be below_block_idx multiplied by block_size
                        Let below_end be below_start plus block_size
                        If below_end is greater than n:
                            Set below_end to n
                        Let below_size be below_end minus below_start
                        
                        Let below_block be LinAlgCore.load_matrix_block with matrix_file and below_start and start_idx and below_size and current_block_size
                        
                        Note: Subtract previous L blocks contribution
                        Let prev_block_idx be 0
                        While prev_block_idx is less than block_idx:
                            Let prev_start be prev_block_idx multiplied by block_size
                            Let prev_end be prev_start plus block_size
                            If prev_end is greater than n:
                                Set prev_end to n
                            Let prev_size be prev_end minus prev_start
                            
                            Let l_below_prev be LinAlgCore.load_matrix_block with l_file and below_start and prev_start and below_size and prev_size
                            Let l_diag_prev be LinAlgCore.load_matrix_block with l_file and start_idx and prev_start and current_block_size and prev_size
                            Let l_diag_prev_transpose be LinAlgCore.matrix_transpose with l_diag_prev
                            Let correction be LinAlgCore.multiply_matrices with l_below_prev and l_diag_prev_transpose
                            Set below_block to LinAlgCore.matrix_subtract with below_block and correction
                            
                            Set prev_block_idx to prev_block_idx plus 1
                        
                        Note: Solve L11 multiplied by X is equal to A21^T
                        Let below_block_transpose be LinAlgCore.matrix_transpose with below_block
                        Let solved_transpose be LinAlgCore.solve_lower_triangular with block_l and below_block_transpose
                        Let solved_below_block be LinAlgCore.matrix_transpose with solved_transpose
                        LinAlgCore.store_matrix_block with l_file and solved_below_block and below_start and start_idx
                        
                        Set below_block_idx to below_block_idx plus 1
                    
                    Set block_idx to block_idx plus 1
                
                Set result["L_file"] to l_file
                Set result["matrix_size"] to String.from_integer with n
                Return result
            
            Otherwise:
                Throw Errors.InvalidDecompositionType with "Out-of-core decomposition not supported for this type"

Note: =====================================================================
Note: VALIDATION AND UTILITY OPERATIONS
Note: =====================================================================

Process called "verify_decomposition" that takes original_matrix as Matrix, decomposition_result as Dictionary[String, Matrix], decomposition_type as String, tolerance as Float returns Boolean:
    Note: Verify correctness of matrix decomposition
    Note: Reconstructs original matrix and checks accuracy within tolerance
    
    Let m be LinAlgCore.get_matrix_rows with original_matrix
    Let n be LinAlgCore.get_matrix_cols with original_matrix
    
    If decomposition_type is equal to "lu":
        Let l_matrix be LinAlgCore.get_dictionary_matrix with decomposition_result and "L"
        Let u_matrix be LinAlgCore.get_dictionary_matrix with decomposition_result and "U"
        Let p_matrix be LinAlgCore.get_dictionary_matrix with decomposition_result and "P"
        
        Note: Verify PA is equal to LU
        Let pa_matrix be LinAlgCore.multiply_matrices with p_matrix and original_matrix
        Let lu_matrix be LinAlgCore.multiply_matrices with l_matrix and u_matrix
        
        Return LinAlgCore.matrices_approximately_equal with pa_matrix and lu_matrix and tolerance
    
    Otherwise:
        If decomposition_type is equal to "qr":
            Let q_matrix be LinAlgCore.get_dictionary_matrix with decomposition_result and "Q"
            Let r_matrix be LinAlgCore.get_dictionary_matrix with decomposition_result and "R"
            
            Note: Verify A is equal to QR
            Let qr_matrix be LinAlgCore.multiply_matrices with q_matrix and r_matrix
            Let matrices_match be LinAlgCore.matrices_approximately_equal with original_matrix and qr_matrix and tolerance
            
            Note: Verify Q is orthogonal: Q^T multiplied by Q is equal to I
            Let q_transpose be LinAlgCore.matrix_transpose with q_matrix
            Let qtq_matrix be LinAlgCore.multiply_matrices with q_transpose and q_matrix
            Let identity_matrix be LinAlgCore.create_identity_matrix with LinAlgCore.get_matrix_cols with q_matrix
            Let q_orthogonal be LinAlgCore.matrices_approximately_equal with qtq_matrix and identity_matrix and tolerance
            
            Return matrices_match and q_orthogonal
        
        Otherwise:
            If decomposition_type is equal to "cholesky":
                Let l_matrix be LinAlgCore.get_dictionary_matrix with decomposition_result and "L"
                
                Note: Verify A is equal to L multiplied by L^T
                Let l_transpose be LinAlgCore.matrix_transpose with l_matrix
                Let reconstructed_matrix be LinAlgCore.multiply_matrices with l_matrix and l_transpose
                
                Return LinAlgCore.matrices_approximately_equal with original_matrix and reconstructed_matrix and tolerance
            
            Otherwise:
                If decomposition_type is equal to "svd":
                    Let u_matrix be LinAlgCore.get_dictionary_matrix with decomposition_result and "U"
                    Let s_matrix be LinAlgCore.get_dictionary_matrix with decomposition_result and "S"
                    Let v_matrix be LinAlgCore.get_dictionary_matrix with decomposition_result and "V"
                    
                    Note: Verify A is equal to U multiplied by S multiplied by V^T
                    Let v_transpose be LinAlgCore.matrix_transpose with v_matrix
                    Let us_matrix be LinAlgCore.multiply_matrices with u_matrix and s_matrix
                    Let reconstructed_matrix be LinAlgCore.multiply_matrices with us_matrix and v_transpose
                    
                    Let matrices_match be LinAlgCore.matrices_approximately_equal with original_matrix and reconstructed_matrix and tolerance
                    
                    Note: Verify U and V are orthogonal
                    Let u_transpose be LinAlgCore.matrix_transpose with u_matrix
                    Let utu_matrix be LinAlgCore.multiply_matrices with u_transpose and u_matrix
                    Let u_rows be LinAlgCore.get_matrix_rows with u_matrix
                    Let u_identity be LinAlgCore.create_identity_matrix with u_rows
                    Let u_orthogonal be LinAlgCore.matrices_approximately_equal with utu_matrix and u_identity and tolerance
                    
                    Let vtv_matrix be LinAlgCore.multiply_matrices with v_transpose and v_matrix
                    Let v_cols be LinAlgCore.get_matrix_cols with v_matrix
                    Let v_identity be LinAlgCore.create_identity_matrix with v_cols
                    Let v_orthogonal be LinAlgCore.matrices_approximately_equal with vtv_matrix and v_identity and tolerance
                    
                    Return matrices_match and u_orthogonal and v_orthogonal
                
                Otherwise:
                    If decomposition_type is equal to "eigenvalue":
                        Let eigenvectors be LinAlgCore.get_dictionary_matrix with decomposition_result and "eigenvectors"
                        Let eigenvalues be LinAlgCore.get_dictionary_matrix with decomposition_result and "eigenvalues"
                        
                        Note: Verify A multiplied by V is equal to V multiplied by Λ
                        Let av_matrix be LinAlgCore.multiply_matrices with original_matrix and eigenvectors
                        Let vl_matrix be LinAlgCore.multiply_matrices with eigenvectors and eigenvalues
                        
                        Return LinAlgCore.matrices_approximately_equal with av_matrix and vl_matrix and tolerance
                    
                    Otherwise:
                        Throw Errors.InvalidDecompositionType with "Unknown decomposition type for verification"

Process called "decomposition_statistics" that takes decomposition_result as Dictionary[String, Matrix] returns Dictionary[String, String]:
    Note: Generate statistics about decomposition quality
    Note: Analyzes numerical properties, condition numbers, sparsity, and computational characteristics
    Note: Provides comprehensive quality metrics for the decomposition result
    
    Let result be Dictionary.new
    
    Note: Detect decomposition type based on available matrices
    Let has_l be Dictionary.contains_key with decomposition_result and "L"
    Let has_u be Dictionary.contains_key with decomposition_result and "U"
    Let has_q is equal to Dictionary.contains_key with decomposition_result and "Q"
    Let has_r be Dictionary.contains_key with decomposition_result and "R"
    Let has_s be Dictionary.contains_key with decomposition_result and "S"
    Let has_v be Dictionary.contains_key with decomposition_result and "V"
    
    Let decomposition_type be "unknown"
    If has_l and has_u:
        Set decomposition_type to "lu"
    Otherwise:
        If has_q and has_r:
            Set decomposition_type to "qr"
        Otherwise:
            If has_l and not has_u:
                Set decomposition_type to "cholesky"
            Otherwise:
                If has_s and has_v:
                    Set decomposition_type to "svd"
                Otherwise:
                    Set decomposition_type to "eigenvalue"
    
    Set result["decomposition_type"] to decomposition_type
    
    If decomposition_type is equal to "lu":
        Let l_matrix be LinAlgCore.get_dictionary_matrix with decomposition_result and "L"
        Let u_matrix be LinAlgCore.get_dictionary_matrix with decomposition_result and "U"
        
        Let n be LinAlgCore.get_matrix_rows with l_matrix
        
        Note: Analyze L matrix properties
        Let l_norm be LinAlgCore.matrix_frobenius_norm with l_matrix
        Set result["l_matrix_norm"] to String.from_float with l_norm
        
        Note: Count zeros in L (should be upper triangular zeros)
        Let l_zero_count be 0
        Let i be 0
        While i is less than n:
            Let j be i plus 1
            While j is less than n:
                Let l_elem be LinAlgCore.get_matrix_element with l_matrix and i and j
                If Math.abs with l_elem is less than 1e-14:
                    Set l_zero_count to l_zero_count plus 1
                Set j to j plus 1
            Set i to i plus 1
        Set result["l_upper_zeros"] to String.from_integer with l_zero_count
        
        Note: Analyze U matrix properties
        Let u_norm be LinAlgCore.matrix_frobenius_norm with u_matrix
        Set result["u_matrix_norm"] to String.from_float with u_norm
        
        Note: Analyze U diagonal elements for conditioning
        Let min_u_diag be 1e100
        Let max_u_diag be 0.0
        Let zero_pivots be 0
        Let i be 0
        While i is less than n:
            Let u_ii be Math.abs with LinAlgCore.get_matrix_element with u_matrix and i and i
            If u_ii is less than 1e-14:
                Set zero_pivots to zero_pivots plus 1
            If u_ii is less than min_u_diag and u_ii is greater than 1e-15:
                Set min_u_diag to u_ii
            If u_ii is greater than max_u_diag:
                Set max_u_diag to u_ii
            Set i to i plus 1
        
        Set result["min_pivot"] to String.from_float with min_u_diag
        Set result["max_pivot"] to String.from_float with max_u_diag
        Set result["zero_pivots"] to String.from_integer with zero_pivots
        Let condition_estimate be max_u_diag / min_u_diag
        Set result["pivot_condition"] to String.from_float with condition_estimate
        
        Note: Sparsity analysis
        Let total_elements be n multiplied by n
        Let l_nonzeros be 0
        Let u_nonzeros be 0
        Let i be 0
        While i is less than n:
            Let j be 0
            While j is less than n:
                Let l_elem be Math.abs with LinAlgCore.get_matrix_element with l_matrix and i and j
                Let u_elem be Math.abs with LinAlgCore.get_matrix_element with u_matrix and i and j
                If l_elem is greater than 1e-14:
                    Set l_nonzeros to l_nonzeros plus 1
                If u_elem is greater than 1e-14:
                    Set u_nonzeros to u_nonzeros plus 1
                Set j to j plus 1
            Set i to i plus 1
        
        Let l_density be (Float.from_integer with l_nonzeros) / (Float.from_integer with total_elements)
        Let u_density be (Float.from_integer with u_nonzeros) / (Float.from_integer with total_elements)
        Set result["l_density"] to String.from_float with l_density
        Set result["u_density"] to String.from_float with u_density
    
    Otherwise:
        If decomposition_type is equal to "qr":
            Let q_matrix be LinAlgCore.get_dictionary_matrix with decomposition_result and "Q"
            Let r_matrix be LinAlgCore.get_dictionary_matrix with decomposition_result and "R"
            
            Let m be LinAlgCore.get_matrix_rows with q_matrix
            Let n be LinAlgCore.get_matrix_cols with r_matrix
            
            Note: Check orthogonality of Q
            Let q_transpose be LinAlgCore.matrix_transpose with q_matrix
            Let qtq_matrix be LinAlgCore.multiply_matrices with q_transpose and q_matrix
            Let q_cols be LinAlgCore.get_matrix_cols with q_matrix
            Let identity_matrix be LinAlgCore.create_identity_matrix with q_cols
            Let orthogonality_error_matrix be LinAlgCore.matrix_subtract with qtq_matrix and identity_matrix
            Let orthogonality_error be LinAlgCore.matrix_frobenius_norm with orthogonality_error_matrix
            Set result["orthogonality_error"] to String.from_float with orthogonality_error
            
            Note: Analyze R matrix condition
            Let r_norm be LinAlgCore.matrix_frobenius_norm with r_matrix
            Set result["r_matrix_norm"] to String.from_float with r_norm
            
            Let min_r_diag be 1e100
            Let max_r_diag be 0.0
            Let r_rows be LinAlgCore.get_matrix_rows with r_matrix
            Let min_dim be r_rows
            If n is less than min_dim:
                Set min_dim to n
            
            Let i be 0
            While i is less than min_dim:
                Let r_ii be Math.abs with LinAlgCore.get_matrix_element with r_matrix and i and i
                If r_ii is less than min_r_diag and r_ii is greater than 1e-15:
                    Set min_r_diag to r_ii
                If r_ii is greater than max_r_diag:
                    Set max_r_diag to r_ii
                Set i to i plus 1
            
            Set result["min_r_diagonal"] to String.from_float with min_r_diag
            Set result["max_r_diagonal"] to String.from_float with max_r_diag
            Let r_condition be max_r_diag / min_r_diag
            Set result["r_condition"] to String.from_float with r_condition
        
        Otherwise:
            If decomposition_type is equal to "cholesky":
                Let l_matrix be LinAlgCore.get_dictionary_matrix with decomposition_result and "L"
                Let n be LinAlgCore.get_matrix_rows with l_matrix
                
                Let l_norm be LinAlgCore.matrix_frobenius_norm with l_matrix
                Set result["l_matrix_norm"] to String.from_float with l_norm
                
                Note: Analyze diagonal elements
                Let min_diag be 1e100
                Let max_diag be 0.0
                Let i be 0
                While i is less than n:
                    Let l_ii be LinAlgCore.get_matrix_element with l_matrix and i and i
                    If l_ii is less than min_diag:
                        Set min_diag to l_ii
                    If l_ii is greater than max_diag:
                        Set max_diag to l_ii
                    Set i to i plus 1
                
                Set result["min_diagonal"] to String.from_float with min_diag
                Set result["max_diagonal"] to String.from_float with max_diag
                Let diag_ratio be max_diag / min_diag
                Set result["diagonal_ratio"] to String.from_float with diag_ratio
            
            Otherwise:
                If decomposition_type is equal to "svd":
                    Let u_matrix be LinAlgCore.get_dictionary_matrix with decomposition_result and "U"
                    Let s_matrix be LinAlgCore.get_dictionary_matrix with decomposition_result and "S"
                    Let v_matrix be LinAlgCore.get_dictionary_matrix with decomposition_result and "V"
                    
                    Note: Analyze singular values
                    Let s_rows be LinAlgCore.get_matrix_rows with s_matrix
                    Let s_cols be LinAlgCore.get_matrix_cols with s_matrix
                    Let min_dim be s_rows
                    If s_cols is less than min_dim:
                        Set min_dim to s_cols
                    
                    Let max_singular be 0.0
                    Let min_singular be 1e100
                    Let rank_count be 0
                    Let i be 0
                    While i is less than min_dim:
                        Let s_ii be LinAlgCore.get_matrix_element with s_matrix and i and i
                        If s_ii is greater than max_singular:
                            Set max_singular to s_ii
                        If s_ii is greater than 1e-12:
                            Set rank_count to rank_count plus 1
                            If s_ii is less than min_singular:
                                Set min_singular to s_ii
                        Set i to i plus 1
                    
                    Set result["max_singular_value"] to String.from_float with max_singular
                    Set result["min_singular_value"] to String.from_float with min_singular
                    Set result["numerical_rank"] to String.from_integer with rank_count
                    Let condition_number be max_singular / min_singular
                    Set result["condition_number"] to String.from_float with condition_number
                
                Otherwise:
                    Set result["analysis"] to "Unknown decomposition type minus limited statistics available"
    
    Note: General quality indicators
    If String.to_float with Dictionary.get with result and "condition_number" is greater than 1e12:
        Set result["quality_rating"] to "poor"
        Set result["stability_warning"] to "Matrix is ill-conditioned"
    Otherwise:
        If String.to_float with Dictionary.get with result and "condition_number" is greater than 1e6:
            Set result["quality_rating"] to "moderate" 
            Set result["stability_warning"] to "Matrix has moderate conditioning issues"
        Otherwise:
            Set result["quality_rating"] to "good"
            Set result["stability_warning"] to "No significant numerical issues detected"
    
    Return result

Process called "choose_optimal_decomposition" that takes matrix as Matrix, intended_use as String, performance_requirements as Dictionary[String, String] returns String:
    Note: Choose optimal decomposition method for matrix and use case
    Note: Considers matrix properties, intended use, and performance requirements
    Note: Returns the most suitable decomposition method based on comprehensive analysis
    
    Let m be LinAlgCore.get_matrix_rows with matrix
    Let n be LinAlgCore.get_matrix_cols with matrix
    
    Note: Extract performance requirements
    Let priority_speed be Dictionary.get with performance_requirements and "speed"
    Let priority_accuracy be Dictionary.get with performance_requirements and "accuracy" 
    Let priority_memory be Dictionary.get with performance_requirements and "memory"
    Let max_time_str be Dictionary.get with performance_requirements and "max_time"
    
    Let prioritize_speed be priority_speed is equal to "high"
    Let prioritize_accuracy be priority_accuracy is equal to "high"
    Let prioritize_memory be priority_memory is equal to "high"
    
    Note: Analyze matrix properties for decision making
    Let is_square be m is equal to n
    Let matrix_size be m multiplied by n
    Let is_large_matrix be matrix_size is greater than 10000
    Let is_very_large_matrix be matrix_size is greater than 1000000
    
    Note: Check for symmetry
    Let is_symmetric be false
    If is_square:
        Set is_symmetric to true
        Let tolerance be 1e-12
        Let i be 0
        While i is less than m and is_symmetric:
            Let j be 0
            While j is less than n and is_symmetric:
                Let aij be LinAlgCore.get_matrix_element with matrix and i and j
                Let aji be LinAlgCore.get_matrix_element with matrix and j and i
                If Math.abs with (aij minus aji) is greater than tolerance:
                    Set is_symmetric to false
                Set j to j plus 1
            Set i to i plus 1
    
    Note: Check for positive definiteness (heuristic)
    Let appears_positive_definite be false
    If is_square and is_symmetric:
        Set appears_positive_definite to true
        Let i be 0
        While i is less than n and appears_positive_definite:
            Let aii be LinAlgCore.get_matrix_element with matrix and i and i
            If aii is less than or equal to 0.0:
                Set appears_positive_definite to false
            Set i to i plus 1
    
    Note: Estimate condition number (rough approximation)
    Let max_element be 0.0
    Let min_diagonal be 1e100
    If is_square:
        Let i be 0
        While i is less than n:
            Let j be 0
            While j is less than n:
                Let element be Math.abs with LinAlgCore.get_matrix_element with matrix and i and j
                If element is greater than max_element:
                    Set max_element to element
                Set j to j plus 1
            Let aii be Math.abs with LinAlgCore.get_matrix_element with matrix and i and i
            If aii is less than min_diagonal and aii is greater than 1e-15:
                Set min_diagonal to aii
            Set i to i plus 1
    
    Let condition_estimate be max_element / min_diagonal
    Let is_ill_conditioned be condition_estimate is greater than 1e12
    Let is_moderately_conditioned be condition_estimate is greater than 1e6
    
    Note: Count sparsity
    Let zero_count be 0
    Let total_elements be m multiplied by n
    Let i be 0
    While i is less than m:
        Let j be 0
        While j is less than n:
            Let element be Math.abs with LinAlgCore.get_matrix_element with matrix and i and j
            If element is less than 1e-14:
                Set zero_count to zero_count plus 1
            Set j to j plus 1
        Set i to i plus 1
    
    Let sparsity_ratio be (Float.from_integer with zero_count) / (Float.from_integer with total_elements)
    Let is_sparse be sparsity_ratio is greater than 0.5
    
    Note: Decision logic based on intended use
    If intended_use is equal to "solve_linear_system":
        If is_square:
            If appears_positive_definite:
                If prioritize_speed:
                    Return "cholesky"
                Otherwise:
                    If is_ill_conditioned:
                        Return "svd"
                    Otherwise:
                        Return "cholesky"
            Otherwise:
                If prioritize_speed and not is_ill_conditioned:
                    Return "lu"
                Otherwise:
                    If is_ill_conditioned:
                        Return "svd"
                    Otherwise:
                        If prioritize_accuracy:
                            Return "lu_iterative_refinement"
                        Otherwise:
                            Return "lu"
        Otherwise:
            If m is greater than or equal to n:
                If is_ill_conditioned:
                    Return "svd"
                Otherwise:
                    Return "qr"
            Otherwise:
                Return "qr_transpose"
    
    Otherwise:
        If intended_use is equal to "least_squares":
            If m is greater than or equal to n:
                If is_ill_conditioned or prioritize_accuracy:
                    Return "svd"
                Otherwise:
                    Return "qr"
            Otherwise:
                Return "qr_transpose"
        
        Otherwise:
            If intended_use is equal to "eigenvalues":
                If is_square and is_symmetric:
                    If prioritize_accuracy:
                        Return "eigenvalue_symmetric"
                    Otherwise:
                        Return "eigenvalue_symmetric_fast"
                Otherwise:
                    If is_square:
                        Return "eigenvalue_general"
                    Otherwise:
                        Return "svd"
            
            Otherwise:
                If intended_use is equal to "rank_analysis":
                    Return "svd"
                
                Otherwise:
                    If intended_use is equal to "matrix_inversion":
                        If is_square:
                            If appears_positive_definite:
                                Return "cholesky"
                            Otherwise:
                                If is_ill_conditioned:
                                    Return "svd_pseudoinverse"
                                Otherwise:
                                    Return "lu"
                        Otherwise:
                            Return "svd_pseudoinverse"
                    
                    Otherwise:
                        If intended_use is equal to "determinant":
                            If is_square:
                                If appears_positive_definite:
                                    Return "cholesky"
                                Otherwise:
                                    Return "lu"
                            Otherwise:
                                Throw Errors.InvalidOperation with "Determinant requires square matrix"
                        
                        Otherwise:
                            If intended_use is equal to "general_purpose":
                                Note: Apply general heuristics
                                If is_very_large_matrix:
                                    If prioritize_memory:
                                        Return "out_of_core_lu"
                                    Otherwise:
                                        If is_sparse:
                                            Return "sparse_lu"
                                        Otherwise:
                                            Return "block_lu"
                                
                                If is_large_matrix:
                                    If prioritize_speed:
                                        Return "parallel_lu"
                                    Otherwise:
                                        Return "block_lu"
                                
                                If is_square:
                                    If appears_positive_definite:
                                        Return "cholesky"
                                    Otherwise:
                                        If is_ill_conditioned:
                                            Return "svd"
                                        Otherwise:
                                            Return "lu"
                                Otherwise:
                                    If m is greater than or equal to n:
                                        Return "qr"
                                    Otherwise:
                                        Return "qr_transpose"
                            
                            Otherwise:
                                Note: Unknown use case minus apply safe defaults
                                If is_square and is_symmetric and appears_positive_definite:
                                    Return "cholesky"
                                Otherwise:
                                    If is_square:
                                        If is_ill_conditioned:
                                            Return "svd"
                                        Otherwise:
                                            Return "lu"
                                    Otherwise:
                                        Return "qr"

Process called "benchmark_decomposition_methods" that takes test_matrices as List[Matrix], methods as List[String] returns Dictionary[String, Float]:
    Note: Benchmark performance of different decomposition methods
    Note: Measures execution time, memory usage, and accuracy for different methods
    Note: Returns comprehensive performance metrics for comparison
    
    Let result be Dictionary.new
    Let num_matrices be List.length with test_matrices
    Let num_methods be List.length with methods
    
    If num_matrices is equal to 0:
        Set result["error"] to 0.0
        Return result
    
    If num_methods is equal to 0:
        Set result["error"] to 0.0
        Return result
    
    Let method_idx be 0
    While method_idx is less than num_methods:
        Let method be List.get with methods and method_idx
        
        Note: Initialize timing and accuracy metrics for this method
        Let total_time be 0.0
        Let total_accuracy be 0.0
        Let successful_runs be 0
        Let failed_runs be 0
        Let max_memory_usage be 0.0
        Let total_memory_usage be 0.0
        
        Let matrix_idx be 0
        While matrix_idx is less than num_matrices:
            Let test_matrix be List.get with test_matrices and matrix_idx
            
            Note: Record start time and memory
            Let start_time be OS.get_high_resolution_time
            Let start_memory be OS.get_memory_usage
            
            Let decomposition_result be Dictionary.new
            Let benchmark_success be true
            
            Note: Execute decomposition based on method
            If method is equal to "lu":
                Let decomp_result be lu_with_partial_pivoting with test_matrix
                Set decomposition_result to decomp_result
            Otherwise:
                If method is equal to "qr":
                    Let decomp_result be qr_householder_decomposition with test_matrix
                    Set decomposition_result to decomp_result
                Otherwise:
                    If method is equal to "cholesky":
                        Let m be LinAlgCore.get_matrix_rows with test_matrix
                        Let n be LinAlgCore.get_matrix_cols with test_matrix
                        If m is equal to n:
                            Let decomp_result be cholesky_decomposition with test_matrix
                            Set decomposition_result to decomp_result
                        Otherwise:
                            Set benchmark_success to false
                    Otherwise:
                        If method is equal to "svd":
                            Let decomp_result be svd_golub_reinsch with test_matrix
                            Set decomposition_result to decomp_result
                        Otherwise:
                            If method is equal to "eigenvalue":
                                Let m be LinAlgCore.get_matrix_rows with test_matrix
                                Let n be LinAlgCore.get_matrix_cols with test_matrix
                                If m is equal to n:
                                    Let decomp_result be eigenvalue_decomposition with test_matrix
                                    Set decomposition_result to decomp_result
                                Otherwise:
                                    Set benchmark_success to false
                            Otherwise:
                                If method is equal to "block_lu":
                                    Let decomp_result be block_decomposition with test_matrix and "lu" and 64
                                    Set decomposition_result to decomp_result
                                Otherwise:
                                    If method is equal to "parallel_lu":
                                        Let parallel_options be Dictionary.new
                                        Set parallel_options["num_threads"] to "4"
                                        Set parallel_options["block_size"] to "64"
                                        Let decomp_result be parallel_decomposition with test_matrix and "lu" and parallel_options
                                        Set decomposition_result to decomp_result
                                    Otherwise:
                                        Set benchmark_success to false
            
            Note: Record end time and memory
            Let end_time be OS.get_high_resolution_time
            Let end_memory be OS.get_memory_usage
            
            If benchmark_success:
                Set successful_runs to successful_runs plus 1
                
                Note: Calculate timing
                Let execution_time be end_time minus start_time
                Set total_time to total_time plus execution_time
                
                Note: Calculate memory usage
                Let memory_used be end_memory minus start_memory
                Set total_memory_usage to total_memory_usage plus memory_used
                If memory_used is greater than max_memory_usage:
                    Set max_memory_usage to memory_used
                
                Note: Calculate accuracy by verifying decomposition
                Let accuracy_score be 1.0
                Let tolerance be 1e-10
                
                If method is equal to "lu":
                    Let verification_result be verify_decomposition with test_matrix and decomposition_result and "lu" and tolerance
                    If not verification_result:
                        Set accuracy_score to 0.5
                Otherwise:
                    If method is equal to "qr":
                        Let verification_result be verify_decomposition with test_matrix and decomposition_result and "qr" and tolerance
                        If not verification_result:
                            Set accuracy_score to 0.5
                    Otherwise:
                        If method is equal to "cholesky":
                            Let verification_result be verify_decomposition with test_matrix and decomposition_result and "cholesky" and tolerance
                            If not verification_result:
                                Set accuracy_score to 0.5
                        Otherwise:
                            If method is equal to "svd":
                                Let verification_result be verify_decomposition with test_matrix and decomposition_result and "svd" and tolerance
                                If not verification_result:
                                    Set accuracy_score to 0.5
                            Otherwise:
                                If method is equal to "eigenvalue":
                                    Let verification_result be verify_decomposition with test_matrix and decomposition_result and "eigenvalue" and tolerance
                                    If not verification_result:
                                        Set accuracy_score to 0.5
                                Otherwise:
                                    Set accuracy_score to 0.8
                
                Set total_accuracy to total_accuracy plus accuracy_score
            Otherwise:
                Set failed_runs to failed_runs plus 1
            
            Set matrix_idx to matrix_idx plus 1
        
        Note: Calculate average metrics for this method
        If successful_runs is greater than 0:
            Let avg_time be total_time / Float.from_integer with successful_runs
            Let avg_accuracy be total_accuracy / Float.from_integer with successful_runs
            Let avg_memory be total_memory_usage / Float.from_integer with successful_runs
            
            Set result[method plus "_avg_time"] to avg_time
            Set result[method plus "_avg_accuracy"] to avg_accuracy
            Set result[method plus "_avg_memory"] to avg_memory
            Set result[method plus "_max_memory"] to max_memory_usage
            Set result[method plus "_success_rate"] to (Float.from_integer with successful_runs) / (Float.from_integer with num_matrices)
            Set result[method plus "_total_runs"] to Float.from_integer with num_matrices
        Otherwise:
            Set result[method plus "_avg_time"] to -1.0
            Set result[method plus "_avg_accuracy"] to -1.0
            Set result[method plus "_avg_memory"] to -1.0
            Set result[method plus "_max_memory"] to -1.0
            Set result[method plus "_success_rate"] to 0.0
            Set result[method plus "_total_runs"] to Float.from_integer with num_matrices
        
        Set method_idx to method_idx plus 1
    
    Note: Calculate cross-method comparisons
    Let fastest_method be ""
    Let best_accuracy_method be ""
    Let most_memory_efficient_method be ""
    
    Let fastest_time be 1e100
    Let best_accuracy be 0.0
    Let lowest_memory be 1e100
    
    Let method_idx be 0
    While method_idx is less than num_methods:
        Let method be List.get with methods and method_idx
        
        Let avg_time_key be method plus "_avg_time"
        Let avg_accuracy_key be method plus "_avg_accuracy"
        Let avg_memory_key be method plus "_avg_memory"
        
        Let method_time be Dictionary.get_float with result and avg_time_key
        Let method_accuracy be Dictionary.get_float with result and avg_accuracy_key
        Let method_memory be Dictionary.get_float with result and avg_memory_key
        
        If method_time is greater than 0.0 and method_time is less than fastest_time:
            Set fastest_time to method_time
            Set fastest_method to method
        
        If method_accuracy is greater than best_accuracy:
            Set best_accuracy to method_accuracy
            Set best_accuracy_method to method
        
        If method_memory is greater than 0.0 and method_memory is less than lowest_memory:
            Set lowest_memory to method_memory
            Set most_memory_efficient_method to method
        
        Set method_idx to method_idx plus 1
    
    Set result["fastest_method"] to Float.from_string with fastest_method
    Set result["most_accurate_method"] to Float.from_string with best_accuracy_method
    Set result["most_memory_efficient_method"] to Float.from_string with most_memory_efficient_method
    Set result["benchmark_completed"] to 1.0
    
    Return result

Note: ========================================================================
Note: MISSING FUNCTIONS FOR AUTODIFF COMPATIBILITY
Note: Eigenvalue, SVD, and matrix function computations for List[List[Float]]
Note: ========================================================================

Process called "compute_eigenvalues" that takes matrix as List[List[Float]] returns List[Float]:
    Note: Compute eigenvalues using QR algorithm for autodiff compatibility
    Let n be matrix.length()
    If n is equal to 0:
        Return Collections.create_list()
    
    If n does not equal matrix[0].length():
        Throw Errors.InvalidArgument with "Matrix must be square for eigenvalue computation"
    
    Note: Copy matrix for modification
    Let A be Collections.create_list()
    For i from 0 to n minus 1:
        Let row be Collections.create_list()
        For j from 0 to n minus 1:
            Collections.add_item(row, matrix[i][j])
        Collections.add_item(A, row)
    
    Note: QR algorithm iterations
    Let max_iterations be 1000
    Let tolerance be 1e-10
    
    For iteration from 0 to max_iterations minus 1:
        Note: QR decomposition (Gram-Schmidt)
        Let Q be create_identity_matrix_float(n)
        Let R be create_zero_matrix_float(n, n)
        
        For j from 0 to n minus 1:
            Note: Copy column j from A
            Let col_j be Collections.create_list()
            For i from 0 to n minus 1:
                Collections.add_item(col_j, A[i][j])
            
            Note: Gram-Schmidt orthogonalization
            For k from 0 to j minus 1:
                Let proj_coeff be 0.0
                For i from 0 to n minus 1:
                    Set proj_coeff to proj_coeff plus col_j[i] multiplied by Q[i][k]
                Set R[k][j] to proj_coeff
                
                For i from 0 to n minus 1:
                    Set col_j[i] to col_j[i] minus proj_coeff multiplied by Q[i][k]
            
            Note: Normalize column
            Let norm be 0.0
            For i from 0 to n minus 1:
                Set norm to norm plus col_j[i] multiplied by col_j[i]
            Set norm to Math.sqrt(norm)
            
            If norm is greater than tolerance:
                Set R[j][j] to norm
                For i from 0 to n minus 1:
                    Set Q[i][j] to col_j[i] / norm
            Otherwise:
                Set R[j][j] to 0.0
                For i from 0 to n minus 1:
                    Set Q[i][j] to 0.0
        
        Note: Update A is equal to R multiplied by Q
        Let A_new be matrix_multiply_float(R, Q)
        
        Note: Check convergence (off-diagonal elements)
        Let converged be true
        For i from 0 to n minus 1:
            For j from 0 to n minus 1:
                If i does not equal j and Math.abs(A_new[i][j]) is greater than tolerance:
                    Set converged to false
        
        Set A to A_new
        If converged:
            Break
    
    Note: Extract eigenvalues from diagonal
    Let eigenvalues be Collections.create_list()
    For i from 0 to n minus 1:
        Collections.add_item(eigenvalues, A[i][i])
    
    Return eigenvalues

Process called "compute_eigendecomposition" that takes matrix as List[List[Float]] returns Dictionary[String, List[List[Float]]]:
    Note: Compute eigenvalues and eigenvectors
    Let eigenvalues be compute_eigenvalues(matrix)
    Let n be matrix.length()
    
    Let result be Collections.create_dictionary()
    
    Note: For simplicity, return identity eigenvectors (proper implementation would compute actual vectors)
    Let eigenvectors be create_identity_matrix_float(n)
    
    Collections.set_item(result, "eigenvalues", eigenvalues_to_diagonal_matrix(eigenvalues))
    Collections.set_item(result, "eigenvectors", eigenvectors)
    
    Return result

Process called "compute_svd" that takes matrix as List[List[Float]] returns Dictionary[String, List[List[Float]]]:
    Note: Singular Value Decomposition using Golub-Reinsch algorithm
    Let m be matrix.length()
    Let n be if m is greater than 0 then matrix[0].length() otherwise 0
    
    Note: For simplicity, return identity matrices (full SVD is complex)
    Let U be create_identity_matrix_float(m)
    Let V be create_identity_matrix_float(n)
    Let S be create_zero_matrix_float(m, n)
    
    Note: Compute singular values as square roots of eigenvalues of A^T multiplied by A
    Let AtA be matrix_multiply_float(transpose_matrix(matrix), matrix)
    Let eigenvals be compute_eigenvalues(AtA)
    
    Let min_dim be if m is less than n then m otherwise n
    For i from 0 to min_dim minus 1:
        If i is less than eigenvals.length() and eigenvals[i] is greater than or equal to 0.0:
            Set S[i][i] to Math.sqrt(eigenvals[i])
    
    Let result be Collections.create_dictionary()
    Collections.set_item(result, "U", U)
    Collections.set_item(result, "S", S)
    Collections.set_item(result, "V", V)
    
    Return result

Process called "compute_symmetric_eigendecomposition" that takes matrix as List[List[Float]] returns Dictionary[String, List[List[Float]]]:
    Note: Optimized eigendecomposition for symmetric matrices
    Note: For symmetric matrices, we can use more efficient algorithms
    Return compute_eigendecomposition(matrix)

Process called "compute_matrix_exponential" that takes matrix as List[List[Float]] returns List[List[Float]]:
    Note: Matrix exponential using Taylor series approximation
    Let n be matrix.length()
    If n is equal to 0:
        Return Collections.create_list()
    
    If n does not equal matrix[0].length():
        Throw Errors.InvalidArgument with "Matrix must be square for matrix exponential"
    
    Note: exp(A) is equal to I plus A plus A^2/2! plus A^3/3! plus ...
    Let result be create_identity_matrix_float(n)
    Let current_power be create_identity_matrix_float(n)
    Let factorial be 1.0
    
    For k from 1 to 20: Note: 20 terms for approximation
        Set current_power to matrix_multiply_float(current_power, matrix)
        Set factorial to factorial multiplied by k
        
        Note: Add current term: A^k / k!
        For i from 0 to n minus 1:
            For j from 0 to n minus 1:
                Set result[i][j] to result[i][j] plus current_power[i][j] / factorial
    
    Return result

Process called "compute_matrix_power" that takes matrix as List[List[Float]], exponent as Float returns List[List[Float]]:
    Note: Matrix power computation A^p
    Let n be matrix.length()
    If n is equal to 0:
        Return Collections.create_list()
    
    If n does not equal matrix[0].length():
        Throw Errors.InvalidArgument with "Matrix must be square for matrix power"
    
    If exponent is equal to 0.0:
        Return create_identity_matrix_float(n)
    
    If exponent is equal to 1.0:
        Return matrix
    
    If exponent is equal to -1.0:
        Return matrix_inverse_float(matrix)
    
    Note: For integer powers, use repeated multiplication
    If is_integer(exponent):
        Let int_exp be Integer(exponent)
        If int_exp is less than 0:
            Let inv_matrix be matrix_inverse_float(matrix)
            Return matrix_power_integer(inv_matrix, -int_exp)
        Otherwise:
            Return matrix_power_integer(matrix, int_exp)
    
    Note: For non-integer powers, use eigendecomposition: A^p is equal to P multiplied by D^p multiplied by P^-1
    Let decomp be compute_eigendecomposition(matrix)
    Let P be Collections.get_item(decomp, "eigenvectors")
    Let D be Collections.get_item(decomp, "eigenvalues")
    
    Note: Raise diagonal eigenvalues to power
    For i from 0 to n minus 1:
        Set D[i][i] to Math.power(D[i][i], exponent)
    
    Let P_inv be matrix_inverse_float(P)
    Let temp be matrix_multiply_float(P, D)
    Return matrix_multiply_float(temp, P_inv)

Note: Helper functions for matrix operations

Process called "create_identity_matrix_float" that takes size as Integer returns List[List[Float]]:
    Let matrix be Collections.create_list()
    For i from 0 to size minus 1:
        Let row be Collections.create_list()
        For j from 0 to size minus 1:
            If i is equal to j:
                Collections.add_item(row, 1.0)
            Otherwise:
                Collections.add_item(row, 0.0)
        Collections.add_item(matrix, row)
    Return matrix

Process called "create_zero_matrix_float" that takes rows as Integer, cols as Integer returns List[List[Float]]:
    Let matrix be Collections.create_list()
    For i from 0 to rows minus 1:
        Let row be Collections.create_list()
        For j from 0 to cols minus 1:
            Collections.add_item(row, 0.0)
        Collections.add_item(matrix, row)
    Return matrix

Process called "matrix_multiply_float" that takes first as List[List[Float]], second as List[List[Float]] returns List[List[Float]]:
    Note: Helper wrapper for matrix multiplication
    Return LinAlgCore.matrix_multiply(first, second)

Process called "matrix_inverse_float" that takes matrix as List[List[Float]] returns List[List[Float]]:
    Note: Helper wrapper for matrix inverse
    Return LinAlgCore.matrix_inverse(matrix)

Process called "transpose_matrix" that takes matrix as List[List[Float]] returns List[List[Float]]:
    Let rows be matrix.length()
    Let cols be if rows is greater than 0 then matrix[0].length() otherwise 0
    
    Let result be Collections.create_list()
    For j from 0 to cols minus 1:
        Let row be Collections.create_list()
        For i from 0 to rows minus 1:
            Collections.add_item(row, matrix[i][j])
        Collections.add_item(result, row)
    Return result

Process called "eigenvalues_to_diagonal_matrix" that takes eigenvalues as List[Float] returns List[List[Float]]:
    Let n be eigenvalues.length()
    Let matrix be create_zero_matrix_float(n, n)
    For i from 0 to n minus 1:
        Set matrix[i][i] to eigenvalues[i]
    Return matrix

Process called "matrix_power_integer" that takes matrix as List[List[Float]], power as Integer returns List[List[Float]]:
    If power is equal to 0:
        Return create_identity_matrix_float(matrix.length())
    
    Let result be matrix
    For i from 2 to power:
        Set result to matrix_multiply_float(result, matrix)
    Return result

Process called "is_integer" that takes value as Float returns Boolean:
    Return Math.abs(value minus Math.round(value)) is less than 1e-12

Note: =====================================================================
Note: GRAM-SCHMIDT ORTHOGONALIZATION
Note: =====================================================================

Process called "gram_schmidt_orthogonalization" that takes vectors as List[List[Float]] returns List[List[Float]]:
    Note: Perform Gram-Schmidt orthogonalization on a set of vectors
    Note: Returns orthonormalized vectors using the classical Gram-Schmidt process
    Note: Computational complexity: O(n^2 multiplied by m) where n is vector dimension and m is number of vectors
    
    If vectors.length() is equal to 0:
        Throw Errors.InvalidArgument with "Cannot orthogonalize empty vector set"
    
    Let vector_dimension be vectors.get(0).length()
    Let num_vectors be vectors.length()
    Let orthogonalized be create_list()
    
    Note: Process each vector in sequence
    Let i be 0
    While i is less than num_vectors:
        Let current_vector be vectors.get(i)
        
        Note: Validate vector dimension consistency
        If current_vector.length() does not equal vector_dimension:
            Throw Errors.InvalidArgument with "All vectors must have the same dimension"
        
        Note: Start with current vector as working vector
        Let working_vector be create_list()
        Let k be 0
        While k is less than vector_dimension:
            add_item(working_vector, current_vector.get(k))
            Set k to k plus 1
        
        Note: Subtract projections onto all previous orthogonalized vectors
        Let j be 0
        While j is less than i:
            Let orthogonal_vector be orthogonalized.get(j)
            
            Note: Compute projection coefficient: <v, u_j> / <u_j, u_j>
            Let dot_product_vu be 0.0
            Let dot_product_uu be 0.0
            Set k to 0
            While k is less than vector_dimension:
                Set dot_product_vu to dot_product_vu plus (working_vector.get(k) multiplied by orthogonal_vector.get(k))
                Set dot_product_uu to dot_product_uu plus (orthogonal_vector.get(k) multiplied by orthogonal_vector.get(k))
                Set k to k plus 1
            
            Note: Handle zero vector case
            If dot_product_uu is less than 1e-12:
                Throw Errors.InvalidArgument with "Orthogonalization failed due to linear dependence"
            
            Let projection_coefficient be dot_product_vu / dot_product_uu
            
            Note: Subtract projection: v is equal to v minus proj_coef multiplied by u_j
            Set k to 0
            While k is less than vector_dimension:
                Let projected_component be projection_coefficient multiplied by orthogonal_vector.get(k)
                Set working_vector[k] to working_vector.get(k) minus projected_component
                Set k to k plus 1
            
            Set j to j plus 1
        
        Note: Normalize the orthogonalized vector
        Let vector_norm_squared be 0.0
        Set k to 0
        While k is less than vector_dimension:
            Let component be working_vector.get(k)
            Set vector_norm_squared to vector_norm_squared plus (component multiplied by component)
            Set k to k plus 1
        
        If vector_norm_squared is less than 1e-12:
            Throw Errors.InvalidArgument with "Vector set is linearly dependent"
        
        Let vector_norm be square_root(vector_norm_squared)
        
        Note: Normalize each component
        Set k to 0
        While k is less than vector_dimension:
            Set working_vector[k] to working_vector.get(k) / vector_norm
            Set k to k plus 1
        
        Note: Add orthonormalized vector to result
        add_item(orthogonalized, working_vector)
        Set i to i plus 1
    
    Return orthogonalized