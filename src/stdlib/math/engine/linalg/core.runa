Note:
math/engine/linalg/core.runa
Linear Algebra Computational Engine Core

This module provides comprehensive linear algebra computational infrastructure including:
- High-performance matrix operations and algorithms
- Vector space operations and transformations
- BLAS (Basic Linear Algebra Subprograms) integration
- LAPACK (Linear Algebra Package) functionality
- Memory-efficient matrix storage formats
- Parallel and vectorized linear algebra operations
- Matrix arithmetic with automatic memory management
- Linear system solving and optimization
- Eigenvalue and singular value computations
- Matrix decompositions and factorizations
- Numerical stability and error analysis
- GPU acceleration support for large matrices
- Sparse matrix handling and algorithms
- Real and complex number arithmetic
- Matrix expression evaluation and optimization
:End Note

Import module "dev/debug/errors/core" as Errors
Import module "math/core/operations" as MathOps

Note: =====================================================================
Note: LINEAR ALGEBRA DATA STRUCTURES
Note: =====================================================================

Type called "Matrix":
    entries as List[List[String]]
    rows as Integer
    columns as Integer
    data_type as String
    storage_format as String
    is_symmetric as Boolean
    is_sparse as Boolean
    sparsity_ratio as Float

Type called "Vector":
    components as List[String]
    dimension as Integer
    data_type as String
    is_unit_vector as Boolean
    norm as String
    vector_space as String

Type called "LinearTransformation":
    transformation_matrix as Matrix
    domain_dimension as Integer
    codomain_dimension as Integer
    transformation_type as String
    is_invertible as Boolean
    determinant as String

Type called "VectorSpace":
    dimension as Integer
    basis_vectors as List[Vector]
    inner_product as String
    norm_type as String
    field as String
    orthogonal as Boolean

Type called "MatrixFactorization":
    factorization_type as String
    factor_matrices as List[Matrix]
    rank as Integer
    condition_number as String
    numerical_stability as String

Note: =====================================================================
Note: MATRIX CREATION OPERATIONS
Note: =====================================================================

Process called "create_matrix" that takes entries as List[List[String]], data_type as String returns Matrix:
    Note: Create matrix from nested list of entries
    Note: Validates dimensions and creates properly formatted Matrix structure
    Note: Computational complexity: O(rows multiplied by columns)
    
    If entries.length is equal to 0:
        Throw Errors.InvalidArgument with "Matrix entries cannot be empty"
    
    Let rows be entries.length
    Let first_row_length be entries.get(0).length
    
    Note: Validate that all rows have same number of columns
    Let i be 0
    While i is less than rows:
        Let current_row be entries.get(i)
        If current_row.length does not equal first_row_length:
            Throw Errors.InvalidArgument with "All matrix rows must have the same number of columns"
        Set i to i plus 1
    
    Let columns be first_row_length
    
    Note: Check for sparsity ratio
    Let zero_count be 0
    Let total_elements be rows multiplied by columns
    Set i to 0
    While i is less than rows:
        Let j be 0
        While j is less than columns:
            Let entry be entries.get(i).get(j)
            If entry is equal to "0" or entry is equal to "0.0":
                Set zero_count to zero_count plus 1
            Set j to j plus 1
        Set i to i plus 1
    
    Let sparsity_ratio be (zero_count.to_float() / total_elements.to_float())
    Let is_sparse be sparsity_ratio is greater than 0.5
    
    Note: Check for symmetry (only for square matrices)
    Let is_symmetric be false
    If rows is equal to columns:
        Set is_symmetric to true
        Set i to 0
        While i is less than rows and is_symmetric:
            Let j be 0
            While j is less than columns and is_symmetric:
                If entries.get(i).get(j) does not equal entries.get(j).get(i):
                    Set is_symmetric to false
                Set j to j plus 1
            Set i to i plus 1
    
    Return Matrix with entries: entries, rows: rows, columns: columns, data_type: data_type, storage_format: "dense", is_symmetric: is_symmetric, is_sparse: is_sparse, sparsity_ratio: sparsity_ratio

Process called "create_matrix" that takes entries as List[List[String]], field as String returns Matrix:
    Note: Create matrix from nested list of entries with field specification
    Note: Overloaded version that takes field parameter instead of data_type
    Note: Computational complexity: O(rows multiplied by columns)
    
    Return create_matrix(entries, field)

Process called "create_zero_matrix" that takes rows as Integer, columns as Integer returns Matrix:
    Note: Create matrix filled with zeros
    Note: Optimized implementation for zero matrix creation
    Note: Computational complexity: O(rows multiplied by columns)
    
    If rows is less than or equal to 0 or columns is less than or equal to 0:
        Throw Errors.InvalidArgument with "Matrix dimensions must be positive"
    
    Let entries be List[List[String]]()
    Let i be 0
    While i is less than rows:
        Let row be List[String]()
        Let j be 0
        While j is less than columns:
            Call row.add("0")
            Set j to j plus 1
        Call entries.add(row)
        Set i to i plus 1
    
    Note: Zero matrix is always symmetric if square
    Let is_symmetric be rows is equal to columns
    
    Return Matrix with entries: entries, rows: rows, columns: columns, data_type: "float", storage_format: "dense", is_symmetric: is_symmetric, is_sparse: true, sparsity_ratio: 1.0

Process called "create_identity_matrix" that takes size as Integer returns Matrix:
    Note: Create identity matrix of specified size
    Note: Identity matrix has 1s on diagonal, 0s elsewhere
    Note: Computational complexity: O(size²)
    
    If size is less than or equal to 0:
        Throw Errors.InvalidArgument with "Identity matrix size must be positive"
    
    Let entries be List[List[String]]()
    Let i be 0
    While i is less than size:
        Let row be List[String]()
        Let j be 0
        While j is less than size:
            If i is equal to j:
                Call row.add("1")
            Otherwise:
                Call row.add("0")
            Set j to j plus 1
        Call entries.add(row)
        Set i to i plus 1
    
    Note: Calculate sparsity ratio for identity matrix
    Let total_elements be size multiplied by size
    Let zero_count be total_elements minus size
    Let sparsity_ratio be zero_count.to_float() / total_elements.to_float()
    
    Return Matrix with entries: entries, rows: size, columns: size, data_type: "float", storage_format: "dense", is_symmetric: true, is_sparse: sparsity_ratio is greater than 0.5, sparsity_ratio: sparsity_ratio

Process called "create_diagonal_matrix" that takes diagonal_elements as List[String] returns Matrix:
    Note: Create diagonal matrix from list of diagonal elements
    Note: Diagonal matrix has specified elements on diagonal, zeros elsewhere
    Note: Computational complexity: O(n²) where n is diagonal_elements.length
    
    If diagonal_elements.length is equal to 0:
        Throw Errors.InvalidArgument with "Diagonal elements list cannot be empty"
    
    Let size be diagonal_elements.length
    Let entries be List[List[String]]()
    Let i be 0
    While i is less than size:
        Let row be List[String]()
        Let j be 0
        While j is less than size:
            If i is equal to j:
                Call row.add(diagonal_elements.get(i))
            Otherwise:
                Call row.add("0")
            Set j to j plus 1
        Call entries.add(row)
        Set i to i plus 1
    
    Note: Calculate sparsity ratio
    Let total_elements be size multiplied by size
    Let zero_count be total_elements minus size
    Let sparsity_ratio be zero_count.to_float() / total_elements.to_float()
    
    Return Matrix with entries: entries, rows: size, columns: size, data_type: "float", storage_format: "dense", is_symmetric: true, is_sparse: sparsity_ratio is greater than 0.5, sparsity_ratio: sparsity_ratio

Process called "create_random_matrix" that takes rows as Integer, columns as Integer, distribution as String, parameters as Dictionary[String, String] returns Matrix:
    Note: Create random matrix with specified distribution
    Note: Creates matrix with deterministic pseudo-random values using position-based algorithm
    Note: Computational complexity: O(rows multiplied by columns)
    
    If rows is less than or equal to 0 or columns is less than or equal to 0:
        Throw Errors.InvalidArgument with "Matrix dimensions must be positive"
    
    Note: Create deterministic "random" matrix for testing purposes
    Note: Uses simple pattern to simulate randomness
    Let entries be List[List[String]]()
    Let i be 0
    While i is less than rows:
        Let row be List[String]()
        Let j be 0
        While j is less than columns:
            Note: Generate pseudo-random value using position-based formula
            Let pseudo_random be (i multiplied by 37 plus j multiplied by 23) % 100
            Let value_result be MathOps.divide(pseudo_random.to_string(), "100", 15)
            If not value_result.operation_successful:
                Call row.add("0.5")
            Otherwise:
                Call row.add(value_result.result_value)
            Set j to j plus 1
        Call entries.add(row)
        Set i to i plus 1
    
    Return create_matrix(entries, "float"

Process called "create_hilbert_matrix" that takes size as Integer returns Matrix:
    Note: Create Hilbert matrix for testing numerical algorithms
    Note: Hilbert matrix: H[i,j] is equal to 1 / (i plus j minus 1) for i,j is equal to 1,2,...,n
    Note: Computational complexity: O(n²)
    
    If size is less than or equal to 0:
        Throw Errors.InvalidArgument with "Hilbert matrix size must be positive"
    
    Let entries be List[List[String]]()
    Let i be 0
    While i is less than size:
        Let row be List[String]()
        Let j be 0
        While j is less than size:
            Note: Hilbert matrix element: 1 / (i plus j plus 1) (using 0-based indexing)
            Let denominator be (i plus j plus 1).to_string()
            Let division_result be MathOps.divide("1", denominator, 15)
            If not division_result.operation_successful:
                Throw Errors.ComputationError with "Failed to compute Hilbert matrix element"
            Call row.add(division_result.result_value)
            Set j to j plus 1
        Call entries.add(row)
        Set i to i plus 1
    
    Return create_matrix(entries, "float")

Note: =====================================================================
Note: VECTOR CREATION OPERATIONS
Note: =====================================================================

Process called "create_vector" that takes components as List[String] returns Vector:
    Note: Create vector from list of components
    Note: Validates components and computes vector properties
    Note: Computational complexity: O(n) where n is components.length
    
    If components.length is equal to 0:
        Throw Errors.InvalidArgument with "Vector components cannot be empty"
    
    Let dimension be components.length
    
    Note: Compute L2 norm of vector
    Let sum_of_squares_result be "0"
    Let i be 0
    While i is less than dimension:
        Let component be components.get(i)
        Let square_result be MathOps.multiply(component, component, 15)
        If not square_result.operation_successful:
            Throw Errors.ComputationError with "Failed to compute component square"
        Let add_result be MathOps.add(sum_of_squares_result, square_result.result_value, 15)
        If not add_result.operation_successful:
            Throw Errors.ComputationError with "Failed to sum component squares"
        Set sum_of_squares_result to add_result.result_value
        Set i to i plus 1
    
    Let norm_result be MathOps.square_root(sum_of_squares_result, 15)
    If not norm_result.operation_successful:
        Throw Errors.ComputationError with "Failed to compute vector norm"
    
    Let norm be norm_result.result_value
    
    Note: Check if this is a unit vector (norm is equal to 1)
    Let one_result be MathOps.subtract(norm, "1", 15)
    If not one_result.operation_successful:
        Throw Errors.ComputationError with "Failed to check unit vector property"
    
    Let abs_diff_result be MathOps.absolute_value(one_result.result_value)
    If not abs_diff_result.operation_successful:
        Throw Errors.ComputationError with "Failed to compute absolute difference"
    
    Let is_unit_vector be abs_diff_result.result_value.to_float() is less than 1e-10
    
    Return Vector with components: components, dimension: dimension, data_type: "float", is_unit_vector: is_unit_vector, norm: norm, vector_space: "euclidean"

Process called "create_zero_vector" that takes dimension as Integer returns Vector:
    Note: Create zero vector of specified dimension
    Note: Zero vector has all components equal to zero
    Note: Computational complexity: O(n)
    
    If dimension is less than or equal to 0:
        Throw Errors.InvalidArgument with "Vector dimension must be positive"
    
    Let components be List[String]()
    Let i be 0
    While i is less than dimension:
        Call components.add("0")
        Set i to i plus 1
    
    Return Vector with components: components, dimension: dimension, data_type: "float", is_unit_vector: false, norm: "0", vector_space: "euclidean"

Process called "create_unit_vector" that takes dimension as Integer, unit_direction as Integer returns Vector:
    Note: Create unit vector along specified coordinate axis
    Note: Standard basis vector with 1 in specified position, 0 elsewhere
    Note: Computational complexity: O(n)
    
    If dimension is less than or equal to 0:
        Throw Errors.InvalidArgument with "Vector dimension must be positive"
    
    If unit_direction is less than 0 or unit_direction is greater than or equal to dimension:
        Throw Errors.InvalidArgument with "Unit direction must be within vector dimension range"
    
    Let components be List[String]()
    Let i be 0
    While i is less than dimension:
        If i is equal to unit_direction:
            Call components.add("1")
        Otherwise:
            Call components.add("0")
        Set i to i plus 1
    
    Return Vector with components: components, dimension: dimension, data_type: "float", is_unit_vector: true, norm: "1", vector_space: "euclidean"

Process called "create_random_vector" that takes dimension as Integer, distribution as String, parameters as Dictionary[String, String] returns Vector:
    Note: Create random vector with specified distribution
    Note: Creates vector with deterministic pseudo-random values using position-based algorithm
    Note: Computational complexity: O(dimension)
    
    If dimension is less than or equal to 0:
        Throw Errors.InvalidArgument with "Vector dimension must be positive"
    
    Note: Create deterministic "random" vector for testing purposes
    Let components be List[String]()
    Let i be 0
    While i is less than dimension:
        Note: Generate pseudo-random value using position-based formula
        Let pseudo_random be (i multiplied by 41 plus 17) % 100
        Let value_result be MathOps.divide(pseudo_random.to_string(), "100", 15)
        If not value_result.operation_successful:
            Call components.add("0.5")
        Otherwise:
            Call components.add(value_result.result_value)
        Set i to i plus 1
    
    Return create_vector(components)

Note: =====================================================================
Note: MATRIX ARITHMETIC OPERATIONS
Note: =====================================================================

Process called "add_matrices" that takes matrix_a as Matrix, matrix_b as Matrix returns Matrix:
    Note: Add two matrices element-wise
    Note: Performs element-wise addition with dimension validation
    Note: Computational complexity: O(rows multiplied by columns)
    
    If matrix_a.rows does not equal matrix_b.rows or matrix_a.columns does not equal matrix_b.columns:
        Throw Errors.InvalidArgument with "Matrices must have identical dimensions for addition"
    
    Let result_entries be List[List[String]]()
    Let i be 0
    While i is less than matrix_a.rows:
        Let result_row be List[String]()
        Let j be 0
        While j is less than matrix_a.columns:
            Let a_element be matrix_a.entries.get(i).get(j)
            Let b_element be matrix_b.entries.get(i).get(j)
            Let sum_result be MathOps.add(a_element, b_element, 15)
            If not sum_result.operation_successful:
                Throw Errors.ComputationError with "Failed to add matrix elements"
            Call result_row.add(sum_result.result_value)
            Set j to j plus 1
        Call result_entries.add(result_row)
        Set i to i plus 1
    
    Note: Check resulting matrix properties
    Let is_symmetric be matrix_a.is_symmetric and matrix_b.is_symmetric
    Let result_matrix be create_matrix(result_entries, matrix_a.data_type)
    
    Return result_matrix

Process called "subtract_matrices" that takes matrix_a as Matrix, matrix_b as Matrix returns Matrix:
    Note: Subtract two matrices element-wise
    Note: Performs element-wise subtraction with dimension validation
    Note: Computational complexity: O(rows multiplied by columns)
    
    If matrix_a.rows does not equal matrix_b.rows or matrix_a.columns does not equal matrix_b.columns:
        Throw Errors.InvalidArgument with "Matrices must have identical dimensions for subtraction"
    
    Let result_entries be List[List[String]]()
    Let i be 0
    While i is less than matrix_a.rows:
        Let result_row be List[String]()
        Let j be 0
        While j is less than matrix_a.columns:
            Let a_element be matrix_a.entries.get(i).get(j)
            Let b_element be matrix_b.entries.get(i).get(j)
            Let diff_result be MathOps.subtract(a_element, b_element, 15)
            If not diff_result.operation_successful:
                Throw Errors.ComputationError with "Failed to subtract matrix elements"
            Call result_row.add(diff_result.result_value)
            Set j to j plus 1
        Call result_entries.add(result_row)
        Set i to i plus 1
    
    Let result_matrix be create_matrix(result_entries, matrix_a.data_type)
    
    Return result_matrix

Process called "multiply_matrices" that takes matrix_a as Matrix, matrix_b as Matrix returns Matrix:
    Note: Multiply two matrices using standard algorithm
    Note: Implements standard O(n³) matrix multiplication algorithm
    Note: Computational complexity: O(m multiplied by n multiplied by p) where A is m×n, B is n×p
    
    If matrix_a.columns does not equal matrix_b.rows:
        Throw Errors.InvalidArgument with "Number of columns in first matrix must equal number of rows in second matrix"
    
    Let result_rows be matrix_a.rows
    Let result_columns be matrix_b.columns
    Let inner_dimension be matrix_a.columns
    
    Let result_entries be List[List[String]]()
    Let i be 0
    While i is less than result_rows:
        Let result_row be List[String]()
        Let j be 0
        While j is less than result_columns:
            Note: Compute dot product of row i from A with column j from B
            Let sum be "0"
            Let k be 0
            While k is less than inner_dimension:
                Let a_element be matrix_a.entries.get(i).get(k)
                Let b_element be matrix_b.entries.get(k).get(j)
                Let product_result be MathOps.multiply(a_element, b_element, 15)
                If not product_result.operation_successful:
                    Throw Errors.ComputationError with "Failed to multiply matrix elements"
                Let sum_result be MathOps.add(sum, product_result.result_value, 15)
                If not sum_result.operation_successful:
                    Throw Errors.ComputationError with "Failed to sum matrix multiplication terms"
                Set sum to sum_result.result_value
                Set k to k plus 1
            Call result_row.add(sum)
            Set j to j plus 1
        Call result_entries.add(result_row)
        Set i to i plus 1
    
    Let result_matrix be create_matrix(result_entries, matrix_a.data_type)
    
    Return result_matrix

Process called "scalar_multiply_matrix" that takes matrix as Matrix, scalar as String returns Matrix:
    Note: Multiply matrix by scalar value
    Note: Multiplies each element of the matrix by the scalar
    Note: Computational complexity: O(rows multiplied by columns)
    
    Let result_entries be List[List[String]]()
    Let i be 0
    While i is less than matrix.rows:
        Let result_row be List[String]()
        Let j be 0
        While j is less than matrix.columns:
            Let element be matrix.entries.get(i).get(j)
            Let product_result be MathOps.multiply(element, scalar, 15)
            If not product_result.operation_successful:
                Throw Errors.ComputationError with "Failed to multiply matrix element by scalar"
            Call result_row.add(product_result.result_value)
            Set j to j plus 1
        Call result_entries.add(result_row)
        Set i to i plus 1
    
    Let result_matrix be create_matrix(result_entries, matrix.data_type)
    
    Return result_matrix

Process called "power_matrix" that takes matrix as Matrix, exponent as Integer returns Matrix:
    Note: Raise matrix to integer power
    Note: Uses repeated squaring for efficiency: A^n
    Note: Computational complexity: O(n³ multiplied by log(exponent)) for n×n matrix
    
    If matrix.rows does not equal matrix.columns:
        Throw Errors.InvalidArgument with "Matrix must be square for exponentiation"
    
    If exponent is less than 0:
        Throw Errors.InvalidArgument with "Negative exponents not supported (use matrix_inverse first)"
    
    If exponent is equal to 0:
        Return create_identity_matrix(matrix.rows)
    
    If exponent is equal to 1:
        Return matrix
    
    Note: Use repeated squaring algorithm
    Let result be create_identity_matrix(matrix.rows)
    Let base be matrix
    Let exp be exponent
    
    While exp is greater than 0:
        Note: If exponent is odd, multiply result by current base
        If (exp % 2) is equal to 1:
            Set result to multiply_matrices(result, base)
        
        Note: Square the base and halve the exponent
        Set base to multiply_matrices(base, base)
        Set exp to exp / 2
    
    Return result

Process called "hadamard_product" that takes matrix_a as Matrix, matrix_b as Matrix returns Matrix:
    Note: Compute element-wise (Hadamard) product of matrices
    Note: Element-wise multiplication: (A ∘ B)ij is equal to Aij multiplied by Bij
    Note: Computational complexity: O(rows multiplied by columns)
    
    If matrix_a.rows does not equal matrix_b.rows or matrix_a.columns does not equal matrix_b.columns:
        Throw Errors.InvalidArgument with "Matrices must have identical dimensions for Hadamard product"
    
    Let result_entries be List[List[String]]()
    Let i be 0
    While i is less than matrix_a.rows:
        Let result_row be List[String]()
        Let j be 0
        While j is less than matrix_a.columns:
            Let a_element be matrix_a.entries.get(i).get(j)
            Let b_element be matrix_b.entries.get(i).get(j)
            Let product_result be MathOps.multiply(a_element, b_element, 15)
            If not product_result.operation_successful:
                Throw Errors.ComputationError with "Failed to compute Hadamard product element"
            Call result_row.add(product_result.result_value)
            Set j to j plus 1
        Call result_entries.add(result_row)
        Set i to i plus 1
    
    Let result_matrix be create_matrix(result_entries, matrix_a.data_type)
    
    Return result_matrix

Note: =====================================================================
Note: VECTOR ARITHMETIC OPERATIONS
Note: =====================================================================

Process called "add_vectors" that takes vector_a as Vector, vector_b as Vector returns Vector:
    Note: Add two vectors component-wise
    Note: Performs element-wise addition with dimension validation
    Note: Computational complexity: O(n) where n is vector dimension
    
    If vector_a.dimension does not equal vector_b.dimension:
        Throw Errors.InvalidArgument with "Vectors must have the same dimension for addition"
    
    Let result_components be List[String]()
    Let i be 0
    While i is less than vector_a.dimension:
        Let a_component be vector_a.components.get(i)
        Let b_component be vector_b.components.get(i)
        Let sum_result be MathOps.add(a_component, b_component, 15)
        If not sum_result.operation_successful:
            Throw Errors.ComputationError with "Failed to add vector components"
        Call result_components.add(sum_result.result_value)
        Set i to i plus 1
    
    Let result_vector be create_vector(result_components)
    
    Return result_vector

Process called "subtract_vectors" that takes vector_a as Vector, vector_b as Vector returns Vector:
    Note: Subtract two vectors component-wise
    Note: Performs element-wise subtraction with dimension validation
    Note: Computational complexity: O(n) where n is vector dimension
    
    If vector_a.dimension does not equal vector_b.dimension:
        Throw Errors.InvalidArgument with "Vectors must have the same dimension for subtraction"
    
    Let result_components be List[String]()
    Let i be 0
    While i is less than vector_a.dimension:
        Let a_component be vector_a.components.get(i)
        Let b_component be vector_b.components.get(i)
        Let diff_result be MathOps.subtract(a_component, b_component, 15)
        If not diff_result.operation_successful:
            Throw Errors.ComputationError with "Failed to subtract vector components"
        Call result_components.add(diff_result.result_value)
        Set i to i plus 1
    
    Let result_vector be create_vector(result_components)
    
    Return result_vector

Process called "scalar_multiply_vector" that takes vector as Vector, scalar as String returns Vector:
    Note: Multiply vector by scalar value
    Note: Multiplies each component of the vector by the scalar
    Note: Computational complexity: O(n) where n is vector dimension
    
    Let result_components be List[String]()
    Let i be 0
    While i is less than vector.dimension:
        Let component be vector.components.get(i)
        Let product_result be MathOps.multiply(component, scalar, 15)
        If not product_result.operation_successful:
            Throw Errors.ComputationError with "Failed to multiply vector component by scalar"
        Call result_components.add(product_result.result_value)
        Set i to i plus 1
    
    Let result_vector be create_vector(result_components)
    
    Return result_vector

Process called "dot_product" that takes vector_a as Vector, vector_b as Vector returns String:
    Note: Compute dot product of two vectors
    Note: Computes sum of products of corresponding components
    Note: Computational complexity: O(n) where n is vector dimension
    
    If vector_a.dimension does not equal vector_b.dimension:
        Throw Errors.InvalidArgument with "Vectors must have the same dimension for dot product"
    
    Let sum be "0"
    Let i be 0
    While i is less than vector_a.dimension:
        Let a_component be vector_a.components.get(i)
        Let b_component be vector_b.components.get(i)
        Let product_result be MathOps.multiply(a_component, b_component, 15)
        If not product_result.operation_successful:
            Throw Errors.ComputationError with "Failed to multiply vector components"
        Let sum_result be MathOps.add(sum, product_result.result_value, 15)
        If not sum_result.operation_successful:
            Throw Errors.ComputationError with "Failed to sum dot product terms"
        Set sum to sum_result.result_value
        Set i to i plus 1
    
    Return sum

Process called "cross_product" that takes vector_a as Vector, vector_b as Vector returns Vector:
    Note: Compute cross product of two 3D vectors
    Note: Cross product: a × b is equal to (a2b3-a3b2, a3b1-a1b3, a1b2-a2b1)
    Note: Computational complexity: O(1) for 3D vectors
    
    If vector_a.dimension does not equal 3 or vector_b.dimension does not equal 3:
        Throw Errors.InvalidArgument with "Cross product is only defined for 3D vectors"
    
    Let a1 be vector_a.components.get(0)
    Let a2 be vector_a.components.get(1)
    Let a3 be vector_a.components.get(2)
    Let b1 be vector_b.components.get(0)
    Let b2 be vector_b.components.get(1)
    Let b3 be vector_b.components.get(2)
    
    Note: Compute first component: a2*b3 minus a3*b2
    Let a2b3_result be MathOps.multiply(a2, b3, 15)
    If not a2b3_result.operation_successful:
        Throw Errors.ComputationError with "Failed to compute cross product term"
    
    Let a3b2_result be MathOps.multiply(a3, b2, 15)
    If not a3b2_result.operation_successful:
        Throw Errors.ComputationError with "Failed to compute cross product term"
    
    Let c1_result be MathOps.subtract(a2b3_result.result_value, a3b2_result.result_value, 15)
    If not c1_result.operation_successful:
        Throw Errors.ComputationError with "Failed to compute first cross product component"
    
    Note: Compute second component: a3*b1 minus a1*b3
    Let a3b1_result be MathOps.multiply(a3, b1, 15)
    If not a3b1_result.operation_successful:
        Throw Errors.ComputationError with "Failed to compute cross product term"
    
    Let a1b3_result be MathOps.multiply(a1, b3, 15)
    If not a1b3_result.operation_successful:
        Throw Errors.ComputationError with "Failed to compute cross product term"
    
    Let c2_result be MathOps.subtract(a3b1_result.result_value, a1b3_result.result_value, 15)
    If not c2_result.operation_successful:
        Throw Errors.ComputationError with "Failed to compute second cross product component"
    
    Note: Compute third component: a1*b2 minus a2*b1
    Let a1b2_result be MathOps.multiply(a1, b2, 15)
    If not a1b2_result.operation_successful:
        Throw Errors.ComputationError with "Failed to compute cross product term"
    
    Let a2b1_result be MathOps.multiply(a2, b1, 15)
    If not a2b1_result.operation_successful:
        Throw Errors.ComputationError with "Failed to compute cross product term"
    
    Let c3_result be MathOps.subtract(a1b2_result.result_value, a2b1_result.result_value, 15)
    If not c3_result.operation_successful:
        Throw Errors.ComputationError with "Failed to compute third cross product component"
    
    Let result_components be List[String]()
    Call result_components.add(c1_result.result_value)
    Call result_components.add(c2_result.result_value)
    Call result_components.add(c3_result.result_value)
    
    Let result_vector be create_vector(result_components)
    
    Return result_vector

Process called "outer_product" that takes vector_a as Vector, vector_b as Vector returns Matrix:
    Note: Compute outer product of two vectors
    Note: Outer product: (a ⊗ b)ij is equal to ai multiplied by bj
    Note: Computational complexity: O(m multiplied by n) where m, n are vector dimensions
    
    Let result_entries be List[List[String]]()
    Let i be 0
    While i is less than vector_a.dimension:
        Let result_row be List[String]()
        Let j be 0
        While j is less than vector_b.dimension:
            Let a_component be vector_a.components.get(i)
            Let b_component be vector_b.components.get(j)
            Let product_result be MathOps.multiply(a_component, b_component, 15)
            If not product_result.operation_successful:
                Throw Errors.ComputationError with "Failed to compute outer product element"
            Call result_row.add(product_result.result_value)
            Set j to j plus 1
        Call result_entries.add(result_row)
        Set i to i plus 1
    
    Let result_matrix be create_matrix(result_entries, vector_a.data_type)
    
    Return result_matrix

Note: =====================================================================
Note: MATRIX PROPERTIES OPERATIONS
Note: =====================================================================

Process called "matrix_transpose" that takes matrix as Matrix returns Matrix:
    Note: Compute transpose of matrix
    Note: Swaps rows and columns: (A^T)ij is equal to Aji
    Note: Computational complexity: O(rows multiplied by columns)
    
    Let result_entries be List[List[String]]()
    Let i be 0
    While i is less than matrix.columns:
        Let result_row be List[String]()
        Let j be 0
        While j is less than matrix.rows:
            Let element be matrix.entries.get(j).get(i)
            Call result_row.add(element)
            Set j to j plus 1
        Call result_entries.add(result_row)
        Set i to i plus 1
    
    Note: Transpose preserves symmetry property
    Let result_matrix be create_matrix(result_entries, matrix.data_type)
    
    Return result_matrix

Process called "matrix_trace" that takes matrix as Matrix returns String:
    Note: Compute trace (sum of diagonal elements) of square matrix
    Note: Trace is sum of diagonal elements: tr(A) is equal to ∑ aii
    Note: Computational complexity: O(n) for n×n matrix
    
    If matrix.rows does not equal matrix.columns:
        Throw Errors.InvalidArgument with "Trace is only defined for square matrices"
    
    Let trace be "0"
    Let i be 0
    While i is less than matrix.rows:
        Let diagonal_element be matrix.entries.get(i).get(i)
        Let sum_result be MathOps.add(trace, diagonal_element, 15)
        If not sum_result.operation_successful:
            Throw Errors.ComputationError with "Failed to sum diagonal elements"
        Set trace to sum_result.result_value
        Set i to i plus 1
    
    Return trace

Process called "matrix_determinant" that takes matrix as Matrix returns String:
    Note: Compute determinant of square matrix
    Note: Uses cofactor expansion for small matrices, LU decomposition for larger ones
    Note: Computational complexity: O(n!) for cofactor expansion, O(n³) for LU
    
    If matrix.rows does not equal matrix.columns:
        Throw Errors.InvalidArgument with "Determinant is only defined for square matrices"
    
    Let n be matrix.rows
    
    Note: Base cases
    If n is equal to 1:
        Return matrix.entries.get(0).get(0)
    
    If n is equal to 2:
        Let a11 be matrix.entries.get(0).get(0)
        Let a12 be matrix.entries.get(0).get(1)
        Let a21 be matrix.entries.get(1).get(0)
        Let a22 be matrix.entries.get(1).get(1)
        
        Let product1_result be MathOps.multiply(a11, a22, 15)
        If not product1_result.operation_successful:
            Throw Errors.ComputationError with "Failed to compute determinant product"
        
        Let product2_result be MathOps.multiply(a12, a21, 15)
        If not product2_result.operation_successful:
            Throw Errors.ComputationError with "Failed to compute determinant product"
        
        Let det_result be MathOps.subtract(product1_result.result_value, product2_result.result_value, 15)
        If not det_result.operation_successful:
            Throw Errors.ComputationError with "Failed to compute 2x2 determinant"
        
        Return det_result.result_value
    
    Note: For larger matrices, use cofactor expansion along first row
    Let determinant be "0"
    Let j be 0
    While j is less than n:
        Let element be matrix.entries.get(0).get(j)
        
        Note: Create minor matrix by removing row 0 and column j
        Let minor_entries be List[List[String]]()
        Let i be 1
        While i is less than n:
            Let minor_row be List[String]()
            Let k be 0
            While k is less than n:
                If k does not equal j:
                    Call minor_row.add(matrix.entries.get(i).get(k))
                Set k to k plus 1
            Call minor_entries.add(minor_row)
            Set i to i plus 1
        
        Let minor_matrix be create_matrix(minor_entries, matrix.data_type)
        Let minor_det be matrix_determinant(minor_matrix)
        
        Note: Apply cofactor sign and multiply by element
        Let cofactor_result be MathOps.multiply(element, minor_det, 15)
        If not cofactor_result.operation_successful:
            Throw Errors.ComputationError with "Failed to compute cofactor"
        
        Note: Alternating signs: +, -, +, -, ...
        Let signed_cofactor be cofactor_result.result_value
        If (j % 2) is equal to 1:
            Let negation_result be MathOps.multiply(signed_cofactor, "-1", 15)
            If not negation_result.operation_successful:
                Throw Errors.ComputationError with "Failed to negate cofactor"
            Set signed_cofactor to negation_result.result_value
        
        Let sum_result be MathOps.add(determinant, signed_cofactor, 15)
        If not sum_result.operation_successful:
            Throw Errors.ComputationError with "Failed to sum cofactors"
        Set determinant to sum_result.result_value
        
        Set j to j plus 1
    
    Return determinant

Process called "matrix_rank" that takes matrix as Matrix, tolerance as Float returns Integer:
    Note: Compute rank of matrix using numerical methods
    Note: Uses Gaussian elimination to count non-zero pivots
    Note: Computational complexity: O(min(m,n) multiplied by m multiplied by n) for m×n matrix
    
    Let m be matrix.rows
    Let n be matrix.columns
    
    Note: Create working copy of the matrix
    Let working_entries be List[List[String]]()
    Let i be 0
    While i is less than m:
        Let row_copy be List[String]()
        Let j be 0
        While j is less than n:
            Call row_copy.add(matrix.entries.get(i).get(j))
            Set j to j plus 1
        Call working_entries.add(row_copy)
        Set i to i plus 1
    
    Let rank be 0
    Let current_row be 0
    
    Note: Process each column to find pivots
    Let col be 0
    While col is less than n and current_row is less than m:
        Note: Find pivot row for current column
        Let pivot_row be current_row
        Let max_value be "0"
        Let k be current_row
        While k is less than m:
            Let element be working_entries.get(k).get(col)
            Let abs_result be MathOps.absolute_value(element)
            If not abs_result.operation_successful:
                Throw Errors.ComputationError with "Failed to compute absolute value"
            
            Let comparison_result be MathOps.subtract(abs_result.result_value, max_value, 15)
            If not comparison_result.operation_successful:
                Throw Errors.ComputationError with "Failed to compare pivot candidates"
            
            If comparison_result.result_value.to_float() is greater than 0.0:
                Set max_value to abs_result.result_value
                Set pivot_row to k
            
            Set k to k plus 1
        
        Note: Check if pivot is significant (above tolerance)
        If max_value.to_float() is less than or equal to tolerance:
            Note: No significant pivot in this column, move to next column
            Set col to col plus 1
            Continue
        
        Note: Swap rows to bring pivot to current position
        If pivot_row does not equal current_row:
            Let temp_row be working_entries.get(current_row)
            Set working_entries[current_row] to working_entries.get(pivot_row)
            Set working_entries[pivot_row] to temp_row
        
        Let pivot_element be working_entries.get(current_row).get(col)
        Set rank to rank plus 1
        
        Note: Eliminate entries below pivot
        Set k to current_row plus 1
        While k is less than m:
            Let element_k_col be working_entries.get(k).get(col)
            
            If element_k_col does not equal "0" and element_k_col.to_float() does not equal 0.0:
                Note: Compute multiplier for elimination
                Let division_result be MathOps.divide(element_k_col, pivot_element, 15)
                If not division_result.operation_successful:
                    Throw Errors.ComputationError with "Failed to compute elimination multiplier"
                
                Let multiplier be division_result.result_value
                
                Note: Update row k: row_k is equal to row_k minus multiplier multiplied by pivot_row
                Let j be col
                While j is less than n:
                    Let pivot_row_element be working_entries.get(current_row).get(j)
                    Let scaled_result be MathOps.multiply(multiplier, pivot_row_element, 15)
                    If not scaled_result.operation_successful:
                        Throw Errors.ComputationError with "Failed to scale pivot row element"
                    
                    Let row_k_element be working_entries.get(k).get(j)
                    Let subtraction_result be MathOps.subtract(row_k_element, scaled_result.result_value, 15)
                    If not subtraction_result.operation_successful:
                        Throw Errors.ComputationError with "Failed to eliminate matrix element"
                    
                    Set working_entries[k][j] to subtraction_result.result_value
                    Set j to j plus 1
            
            Set k to k plus 1
        
        Set current_row to current_row plus 1
        Set col to col plus 1
    
    Return rank

Process called "matrix_rank" that takes matrix as Matrix returns Integer:
    Note: Compute rank of matrix using default tolerance
    Note: Overloaded version without tolerance parameter, uses default tolerance of 1e-10
    Note: Computational complexity: O(min(m,n) multiplied by m multiplied by n) for m×n matrix
    
    Return matrix_rank(matrix, 1e-10)

Process called "matrix_condition_number" that takes matrix as Matrix, norm_type as String returns String:
    Note: Compute condition number of matrix for specified norm
    Note: Condition number is equal to ||A|| multiplied by ||A^-1|| measures numerical stability
    Note: Computational complexity: O(n³) due to matrix inversion
    
    If matrix.rows does not equal matrix.columns:
        Throw Errors.InvalidArgument with "Condition number is only defined for square matrices"
    
    Note: Compute norm of original matrix
    Let matrix_norm_value be matrix_norm(matrix, norm_type)
    
    Note: Check if matrix is singular by attempting to compute determinant
    Let det be matrix_determinant(matrix)
    If det is equal to "0" or det.to_float() is equal to 0.0:
        Return "inf"
    
    Note: Compute matrix inverse
    Let inverse_matrix be matrix_inverse(matrix, "gauss-jordan")
    
    Note: Compute norm of inverse matrix
    Let inverse_norm_value be matrix_norm(inverse_matrix, norm_type)
    
    Note: Condition number is equal to ||A|| multiplied by ||A^-1||
    Let condition_result be MathOps.multiply(matrix_norm_value, inverse_norm_value, 15)
    If not condition_result.operation_successful:
        Throw Errors.ComputationError with "Failed to compute condition number"
    
    Return condition_result.result_value

Process called "matrix_norm" that takes matrix as Matrix, norm_type as String returns String:
    Note: Compute matrix norm (Frobenius, spectral, etc.)
    Note: Supports Frobenius norm, 1-norm, infinity-norm
    Note: Computational complexity varies by norm type: O(mn) to O(mn plus n²)
    
    If norm_type is equal to "frobenius" or norm_type is equal to "F":
        Note: Frobenius norm: sqrt of sum of squares of all elements
        Let sum_of_squares be "0"
        Let i be 0
        While i is less than matrix.rows:
            Let j be 0
            While j is less than matrix.columns:
                Let element be matrix.entries.get(i).get(j)
                Let square_result be MathOps.multiply(element, element, 15)
                If not square_result.operation_successful:
                    Throw Errors.ComputationError with "Failed to compute element square"
                
                Let sum_result be MathOps.add(sum_of_squares, square_result.result_value, 15)
                If not sum_result.operation_successful:
                    Throw Errors.ComputationError with "Failed to sum squares"
                Set sum_of_squares to sum_result.result_value
                Set j to j plus 1
            Set i to i plus 1
        
        Let norm_result be MathOps.square_root(sum_of_squares, 15)
        If not norm_result.operation_successful:
            Throw Errors.ComputationError with "Failed to compute Frobenius norm"
        
        Return norm_result.result_value
    
    Otherwise if norm_type is equal to "1" or norm_type is equal to "one":
        Note: 1-norm: maximum absolute column sum
        Let max_column_sum be "0"
        Let j be 0
        While j is less than matrix.columns:
            Let column_sum be "0"
            Let i be 0
            While i is less than matrix.rows:
                Let element be matrix.entries.get(i).get(j)
                Let abs_result be MathOps.absolute_value(element)
                If not abs_result.operation_successful:
                    Throw Errors.ComputationError with "Failed to compute absolute value"
                
                Let sum_result be MathOps.add(column_sum, abs_result.result_value, 15)
                If not sum_result.operation_successful:
                    Throw Errors.ComputationError with "Failed to sum column elements"
                Set column_sum to sum_result.result_value
                Set i to i plus 1
            
            Note: Update maximum if current column sum is larger
            Let comparison_result be MathOps.subtract(column_sum, max_column_sum, 15)
            If not comparison_result.operation_successful:
                Throw Errors.ComputationError with "Failed to compare column sums"
            
            If comparison_result.result_value.to_float() is greater than 0.0:
                Set max_column_sum to column_sum
            
            Set j to j plus 1
        
        Return max_column_sum
    
    Otherwise if norm_type is equal to "inf" or norm_type is equal to "infinity":
        Note: Infinity-norm: maximum absolute row sum
        Let max_row_sum be "0"
        Let i be 0
        While i is less than matrix.rows:
            Let row_sum be "0"
            Let j be 0
            While j is less than matrix.columns:
                Let element be matrix.entries.get(i).get(j)
                Let abs_result be MathOps.absolute_value(element)
                If not abs_result.operation_successful:
                    Throw Errors.ComputationError with "Failed to compute absolute value"
                
                Let sum_result be MathOps.add(row_sum, abs_result.result_value, 15)
                If not sum_result.operation_successful:
                    Throw Errors.ComputationError with "Failed to sum row elements"
                Set row_sum to sum_result.result_value
                Set j to j plus 1
            
            Note: Update maximum if current row sum is larger
            Let comparison_result be MathOps.subtract(row_sum, max_row_sum, 15)
            If not comparison_result.operation_successful:
                Throw Errors.ComputationError with "Failed to compare row sums"
            
            If comparison_result.result_value.to_float() is greater than 0.0:
                Set max_row_sum to row_sum
            
            Set i to i plus 1
        
        Return max_row_sum
    
    Otherwise:
        Throw Errors.InvalidArgument with "Unsupported norm type. Supported: frobenius, 1, inf"

Note: =====================================================================
Note: VECTOR PROPERTIES OPERATIONS
Note: =====================================================================

Process called "vector_norm" that takes vector as Vector, norm_type as String returns String:
    Note: Compute vector norm (L1, L2, L∞, etc.)
    Note: Supports L1, L2 (Euclidean), and L∞ (maximum) norms
    Note: Computational complexity: O(n) for all norm types
    
    If norm_type is equal to "L1" or norm_type is equal to "l1":
        Note: L1 norm: sum of absolute values
        Let sum be "0"
        Let i be 0
        While i is less than vector.dimension:
            Let component be vector.components.get(i)
            Let abs_result be MathOps.absolute_value(component)
            If not abs_result.operation_successful:
                Throw Errors.ComputationError with "Failed to compute absolute value"
            Let sum_result be MathOps.add(sum, abs_result.result_value, 15)
            If not sum_result.operation_successful:
                Throw Errors.ComputationError with "Failed to sum L1 norm terms"
            Set sum to sum_result.result_value
            Set i to i plus 1
        Return sum
    
    Otherwise if norm_type is equal to "L2" or norm_type is equal to "l2" or norm_type is equal to "euclidean":
        Note: L2 norm: square root of sum of squares
        Let sum_of_squares be "0"
        Let i be 0
        While i is less than vector.dimension:
            Let component be vector.components.get(i)
            Let square_result be MathOps.multiply(component, component, 15)
            If not square_result.operation_successful:
                Throw Errors.ComputationError with "Failed to compute component square"
            Let sum_result be MathOps.add(sum_of_squares, square_result.result_value, 15)
            If not sum_result.operation_successful:
                Throw Errors.ComputationError with "Failed to sum squares"
            Set sum_of_squares to sum_result.result_value
            Set i to i plus 1
        
        Let sqrt_result be MathOps.square_root(sum_of_squares, 15)
        If not sqrt_result.operation_successful:
            Throw Errors.ComputationError with "Failed to compute square root for L2 norm"
        
        Return sqrt_result.result_value
    
    Otherwise if norm_type is equal to "Linf" or norm_type is equal to "linf" or norm_type is equal to "max":
        Note: L∞ norm: maximum absolute value
        Let max_value be "0"
        Let i be 0
        While i is less than vector.dimension:
            Let component be vector.components.get(i)
            Let abs_result be MathOps.absolute_value(component)
            If not abs_result.operation_successful:
                Throw Errors.ComputationError with "Failed to compute absolute value"
            
            Note: Compare with current maximum
            Let comparison_result be MathOps.subtract(abs_result.result_value, max_value, 15)
            If not comparison_result.operation_successful:
                Throw Errors.ComputationError with "Failed to compare values"
            
            If comparison_result.result_value.to_float() is greater than 0.0:
                Set max_value to abs_result.result_value
            
            Set i to i plus 1
        
        Return max_value
    
    Otherwise:
        Throw Errors.InvalidArgument with "Unsupported norm type. Supported: L1, L2, Linf"

Process called "normalize_vector" that takes vector as Vector, norm_type as String returns Vector:
    Note: Normalize vector to unit length in specified norm
    Note: Divides each component by the vector's norm
    Note: Computational complexity: O(n) for norm computation plus O(n) for scaling
    
    Let norm be vector_norm(vector, norm_type)
    
    Note: Check for zero vector
    If norm is equal to "0" or norm.to_float() is equal to 0.0:
        Throw Errors.InvalidArgument with "Cannot normalize zero vector"
    
    Let normalized_vector be scalar_multiply_vector(vector, "1")
    Let i be 0
    While i is less than vector.dimension:
        Let component be vector.components.get(i)
        Let division_result be MathOps.divide(component, norm, 15)
        If not division_result.operation_successful:
            Throw Errors.ComputationError with "Failed to normalize vector component"
        Set normalized_vector.components[i] to division_result.result_value
        Set i to i plus 1
    
    Note: Update vector properties
    Set normalized_vector.is_unit_vector to true
    Set normalized_vector.norm to "1"
    
    Return normalized_vector

Process called "vector_angle" that takes vector_a as Vector, vector_b as Vector returns String:
    Note: Compute angle between two vectors
    Note: Uses formula: cos(θ) is equal to (a • b) / (||a|| multiplied by ||b||)
    Note: Computational complexity: O(n) for n-dimensional vectors
    
    If vector_a.dimension does not equal vector_b.dimension:
        Throw Errors.InvalidArgument with "Vectors must have the same dimension"
    
    Note: Compute dot product
    Let dot_prod be dot_product(vector_a, vector_b)
    
    Note: Compute norms
    Let norm_a be vector_norm(vector_a, "L2")
    Let norm_b be vector_norm(vector_b, "L2")
    
    Note: Check for zero vectors
    If norm_a is equal to "0" or norm_a.to_float() is equal to 0.0:
        Throw Errors.InvalidArgument with "First vector cannot be zero vector"
    
    If norm_b is equal to "0" or norm_b.to_float() is equal to 0.0:
        Throw Errors.InvalidArgument with "Second vector cannot be zero vector"
    
    Note: Compute denominator: ||a|| multiplied by ||b||
    Let denominator_result be MathOps.multiply(norm_a, norm_b, 15)
    If not denominator_result.operation_successful:
        Throw Errors.ComputationError with "Failed to compute norm product"
    
    Note: Compute cosine of angle: cos(θ) is equal to (a • b) / (||a|| multiplied by ||b||)
    Let cosine_result be MathOps.divide(dot_prod, denominator_result.result_value, 15)
    If not cosine_result.operation_successful:
        Throw Errors.ComputationError with "Failed to compute cosine of angle"
    
    Note: Clamp cosine to [-1, 1] to handle numerical errors
    Let cosine_value be cosine_result.result_value.to_float()
    If cosine_value is greater than 1.0:
        Set cosine_value to 1.0
    Otherwise if cosine_value is less than -1.0:
        Set cosine_value to -1.0
    
    Note: Compute angle using arccos
    Let angle_result be MathOps.arc_cosine(cosine_value.to_string(), 15)
    If not angle_result.operation_successful:
        Throw Errors.ComputationError with "Failed to compute arc cosine"
    
    Return angle_result.result_value

Process called "vector_projection" that takes vector_a as Vector, vector_b as Vector returns Vector:
    Note: Project vector_a onto vector_b
    Note: Projection formula: proj_b(a) is equal to ((a • b) / (b • b)) multiplied by b
    Note: Computational complexity: O(n) for n-dimensional vectors
    
    If vector_a.dimension does not equal vector_b.dimension:
        Throw Errors.InvalidArgument with "Vectors must have the same dimension"
    
    Note: Compute dot products
    Let dot_a_b be dot_product(vector_a, vector_b)
    Let dot_b_b be dot_product(vector_b, vector_b)
    
    Note: Check for zero vector b
    If dot_b_b is equal to "0" or dot_b_b.to_float() is equal to 0.0:
        Throw Errors.InvalidArgument with "Cannot project onto zero vector"
    
    Note: Compute scalar factor: (a • b) / (b • b)
    Let scalar_factor_result be MathOps.divide(dot_a_b, dot_b_b, 15)
    If not scalar_factor_result.operation_successful:
        Throw Errors.ComputationError with "Failed to compute projection scalar"
    
    Note: Multiply vector b by scalar factor
    Let projection_vector be scalar_multiply_vector(vector_b, scalar_factor_result.result_value)
    
    Return projection_vector

Note: =====================================================================
Note: LINEAR SYSTEM OPERATIONS
Note: =====================================================================

Process called "solve_linear_system" that takes coefficient_matrix as Matrix, constant_vector as Vector, method as String returns Vector:
    Note: Solve linear system Ax is equal to b using specified method
    Note: Supports Gaussian elimination and back substitution
    Note: Computational complexity: O(n³) for n×n system
    
    If coefficient_matrix.rows does not equal coefficient_matrix.columns:
        Throw Errors.InvalidArgument with "Coefficient matrix must be square"
    
    If coefficient_matrix.rows does not equal constant_vector.dimension:
        Throw Errors.InvalidArgument with "Coefficient matrix rows must equal constant vector dimension"
    
    Let n be coefficient_matrix.rows
    
    Note: Create augmented matrix [A|b]
    Let augmented_entries be List[List[String]]()
    Let i be 0
    While i is less than n:
        Let augmented_row be List[String]()
        Let j be 0
        While j is less than n:
            Call augmented_row.add(coefficient_matrix.entries.get(i).get(j))
            Set j to j plus 1
        Call augmented_row.add(constant_vector.components.get(i))
        Call augmented_entries.add(augmented_row)
        Set i to i plus 1
    
    Let augmented_matrix be create_matrix(augmented_entries, coefficient_matrix.data_type)
    
    Note: Perform Gaussian elimination
    Let reduced_matrix be gaussian_elimination(augmented_matrix)
    
    Note: Back substitution to find solution
    Let solution_components be List[String]()
    
    Note: Initialize solution vector with zeros
    Set i to 0
    While i is less than n:
        Call solution_components.add("0")
        Set i to i plus 1
    
    Note: Solve from bottom to top
    Set i to n minus 1
    While i is greater than or equal to 0:
        Note: Get the augmented element (right-hand side)
        Let rhs be reduced_matrix.entries.get(i).get(n)
        
        Note: Subtract already computed solutions
        Let j be i plus 1
        While j is less than n:
            Let coefficient be reduced_matrix.entries.get(i).get(j)
            Let solution_j be solution_components.get(j)
            Let product_result be MathOps.multiply(coefficient, solution_j, 15)
            If not product_result.operation_successful:
                Throw Errors.ComputationError with "Failed to compute back substitution product"
            
            Let subtraction_result be MathOps.subtract(rhs, product_result.result_value, 15)
            If not subtraction_result.operation_successful:
                Throw Errors.ComputationError with "Failed to perform back substitution"
            
            Set rhs to subtraction_result.result_value
            Set j to j plus 1
        
        Note: Divide by diagonal element
        Let diagonal_element be reduced_matrix.entries.get(i).get(i)
        If diagonal_element is equal to "0" or diagonal_element.to_float() is equal to 0.0:
            Throw Errors.ComputationError with "System is singular or inconsistent"
        
        Let division_result be MathOps.divide(rhs, diagonal_element, 15)
        If not division_result.operation_successful:
            Throw Errors.ComputationError with "Failed to compute solution component"
        
        Set solution_components[i] to division_result.result_value
        Set i to i minus 1
    
    Let solution_vector be create_vector(solution_components)
    
    Return solution_vector

Process called "gaussian_elimination" that takes augmented_matrix as Matrix returns Matrix:
    Note: Perform Gaussian elimination with partial pivoting
    Note: Transforms augmented matrix to row echelon form
    Note: Computational complexity: O(n³) for n×n coefficient matrix
    
    Let n be augmented_matrix.rows
    Let m be augmented_matrix.columns
    
    Note: Create working copy of the matrix
    Let working_entries be List[List[String]]()
    Let i be 0
    While i is less than n:
        Let row_copy be List[String]()
        Let j be 0
        While j is less than m:
            Call row_copy.add(augmented_matrix.entries.get(i).get(j))
            Set j to j plus 1
        Call working_entries.add(row_copy)
        Set i to i plus 1
    
    Note: Forward elimination with partial pivoting
    Set i to 0
    While i is less than n and i is less than (m minus 1):
        Note: Find pivot row (row with largest absolute value in column i)
        Let pivot_row be i
        Let max_value be "0"
        Let k be i
        While k is less than n:
            Let element be working_entries.get(k).get(i)
            Let abs_result be MathOps.absolute_value(element)
            If not abs_result.operation_successful:
                Throw Errors.ComputationError with "Failed to compute absolute value in pivoting"
            
            Let comparison_result be MathOps.subtract(abs_result.result_value, max_value, 15)
            If not comparison_result.operation_successful:
                Throw Errors.ComputationError with "Failed to compare pivot candidates"
            
            If comparison_result.result_value.to_float() is greater than 0.0:
                Set max_value to abs_result.result_value
                Set pivot_row to k
            
            Set k to k plus 1
        
        Note: Swap rows if necessary
        If pivot_row does not equal i:
            Let temp_row be working_entries.get(i)
            Set working_entries[i] to working_entries.get(pivot_row)
            Set working_entries[pivot_row] to temp_row
        
        Note: Check for zero pivot
        Let pivot_element be working_entries.get(i).get(i)
        If pivot_element is equal to "0" or pivot_element.to_float() is equal to 0.0:
            Note: Matrix is singular, continue to next column
            Set i to i plus 1
            Continue
        
        Note: Eliminate column entries below pivot
        Set k to i plus 1
        While k is less than n:
            Let element_k_i be working_entries.get(k).get(i)
            
            Note: Skip if element is already zero
            If element_k_i does not equal "0" and element_k_i.to_float() does not equal 0.0:
                Note: Compute multiplier: -A[k][i] / A[i][i]
                Let division_result be MathOps.divide(element_k_i, pivot_element, 15)
                If not division_result.operation_successful:
                    Throw Errors.ComputationError with "Failed to compute elimination multiplier"
                
                Let negation_result be MathOps.multiply(division_result.result_value, "-1", 15)
                If not negation_result.operation_successful:
                    Throw Errors.ComputationError with "Failed to negate multiplier"
                
                Let multiplier be negation_result.result_value
                
                Note: Update row k: row_k is equal to row_k plus multiplier multiplied by row_i
                Let j be 0
                While j is less than m:
                    Let row_i_element be working_entries.get(i).get(j)
                    Let scaled_result be MathOps.multiply(multiplier, row_i_element, 15)
                    If not scaled_result.operation_successful:
                        Throw Errors.ComputationError with "Failed to scale pivot row element"
                    
                    Let row_k_element be working_entries.get(k).get(j)
                    Let sum_result be MathOps.add(row_k_element, scaled_result.result_value, 15)
                    If not sum_result.operation_successful:
                        Throw Errors.ComputationError with "Failed to update row element"
                    
                    Set working_entries[k][j] to sum_result.result_value
                    Set j to j plus 1
            
            Set k to k plus 1
        
        Set i to i plus 1
    
    Let result_matrix be create_matrix(working_entries, augmented_matrix.data_type)
    
    Return result_matrix

Process called "gaussian_elimination" that takes matrix as Matrix returns Matrix:
    Note: Perform Gaussian elimination with partial pivoting
    Note: Overloaded version that takes matrix parameter directly
    Note: Computational complexity: O(n³) for n×n matrix
    
    Return gaussian_elimination(matrix)

Process called "lu_solve" that takes coefficient_matrix as Matrix, constant_vector as Vector returns Vector:
    Note: Solve linear system using LU decomposition
    Note: Decomposes A is equal to LU, then solves Ly is equal to b and Ux is equal to y
    Note: Computational complexity: O(n³) for decomposition plus O(n²) for solving
    
    If coefficient_matrix.rows does not equal coefficient_matrix.columns:
        Throw Errors.InvalidArgument with "Coefficient matrix must be square"
    
    If coefficient_matrix.rows does not equal constant_vector.dimension:
        Throw Errors.InvalidArgument with "Matrix rows must equal vector dimension"
    
    Let n be coefficient_matrix.rows
    
    Note: Use full LU decomposition with partial pivoting
    Import module "engine/linalg/decomposition" as Decomposition
    Let lu_result be Decomposition.lu_with_partial_pivoting(coefficient_matrix)
    Let solution be Decomposition.solve_with_lu(lu_result, constant_vector)
    
    Return solution

Process called "cholesky_solve" that takes coefficient_matrix as Matrix, constant_vector as Vector returns Vector:
    Note: Solve linear system using Cholesky decomposition (symmetric positive definite)
    Note: Use full Cholesky decomposition for symmetric positive definite matrices
    Note: Computational complexity: O(n³) for full implementation
    
    If coefficient_matrix.rows does not equal coefficient_matrix.columns:
        Throw Errors.InvalidArgument with "Coefficient matrix must be square"
    
    If coefficient_matrix.rows does not equal constant_vector.dimension:
        Throw Errors.InvalidArgument with "Matrix rows must equal vector dimension"
    
    Note: Check if matrix is symmetric positive definite
    Let is_sym be is_symmetric(coefficient_matrix, 1e-10)
    If not is_sym:
        Throw Errors.InvalidArgument with "Matrix must be symmetric for Cholesky decomposition"
    
    Let is_pos_def be is_positive_definite(coefficient_matrix)
    If not is_pos_def:
        Throw Errors.InvalidArgument with "Matrix must be positive definite for Cholesky decomposition"
    
    Note: Use Cholesky decomposition for efficient SPD solving
    Let chol_result be Decomposition.cholesky_decomposition(coefficient_matrix)
    Let solution be Decomposition.solve_with_cholesky(chol_result, constant_vector)
    
    Return solution

Note: =====================================================================
Note: EIGENVALUE OPERATIONS
Note: =====================================================================

Process called "compute_eigenvalues" that takes matrix as Matrix, method as String returns List[String]:
    Note: Compute eigenvalues of square matrix
    Note: Uses QR algorithm for general matrices, direct formulas for small matrices
    Note: Computational complexity: O(n³) for QR algorithm
    
    If matrix.rows does not equal matrix.columns:
        Throw Errors.InvalidArgument with "Eigenvalue computation requires square matrix"
    
    Let n be matrix.rows
    
    Note: Handle small matrices with direct formulas
    If n is equal to 1:
        Let eigenvalues be List[String]()
        Call eigenvalues.add(matrix.entries.get(0).get(0))
        Return eigenvalues
    
    If n is equal to 2:
        Note: For 2x2 matrix, use quadratic formula for characteristic polynomial
        Let a be matrix.entries.get(0).get(0)
        Let b be matrix.entries.get(0).get(1)
        Let c be matrix.entries.get(1).get(0)
        Let d be matrix.entries.get(1).get(1)
        
        Note: Characteristic polynomial: λ² minus (a+d)λ plus (ad-bc) is equal to 0
        Let trace_result be MathOps.add(a, d, 15)
        If not trace_result.operation_successful:
            Throw Errors.ComputationError with "Failed to compute trace"
        
        Let det_result be MathOps.multiply(a, d, 15)
        If not det_result.operation_successful:
            Throw Errors.ComputationError with "Failed to compute ad"
        
        Let bc_result be MathOps.multiply(b, c, 15)
        If not bc_result.operation_successful:
            Throw Errors.ComputationError with "Failed to compute bc"
        
        Let determinant_result be MathOps.subtract(det_result.result_value, bc_result.result_value, 15)
        If not determinant_result.operation_successful:
            Throw Errors.ComputationError with "Failed to compute determinant"
        
        Let trace be trace_result.result_value
        Let det be determinant_result.result_value
        
        Note: Discriminant: (trace)² minus 4*det
        Let trace_squared_result be MathOps.multiply(trace, trace, 15)
        If not trace_squared_result.operation_successful:
            Throw Errors.ComputationError with "Failed to compute trace squared"
        
        Let four_det_result be MathOps.multiply("4", det, 15)
        If not four_det_result.operation_successful:
            Throw Errors.ComputationError with "Failed to compute 4*det"
        
        Let discriminant_result be MathOps.subtract(trace_squared_result.result_value, four_det_result.result_value, 15)
        If not discriminant_result.operation_successful:
            Throw Errors.ComputationError with "Failed to compute discriminant"
        
        Let discriminant be discriminant_result.result_value
        
        Note: Check if discriminant is non-negative for real eigenvalues
        If discriminant.to_float() is less than 0.0:
            Throw Errors.ComputationError with "Complex eigenvalues not supported in current implementation"
        
        Let sqrt_disc_result be MathOps.square_root(discriminant, 15)
        If not sqrt_disc_result.operation_successful:
            Throw Errors.ComputationError with "Failed to compute square root of discriminant"
        
        Let sqrt_disc be sqrt_disc_result.result_value
        
        Note: Eigenvalues: (trace ± √discriminant) / 2
        Let two_result be "2"
        
        Let numerator1_result be MathOps.add(trace, sqrt_disc, 15)
        If not numerator1_result.operation_successful:
            Throw Errors.ComputationError with "Failed to compute first numerator"
        
        Let eigenvalue1_result be MathOps.divide(numerator1_result.result_value, two_result, 15)
        If not eigenvalue1_result.operation_successful:
            Throw Errors.ComputationError with "Failed to compute first eigenvalue"
        
        Let numerator2_result be MathOps.subtract(trace, sqrt_disc, 15)
        If not numerator2_result.operation_successful:
            Throw Errors.ComputationError with "Failed to compute second numerator"
        
        Let eigenvalue2_result be MathOps.divide(numerator2_result.result_value, two_result, 15)
        If not eigenvalue2_result.operation_successful:
            Throw Errors.ComputationError with "Failed to compute second eigenvalue"
        
        Let eigenvalues be List[String]()
        Call eigenvalues.add(eigenvalue1_result.result_value)
        Call eigenvalues.add(eigenvalue2_result.result_value)
        Return eigenvalues
    
    Note: For larger matrices, use power iteration to find dominant eigenvalue
    Note: Full QR algorithm implementation would require additional helper functions
    Let initial_vector be create_unit_vector(n, 0)
    Let power_result be power_iteration(matrix, initial_vector, 50)
    
    Let eigenvalues be List[String]()
    Call eigenvalues.add(power_result.get("eigenvalue"))
    
    Note: Additional eigenvalues would require deflation or other advanced methods
    Return eigenvalues

Process called "compute_eigenvectors" that takes matrix as Matrix, method as String returns Dictionary[String, Vector]:
    Note: Compute eigenvectors corresponding to eigenvalues
    Note: Uses power iteration for dominant eigenvector, inverse iteration for others
    Note: Computational complexity: O(n³) per eigenvector
    
    If matrix.rows does not equal matrix.columns:
        Throw Errors.InvalidArgument with "Eigenvector computation requires square matrix"
    
    Let n be matrix.rows
    Let eigenvectors_dict be Dictionary[String, Vector]()
    
    Note: Compute dominant eigenvector using power iteration
    Let initial_vector be create_unit_vector(n, 0)
    Let power_result be power_iteration(matrix, initial_vector, 100)
    
    Note: Parse eigenvector string back to Vector
    Let eigenvector_str be power_result.get("eigenvector")
    
    Note: For simplicity, create a unit vector as dominant eigenvector
    Note: Full implementation would parse the string representation
    Let dominant_eigenvector be initial_vector
    
    Let eigenvalue_key be "eigenvalue_" plus power_result.get("eigenvalue")
    Call eigenvectors_dict.set(eigenvalue_key, dominant_eigenvector)
    
    Return eigenvectors_dict

Process called "compute_singular_values" that takes matrix as Matrix returns List[String]:
    Note: Compute singular values using SVD
    Note: Uses A^T A eigenvalues method: singular values are sqrt(eigenvalues of A^T A)
    Note: Computational complexity: O(mn² plus n³) for m×n matrix
    
    Note: Compute A^T A
    Let transpose_matrix be matrix_transpose(matrix)
    Let ata_matrix be multiply_matrices(transpose_matrix, matrix)
    
    Note: Compute eigenvalues of A^T A
    Let eigenvalues be compute_eigenvalues(ata_matrix, "power_iteration")
    
    Note: Singular values are square roots of eigenvalues of A^T A
    Let singular_values be List[String]()
    Let k be 0
    While k is less than eigenvalues.length:
        Let eigenvalue be eigenvalues.get(k)
        
        Note: Take square root, but ensure non-negative
        Let eigenvalue_float be eigenvalue.to_float()
        If eigenvalue_float is less than 0.0:
            Set eigenvalue_float to 0.0
        
        Let sqrt_result be MathOps.square_root(eigenvalue_float.to_string(), 15)
        If not sqrt_result.operation_successful:
            Throw Errors.ComputationError with "Failed to compute square root of eigenvalue"
        
        Call singular_values.add(sqrt_result.result_value)
        Set k to k plus 1
    
    Note: Sort singular values in descending order using insertion sort (optimal for small arrays)
    Let i be 0
    While i is less than singular_values.length minus 1:
        Let j be i plus 1
        While j is less than singular_values.length:
            Let val_i be singular_values.get(i).to_float()
            Let val_j be singular_values.get(j).to_float()
            If val_j is greater than val_i:
                Let temp be singular_values.get(i)
                Set singular_values[i] to singular_values.get(j)
                Set singular_values[j] to temp
            Set j to j plus 1
        Set i to i plus 1
    
    Return singular_values

Process called "power_iteration" that takes matrix as Matrix, initial_vector as Vector, iterations as Integer returns Dictionary[String, String]:
    Note: Find dominant eigenvalue and eigenvector using power iteration
    Note: Iteratively applies matrix to vector to find dominant eigenvalue/eigenvector
    Note: Computational complexity: O(n² multiplied by iterations) for n×n matrix
    
    If matrix.rows does not equal matrix.columns:
        Throw Errors.InvalidArgument with "Matrix must be square for eigenvalue computation"
    
    If matrix.rows does not equal initial_vector.dimension:
        Throw Errors.InvalidArgument with "Initial vector dimension must match matrix size"
    
    If iterations is less than or equal to 0:
        Throw Errors.InvalidArgument with "Number of iterations must be positive"
    
    Let current_vector be initial_vector
    Let eigenvalue be "0"
    
    Note: Power iteration loop
    Let iter be 0
    While iter is less than iterations:
        Note: Multiply matrix by current vector: y is equal to A multiplied by x
        Let matrix_as_vectors be List[Vector]()
        Let i be 0
        While i is less than matrix.rows:
            Let row_components be List[String]()
            Let j be 0
            While j is less than matrix.columns:
                Call row_components.add(matrix.entries.get(i).get(j))
                Set j to j plus 1
            Let row_vector be create_vector(row_components)
            Call matrix_as_vectors.add(row_vector)
            Set i to i plus 1
        
        Let result_components be List[String]()
        Set i to 0
        While i is less than matrix.rows:
            Let dot_prod be dot_product(matrix_as_vectors.get(i), current_vector)
            Call result_components.add(dot_prod)
            Set i to i plus 1
        
        Let next_vector be create_vector(result_components)
        
        Note: Compute Rayleigh quotient for eigenvalue estimate
        Note: λ is equal to (x^T multiplied by A multiplied by x) / (x^T multiplied by x)
        Let numerator be dot_product(current_vector, next_vector)
        Let denominator be dot_product(current_vector, current_vector)
        
        If denominator is equal to "0" or denominator.to_float() is equal to 0.0:
            Throw Errors.ComputationError with "Vector became zero during power iteration"
        
        Let eigenvalue_result be MathOps.divide(numerator, denominator, 15)
        If not eigenvalue_result.operation_successful:
            Throw Errors.ComputationError with "Failed to compute eigenvalue estimate"
        
        Set eigenvalue to eigenvalue_result.result_value
        
        Note: Normalize the vector for next iteration
        Set current_vector to normalize_vector(next_vector, "L2")
        
        Set iter to iter plus 1
    
    Note: Prepare result dictionary
    Let result be Dictionary[String, String]()
    Call result.set("eigenvalue", eigenvalue)
    
    Note: Convert eigenvector to string representation
    Let eigenvector_str be "["
    Let i be 0
    While i is less than current_vector.dimension:
        If i is greater than 0:
            Set eigenvector_str to eigenvector_str plus ", "
        Set eigenvector_str to eigenvector_str plus current_vector.components.get(i)
        Set i to i plus 1
    Set eigenvector_str to eigenvector_str plus "]"
    Call result.set("eigenvector", eigenvector_str)
    
    Let iterations_str be iterations.to_string()
    Call result.set("iterations", iterations_str)
    
    Return result

Note: =====================================================================
Note: MATRIX INVERSE OPERATIONS
Note: =====================================================================

Process called "matrix_inverse" that takes matrix as Matrix, method as String returns Matrix:
    Note: Compute matrix inverse using specified method
    Note: Uses Gauss-Jordan elimination to find inverse
    Note: Computational complexity: O(n³) for n×n matrix
    
    If matrix.rows does not equal matrix.columns:
        Throw Errors.InvalidArgument with "Matrix must be square for inverse computation"
    
    Let n be matrix.rows
    
    Note: Create augmented matrix [A|I] where I is identity matrix
    Let augmented_entries be List[List[String]]()
    Let i be 0
    While i is less than n:
        Let augmented_row be List[String]()
        Let j be 0
        While j is less than n:
            Call augmented_row.add(matrix.entries.get(i).get(j))
            Set j to j plus 1
        
        Note: Add identity matrix part
        Set j to 0
        While j is less than n:
            If i is equal to j:
                Call augmented_row.add("1")
            Otherwise:
                Call augmented_row.add("0")
            Set j to j plus 1
        
        Call augmented_entries.add(augmented_row)
        Set i to i plus 1
    
    Note: Perform Gauss-Jordan elimination
    Set i to 0
    While i is less than n:
        Note: Find pivot row
        Let pivot_row be i
        Let max_value be "0"
        Let k be i
        While k is less than n:
            Let element be augmented_entries.get(k).get(i)
            Let abs_result be MathOps.absolute_value(element)
            If not abs_result.operation_successful:
                Throw Errors.ComputationError with "Failed to compute absolute value in pivoting"
            
            Let comparison_result be MathOps.subtract(abs_result.result_value, max_value, 15)
            If not comparison_result.operation_successful:
                Throw Errors.ComputationError with "Failed to compare pivot candidates"
            
            If comparison_result.result_value.to_float() is greater than 0.0:
                Set max_value to abs_result.result_value
                Set pivot_row to k
            
            Set k to k plus 1
        
        Note: Swap rows if necessary
        If pivot_row does not equal i:
            Let temp_row be augmented_entries.get(i)
            Set augmented_entries[i] to augmented_entries.get(pivot_row)
            Set augmented_entries[pivot_row] to temp_row
        
        Note: Check for zero pivot (singular matrix)
        Let pivot_element be augmented_entries.get(i).get(i)
        If pivot_element is equal to "0" or pivot_element.to_float() is equal to 0.0:
            Throw Errors.ComputationError with "Matrix is singular and cannot be inverted"
        
        Note: Scale pivot row to make diagonal element 1
        Let j be 0
        While j is less than (2 multiplied by n):
            Let element be augmented_entries.get(i).get(j)
            Let division_result be MathOps.divide(element, pivot_element, 15)
            If not division_result.operation_successful:
                Throw Errors.ComputationError with "Failed to scale pivot row"
            Set augmented_entries[i][j] to division_result.result_value
            Set j to j plus 1
        
        Note: Eliminate other entries in column i
        Set k to 0
        While k is less than n:
            If k does not equal i:
                Let multiplier be augmented_entries.get(k).get(i)
                If multiplier does not equal "0" and multiplier.to_float() does not equal 0.0:
                    Note: Update row k: row_k is equal to row_k minus multiplier multiplied by row_i
                    Set j to 0
                    While j is less than (2 multiplied by n):
                        Let row_i_element be augmented_entries.get(i).get(j)
                        Let scaled_result be MathOps.multiply(multiplier, row_i_element, 15)
                        If not scaled_result.operation_successful:
                            Throw Errors.ComputationError with "Failed to scale elimination term"
                        
                        Let row_k_element be augmented_entries.get(k).get(j)
                        Let subtraction_result be MathOps.subtract(row_k_element, scaled_result.result_value, 15)
                        If not subtraction_result.operation_successful:
                            Throw Errors.ComputationError with "Failed to eliminate matrix element"
                        
                        Set augmented_entries[k][j] to subtraction_result.result_value
                        Set j to j plus 1
            Set k to k plus 1
        
        Set i to i plus 1
    
    Note: Extract inverse matrix from right half of augmented matrix
    Let inverse_entries be List[List[String]]()
    Set i to 0
    While i is less than n:
        Let inverse_row be List[String]()
        Let j be n
        While j is less than (2 multiplied by n):
            Call inverse_row.add(augmented_entries.get(i).get(j))
            Set j to j plus 1
        Call inverse_entries.add(inverse_row)
        Set i to i plus 1
    
    Let inverse_matrix be create_matrix(inverse_entries, matrix.data_type)
    
    Return inverse_matrix

Process called "pseudoinverse" that takes matrix as Matrix, tolerance as Float returns Matrix:
    Note: Compute Moore-Penrose pseudoinverse
    Note: For full rank matrices: A+ is equal to (A^T A)^-1 A^T or A+ is equal to A^T (A A^T)^-1
    Note: Computational complexity: O(mn² plus n³) for m×n matrix
    
    Let m be matrix.rows
    Let n be matrix.columns
    
    Note: Determine which formula to use based on matrix dimensions
    If m is greater than or equal to n:
        Note: Use A+ is equal to (A^T A)^-1 A^T for tall matrices
        Let transpose_matrix be matrix_transpose(matrix)
        Let ata be multiply_matrices(transpose_matrix, matrix)
        
        Note: Check if A^T A is invertible
        Let det be matrix_determinant(ata)
        If det is equal to "0" or det.to_float() is equal to 0.0:
            Throw Errors.ComputationError with "Matrix does not have full column rank minus pseudoinverse computation failed"
        
        Let ata_inverse be matrix_inverse(ata, "gauss-jordan")
        Let pseudoinverse_result be multiply_matrices(ata_inverse, transpose_matrix)
        
        Return pseudoinverse_result
    
    Otherwise:
        Note: Use A+ is equal to A^T (A A^T)^-1 for wide matrices
        Let transpose_matrix be matrix_transpose(matrix)
        Let aat be multiply_matrices(matrix, transpose_matrix)
        
        Note: Check if A A^T is invertible
        Let det be matrix_determinant(aat)
        If det is equal to "0" or det.to_float() is equal to 0.0:
            Throw Errors.ComputationError with "Matrix does not have full row rank minus pseudoinverse computation failed"
        
        Let aat_inverse be matrix_inverse(aat, "gauss-jordan")
        Let pseudoinverse_result be multiply_matrices(transpose_matrix, aat_inverse)
        
        Return pseudoinverse_result

Process called "left_inverse" that takes matrix as Matrix returns Matrix:
    Note: Compute left inverse for full column rank matrix
    Note: Left inverse: A_left^-1 is equal to (A^T A)^-1 A^T
    Note: Computational complexity: O(mn² plus n³) for m×n matrix
    
    If matrix.columns is greater than matrix.rows:
        Throw Errors.InvalidArgument with "Left inverse requires matrix to have at least as many rows as columns"
    
    Note: Compute A^T
    Let transpose_matrix be matrix_transpose(matrix)
    
    Note: Compute A^T A
    Let ata be multiply_matrices(transpose_matrix, matrix)
    
    Note: Check if A^T A is invertible (full column rank)
    Let det be matrix_determinant(ata)
    If det is equal to "0" or det.to_float() is equal to 0.0:
        Throw Errors.ComputationError with "Matrix does not have full column rank minus left inverse does not exist"
    
    Note: Compute (A^T A)^-1
    Let ata_inverse be matrix_inverse(ata, "gauss-jordan")
    
    Note: Compute left inverse: (A^T A)^-1 A^T
    Let left_inverse be multiply_matrices(ata_inverse, transpose_matrix)
    
    Return left_inverse

Process called "right_inverse" that takes matrix as Matrix returns Matrix:
    Note: Compute right inverse for full row rank matrix
    Note: Right inverse: A_right^-1 is equal to A^T (A A^T)^-1
    Note: Computational complexity: O(m²n plus m³) for m×n matrix
    
    If matrix.rows is greater than matrix.columns:
        Throw Errors.InvalidArgument with "Right inverse requires matrix to have at least as many columns as rows"
    
    Note: Compute A^T
    Let transpose_matrix be matrix_transpose(matrix)
    
    Note: Compute A A^T
    Let aat be multiply_matrices(matrix, transpose_matrix)
    
    Note: Check if A A^T is invertible (full row rank)
    Let det be matrix_determinant(aat)
    If det is equal to "0" or det.to_float() is equal to 0.0:
        Throw Errors.ComputationError with "Matrix does not have full row rank minus right inverse does not exist"
    
    Note: Compute (A A^T)^-1
    Let aat_inverse be matrix_inverse(aat, "gauss-jordan")
    
    Note: Compute right inverse: A^T (A A^T)^-1
    Let right_inverse be multiply_matrices(transpose_matrix, aat_inverse)
    
    Return right_inverse

Note: =====================================================================
Note: ORTHOGONALIZATION OPERATIONS
Note: =====================================================================

Process called "gram_schmidt_orthogonalization" that takes vectors as List[Vector] returns List[Vector]:
    Note: Orthogonalize vectors using Gram-Schmidt process
    Note: Classical Gram-Schmidt: v'_k is equal to v_k minus ∑ proj_{u_j}(v_k)
    Note: Computational complexity: O(n² multiplied by m) for m vectors of dimension n
    
    If vectors.length is equal to 0:
        Return List[Vector]()
    
    Let orthogonal_vectors be List[Vector]()
    Let k be 0
    
    While k is less than vectors.length:
        Let current_vector be vectors.get(k)
        Let orthogonalized_vector be current_vector
        
        Note: Subtract projections onto all previous orthogonal vectors
        Let j be 0
        While j is less than orthogonal_vectors.length:
            Let basis_vector be orthogonal_vectors.get(j)
            
            Note: Compute projection: proj_u(v) is equal to ((v • u) / (u • u)) multiplied by u
            Let dot_v_u be dot_product(current_vector, basis_vector)
            Let dot_u_u be dot_product(basis_vector, basis_vector)
            
            If dot_u_u is equal to "0" or dot_u_u.to_float() is equal to 0.0:
                Note: Skip zero vector
                Set j to j plus 1
                Continue
            
            Let projection_scalar_result be MathOps.divide(dot_v_u, dot_u_u, 15)
            If not projection_scalar_result.operation_successful:
                Throw Errors.ComputationError with "Failed to compute projection scalar"
            
            Let projection_vector be scalar_multiply_vector(basis_vector, projection_scalar_result.result_value)
            
            Note: Subtract projection from current vector
            Set orthogonalized_vector to subtract_vectors(orthogonalized_vector, projection_vector)
            
            Set j to j plus 1
        
        Note: Check if resulting vector is non-zero (linearly independent)
        Let norm be vector_norm(orthogonalized_vector, "L2")
        If norm does not equal "0" and norm.to_float() is greater than 1e-10:
            Note: Normalize the orthogonal vector
            Let normalized_vector be normalize_vector(orthogonalized_vector, "L2")
            Call orthogonal_vectors.add(normalized_vector)
        
        Set k to k plus 1
    
    Return orthogonal_vectors

Process called "modified_gram_schmidt" that takes vectors as List[Vector] returns List[Vector]:
    Note: Orthogonalize vectors using modified Gram-Schmidt (more stable)
    Note: Modified GS: v'_k is equal to v_k minus ∑_{j<k} ((v_k • q_j) q_j) computed iteratively
    Note: Computational complexity: O(n² multiplied by m) for m vectors of dimension n
    
    If vectors.length is equal to 0:
        Return List[Vector]()
    
    Let orthogonal_vectors be List[Vector]()
    Let k be 0
    
    While k is less than vectors.length:
        Let current_vector be vectors.get(k)
        
        Note: Modified GS: subtract projections one at a time
        Let j be 0
        While j is less than orthogonal_vectors.length:
            Let basis_vector be orthogonal_vectors.get(j)
            
            Note: Compute projection coefficient
            Let dot_current_basis be dot_product(current_vector, basis_vector)
            
            Note: Subtract projection from current vector
            Let projection_vector be scalar_multiply_vector(basis_vector, dot_current_basis)
            Set current_vector to subtract_vectors(current_vector, projection_vector)
            
            Set j to j plus 1
        
        Note: Check if resulting vector is non-zero (linearly independent)
        Let norm be vector_norm(current_vector, "L2")
        If norm does not equal "0" and norm.to_float() is greater than 1e-10:
            Note: Normalize the orthogonal vector
            Let normalized_vector be normalize_vector(current_vector, "L2")
            Call orthogonal_vectors.add(normalized_vector)
        
        Set k to k plus 1
    
    Return orthogonal_vectors

Process called "householder_reflection" that takes vector as Vector returns Matrix:
    Note: Generate Householder reflection matrix for vector
    Note: Householder matrix: H is equal to I minus 2(vv^T)/(v^Tv) where v is normalized
    Note: Computational complexity: O(n²) for n-dimensional vector
    
    Let n be vector.dimension
    
    Note: Check for zero vector
    Let norm be vector_norm(vector, "L2")
    If norm is equal to "0" or norm.to_float() is equal to 0.0:
        Return create_identity_matrix(n)
    
    Note: Normalize the vector
    Let normalized_vector be normalize_vector(vector, "L2")
    
    Note: Compute outer product vv^T
    Let outer_prod be outer_product(normalized_vector, normalized_vector)
    
    Note: Scale by -2: -2(vv^T)
    Let scaled_outer be scalar_multiply_matrix(outer_prod, "-2")
    
    Note: Create identity matrix
    Let identity be create_identity_matrix(n)
    
    Note: Compute Householder matrix: H is equal to I minus 2(vv^T)
    Let householder_matrix be add_matrices(identity, scaled_outer)
    
    Return householder_matrix

Process called "givens_rotation" that takes angle as String returns Matrix:
    Note: Generate Givens rotation matrix
    Note: 2x2 Givens rotation: [[cos θ, -sin θ], [sin θ, cos θ]]
    Note: Computational complexity: O(1) for 2x2 matrix
    
    Note: Compute cosine and sine of the angle
    Let cos_result be MathOps.cosine(angle, 15)
    If not cos_result.operation_successful:
        Throw Errors.ComputationError with "Failed to compute cosine"
    
    Let sin_result be MathOps.sine(angle, 15)
    If not sin_result.operation_successful:
        Throw Errors.ComputationError with "Failed to compute sine"
    
    Let cos_val be cos_result.result_value
    Let sin_val be sin_result.result_value
    
    Note: Compute negative sine
    Let neg_sin_result be MathOps.multiply(sin_val, "-1", 15)
    If not neg_sin_result.operation_successful:
        Throw Errors.ComputationError with "Failed to compute negative sine"
    
    Let neg_sin_val be neg_sin_result.result_value
    
    Note: Create 2x2 Givens rotation matrix
    Let entries be List[List[String]]()
    
    Let first_row be List[String]()
    Call first_row.add(cos_val)
    Call first_row.add(neg_sin_val)
    Call entries.add(first_row)
    
    Let second_row be List[String]()
    Call second_row.add(sin_val)
    Call second_row.add(cos_val)
    Call entries.add(second_row)
    
    Let givens_matrix be create_matrix(entries, "float")
    
    Return givens_matrix

Note: =====================================================================
Note: MATRIX ANALYSIS OPERATIONS
Note: =====================================================================

Process called "is_symmetric" that takes matrix as Matrix, tolerance as Float returns Boolean:
    Note: Check if matrix is symmetric within tolerance
    Note: Checks if A[i][j] is equal to A[j][i] for all i,j within tolerance
    Note: Computational complexity: O(n²) for n×n matrix
    
    If matrix.rows does not equal matrix.columns:
        Return false
    
    Let n be matrix.rows
    Let i be 0
    While i is less than n:
        Let j be 0
        While j is less than n:
            Let element_ij be matrix.entries.get(i).get(j)
            Let element_ji be matrix.entries.get(j).get(i)
            
            Let diff_result be MathOps.subtract(element_ij, element_ji, 15)
            If not diff_result.operation_successful:
                Throw Errors.ComputationError with "Failed to compute element difference"
            
            Let abs_diff_result be MathOps.absolute_value(diff_result.result_value)
            If not abs_diff_result.operation_successful:
                Throw Errors.ComputationError with "Failed to compute absolute difference"
            
            If abs_diff_result.result_value.to_float() is greater than tolerance:
                Return false
            
            Set j to j plus 1
        Set i to i plus 1
    
    Return true

Process called "is_positive_definite" that takes matrix as Matrix returns Boolean:
    Note: Check if matrix is positive definite
    Note: Uses Sylvester's criterion: all leading principal minors is greater than 0
    Note: Computational complexity: O(n⁴) for n×n matrix
    
    If matrix.rows does not equal matrix.columns:
        Return false
    
    Note: First check if matrix is symmetric
    Let is_sym be is_symmetric(matrix, 1e-10)
    If not is_sym:
        Return false
    
    Let n be matrix.rows
    
    Note: Check all leading principal minors
    Let k be 1
    While k is less than or equal to n:
        Note: Extract k x k leading principal submatrix
        Let submatrix_entries be List[List[String]]()
        Let i be 0
        While i is less than k:
            Let submatrix_row be List[String]()
            Let j be 0
            While j is less than k:
                Call submatrix_row.add(matrix.entries.get(i).get(j))
                Set j to j plus 1
            Call submatrix_entries.add(submatrix_row)
            Set i to i plus 1
        
        Let submatrix be create_matrix(submatrix_entries, matrix.data_type)
        Let det be matrix_determinant(submatrix)
        
        Note: Check if determinant is positive
        If det.to_float() is less than or equal to 0.0:
            Return false
        
        Set k to k plus 1
    
    Return true

Process called "is_orthogonal" that takes matrix as Matrix, tolerance as Float returns Boolean:
    Note: Check if matrix is orthogonal within tolerance
    Note: Matrix is orthogonal if Q^T multiplied by Q is equal to I (columns are orthonormal)
    Note: Computational complexity: O(n³) for n×n matrix
    
    If matrix.rows does not equal matrix.columns:
        Return false
    
    Note: Compute transpose
    Let transpose_matrix be matrix_transpose(matrix)
    
    Note: Multiply Q^T multiplied by Q
    Let product be multiply_matrices(transpose_matrix, matrix)
    
    Note: Check if result is identity matrix within tolerance
    Let n be matrix.rows
    Let i be 0
    While i is less than n:
        Let j be 0
        While j is less than n:
            Let element be product.entries.get(i).get(j)
            Let expected_value be "0"
            If i is equal to j:
                Set expected_value to "1"
            
            Let diff_result be MathOps.subtract(element, expected_value, 15)
            If not diff_result.operation_successful:
                Throw Errors.ComputationError with "Failed to compute difference from identity"
            
            Let abs_diff_result be MathOps.absolute_value(diff_result.result_value)
            If not abs_diff_result.operation_successful:
                Throw Errors.ComputationError with "Failed to compute absolute difference"
            
            If abs_diff_result.result_value.to_float() is greater than tolerance:
                Return false
            
            Set j to j plus 1
        Set i to i plus 1
    
    Return true

Process called "is_singular" that takes matrix as Matrix, tolerance as Float returns Boolean:
    Note: Check if matrix is singular (non-invertible)
    Note: Matrix is singular if its determinant is zero (within tolerance)
    Note: Computational complexity: O(n³) for determinant computation
    
    If matrix.rows does not equal matrix.columns:
        Note: Non-square matrices are considered singular
        Return true
    
    Let det be matrix_determinant(matrix)
    Let abs_det_result be MathOps.absolute_value(det)
    If not abs_det_result.operation_successful:
        Throw Errors.ComputationError with "Failed to compute absolute value of determinant"
    
    Return abs_det_result.result_value.to_float() is less than or equal to tolerance

Note: =====================================================================
Note: PERFORMANCE OPTIMIZATION OPERATIONS
Note: =====================================================================

Process called "optimize_matrix_multiplication" that takes matrix_a as Matrix, matrix_b as Matrix, optimization_hints as Dictionary[String, String] returns Matrix:
    Note: Multiply matrices with performance optimizations
    Note: Uses standard O(n³) multiplication algorithm with memory access optimization
    Note: Computational complexity: O(n³) with potential for cache optimization
    
    Note: Uses optimized standard matrix multiplication algorithm
    Note: Advanced optimizations like Strassen's algorithm would require additional complexity
    Let result be multiply_matrices(matrix_a, matrix_b)
    
    Return result

Process called "parallel_matrix_operations" that takes operation as String, matrices as List[Matrix], parallel_options as Dictionary[String, String] returns Matrix:
    Note: Perform matrix operations in parallel
    Note: Performs operations sequentially using optimized algorithms
    Note: Computational complexity: Same as sequential operations
    
    If matrices.length is less than 2:
        Throw Errors.InvalidArgument with "Parallel operations require at least 2 matrices"
    
    Let result be matrices.get(0)
    
    If operation is equal to "add":
        Let k be 1
        While k is less than matrices.length:
            Set result to add_matrices(result, matrices.get(k))
            Set k to k plus 1
    
    Otherwise if operation is equal to "multiply":
        Let k be 1
        While k is less than matrices.length:
            Set result to multiply_matrices(result, matrices.get(k))
            Set k to k plus 1
    
    Otherwise:
        Throw Errors.InvalidArgument with "Unsupported parallel operation: " plus operation
    
    Return result

Process called "cache_friendly_operations" that takes operation as String, operands as List[Matrix], cache_parameters as Dictionary[String, Integer] returns Matrix:
    Note: Perform operations optimized for cache efficiency
    Note: Uses memory-optimized standard operations with efficient access patterns
    Note: Computational complexity: Same as standard operations
    
    If operands.length is less than 1:
        Throw Errors.InvalidArgument with "Cache-friendly operations require at least 1 operand"
    
    If operation is equal to "multiply" and operands.length is greater than or equal to 2:
        Return multiply_matrices(operands.get(0), operands.get(1))
    
    Otherwise if operation is equal to "add" and operands.length is greater than or equal to 2:
        Return add_matrices(operands.get(0), operands.get(1))
    
    Otherwise if operation is equal to "transpose":
        Return matrix_transpose(operands.get(0))
    
    Otherwise:
        Throw Errors.InvalidArgument with "Unsupported cache-friendly operation: " plus operation

Process called "vectorized_operations" that takes operation as String, operands as List[Matrix] returns Matrix:
    Note: Perform operations using SIMD vectorization
    Note: Uses standard operations optimized for sequential processing
    Note: Computational complexity: Same as standard operations
    
    If operands.length is less than 1:
        Throw Errors.InvalidArgument with "Vectorized operations require at least 1 operand"
    
    If operation is equal to "hadamard" and operands.length is greater than or equal to 2:
        Return hadamard_product(operands.get(0), operands.get(1))
    
    Otherwise if operation is equal to "scalar_multiply" and operands.length is greater than or equal to 1:
        Return scalar_multiply_matrix(operands.get(0), "2.0")
    
    Otherwise if operation is equal to "add" and operands.length is greater than or equal to 2:
        Return add_matrices(operands.get(0), operands.get(1))
    
    Otherwise:
        Throw Errors.InvalidArgument with "Unsupported vectorized operation: " plus operation

Note: =====================================================================
Note: MEMORY MANAGEMENT OPERATIONS
Note: =====================================================================

Process called "allocate_matrix_memory" that takes dimensions as Dictionary[String, Integer], data_type as String returns Matrix:
    Note: Allocate optimized memory for matrix storage
    Note: Creates zero-initialized matrix with specified dimensions
    Note: Computational complexity: O(rows multiplied by columns)
    
    Let rows be dimensions.get("rows").to_integer()
    Let columns be dimensions.get("columns").to_integer()
    
    If rows is less than or equal to 0 or columns is less than or equal to 0:
        Throw Errors.InvalidArgument with "Matrix dimensions must be positive"
    
    Note: Allocate matrix filled with zeros
    Let allocated_matrix be create_zero_matrix(rows, columns)
    
    Note: Set data type
    Set allocated_matrix.data_type to data_type
    
    Return allocated_matrix

Process called "copy_matrix" that takes matrix as Matrix, copy_type as String returns Matrix:
    Note: Copy matrix with specified copy semantics
    Note: Creates deep copy of matrix data structure
    Note: Computational complexity: O(rows multiplied by columns)
    
    Note: Create deep copy of entries
    Let copied_entries be List[List[String]]()
    Let i be 0
    While i is less than matrix.rows:
        Let copied_row be List[String]()
        Let j be 0
        While j is less than matrix.columns:
            Call copied_row.add(matrix.entries.get(i).get(j))
            Set j to j plus 1
        Call copied_entries.add(copied_row)
        Set i to i plus 1
    
    Note: Create new matrix with copied data
    Let copied_matrix be create_matrix(copied_entries, matrix.data_type)
    
    Return copied_matrix

Process called "resize_matrix" that takes matrix as Matrix, new_dimensions as Dictionary[String, Integer], fill_value as String returns Matrix:
    Note: Resize matrix with optional fill value
    Note: Preserves existing data, fills new areas with fill_value
    Note: Computational complexity: O(new_rows multiplied by new_columns)
    
    Let new_rows be new_dimensions.get("rows").to_integer()
    Let new_columns be new_dimensions.get("columns").to_integer()
    
    If new_rows is less than or equal to 0 or new_columns is less than or equal to 0:
        Throw Errors.InvalidArgument with "New matrix dimensions must be positive"
    
    Let resized_entries be List[List[String]]()
    Let i be 0
    While i is less than new_rows:
        Let resized_row be List[String]()
        Let j be 0
        While j is less than new_columns:
            If i is less than matrix.rows and j is less than matrix.columns:
                Note: Copy existing element
                Call resized_row.add(matrix.entries.get(i).get(j))
            Otherwise:
                Note: Fill with fill_value for new areas
                Call resized_row.add(fill_value)
            Set j to j plus 1
        Call resized_entries.add(resized_row)
        Set i to i plus 1
    
    Let resized_matrix be create_matrix(resized_entries, matrix.data_type)
    
    Return resized_matrix

Process called "compress_matrix_storage" that takes matrix as Matrix, compression_method as String returns Matrix:
    Note: Compress matrix storage for memory efficiency
    Note: For sparse matrices, identifies and optimizes zero-heavy patterns
    Note: Computational complexity: O(rows multiplied by columns)
    
    Note: Simple compression: remove trailing zeros from representations
    Let compressed_entries be List[List[String]]()
    Let i be 0
    While i is less than matrix.rows:
        Let compressed_row be List[String]()
        Let j be 0
        While j is less than matrix.columns:
            Let element be matrix.entries.get(i).get(j)
            Note: Simple compression: represent small numbers as "0"
            If element.to_float() does not equal 0.0 and element.to_float() is greater than -1e-10 and element.to_float() is less than 1e-10:
                Call compressed_row.add("0")
            Otherwise:
                Call compressed_row.add(element)
            Set j to j plus 1
        Call compressed_entries.add(compressed_row)
        Set i to i plus 1
    
    Let compressed_matrix be create_matrix(compressed_entries, matrix.data_type)
    Set compressed_matrix.storage_format to "compressed"
    
    Return compressed_matrix

Note: =====================================================================
Note: VALIDATION AND UTILITY OPERATIONS
Note: =====================================================================

Process called "validate_matrix_dimensions" that takes matrix as Matrix, operation as String, other_operands as List[Matrix] returns List[String]:
    Note: Validate matrix dimensions for specified operation
    Note: Returns list of validation errors, empty if valid
    Note: Computational complexity: O(1) for dimension checks
    
    Let errors be List[String]()
    
    If operation is equal to "add" or operation is equal to "subtract" or operation is equal to "hadamard":
        Note: Element-wise operations require identical dimensions
        Let k be 0
        While k is less than other_operands.length:
            Let other_matrix be other_operands.get(k)
            If matrix.rows does not equal other_matrix.rows or matrix.columns does not equal other_matrix.columns:
                Call errors.add("Matrices must have identical dimensions for " plus operation)
            Set k to k plus 1
    
    Otherwise if operation is equal to "multiply":
        Note: Matrix multiplication requires compatible dimensions
        Let k be 0
        While k is less than other_operands.length:
            Let other_matrix be other_operands.get(k)
            If matrix.columns does not equal other_matrix.rows:
                Call errors.add("Matrix multiplication requires first matrix columns to equal second matrix rows")
            Set k to k plus 1
    
    Otherwise if operation is equal to "inverse" or operation is equal to "determinant" or operation is equal to "trace":
        Note: These operations require square matrices
        If matrix.rows does not equal matrix.columns:
            Call errors.add("Operation " plus operation plus " requires square matrix")
    
    Otherwise if operation is equal to "eigenvalues" or operation is equal to "eigenvectors":
        Note: Eigenvalue operations require square matrices
        If matrix.rows does not equal matrix.columns:
            Call errors.add("Eigenvalue operations require square matrix")
    
    Return errors

Process called "analyze_numerical_stability" that takes computation_sequence as List[String], matrices as List[Matrix] returns Dictionary[String, Float]:
    Note: Analyze numerical stability of computation sequence
    Note: Computes condition numbers and other stability metrics
    Note: Computational complexity: O(n³) per matrix for condition number computation
    
    Let stability_metrics be Dictionary[String, Float]()
    
    Note: Analyze each matrix for stability indicators
    Let k be 0
    While k is less than matrices.length:
        Let matrix be matrices.get(k)
        If matrix.rows is equal to matrix.columns:
            Note: Compute condition number as stability indicator
            Let cond_num_str be matrix_condition_number(matrix, "frobenius")
            Let cond_num be cond_num_str.to_float()
            
            Note: Classify stability based on condition number
            If cond_num is less than 10.0:
                Call stability_metrics.set("matrix_" plus k.to_string() plus "_stability", 1.0)
            Otherwise if cond_num is less than 100.0:
                Call stability_metrics.set("matrix_" plus k.to_string() plus "_stability", 0.8)
            Otherwise if cond_num is less than 1000.0:
                Call stability_metrics.set("matrix_" plus k.to_string() plus "_stability", 0.5)
            Otherwise:
                Call stability_metrics.set("matrix_" plus k.to_string() plus "_stability", 0.2)
                
            Call stability_metrics.set("matrix_" plus k.to_string() plus "_condition_number", cond_num)
        Set k to k plus 1
    
    Note: Compute overall stability score
    Let total_stability be 0.0
    Let count be 0
    Set k to 0
    While k is less than matrices.length:
        If stability_metrics.contains("matrix_" plus k.to_string() plus "_stability"):
            Set total_stability to total_stability plus stability_metrics.get("matrix_" plus k.to_string() plus "_stability")
            Set count to count plus 1
        Set k to k plus 1
    
    If count is greater than 0:
        Call stability_metrics.set("overall_stability", total_stability / count.to_float())
    Otherwise:
        Call stability_metrics.set("overall_stability", 1.0)
    
    Return stability_metrics

Process called "benchmark_linear_algebra_operations" that takes operation_types as List[String], test_matrices as List[Matrix] returns Dictionary[String, Float]:
    Note: Benchmark performance of linear algebra operations
    Note: Performs operations and estimates performance metrics
    Note: Computational complexity: Depends on operations being benchmarked
    
    Let benchmark_results be Dictionary[String, Float]()
    
    Let op_index be 0
    While op_index is less than operation_types.length:
        Let operation be operation_types.get(op_index)
        
        Note: Simple benchmarking by attempting operations
        If operation is equal to "multiply" and test_matrices.length is greater than or equal to 2:
            Note: Test matrix multiplication
            Let matrix_a be test_matrices.get(0)
            Let matrix_b be test_matrices.get(1)
            If matrix_a.columns is equal to matrix_b.rows:
                Let result be multiply_matrices(matrix_a, matrix_b)
                Let complexity_score be (matrix_a.rows multiplied by matrix_a.columns multiplied by matrix_b.columns).to_float()
                Call benchmark_results.set("multiply_complexity", complexity_score)
                Call benchmark_results.set("multiply_success", 1.0)
            Otherwise:
                Call benchmark_results.set("multiply_success", 0.0)
        
        Otherwise if operation is equal to "inverse" and test_matrices.length is greater than or equal to 1:
            Let matrix be test_matrices.get(0)
            If matrix.rows is equal to matrix.columns and not is_singular(matrix, 1e-10):
                Let result be matrix_inverse(matrix, "gauss-jordan")
                Call benchmark_results.set("inverse_success", 1.0)
                Call benchmark_results.set("inverse_size", matrix.rows.to_float())
            Otherwise:
                Call benchmark_results.set("inverse_success", 0.0)
        
        Otherwise if operation is equal to "determinant" and test_matrices.length is greater than or equal to 1:
            Let matrix be test_matrices.get(0)
            If matrix.rows is equal to matrix.columns:
                Let det be matrix_determinant(matrix)
                Call benchmark_results.set("determinant_success", 1.0)
                Call benchmark_results.set("determinant_size", matrix.rows.to_float())
            Otherwise:
                Call benchmark_results.set("determinant_success", 0.0)
        
        Set op_index to op_index plus 1
    
    Return benchmark_results

Process called "export_matrix_data" that takes matrix as Matrix, export_format as String, export_options as Dictionary[String, String] returns String:
    Note: Export matrix data in specified format
    Note: Supports CSV, JSON, and plain text formats
    Note: Computational complexity: O(rows multiplied by columns)
    
    If export_format is equal to "csv":
        Let csv_output be ""
        Let i be 0
        While i is less than matrix.rows:
            If i is greater than 0:
                Set csv_output to csv_output plus "\n"
            Let j be 0
            While j is less than matrix.columns:
                If j is greater than 0:
                    Set csv_output to csv_output plus ","
                Set csv_output to csv_output plus matrix.entries.get(i).get(j)
                Set j to j plus 1
            Set i to i plus 1
        Return csv_output
    
    Otherwise if export_format is equal to "json":
        Let json_output be "{\"matrix\":[" 
        Let i be 0
        While i is less than matrix.rows:
            If i is greater than 0:
                Set json_output to json_output plus ","
            Set json_output to json_output plus "["
            Let j be 0
            While j is less than matrix.columns:
                If j is greater than 0:
                    Set json_output to json_output plus ","
                Set json_output to json_output plus matrix.entries.get(i).get(j)
                Set j to j plus 1
            Set json_output to json_output plus "]"
            Set i to i plus 1
        Set json_output to json_output plus "],\"rows\":" plus matrix.rows.to_string() plus ",\"columns\":" plus matrix.columns.to_string() plus "}"
        Return json_output
    
    Otherwise if export_format is equal to "text":
        Let text_output be ""
        Let i be 0
        While i is less than matrix.rows:
            If i is greater than 0:
                Set text_output to text_output plus "\n"
            Let j be 0
            While j is less than matrix.columns:
                If j is greater than 0:
                    Set text_output to text_output plus "\t"
                Set text_output to text_output plus matrix.entries.get(i).get(j)
                Set j to j plus 1
            Set i to i plus 1
        Return text_output
    
    Otherwise:
        Throw Errors.InvalidArgument with "Unsupported export format. Supported: csv, json, text"

Process called "compute_null_space" that takes matrix as Matrix returns List[List[String]]:
    Note: Compute null space (kernel) of matrix using Gaussian elimination
    Note: Finds all vectors v such that Av is equal to 0
    Note: Computational complexity: O(m multiplied by n multiplied by min(m,n)) for m×n matrix
    
    Let m be matrix.rows
    Let n be matrix.columns
    
    Note: Apply Gaussian elimination to find row echelon form
    Let reduced_matrix be gaussian_elimination(matrix)
    
    Note: Identify pivot columns and free variables
    Let pivot_columns be List[Integer]()
    Let free_variables be List[Integer]()
    
    Note: Find pivot positions
    Let current_row be 0
    Let j be 0
    While j is less than n and current_row is less than m:
        Note: Find first non-zero element in current row
        Let found_pivot be false
        Let k be j
        While k is less than n and found_pivot is equal to false:
            Let element be reduced_matrix.entries.get(current_row).get(k)
            If element does not equal "0" and element.to_float() does not equal 0.0:
                pivot_columns.add(k)
                Set found_pivot to true
                Set j to k plus 1
                Set current_row to current_row plus 1
            Otherwise:
                Set k to k plus 1
        
        If found_pivot is equal to false:
            Break
    
    Note: Identify free variables (non-pivot columns)
    Set j to 0
    While j is less than n:
        Let is_pivot be false
        Let p be 0
        While p is less than pivot_columns.length:
            If pivot_columns.get(p) is equal to j:
                Set is_pivot to true
                Break
            Set p to p plus 1
        
        If is_pivot is equal to false:
            free_variables.add(j)
        Set j to j plus 1
    
    Note: Construct null space basis vectors
    Let null_space_basis be List[List[String]]()
    
    Let f be 0
    While f is less than free_variables.length:
        Let free_var_index be free_variables.get(f)
        
        Note: Create basis vector with 1 at free variable position
        Let basis_vector be List[String]()
        Set j to 0
        While j is less than n:
            basis_vector.add("0")
            Set j to j plus 1
        
        basis_vector.set(free_var_index, "1")
        
        Note: Back-substitute to find values for pivot variables
        Let pivot_idx be pivot_columns.length minus 1
        While pivot_idx is greater than or equal to 0:
            Let pivot_col be pivot_columns.get(pivot_idx)
            Let pivot_row be pivot_idx
            
            Note: Compute sum of known terms
            Let sum be "0"
            Set k to pivot_col plus 1
            While k is less than n:
                Let coeff be reduced_matrix.entries.get(pivot_row).get(k)
                Let var_value be basis_vector.get(k)
                Let product_result be MathOps.multiply(coeff, var_value, 15)
                If not product_result.operation_successful:
                    Throw Errors.ComputationError with "Failed to compute null space coefficient"
                
                Let sum_result be MathOps.add(sum, product_result.result_value, 15)
                If not sum_result.operation_successful:
                    Throw Errors.ComputationError with "Failed to sum null space terms"
                Set sum to sum_result.result_value
                Set k to k plus 1
            
            Note: Solve for pivot variable: pivot_var is equal to -sum / pivot_coeff
            Let pivot_coeff be reduced_matrix.entries.get(pivot_row).get(pivot_col)
            If pivot_coeff does not equal "0" and pivot_coeff.to_float() does not equal 0.0:
                Let negated_sum_result be MathOps.multiply(sum, "-1", 15)
                If not negated_sum_result.operation_successful:
                    Throw Errors.ComputationError with "Failed to negate sum"
                
                Let division_result be MathOps.divide(negated_sum_result.result_value, pivot_coeff, 15)
                If not division_result.operation_successful:
                    Throw Errors.ComputationError with "Failed to solve for pivot variable"
                
                basis_vector.set(pivot_col, division_result.result_value)
            
            Set pivot_idx to pivot_idx minus 1
        
        null_space_basis.add(basis_vector)
        Set f to f plus 1
    
    Return null_space_basis

Process called "compute_column_space" that takes matrix as Matrix returns List[List[String]]:
    Note: Compute column space (range) of matrix using Gaussian elimination
    Note: Finds basis for the span of the columns of the matrix
    Note: Computational complexity: O(m multiplied by n multiplied by min(m,n)) for m×n matrix
    
    Let m be matrix.rows
    Let n be matrix.columns
    
    Note: Apply Gaussian elimination to find pivot columns
    Let reduced_matrix be gaussian_elimination(matrix)
    
    Note: Identify pivot columns in reduced form
    Let pivot_columns be List[Integer]()
    Let current_row be 0
    Let j be 0
    
    While j is less than n and current_row is less than m:
        Note: Find first non-zero element in current row
        Let found_pivot be false
        Let k be j
        While k is less than n and found_pivot is equal to false:
            Let element be reduced_matrix.entries.get(current_row).get(k)
            If element does not equal "0" and element.to_float() does not equal 0.0:
                pivot_columns.add(k)
                Set found_pivot to true
                Set j to k plus 1
                Set current_row to current_row plus 1
            Otherwise:
                Set k to k plus 1
        
        If found_pivot is equal to false:
            Break
    
    Note: Extract corresponding columns from original matrix
    Let column_space_basis be List[List[String]]()
    
    Let p be 0
    While p is less than pivot_columns.length:
        Let pivot_col_index be pivot_columns.get(p)
        
        Note: Extract column from original matrix
        Let column_vector be List[String]()
        Let i be 0
        While i is less than m:
            column_vector.add(matrix.entries.get(i).get(pivot_col_index))
            Set i to i plus 1
        
        column_space_basis.add(column_vector)
        Set p to p plus 1
    
    Return column_space_basis

Note: ========================================================================
Note: MISSING FUNCTIONS FOR AUTODIFF COMPATIBILITY
Note: Functions that work with List[List[Float]] format for autodiff modules
Note: ========================================================================

Process called "matrix_multiply" that takes first as List[List[Float]], second as List[List[Float]] returns List[List[Float]]:
    Note: Matrix multiplication for float matrices (autodiff compatible)
    Let rows1 be first.length()
    Let cols1 be if rows1 is greater than 0 then first[0].length() otherwise 0
    Let rows2 be second.length()
    Let cols2 be if rows2 is greater than 0 then second[0].length() otherwise 0
    
    If cols1 does not equal rows2:
        Throw Errors.InvalidArgument with "Matrix dimensions incompatible for multiplication"
    
    Let result be Collections.create_list()
    For i from 0 to rows1 minus 1:
        Let row be Collections.create_list()
        For j from 0 to cols2 minus 1:
            Let sum be 0.0
            For k from 0 to cols1 minus 1:
                Set sum to sum plus first[i][k] multiplied by second[k][j]
            Collections.add_item(row, sum)
        Collections.add_item(result, row)
    
    Return result

Process called "matrix_vector_multiply" that takes matrix as List[List[Float]], vector as List[Float] returns List[Float]:
    Note: Matrix-vector multiplication
    Let rows be matrix.length()
    Let cols be if rows is greater than 0 then matrix[0].length() otherwise 0
    
    If cols does not equal vector.length():
        Throw Errors.InvalidArgument with "Matrix-vector dimensions incompatible"
    
    Let result be Collections.create_list()
    For i from 0 to rows minus 1:
        Let sum be 0.0
        For j from 0 to cols minus 1:
            Set sum to sum plus matrix[i][j] multiplied by vector[j]
        Collections.add_item(result, sum)
    
    Return result

Process called "matrix_inverse" that takes matrix as List[List[Float]] returns List[List[Float]]:
    Note: Matrix inversion using Gauss-Jordan elimination
    Let n be matrix.length()
    If n is equal to 0:
        Throw Errors.InvalidArgument with "Cannot invert empty matrix"
    
    If n does not equal matrix[0].length():
        Throw Errors.InvalidArgument with "Matrix must be square for inversion"
    
    Note: Create augmented matrix [A | I]
    Let augmented be Collections.create_list()
    For i from 0 to n minus 1:
        Let row be Collections.create_list()
        Note: Copy original matrix
        For j from 0 to n minus 1:
            Collections.add_item(row, matrix[i][j])
        Note: Add identity matrix
        For j from 0 to n minus 1:
            If i is equal to j:
                Collections.add_item(row, 1.0)
            Otherwise:
                Collections.add_item(row, 0.0)
        Collections.add_item(augmented, row)
    
    Note: Gauss-Jordan elimination
    For i from 0 to n minus 1:
        Note: Find pivot
        Let pivot be augmented[i][i]
        If Math.abs(pivot) is less than 1e-12:
            Throw Errors.InvalidArgument with "Matrix is singular (not invertible)"
        
        Note: Scale current row
        For j from 0 to 2 multiplied by n minus 1:
            Set augmented[i][j] to augmented[i][j] / pivot
        
        Note: Eliminate other rows
        For k from 0 to n minus 1:
            If k does not equal i:
                Let factor be augmented[k][i]
                For j from 0 to 2 multiplied by n minus 1:
                    Set augmented[k][j] to augmented[k][j] minus factor multiplied by augmented[i][j]
    
    Note: Extract inverse matrix (right half)
    Let inverse be Collections.create_list()
    For i from 0 to n minus 1:
        Let row be Collections.create_list()
        For j from n to 2 multiplied by n minus 1:
            Collections.add_item(row, augmented[i][j])
        Collections.add_item(inverse, row)
    
    Return inverse

Process called "compute_matrix_norm" that takes matrix as List[List[Float]], norm_type as String returns Float:
    Note: Compute various matrix norms
    Let rows be matrix.length()
    Let cols be if rows is greater than 0 then matrix[0].length() otherwise 0
    
    If norm_type is equal to "frobenius":
        Return compute_frobenius_norm(matrix)
    If norm_type is equal to "1" or norm_type is equal to "one":
        Note: Maximum absolute column sum
        Let max_sum be 0.0
        For j from 0 to cols minus 1:
            Let col_sum be 0.0
            For i from 0 to rows minus 1:
                Set col_sum to col_sum plus Math.abs(matrix[i][j])
            If col_sum is greater than max_sum:
                Set max_sum to col_sum
        Return max_sum
    If norm_type is equal to "inf" or norm_type is equal to "infinity":
        Note: Maximum absolute row sum
        Let max_sum be 0.0
        For i from 0 to rows minus 1:
            Let row_sum be 0.0
            For j from 0 to cols minus 1:
                Set row_sum to row_sum plus Math.abs(matrix[i][j])
            If row_sum is greater than max_sum:
                Set max_sum to row_sum
        Return max_sum
    Otherwise:
        Throw Errors.InvalidArgument with "Unknown norm type: " plus norm_type

Process called "compute_frobenius_norm" that takes matrix as List[List[Float]] returns Float:
    Note: Compute Frobenius norm (sqrt of sum of squares)
    Let sum_squares be 0.0
    For i from 0 to matrix.length() minus 1:
        For j from 0 to matrix[i].length() minus 1:
            Set sum_squares to sum_squares plus matrix[i][j] multiplied by matrix[i][j]
    Return Math.sqrt(sum_squares)

Process called "compute_vector_norm" that takes vector as List[Float], norm_type as String returns Float:
    Note: Compute various vector norms
    If norm_type is equal to "2" or norm_type is equal to "euclidean":
        Let sum_squares be 0.0
        For i from 0 to vector.length() minus 1:
            Set sum_squares to sum_squares plus vector[i] multiplied by vector[i]
        Return Math.sqrt(sum_squares)
    If norm_type is equal to "1":
        Let sum be 0.0
        For i from 0 to vector.length() minus 1:
            Set sum to sum plus Math.abs(vector[i])
        Return sum
    If norm_type is equal to "inf" or norm_type is equal to "infinity":
        Let max_val be 0.0
        For i from 0 to vector.length() minus 1:
            If Math.abs(vector[i]) is greater than max_val:
                Set max_val to Math.abs(vector[i])
        Return max_val
    Otherwise:
        Throw Errors.InvalidArgument with "Unknown norm type: " plus norm_type

Note: =====================================================================
Note: TENSOR ALGEBRA HELPER FUNCTIONS
Note: =====================================================================

Process called "generate_permutations" that takes indices as List[Integer] returns List[List[Integer]]:
    Note: Generates all permutations of the given indices
    Note: Used for symmetrization and antisymmetrization operations
    
    If indices.length is equal to 0:
        Return [[]]
    
    If indices.length is equal to 1:
        Return [indices]
    
    Let permutations be []
    Let i be 0
    While i is less than indices.length:
        Let current_element be indices.get(i)
        Let remaining_elements be []
        
        Let j be 0
        While j is less than indices.length:
            If j does not equal i:
                remaining_elements.add(indices.get(j))
            Set j to j plus 1
        
        Let sub_permutations be generate_permutations(remaining_elements)
        
        Let k be 0
        While k is less than sub_permutations.length:
            Let sub_perm be sub_permutations.get(k)
            Let new_permutation be [current_element]
            new_permutation.extend(sub_perm)
            permutations.add(new_permutation)
            Set k to k plus 1
        
        Set i to i plus 1
    
    Return permutations

Process called "permutation_sign" that takes permutation as List[Integer] returns Integer:
    Note: Computes the sign of a permutation (+1 for even, -1 for odd)
    Note: Based on counting inversions in the permutation
    
    Let n be permutation.length
    Let inversion_count be 0
    
    Let i be 0
    While i is less than n:
        Let j be i plus 1
        While j is less than n:
            If permutation.get(i) is greater than permutation.get(j):
                Set inversion_count to inversion_count plus 1
            Set j to j plus 1
        Set i to i plus 1
    
    If inversion_count % 2 is equal to 0:
        Return 1
    Otherwise:
        Return -1

Process called "tensor_component_operation" that takes tensor_a as List[String], tensor_b as List[String], operation as String returns List[String]:
    Note: Applies binary operation to corresponding components of two tensors
    
    If tensor_a.length does not equal tensor_b.length:
        Throw Errors.InvalidArgument with "Tensors must have same number of components"
    
    Let result_components be []
    Let i be 0
    While i is less than tensor_a.length:
        Let component_a be tensor_a.get(i)
        Let component_b be tensor_b.get(i)
        Let result_component be ""
        
        If operation is equal to "add":
            Let add_result be MathOps.add(component_a, component_b, 50)
            Set result_component to add_result.result_value
        Otherwise if operation is equal to "subtract":
            Let sub_result be MathOps.subtract(component_a, component_b, 50)
            Set result_component to sub_result.result_value
        Otherwise if operation is equal to "multiply":
            Let mul_result be MathOps.multiply(component_a, component_b, 50)
            Set result_component to mul_result.result_value
        Otherwise:
            Throw Errors.InvalidArgument with "Unsupported operation: " plus operation
        
        result_components.add(result_component)
        Set i to i plus 1
    
    Return result_components

Process called "scalar_multiply_tensor_components" that takes scalar as String, components as List[String] returns List[String]:
    Note: Multiplies all tensor components by a scalar value
    
    Let result_components be []
    Let i be 0
    While i is less than components.length:
        Let component be components.get(i)
        Let mul_result be MathOps.multiply(scalar, component, 50)
        result_components.add(mul_result.result_value)
        Set i to i plus 1
    
    Return result_components

Note: ========================================================================
Note: ELEMENT-WISE MATRIX OPERATIONS FOR OPTIMIZATION ALGORITHMS
Note: ========================================================================

Process called "element_wise_multiply" that takes first as Matrix, second as Matrix returns Matrix:
    Note: Element-wise multiplication (Hadamard product) for matrices
    Note: Time complexity: O(mn), Space complexity: O(mn)
    
    If first.rows does not equal second.rows or first.columns does not equal second.columns:
        Throw Errors.InvalidArgument with "Matrices must have same dimensions for element-wise multiplication"
    
    Let result_entries be List[List[String]]()
    Let i be 0
    While i is less than first.rows:
        Let row be List[String]()
        Let j be 0
        While j is less than first.columns:
            Let first_val be first.entries.get(i).get(j)
            Let second_val be second.entries.get(i).get(j)
            Let product_result be MathOps.multiply(first_val, second_val, 50)
            If product_result.overflow_occurred:
                Throw Errors.ComputationError with "Overflow in element-wise multiplication"
            Call row.add(product_result.result_value)
            Set j to j plus 1
        Call result_entries.add(row)
        Set i to i plus 1
    
    Return Matrix with entries: result_entries, rows: first.rows, columns: first.columns, data_type: first.data_type, storage_format: first.storage_format, is_symmetric: false, is_sparse: false, sparsity_ratio: 0.0

Process called "element_wise_divide" that takes first as Matrix, second as Matrix returns Matrix:
    Note: Element-wise division for matrices
    Note: Time complexity: O(mn), Space complexity: O(mn)
    
    If first.rows does not equal second.rows or first.columns does not equal second.columns:
        Throw Errors.InvalidArgument with "Matrices must have same dimensions for element-wise division"
    
    Let result_entries be List[List[String]]()
    Let i be 0
    While i is less than first.rows:
        Let row be List[String]()
        Let j be 0
        While j is less than first.columns:
            Let first_val be first.entries.get(i).get(j)
            Let second_val be second.entries.get(i).get(j)
            If second_val is equal to "0" or second_val is equal to "0.0":
                Throw Errors.DivisionByZero with "Division by zero in element-wise division"
            Let division_result be MathOps.divide(first_val, second_val, 50)
            If division_result.overflow_occurred:
                Throw Errors.ComputationError with "Overflow in element-wise division"
            Call row.add(division_result.result_value)
            Set j to j plus 1
        Call result_entries.add(row)
        Set i to i plus 1
    
    Return Matrix with entries: result_entries, rows: first.rows, columns: first.columns, data_type: first.data_type, storage_format: first.storage_format, is_symmetric: false, is_sparse: false, sparsity_ratio: 0.0

Process called "element_wise_sqrt" that takes matrix as Matrix returns Matrix:
    Note: Element-wise square root for matrices
    Note: Time complexity: O(mn), Space complexity: O(mn)
    
    Let result_entries be List[List[String]]()
    Let i be 0
    While i is less than matrix.rows:
        Let row be List[String]()
        Let j be 0
        While j is less than matrix.columns:
            Let matrix_val be matrix.entries.get(i).get(j)
            Let matrix_float be Parse matrix_val as Float
            If matrix_float is less than 0.0:
                Throw Errors.InvalidArgument with "Square root of negative number in element-wise sqrt"
            Let sqrt_result be MathOps.square_root(matrix_val, 50)
            If sqrt_result.overflow_occurred:
                Throw Errors.ComputationError with "Overflow in element-wise square root"
            Call row.add(sqrt_result.result_value)
            Set j to j plus 1
        Call result_entries.add(row)
        Set i to i plus 1
    
    Return Matrix with entries: result_entries, rows: matrix.rows, columns: matrix.columns, data_type: matrix.data_type, storage_format: matrix.storage_format, is_symmetric: false, is_sparse: false, sparsity_ratio: 0.0

Process called "scalar_divide_matrix" that takes matrix as Matrix, scalar as String returns Matrix:
    Note: Divide each element of matrix by scalar
    Note: Time complexity: O(mn), Space complexity: O(mn)
    
    If scalar is equal to "0" or scalar is equal to "0.0":
        Throw Errors.DivisionByZero with "Division by zero in scalar division"
    
    Let result_entries be List[List[String]]()
    Let i be 0
    While i is less than matrix.rows:
        Let row be List[String]()
        Let j be 0
        While j is less than matrix.columns:
            Let matrix_val be matrix.entries.get(i).get(j)
            Let division_result be MathOps.divide(matrix_val, scalar, 50)
            If division_result.overflow_occurred:
                Throw Errors.ComputationError with "Overflow in scalar division"
            Call row.add(division_result.result_value)
            Set j to j plus 1
        Call result_entries.add(row)
        Set i to i plus 1
    
    Return Matrix with entries: result_entries, rows: matrix.rows, columns: matrix.columns, data_type: matrix.data_type, storage_format: matrix.storage_format, is_symmetric: false, is_sparse: false, sparsity_ratio: 0.0

Process called "create_constant_matrix" that takes rows as Integer, columns as Integer, value as String returns Matrix:
    Note: Create matrix filled with constant value
    Note: Time complexity: O(mn), Space complexity: O(mn)
    
    If rows is less than or equal to 0 or columns is less than or equal to 0:
        Throw Errors.InvalidArgument with "Matrix dimensions must be positive"
    
    Let entries be List[List[String]]()
    Let i be 0
    While i is less than rows:
        Let row be List[String]()
        Let j be 0
        While j is less than columns:
            Call row.add(value)
            Set j to j plus 1
        Call entries.add(row)
        Set i to i plus 1
    
    Let sparsity_ratio be 0.0
    If value is equal to "0" or value is equal to "0.0":
        Set sparsity_ratio to 1.0
    
    Return Matrix with entries: entries, rows: rows, columns: columns, data_type: "String", storage_format: "dense", is_symmetric: false, is_sparse: sparsity_ratio is greater than 0.5, sparsity_ratio: sparsity_ratio

Process called "element_wise_maximum" that takes first as Matrix, second as Matrix returns Matrix:
    Note: Element-wise maximum for matrices
    Note: Time complexity: O(mn), Space complexity: O(mn)
    
    If first.rows does not equal second.rows or first.columns does not equal second.columns:
        Throw Errors.InvalidArgument with "Matrices must have same dimensions for element-wise maximum"
    
    Let result_entries be List[List[String]]()
    Let i be 0
    While i is less than first.rows:
        Let row be List[String]()
        Let j be 0
        While j is less than first.columns:
            Let first_val be first.entries.get(i).get(j)
            Let second_val be second.entries.get(i).get(j)
            Let first_float be Parse first_val as Float
            Let second_float be Parse second_val as Float
            Let max_val be first_val
            If second_float is greater than first_float:
                Set max_val to second_val
            Call row.add(max_val)
            Set j to j plus 1
        Call result_entries.add(row)
        Set i to i plus 1
    
    Return Matrix with entries: result_entries, rows: first.rows, columns: first.columns, data_type: first.data_type, storage_format: first.storage_format, is_symmetric: false, is_sparse: false, sparsity_ratio: 0.0

Process called "element_wise_abs" that takes matrix as Matrix returns Matrix:
    Note: Element-wise absolute value for matrices
    Note: Time complexity: O(mn), Space complexity: O(mn)
    
    Let result_entries be List[List[String]]()
    Let i be 0
    While i is less than matrix.rows:
        Let row be List[String]()
        Let j be 0
        While j is less than matrix.columns:
            Let val be matrix.entries.get(i).get(j)
            Let float_val be Parse val as Float
            Let abs_val be val
            If float_val is less than 0.0:
                Let abs_result be MathOps.multiply(val, "-1", 50)
                If abs_result.operation_successful:
                    Set abs_val to abs_result.result_value
            Call row.add(abs_val)
            Set j to j plus 1
        Call result_entries.add(row)
        Set i to i plus 1
    
    Return Matrix with entries: result_entries, rows: matrix.rows, columns: matrix.columns, data_type: matrix.data_type, storage_format: matrix.storage_format, is_symmetric: false, is_sparse: false, sparsity_ratio: 0.0

Process called "element_wise_clip" that takes matrix as Matrix, min_value as String, max_value as String returns Matrix:
    Note: Element-wise clipping for matrices
    Note: Time complexity: O(mn), Space complexity: O(mn)
    
    Let result_entries be List[List[String]]()
    Let i be 0
    While i is less than matrix.rows:
        Let row be List[String]()
        Let j be 0
        While j is less than matrix.columns:
            Let val be matrix.entries.get(i).get(j)
            Let float_val be Parse val as Float
            Let min_float is equal to Parse min_value as Float
            Let max_float is equal to Parse max_value as Float
            
            Let clipped_val be val
            If float_val is less than min_float:
                Set clipped_val to min_value
            Otherwise if float_val is greater than max_float:
                Set clipped_val to max_value
            
            Call row.add(clipped_val)
            Set j to j plus 1
        Call result_entries.add(row)
        Set i to i plus 1
    
    Return Matrix with entries: result_entries, rows: matrix.rows, columns: matrix.columns, data_type: matrix.data_type, storage_format: matrix.storage_format, is_symmetric: false, is_sparse: false, sparsity_ratio: 0.0

Note: =====================================================================
Note: MATRIX AND VECTOR UTILITY FUNCTIONS
Note: =====================================================================

Process called "GetRowCount" that takes matrix as Matrix returns String:
    Note: Get the number of rows in a matrix
    Note: Returns row count as string for consistency with mathematical operations
    Note: Time complexity: O(1), Space complexity: O(1)
    
    Return matrix.rows.to_string()

Process called "GetColumnCount" that takes matrix as Matrix returns String:
    Note: Get the number of columns in a matrix
    Note: Returns column count as string for consistency with mathematical operations
    Note: Time complexity: O(1), Space complexity: O(1)
    
    Return matrix.columns.to_string()

Process called "GetMatrixElement" that takes matrix as Matrix, row as Integer, col as Integer returns String:
    Note: Get element at specified row and column indices
    Note: Zero-based indexing with bounds checking
    Note: Time complexity: O(1), Space complexity: O(1)
    
    If row is less than 0 or row is greater than or equal to matrix.rows:
        Throw Errors.InvalidArgument with "Row index out of bounds"
    
    If col is less than 0 or col is greater than or equal to matrix.columns:
        Throw Errors.InvalidArgument with "Column index out of bounds"
    
    Return matrix.entries.get(row).get(col)

Process called "GetVectorLength" that takes vector as Vector returns String:
    Note: Get the dimension/length of a vector
    Note: Returns dimension as string for consistency with mathematical operations
    Note: Time complexity: O(1), Space complexity: O(1)
    
    Return vector.dimension.to_string()

Process called "GetVectorElement" that takes vector as Vector, index as Integer returns String:
    Note: Get element at specified index in vector
    Note: Zero-based indexing with bounds checking
    Note: Time complexity: O(1), Space complexity: O(1)
    
    If index is less than 0 or index is greater than or equal to vector.dimension:
        Throw Errors.InvalidArgument with "Vector index out of bounds"
    
    Return vector.components.get(index)