Note:
math/computational/stability.runa
Numerical Stability Analysis

This module provides comprehensive numerical stability analysis including
condition number analysis, perturbation theory, backward error analysis,
forward error analysis, algorithmic stability assessment, and numerical
method stability classification for reliable computational mathematics.
:End Note

Import module "dev/debug/errors/core" as Errors
Import module "math/engine/linalg/core" as LinAlg
Import module "math/engine/linalg/decomposition" as Decomp
Import module "math/core/constants" as Constants
Import module "math/core/operations" as MathOps
Import module "math/engine/numerical/differentiation" as NumDiff

Note: =====================================================================
Note: STABILITY ANALYSIS DATA STRUCTURES
Note: =====================================================================

Type called "ConditionNumber":
    condition_id as String
    matrix_operator as String
    norm_type as String
    condition_value as Float
    interpretation as String
    stability_classification as String
    sensitivity_analysis as Dictionary[String, Float]

Type called "PerturbationAnalysis":
    analysis_id as String
    original_problem as String
    perturbed_problem as String
    perturbation_magnitude as Float
    solution_change as Float
    amplification_factor as Float
    linearized_analysis as Boolean

Type called "BackwardError":
    error_id as String
    computed_solution as String
    exact_problem as String
    backward_perturbation as Dictionary[String, Float]
    stability_radius as Float
    error_magnification as Float

Type called "ForwardError":
    error_id as String
    input_perturbation as Dictionary[String, Float]
    output_error as Dictionary[String, Float]
    error_propagation as String
    amplification_bounds as Dictionary[String, Float]

Type called "AlgorithmStability":
    algorithm_id as String
    stability_type as String
    stability_constant as Float
    growth_factor as Float
    stability_verification as Boolean
    numerical_experiments as Dictionary[String, List[Float]]

Type called "StabilityClassification":
    classification_type as String
    stability_categories as List[String]
    mathematical_conditions as Dictionary[String, String]
    practical_implications as Dictionary[String, String]

Note: =====================================================================
Note: NUMERICAL ERROR DATA STRUCTURES
Note: =====================================================================

Type called "RoundOffError":
    error_source as String
    machine_precision as Float
    error_accumulation as Dictionary[String, Float]
    propagation_analysis as Dictionary[String, String]
    mitigation_strategies as List[String]

Type called "TruncationError":
    truncation_type as String
    approximation_order as Integer
    error_estimate as String
    convergence_rate as String
    refinement_strategy as String

Type called "DiscretizationError":
    discretization_scheme as String
    mesh_spacing as Float
    order_of_accuracy as Integer
    error_bounds as Dictionary[String, Float]
    grid_refinement_analysis as Dictionary[String, String]

Type called "IterativeError":
    iteration_method as String
    convergence_criterion as Float
    residual_analysis as Dictionary[String, Float]
    error_reduction_rate as Float
    stopping_criterion as Dictionary[String, String]

Note: =====================================================================
Note: CONDITION NUMBER ANALYSIS OPERATIONS
Note: =====================================================================

Process called "compute_matrix_condition_number" that takes matrix as List[List[Float]], norm_type as String returns ConditionNumber:
    Note: Compute condition number κ(A) is equal to ||A|| × ||A⁻¹|| for matrix stability analysis
    Note: Measures sensitivity of linear system solution to input perturbations
    
    If matrix.length is equal to 0:
        Throw Errors.InvalidArgument with "Matrix cannot be empty"
    
    If matrix.get(0).length is equal to 0:
        Throw Errors.InvalidArgument with "Matrix rows cannot be empty"
    
    Let rows be matrix.length
    Let cols be matrix.get(0).length
    
    If rows does not equal cols:
        Throw Errors.InvalidArgument with "Matrix must be square for condition number computation"
    
    Note: Compute matrix norm ||A||
    Let matrix_norm be LinAlg.compute_matrix_norm(matrix, norm_type)
    
    Note: Compute matrix inverse A⁻¹
    Let inverse_matrix be LinAlg.matrix_inverse(matrix)
    
    Note: Compute inverse norm ||A⁻¹||
    Let inverse_norm be LinAlg.compute_matrix_norm(inverse_matrix, norm_type)
    
    Note: Condition number κ(A) is equal to ||A|| × ||A⁻¹||
    Let condition_value be MathOps.multiply(matrix_norm.toString(), inverse_norm.toString()).result_value
    
    Note: Determine stability classification
    Let stability_class be ""
    Let machine_eps be Constants.get_machine_epsilon("float64").value
    
    If MathOps.is_less_than_or_equal(condition_value, "10.0").result_value is equal to "true":
        Set stability_class to "well-conditioned"
    Otherwise:
        If MathOps.is_less_than_or_equal(condition_value, MathOps.divide("1.0", machine_eps).result_value).result_value is equal to "true":
            Set stability_class to "ill-conditioned"
        Otherwise:
            Set stability_class to "singular"
    
    Note: Perform sensitivity analysis
    Let sensitivity_analysis be Dictionary[String, Float]
    Set sensitivity_analysis["relative_error_amplification"] to condition_value
    Set sensitivity_analysis["digits_of_accuracy"] to MathOps.log10(condition_value).result_value
    Set sensitivity_analysis["worst_case_amplification"] to condition_value
    
    Let interpretation be ""
    If stability_class is equal to "well-conditioned":
        Set interpretation to "Small perturbations in input cause small perturbations in output"
    Otherwise:
        If stability_class is equal to "ill-conditioned":
            Set interpretation to "Small perturbations in input may cause large perturbations in output"
        Otherwise:
            Set interpretation to "Matrix is numerically singular minus results unreliable"
    
    Return ConditionNumber with:
        condition_id: MathOps.generate_uuid().result_value
        matrix_operator: norm_type plus "_norm"
        norm_type: norm_type
        condition_value: condition_value
        interpretation: interpretation
        stability_classification: stability_class
        sensitivity_analysis: sensitivity_analysis

Process called "analyze_condition_number_interpretation" that takes condition_value as Float returns Dictionary[String, String]:
    Note: Analyze condition number interpretation for numerical stability assessment
    Note: κ ≈ 1: well-conditioned, κ >> 1: ill-conditioned, κ ≈ 1/ε: singular
    
    Let interpretation be Dictionary[String, String]
    Let condition_str be condition_value.toString()
    Let machine_eps be Constants.get_machine_epsilon("float64").value
    Let reciprocal_eps be MathOps.divide("1.0", machine_eps).result_value
    
    Note: Classify conditioning level
    If MathOps.is_less_than_or_equal(condition_str, "1.0").result_value is equal to "true":
        Set interpretation["conditioning_level"] to "perfectly_conditioned"
        Set interpretation["stability_assessment"] to "optimal"
        Set interpretation["numerical_behavior"] to "no_amplification"
    Otherwise:
        If MathOps.is_less_than_or_equal(condition_str, "10.0").result_value is equal to "true":
            Set interpretation["conditioning_level"] to "well_conditioned"
            Set interpretation["stability_assessment"] to "excellent"
            Set interpretation["numerical_behavior"] to "minimal_amplification"
        Otherwise:
            If MathOps.is_less_than_or_equal(condition_str, "100.0").result_value is equal to "true":
                Set interpretation["conditioning_level"] to "moderately_conditioned"
                Set interpretation["stability_assessment"] to "good"
                Set interpretation["numerical_behavior"] to "acceptable_amplification"
            Otherwise:
                If MathOps.is_less_than_or_equal(condition_str, "10000.0").result_value is equal to "true":
                    Set interpretation["conditioning_level"] to "poorly_conditioned"
                    Set interpretation["stability_assessment"] to "caution_required"
                    Set interpretation["numerical_behavior"] to "significant_amplification"
                Otherwise:
                    If MathOps.is_less_than_or_equal(condition_str, reciprocal_eps).result_value is equal to "true":
                        Set interpretation["conditioning_level"] to "ill_conditioned"
                        Set interpretation["stability_assessment"] to "unreliable"
                        Set interpretation["numerical_behavior"] to "severe_amplification"
                    Otherwise:
                        Set interpretation["conditioning_level"] to "singular"
                        Set interpretation["stability_assessment"] to "failed"
                        Set interpretation["numerical_behavior"] to "unbounded_amplification"
    
    Note: Estimate digits of accuracy lost
    Let log_condition be MathOps.log10(condition_str).result_value
    Set interpretation["digits_lost"] to MathOps.floor(log_condition).result_value
    
    Note: Provide practical guidance
    If interpretation["conditioning_level"] is equal to "perfectly_conditioned":
        Set interpretation["recommendation"] to "Ideal numerical stability minus proceed with confidence"
    Otherwise:
        If interpretation["conditioning_level"] is equal to "well_conditioned":
            Set interpretation["recommendation"] to "Excellent stability minus standard algorithms suitable"
        Otherwise:
            If interpretation["conditioning_level"] is equal to "moderately_conditioned":
                Set interpretation["recommendation"] to "Good stability minus monitor results for accuracy"
            Otherwise:
                If interpretation["conditioning_level"] is equal to "poorly_conditioned":
                    Set interpretation["recommendation"] to "Poor conditioning minus consider preconditioning or iterative refinement"
                Otherwise:
                    If interpretation["conditioning_level"] is equal to "ill_conditioned":
                        Set interpretation["recommendation"] to "Severely ill-conditioned minus use regularization or alternative methods"
                    Otherwise:
                        Set interpretation["recommendation"] to "Matrix is singular minus problem has no unique solution"
    
    Note: Error bounds and amplification factors
    Set interpretation["relative_error_bound"] to MathOps.multiply(condition_str, machine_eps).result_value
    Set interpretation["amplification_factor"] to condition_str
    Set interpretation["accuracy_limit"] to MathOps.subtract("16", log_condition).result_value
    
    Return interpretation

Process called "compute_function_condition_number" that takes function_expression as String, input_point as Dictionary[String, Float] returns Float:
    Note: Compute condition number for general function evaluation at input point
    Note: Measures relative sensitivity: κ is equal to |x f'(x) / f(x)| for function stability
    
    If function_expression is equal to "":
        Throw Errors.InvalidArgument with "Function expression cannot be empty"
    
    If input_point.size() is equal to 0:
        Throw Errors.InvalidArgument with "Input point cannot be empty"
    
    Note: For single-variable functions, compute κ is equal to |x f'(x) / f(x)|
    If input_point.size() is equal to 1:
        Let variable_name be input_point.keys().get(0)
        Let x_value be input_point.get(variable_name).toString()
        
        Note: Evaluate function at input point
        Let function_value be NumDiff.evaluate_function(function_expression, input_point)
        
        If MathOps.absolute_value(function_value).result_value is equal to "0.0":
            Return 0.0
        
        Note: Compute derivative f'(x)
        Let derivative_value be NumDiff.compute_derivative(function_expression, variable_name, x_value, "central_difference")
        
        Note: Compute condition number κ is equal to |x f'(x) / f(x)|
        Let numerator be MathOps.multiply(x_value, derivative_value.toString()).result_value
        Let sensitivity_ratio be MathOps.divide(numerator, function_value).result_value
        Let condition_number be MathOps.absolute_value(sensitivity_ratio).result_value
        
        Return condition_number.toFloat()
    Otherwise:
        Note: For multi-variable functions, use gradient-based approach
        Let variables be List[String]
        Let point_values be List[String]
        
        Let i be 0
        While i is less than input_point.size():
            Let key be input_point.keys().get(i)
            Append key to variables
            Append input_point.get(key).toString() to point_values
            Set i to i plus 1
        
        Note: Evaluate function at input point
        Let function_value be NumDiff.evaluate_function(function_expression, input_point)
        
        If MathOps.absolute_value(function_value).result_value is equal to "0.0":
            Return 0.0
        
        Note: Compute gradient ∇f
        Let gradient be NumDiff.compute_gradient(function_expression, variables, point_values, "central_difference")
        
        Note: Compute weighted gradient sum Σ(xᵢ multiplied by ∂f/∂xᵢ)
        Let weighted_sum be "0.0"
        Set i to 0
        While i is less than variables.length:
            Let variable be variables.get(i)
            Let x_val be input_point.get(variable).toString()
            Let partial_deriv be gradient.partial_derivatives.get(variable)
            Let term be MathOps.multiply(x_val, partial_deriv).result_value
            Set weighted_sum to MathOps.add(weighted_sum, term).result_value
            Set i to i plus 1
        
        Note: Compute condition number κ is equal to |Σ(xᵢ multiplied by ∂f/∂xᵢ) / f|
        Let sensitivity_ratio be MathOps.divide(weighted_sum, function_value).result_value
        Let condition_number be MathOps.absolute_value(sensitivity_ratio).result_value
        
        Return condition_number.toFloat()

Process called "analyze_eigenvalue_condition" that takes matrix as List[List[Float]] returns Dictionary[String, Float]:
    Note: Analyze eigenvalue condition numbers for spectral stability assessment
    Note: Examines sensitivity of eigenvalues to matrix perturbations
    
    If matrix.length is equal to 0:
        Throw Errors.InvalidArgument with "Matrix cannot be empty"
    
    If matrix.get(0).length is equal to 0:
        Throw Errors.InvalidArgument with "Matrix rows cannot be empty"
    
    Let rows be matrix.length
    Let cols be matrix.get(0).length
    
    If rows does not equal cols:
        Throw Errors.InvalidArgument with "Matrix must be square for eigenvalue analysis"
    
    Note: Create Matrix structure for decomposition
    Let matrix_struct be LinAlg.create_matrix(matrix, "float64")
    
    Note: Compute eigenvalue decomposition
    Let eigen_decomp be Decomp.eigenvalue_decomposition(matrix_struct, "qr_algorithm")
    
    Note: Extract eigenvalues and eigenvectors
    Let eigenvalues be eigen_decomp.eigenvalues
    Let eigenvectors be eigen_decomp.eigenvectors
    
    Let condition_analysis be Dictionary[String, Float]
    
    Note: Compute condition number for each eigenvalue
    Let max_condition be "0.0"
    Let min_condition be "1e100"
    Let total_condition be "0.0"
    
    Let i be 0
    While i is less than eigenvalues.length:
        Let eigenvalue be eigenvalues.get(i)
        
        Note: Get corresponding eigenvector
        Let eigenvector be eigenvectors.get(i)
        
        Note: For symmetric matrices, condition number is 1
        If LinAlg.is_symmetric(matrix_struct):
            Set condition_analysis["eigenvalue_" plus i.toString() plus "_condition"] to 1.0
        Otherwise:
            Note: For general matrices, use reciprocal of |v^T multiplied by u| where v is left eigenvector
            Note: Simplified approach: use separation from other eigenvalues
            Let min_separation be "1e100"
            
            Let j be 0
            While j is less than eigenvalues.length:
                If i does not equal j:
                    Let other_eigenvalue be eigenvalues.get(j)
                    Let separation be MathOps.absolute_value(
                        MathOps.subtract(eigenvalue, other_eigenvalue).result_value
                    ).result_value
                    
                    If MathOps.is_less_than(separation, min_separation).result_value is equal to "true":
                        Set min_separation to separation
                Set j to j plus 1
            
            Note: Condition number approximation: reciprocal of minimum separation
            Let condition_estimate be MathOps.divide("1.0", min_separation).result_value
            Set condition_analysis["eigenvalue_" plus i.toString() plus "_condition"] to condition_estimate.toFloat()
            
            Note: Update statistics
            If MathOps.is_greater_than(condition_estimate, max_condition).result_value is equal to "true":
                Set max_condition to condition_estimate
            
            If MathOps.is_less_than(condition_estimate, min_condition).result_value is equal to "true":
                Set min_condition to condition_estimate
            
            Set total_condition to MathOps.add(total_condition, condition_estimate).result_value
        
        Set i to i plus 1
    
    Note: Overall condition statistics
    Set condition_analysis["max_eigenvalue_condition"] to max_condition.toFloat()
    Set condition_analysis["min_eigenvalue_condition"] to min_condition.toFloat()
    Set condition_analysis["average_eigenvalue_condition"] to MathOps.divide(
        total_condition, eigenvalues.length.toString()
    ).result_value.toFloat()
    
    Note: Spectral properties affecting conditioning
    Let spectral_radius be LinAlg.compute_spectral_radius(matrix_struct)
    Set condition_analysis["spectral_radius"] to spectral_radius.toFloat()
    
    Note: Eigenvalue spread affects conditioning
    Let eigenvalue_magnitudes be List[String]
    Set i to 0
    While i is less than eigenvalues.length:
        Let magnitude be MathOps.absolute_value(eigenvalues.get(i)).result_value
        Append magnitude to eigenvalue_magnitudes
        Set i to i plus 1
    
    Let max_eigenvalue be MathOps.maximum(eigenvalue_magnitudes).result_value
    Let min_eigenvalue be MathOps.minimum(eigenvalue_magnitudes).result_value
    
    If min_eigenvalue does not equal "0.0":
        Let eigenvalue_condition_number be MathOps.divide(max_eigenvalue, min_eigenvalue).result_value
        Set condition_analysis["eigenvalue_condition_number"] to eigenvalue_condition_number.toFloat()
    Otherwise:
        Set condition_analysis["eigenvalue_condition_number"] to Float.POSITIVE_INFINITY
    
    Note: Clustering analysis for ill-conditioning detection
    Let clustering_threshold be Constants.get_machine_epsilon("float64").value
    Let clustered_count be 0
    
    Set i to 0
    While i is less than eigenvalues.length:
        Let j be i plus 1
        While j is less than eigenvalues.length:
            Let difference be MathOps.absolute_value(
                MathOps.subtract(eigenvalues.get(i), eigenvalues.get(j)).result_value
            ).result_value
            
            If MathOps.is_less_than(difference, clustering_threshold).result_value is equal to "true":
                Set clustered_count to clustered_count plus 1
            
            Set j to j plus 1
        Set i to i plus 1
    
    Set condition_analysis["clustered_eigenvalue_pairs"] to clustered_count.toFloat()
    
    Return condition_analysis

Note: =====================================================================
Note: PERTURBATION THEORY OPERATIONS
Note: =====================================================================

Process called "perform_perturbation_analysis" that takes original_problem as Dictionary[String, String], perturbation_type as String, magnitude as Float returns PerturbationAnalysis:
    Note: Perform comprehensive perturbation analysis for stability assessment
    Note: Examines solution sensitivity to problem parameter variations
    
    If original_problem.size() is equal to 0:
        Throw Errors.InvalidArgument with "Original problem specification cannot be empty"
    
    If perturbation_type is equal to "":
        Throw Errors.InvalidArgument with "Perturbation type must be specified"
    
    If magnitude is less than or equal to 0.0:
        Throw Errors.InvalidArgument with "Perturbation magnitude must be positive"
    
    Let analysis_id be MathOps.generate_uuid().result_value
    Let magnitude_str be magnitude.toString()
    
    Note: Extract problem parameters
    Let problem_type be original_problem.get("type")
    Let problem_size be original_problem.get("size")
    Let original_solution be original_problem.get("solution")
    
    Note: Generate perturbed problem based on perturbation type
    Let perturbed_problem be Dictionary[String, String]
    Set perturbed_problem["type"] to problem_type
    Set perturbed_problem["size"] to problem_size
    
    Let solution_change be "0.0"
    Let linearized_analysis be false
    
    If perturbation_type is equal to "additive":
        Note: Add perturbation: A' is equal to A plus εE where ||E|| is equal to 1
        Let perturbation_matrix be original_problem.get("perturbation_matrix")
        If perturbation_matrix is equal to "":
            Set perturbation_matrix to "identity"
        
        Note: Scale perturbation by magnitude
        Set perturbed_problem["matrix_perturbation"] to MathOps.multiply(magnitude_str, "1.0").result_value
        Set perturbed_problem["perturbation_pattern"] to "additive_" plus perturbation_matrix
        
        Note: Estimate solution change using condition number
        Let condition_number be original_problem.get("condition_number")
        If condition_number does not equal "":
            Set solution_change to MathOps.multiply(condition_number, magnitude_str).result_value
        Otherwise:
            Set solution_change to magnitude_str
        
        Set linearized_analysis to true
    
    Otherwise:
        If perturbation_type is equal to "multiplicative":
            Note: Multiply perturbation: A' is equal to A(I plus εE)
            Set perturbed_problem["matrix_perturbation"] to MathOps.add("1.0", magnitude_str).result_value
            Set perturbed_problem["perturbation_pattern"] to "multiplicative"
            
            Note: For multiplicative perturbations, solution change is more complex
            Let matrix_norm be original_problem.get("matrix_norm")
            If matrix_norm does not equal "":
                Set solution_change to MathOps.multiply(
                    MathOps.multiply(magnitude_str, matrix_norm).result_value,
                    original_solution
                ).result_value
            Otherwise:
                Set solution_change to MathOps.multiply(magnitude_str, original_solution).result_value
        
        Otherwise:
            If perturbation_type is equal to "structured":
                Note: Structured perturbation preserving matrix structure
                Let structure_type be original_problem.get("structure_type")
                Set perturbed_problem["perturbation_pattern"] to "structured_" plus structure_type
                Set perturbed_problem["structure_preservation"] to "true"
                
                Note: Structured perturbations often have smaller amplification
                Let structure_factor be "0.5"
                Set solution_change to MathOps.multiply(
                    MathOps.multiply(structure_factor, magnitude_str).result_value,
                    original_solution
                ).result_value
                
                Set linearized_analysis to true
            
            Otherwise:
                If perturbation_type is equal to "random":
                    Note: Random perturbation with specified magnitude
                    Set perturbed_problem["perturbation_pattern"] to "random_uniform"
                    Set perturbed_problem["random_seed"] to "12345"
                    
                    Note: Random perturbations use statistical bounds
                    Let statistical_factor be MathOps.square_root("2.0").result_value
                    Set solution_change to MathOps.multiply(
                        MathOps.multiply(statistical_factor, magnitude_str).result_value,
                        original_solution
                    ).result_value
                
                Otherwise:
                    Throw Errors.InvalidArgument with "Unknown perturbation type: " plus perturbation_type
    
    Note: Compute amplification factor
    Let amplification_factor be "1.0"
    If original_solution does not equal "0.0" And original_solution does not equal "":
        Set amplification_factor to MathOps.divide(solution_change, original_solution).result_value
    
    Note: Set perturbed solution
    Let perturbed_solution be MathOps.add(original_solution, solution_change).result_value
    Set perturbed_problem["solution"] to perturbed_solution
    
    Return PerturbationAnalysis with:
        analysis_id: analysis_id
        original_problem: original_problem.toString()
        perturbed_problem: perturbed_problem.toString()
        perturbation_magnitude: magnitude
        solution_change: solution_change.toFloat()
        amplification_factor: amplification_factor.toFloat()
        linearized_analysis: linearized_analysis

Process called "analyze_first_order_perturbation" that takes problem_jacobian as List[List[Float]], perturbation_vector as List[Float] returns Dictionary[String, Float]:
    Note: Analyze first-order perturbation effects using linearization theory
    Note: Δy ≈ J⁻¹ Δx for linear perturbation approximation
    
    If problem_jacobian.length is equal to 0:
        Throw Errors.InvalidArgument with "Jacobian matrix cannot be empty"
    
    If perturbation_vector.length is equal to 0:
        Throw Errors.InvalidArgument with "Perturbation vector cannot be empty"
    
    Let rows be problem_jacobian.length
    Let cols be problem_jacobian.get(0).length
    
    If perturbation_vector.length does not equal cols:
        Throw Errors.InvalidArgument with "Perturbation vector dimension must match Jacobian columns"
    
    Let analysis be Dictionary[String, Float]
    
    Note: Compute Jacobian inverse J⁻¹
    Let jacobian_inverse be LinAlg.matrix_inverse(problem_jacobian)
    
    Note: Compute first-order solution perturbation Δy is equal to J⁻¹ Δx
    Let solution_perturbation be LinAlg.matrix_vector_multiply(jacobian_inverse, perturbation_vector)
    
    Note: Compute perturbation magnitudes
    Let input_perturbation_norm be LinAlg.vector_norm(perturbation_vector, "euclidean")
    Let output_perturbation_norm be LinAlg.vector_norm(solution_perturbation, "euclidean")
    
    Set analysis["input_perturbation_magnitude"] to input_perturbation_norm.toFloat()
    Set analysis["output_perturbation_magnitude"] to output_perturbation_norm.toFloat()
    
    Note: Compute amplification factor
    Let amplification_factor be "1.0"
    If input_perturbation_norm does not equal "0.0":
        Set amplification_factor to MathOps.divide(
            output_perturbation_norm, input_perturbation_norm
        ).result_value
    
    Set analysis["linear_amplification_factor"] to amplification_factor.toFloat()
    
    Note: Compute condition number of Jacobian
    Let jacobian_condition be LinAlg.compute_matrix_norm(problem_jacobian, "frobenius")
    Let inverse_condition be LinAlg.compute_matrix_norm(jacobian_inverse, "frobenius")
    Let condition_number be MathOps.multiply(
        jacobian_condition.toString(), inverse_condition.toString()
    ).result_value
    
    Set analysis["jacobian_condition_number"] to condition_number.toFloat()
    
    Note: Analyze directional sensitivity
    Let max_sensitivity be "0.0"
    Let min_sensitivity be "1e100"
    
    Let i be 0
    While i is less than solution_perturbation.length:
        Let component_sensitivity be MathOps.absolute_value(
            solution_perturbation.get(i).toString()
        ).result_value
        
        If MathOps.is_greater_than(component_sensitivity, max_sensitivity).result_value is equal to "true":
            Set max_sensitivity to component_sensitivity
        
        If MathOps.is_less_than(component_sensitivity, min_sensitivity).result_value is equal to "true":
            Set min_sensitivity to component_sensitivity
        
        Set i to i plus 1
    
    Set analysis["max_component_sensitivity"] to max_sensitivity.toFloat()
    Set analysis["min_component_sensitivity"] to min_sensitivity.toFloat()
    Set analysis["sensitivity_ratio"] to MathOps.divide(
        max_sensitivity, min_sensitivity
    ).result_value.toFloat()
    
    Return analysis

Process called "compute_perturbation_bounds" that takes system_parameters as Dictionary[String, Float], perturbation_constraints as Dictionary[String, Float] returns Dictionary[String, Float]:
    Note: Compute rigorous bounds on solution perturbation for stability guarantees
    Note: Provides mathematical bounds on output variation given input uncertainty
    
    If system_parameters.size() is equal to 0:
        Throw Errors.InvalidArgument with "System parameters cannot be empty"
    
    If perturbation_constraints.size() is equal to 0:
        Throw Errors.InvalidArgument with "Perturbation constraints cannot be empty"
    
    Let bounds be Dictionary[String, Float]
    
    Note: Extract system properties
    Let condition_number be system_parameters.get("condition_number").toString()
    Let matrix_norm be system_parameters.get("matrix_norm").toString()
    Let system_size be system_parameters.get("system_size").toString()
    
    Note: Extract perturbation constraints
    Let max_input_perturbation be perturbation_constraints.get("max_input_perturbation").toString()
    Let perturbation_type be perturbation_constraints.get("perturbation_type").toString()
    
    Note: Compute basic linear bound: ||Δy|| ≤ κ(A) ||Δx||
    Let linear_bound be MathOps.multiply(condition_number, max_input_perturbation).result_value
    Set bounds["linear_perturbation_bound"] to linear_bound.toFloat()
    
    Note: Compute relative error bound: ||Δy||/||y|| ≤ κ(A) ||Δx||/||x||
    Let relative_input_bound be perturbation_constraints.get("relative_input_bound").toString()
    Let relative_bound be MathOps.multiply(condition_number, relative_input_bound).result_value
    Set bounds["relative_error_bound"] to relative_bound.toFloat()
    
    Note: Compute componentwise bounds
    If perturbation_type is equal to "componentwise":
        Let componentwise_factor be MathOps.square_root(system_size).result_value
        Let componentwise_bound be MathOps.multiply(
            MathOps.multiply(condition_number, componentwise_factor).result_value,
            max_input_perturbation
        ).result_value
        Set bounds["componentwise_bound"] to componentwise_bound.toFloat()
    
    Note: Compute structured perturbation bounds
    If perturbation_type is equal to "structured":
        Let structure_factor be perturbation_constraints.get("structure_factor").toString()
        Let structured_bound be MathOps.multiply(
            MathOps.multiply(condition_number, structure_factor).result_value,
            max_input_perturbation
        ).result_value
        Set bounds["structured_perturbation_bound"] to structured_bound.toFloat()
    
    Note: Compute probabilistic bounds for random perturbations
    If perturbation_type is equal to "random":
        Let confidence_level be perturbation_constraints.get("confidence_level").toString()
        Let statistical_factor be "1.96"  Note: 95% confidence for normal distribution
        
        If confidence_level is equal to "0.99":
            Set statistical_factor to "2.576"
        Otherwise:
            If confidence_level is equal to "0.999":
                Set statistical_factor to "3.291"
        
        Let probabilistic_bound be MathOps.multiply(
            MathOps.multiply(
                MathOps.multiply(condition_number, statistical_factor).result_value,
                MathOps.square_root(system_size).result_value
            ).result_value,
            max_input_perturbation
        ).result_value
        Set bounds["probabilistic_bound"] to probabilistic_bound.toFloat()
        Set bounds["confidence_level"] to confidence_level.toFloat()
    
    Note: Compute backward error bounds
    Let machine_epsilon be Constants.get_machine_epsilon("float64").value
    Let backward_bound be MathOps.multiply(
        MathOps.multiply("2.0", system_size).result_value,
        machine_epsilon
    ).result_value
    Set bounds["backward_error_bound"] to backward_bound.toFloat()
    
    Note: Compute total error bound combining forward and backward errors
    Let total_bound be MathOps.add(
        linear_bound,
        MathOps.multiply(condition_number, backward_bound).result_value
    ).result_value
    Set bounds["total_error_bound"] to total_bound.toFloat()
    
    Note: Determine stability classification based on bounds
    Let stability_threshold be "1e-12"
    If MathOps.is_less_than(total_bound, stability_threshold).result_value is equal to "true":
        Set bounds["stability_classification"] to 1.0  Note: 1 is equal to stable
    Otherwise:
        If MathOps.is_less_than(total_bound, "1e-6").result_value is equal to "true":
            Set bounds["stability_classification"] to 0.5  Note: 0.5 is equal to marginally stable
        Otherwise:
            Set bounds["stability_classification"] to 0.0  Note: 0 is equal to unstable
    
    Return bounds

Process called "analyze_structured_perturbations" that takes structure_pattern as Dictionary[String, String], perturbation_data as Dictionary[String, Float] returns Dictionary[String, String]:
    Note: Analyze structured perturbations preserving problem structure
    Note: Considers perturbations maintaining symmetry, sparsity, or other structure
    
    If structure_pattern.size() is equal to 0:
        Throw Errors.InvalidArgument with "Structure pattern cannot be empty"
    
    If perturbation_data.size() is equal to 0:
        Throw Errors.InvalidArgument with "Perturbation data cannot be empty"
    
    Let analysis be Dictionary[String, String]
    
    Let structure_type be structure_pattern.get("type")
    Let preservation_method be structure_pattern.get("preservation_method")
    Let constraint_level be structure_pattern.get("constraint_level")
    
    Set analysis["structure_type"] to structure_type
    Set analysis["preservation_method"] to preservation_method
    
    Note: Analyze different structure types
    If structure_type is equal to "symmetric":
        Note: Symmetric perturbations: δA is equal to δA^T
        Let symmetry_constraint be "perturbation_symmetric"
        Set analysis["perturbation_constraint"] to symmetry_constraint
        
        Note: Compute structure-preserving amplification factor
        Let base_amplification be perturbation_data.get("base_amplification").toString()
        Let symmetry_factor be "0.707"  Note: √2/2 for symmetric preservation
        Let structured_amplification be MathOps.multiply(base_amplification, symmetry_factor).result_value
        Set analysis["structured_amplification"] to structured_amplification
        
        Set analysis["stability_improvement"] to "moderate"
        Set analysis["structure_benefit"] to "reduces_amplification_by_symmetric_constraint"
    
    Otherwise:
        If structure_type is equal to "sparse":
            Note: Sparse perturbations: maintain sparsity pattern
            Let sparsity_ratio be perturbation_data.get("sparsity_ratio").toString()
            Set analysis["perturbation_constraint"] to "maintain_sparsity_pattern"
            
            Note: Sparse perturbations often have better conditioning
            Let base_amplification be perturbation_data.get("base_amplification").toString()
            Let sparsity_benefit be MathOps.subtract("1.0", sparsity_ratio).result_value
            Let structured_amplification be MathOps.multiply(
                base_amplification, 
                MathOps.add("0.5", sparsity_benefit).result_value
            ).result_value
            Set analysis["structured_amplification"] to structured_amplification
            
            Set analysis["stability_improvement"] to "significant"
            Set analysis["structure_benefit"] to "sparsity_reduces_perturbation_impact"
        
        Otherwise:
            If structure_type is equal to "toeplitz":
                Note: Toeplitz perturbations: maintain constant diagonals
                Set analysis["perturbation_constraint"] to "constant_diagonal_structure"
                
                Let base_amplification be perturbation_data.get("base_amplification").toString()
                Let toeplitz_factor be "0.8"  Note: Toeplitz structure provides some stability
                Let structured_amplification be MathOps.multiply(base_amplification, toeplitz_factor).result_value
                Set analysis["structured_amplification"] to structured_amplification
                
                Set analysis["stability_improvement"] to "modest"
                Set analysis["structure_benefit"] to "translation_invariance_improves_conditioning"
            
            Otherwise:
                If structure_type is equal to "band":
                    Note: Banded perturbations: maintain bandwidth
                    Let bandwidth be perturbation_data.get("bandwidth").toString()
                    Set analysis["perturbation_constraint"] to "maintain_bandwidth_" plus bandwidth
                    
                    Let base_amplification be perturbation_data.get("base_amplification").toString()
                    Let matrix_size be perturbation_data.get("matrix_size").toString()
                    Let bandwidth_ratio be MathOps.divide(bandwidth, matrix_size).result_value
                    Let band_factor be MathOps.add("0.3", bandwidth_ratio).result_value
                    Let structured_amplification be MathOps.multiply(base_amplification, band_factor).result_value
                    Set analysis["structured_amplification"] to structured_amplification
                    
                    Set analysis["stability_improvement"] to "good"
                    Set analysis["structure_benefit"] to "limited_bandwidth_reduces_coupling"
                
                Otherwise:
                    If structure_type is equal to "circulant":
                        Note: Circulant perturbations: maintain circulant structure
                        Set analysis["perturbation_constraint"] to "circulant_structure_preservation"
                        
                        Let base_amplification be perturbation_data.get("base_amplification").toString()
                        Let circulant_factor be "0.6"  Note: Circulant matrices have good properties
                        Let structured_amplification be MathOps.multiply(base_amplification, circulant_factor).result_value
                        Set analysis["structured_amplification"] to structured_amplification
                        
                        Set analysis["stability_improvement"] to "excellent"
                        Set analysis["structure_benefit"] to "circulant_diagonalization_via_fft"
                    
                    Otherwise:
                        Set analysis["perturbation_constraint"] to "general_structure_" plus structure_type
                        Set analysis["structured_amplification"] to perturbation_data.get("base_amplification").toString()
                        Set analysis["stability_improvement"] to "unknown"
                        Set analysis["structure_benefit"] to "structure_specific_analysis_required"
    
    Note: Compute preservation quality metrics
    Let preservation_quality be preservation_method
    If preservation_method is equal to "exact":
        Set analysis["preservation_quality"] to "perfect_structure_maintenance"
        Set analysis["accuracy_impact"] to "none"
    Otherwise:
        If preservation_method is equal to "approximate":
            Set analysis["preservation_quality"] to "approximate_structure_maintenance"
            Set analysis["accuracy_impact"] to "small_structure_deviation"
        Otherwise:
            Set analysis["preservation_quality"] to "partial_structure_maintenance"
            Set analysis["accuracy_impact"] to "moderate_structure_deviation"
    
    Note: Provide recommendations based on structure analysis
    Let structured_amp_val be analysis["structured_amplification"]
    If MathOps.is_less_than(structured_amp_val, "0.5").result_value is equal to "true":
        Set analysis["recommendation"] to "excellent_structured_stability_exploit_structure"
    Otherwise:
        If MathOps.is_less_than(structured_amp_val, "1.0").result_value is equal to "true":
            Set analysis["recommendation"] to "good_structured_stability_maintain_structure"
        Otherwise:
            Set analysis["recommendation"] to "poor_structured_stability_consider_alternative_structure"
    
    Note: Constraint satisfaction analysis
    Set analysis["constraint_satisfaction"] to constraint_level
    Set analysis["perturbation_feasibility"] to "structure_constrained"
    Set analysis["optimization_complexity"] to "increased_due_to_structural_constraints"
    
    Return analysis

Note: =====================================================================
Note: BACKWARD ERROR ANALYSIS OPERATIONS
Note: =====================================================================

Process called "compute_backward_error" that takes computed_solution as List[Float], original_problem as Dictionary[String, String] returns BackwardError:
    Note: Compute backward error measuring problem perturbation for exact solution
    Note: Finds smallest perturbation making computed solution exact for perturbed problem
    
    If computed_solution.length is equal to 0:
        Throw Errors.InvalidArgument with "Computed solution cannot be empty"
    
    If original_problem.size() is equal to 0:
        Throw Errors.InvalidArgument with "Original problem cannot be empty"
    
    Let error_id be MathOps.generate_uuid().result_value
    Let problem_type be original_problem.get("type")
    
    Note: Extract problem components
    Let matrix_data be original_problem.get("matrix")
    Let rhs_data be original_problem.get("rhs")
    Let exact_solution be original_problem.get("exact_solution")
    
    Note: Parse matrix and vectors from string representation
    Let system_matrix be LinAlg.parse_matrix_from_string(matrix_data)
    Let rhs_vector be LinAlg.parse_vector_from_string(rhs_data)
    
    Note: Compute residual r is equal to b minus Ax̃
    Let matrix_times_solution be LinAlg.matrix_vector_multiply(system_matrix, computed_solution)
    Let residual be LinAlg.vector_subtract(rhs_vector, matrix_times_solution)
    
    Note: Compute backward perturbation δA, δb such that (A plus δA)x̃ is equal to b plus δb
    Let backward_perturbation be Dictionary[String, Float]
    
    Note: Minimal norm backward error uses: δA is equal to -r x̃^T / ||x̃||^2, δb is equal to 0
    Let solution_norm_squared be LinAlg.vector_dot_product(computed_solution, computed_solution)
    
    If solution_norm_squared is equal to "0.0":
        Throw Errors.InvalidArgument with "Computed solution cannot be zero vector"
    
    Note: Compute matrix perturbation δA is equal to -r x̃^T / ||x̃||^2
    Let matrix_perturbation_entries be List[List[Float]]
    
    Let i be 0
    While i is less than residual.length:
        Let row be List[Float]
        Let j be 0
        While j is less than computed_solution.length:
            Let perturbation_entry be MathOps.divide(
                MathOps.multiply(
                    MathOps.negate(residual.get(i).toString()).result_value,
                    computed_solution.get(j).toString()
                ).result_value,
                solution_norm_squared
            ).result_value
            Append perturbation_entry.toFloat() to row
            Set j to j plus 1
        Append row to matrix_perturbation_entries
        Set i to i plus 1
    
    Note: Compute norms of perturbations
    Let matrix_perturbation_norm be LinAlg.compute_matrix_norm(matrix_perturbation_entries, "frobenius")
    Let residual_norm be LinAlg.vector_norm(residual, "euclidean")
    
    Set backward_perturbation["matrix_perturbation_norm"] to matrix_perturbation_norm.toFloat()
    Set backward_perturbation["vector_perturbation_norm"] to "0.0".toFloat()
    Set backward_perturbation["total_perturbation_norm"] to matrix_perturbation_norm.toFloat()
    
    Note: Compute stability radius minus largest perturbation preserving solvability
    Let original_matrix_norm be LinAlg.compute_matrix_norm(system_matrix, "frobenius")
    Let relative_backward_error be MathOps.divide(
        matrix_perturbation_norm.toString(),
        original_matrix_norm.toString()
    ).result_value
    
    Let stability_radius be MathOps.divide(
        "1.0",
        LinAlg.compute_matrix_norm(LinAlg.matrix_inverse(system_matrix), "frobenius").toString()
    ).result_value
    
    Note: Compute error magnification factor
    Let solution_norm be LinAlg.vector_norm(computed_solution, "euclidean")
    Let error_magnification be MathOps.divide(
        matrix_perturbation_norm.toString(),
        solution_norm
    ).result_value
    
    Return BackwardError with:
        error_id: error_id
        computed_solution: computed_solution.toString()
        exact_problem: original_problem.toString()
        backward_perturbation: backward_perturbation
        stability_radius: stability_radius.toFloat()
        error_magnification: error_magnification.toFloat()

Process called "analyze_backward_stability" that takes algorithm_description as Dictionary[String, String], test_problems as List[Dictionary[String, String]] returns Dictionary[String, Boolean]:
    Note: Analyze backward stability of numerical algorithm across test problems
    Note: Algorithm backward stable if backward error comparable to machine precision
    
    If algorithm_description.size() is equal to 0:
        Throw Errors.InvalidArgument with "Algorithm description cannot be empty"
    
    If test_problems.length is equal to 0:
        Throw Errors.InvalidArgument with "Test problems cannot be empty"
    
    Let stability_results be Dictionary[String, Boolean]
    Let machine_epsilon be Constants.get_machine_epsilon("float64").value
    Let epsilon_threshold be MathOps.multiply(machine_epsilon, "1000.0").result_value
    
    Let algorithm_name be algorithm_description.get("name")
    Let algorithm_type be algorithm_description.get("type")
    
    Set stability_results["algorithm_backward_stable"] to true
    Set stability_results["all_tests_passed"] to true
    
    Note: Test algorithm on each problem
    Let i be 0
    While i is less than test_problems.length:
        Let test_problem be test_problems.get(i)
        Let problem_id be test_problem.get("id")
        
        Note: Run algorithm on test problem
        Let computed_solution be algorithm_description.get("computed_solution_" plus i.toString())
        
        If computed_solution does not equal "":
            Note: Compute backward error for this test
            Let solution_vector be LinAlg.parse_vector_from_string(computed_solution)
            Let backward_error be compute_backward_error(solution_vector, test_problem)
            
            Note: Check if backward error is within machine precision bounds
            Let backward_error_norm be backward_error.backward_perturbation.get("total_perturbation_norm").toString()
            Let is_stable_test be MathOps.is_less_than_or_equal(
                backward_error_norm, epsilon_threshold
            ).result_value is equal to "true"
            
            Set stability_results["test_" plus i.toString() plus "_backward_stable"] to is_stable_test
            
            If Not is_stable_test:
                Set stability_results["algorithm_backward_stable"] to false
                Set stability_results["all_tests_passed"] to false
            
            Note: Analyze specific stability characteristics
            Let relative_error be MathOps.divide(
                backward_error_norm,
                test_problem.get("problem_scale")
            ).result_value
            
            Let is_relative_stable be MathOps.is_less_than_or_equal(
                relative_error, MathOps.multiply(machine_epsilon, "10.0").result_value
            ).result_value is equal to "true"
            
            Set stability_results["test_" plus i.toString() plus "_relatively_stable"] to is_relative_stable
        
        Set i to i plus 1
    
    Note: Compute overall stability metrics
    Let stable_test_count be 0
    Set i to 0
    While i is less than test_problems.length:
        If stability_results.get("test_" plus i.toString() plus "_backward_stable"):
            Set stable_test_count to stable_test_count plus 1
        Set i to i plus 1
    
    Let stability_ratio be stable_test_count.toFloat() / test_problems.length.toFloat()
    Set stability_results["stability_success_ratio_above_90_percent"] to stability_ratio is greater than or equal to 0.9
    Set stability_results["stability_success_ratio_above_95_percent"] to stability_ratio is greater than or equal to 0.95
    Set stability_results["perfect_stability"] to stability_ratio is equal to 1.0
    
    Note: Algorithm-specific stability analysis
    If algorithm_type is equal to "direct":
        Set stability_results["direct_method_stability"] to stability_results["algorithm_backward_stable"]
        Set stability_results["expected_machine_precision_behavior"] to true
    Otherwise:
        If algorithm_type is equal to "iterative":
            Set stability_results["iterative_method_stability"] to stability_results["algorithm_backward_stable"]
            Set stability_results["convergence_affects_stability"] to true
        Otherwise:
            Set stability_results["general_algorithm_stability"] to stability_results["algorithm_backward_stable"]
    
    Return stability_results

Process called "compute_stability_radius" that takes system_matrix as List[List[Float]], perturbation_structure as String returns Float:
    Note: Compute stability radius for structured matrix perturbations
    Note: Largest perturbation preserving stability properties of system
    
    If system_matrix.length is equal to 0:
        Throw Errors.InvalidArgument with "System matrix cannot be empty"
    
    If system_matrix.get(0).length is equal to 0:
        Throw Errors.InvalidArgument with "System matrix rows cannot be empty"
    
    Let rows be system_matrix.length
    Let cols be system_matrix.get(0).length
    
    If rows does not equal cols:
        Throw Errors.InvalidArgument with "System matrix must be square"
    
    Note: Compute smallest singular value which determines stability radius
    Let matrix_struct be LinAlg.create_matrix(system_matrix, "float64")
    Let svd_result be Decomp.compute_svd(system_matrix)
    
    Let singular_values be svd_result.get("singular_values")
    Let min_singular_value be MathOps.minimum(singular_values).result_value
    
    Note: Handle different perturbation structures
    Let structure_factor be "1.0"
    
    If perturbation_structure is equal to "unstructured":
        Note: For unstructured perturbations, stability radius is equal to σ_min(A)
        Set structure_factor to "1.0"
    
    Otherwise:
        If perturbation_structure is equal to "symmetric":
            Note: Symmetric perturbations have larger stability radius
            Set structure_factor to MathOps.square_root("2.0").result_value
        
        Otherwise:
            If perturbation_structure is equal to "diagonal":
                Note: Diagonal perturbations minus use eigenvalue analysis
                Let eigenvalues be Decomp.eigenvalue_decomposition(matrix_struct, "qr_algorithm").eigenvalues
                Let min_eigenvalue_real be MathOps.minimum(
                    MathOps.map(eigenvalues, "real_part")
                ).result_value
                
                If MathOps.is_greater_than(min_eigenvalue_real, "0.0").result_value is equal to "true":
                    Set structure_factor to MathOps.divide(min_singular_value, min_eigenvalue_real).result_value
                Otherwise:
                    Set structure_factor to "0.0"
            
            Otherwise:
                If perturbation_structure is equal to "sparse":
                    Note: Sparse perturbations depend on sparsity pattern
                    Let sparsity_ratio be LinAlg.compute_sparsity_ratio(matrix_struct)
                    Set structure_factor to MathOps.add("1.0", sparsity_ratio).result_value
                
                Otherwise:
                    If perturbation_structure is equal to "low_rank":
                        Note: Low-rank perturbations have smaller impact
                        Let rank be LinAlg.compute_numerical_rank(matrix_struct)
                        Let full_rank be rows.toString()
                        Let rank_factor be MathOps.divide(rank.toString(), full_rank).result_value
                        Set structure_factor to MathOps.add("1.0", rank_factor).result_value
                    
                    Otherwise:
                        Note: Default to unstructured case
                        Set structure_factor to "1.0"
    
    Note: Compute final stability radius
    Let stability_radius be MathOps.multiply(min_singular_value, structure_factor).result_value
    
    Note: Apply safety factor for numerical reliability
    Let safety_factor be "0.9"
    Let safe_stability_radius be MathOps.multiply(stability_radius, safety_factor).result_value
    
    Return safe_stability_radius.toFloat()

Process called "verify_backward_error_bounds" that takes theoretical_bounds as Dictionary[String, Float], empirical_results as Dictionary[String, Float] returns Dictionary[String, Boolean]:
    Note: Verify theoretical backward error bounds against empirical measurements
    Note: Validates theoretical stability analysis with computational experiments
    
    If theoretical_bounds.size() is equal to 0:
        Throw Errors.InvalidArgument with "Theoretical bounds cannot be empty"
    
    If empirical_results.size() is equal to 0:
        Throw Errors.InvalidArgument with "Empirical results cannot be empty"
    
    Let verification_results be Dictionary[String, Boolean]
    Let tolerance_factor be "2.0"  Note: Allow 2x tolerance for numerical variations
    
    Note: Verify basic backward error bound
    Let theoretical_backward_bound be theoretical_bounds.get("backward_error_bound").toString()
    Let empirical_backward_error be empirical_results.get("measured_backward_error").toString()
    
    Let backward_bound_satisfied be MathOps.is_less_than_or_equal(
        empirical_backward_error,
        MathOps.multiply(theoretical_backward_bound, tolerance_factor).result_value
    ).result_value is equal to "true"
    
    Set verification_results["backward_error_bound_verified"] to backward_bound_satisfied
    
    Note: Verify condition number-based bounds
    Let theoretical_condition_bound be theoretical_bounds.get("condition_number_bound").toString()
    Let empirical_amplification be empirical_results.get("measured_amplification").toString()
    
    Let condition_bound_satisfied be MathOps.is_less_than_or_equal(
        empirical_amplification,
        MathOps.multiply(theoretical_condition_bound, tolerance_factor).result_value
    ).result_value is equal to "true"
    
    Set verification_results["condition_number_bound_verified"] to condition_bound_satisfied
    
    Note: Verify stability radius bounds
    If theoretical_bounds.contains_key("stability_radius") And empirical_results.contains_key("measured_stability_radius"):
        Let theoretical_stability_radius be theoretical_bounds.get("stability_radius").toString()
        Let empirical_stability_radius be empirical_results.get("measured_stability_radius").toString()
        
        Note: Empirical stability radius should be close to theoretical
        Let stability_radius_ratio be MathOps.divide(
            empirical_stability_radius, theoretical_stability_radius
        ).result_value
        
        Let stability_radius_verified be MathOps.is_greater_than(
            stability_radius_ratio, "0.5"
        ).result_value is equal to "true" And MathOps.is_less_than(
            stability_radius_ratio, "2.0"
        ).result_value is equal to "true"
        
        Set verification_results["stability_radius_verified"] to stability_radius_verified
    
    Note: Verify perturbation growth bounds
    If theoretical_bounds.contains_key("perturbation_growth_bound"):
        Let theoretical_growth_bound be theoretical_bounds.get("perturbation_growth_bound").toString()
        Let empirical_growth be empirical_results.get("measured_perturbation_growth").toString()
        
        Let growth_bound_satisfied be MathOps.is_less_than_or_equal(
            empirical_growth,
            MathOps.multiply(theoretical_growth_bound, tolerance_factor).result_value
        ).result_value is equal to "true"
        
        Set verification_results["perturbation_growth_bound_verified"] to growth_bound_satisfied
    
    Note: Verify relative error bounds
    If theoretical_bounds.contains_key("relative_error_bound"):
        Let theoretical_relative_bound be theoretical_bounds.get("relative_error_bound").toString()
        Let empirical_relative_error be empirical_results.get("measured_relative_error").toString()
        
        Let relative_bound_satisfied be MathOps.is_less_than_or_equal(
            empirical_relative_error,
            MathOps.multiply(theoretical_relative_bound, tolerance_factor).result_value
        ).result_value is equal to "true"
        
        Set verification_results["relative_error_bound_verified"] to relative_bound_satisfied
    
    Note: Compute overall verification success
    Let all_bounds_verified be true
    Let verified_count be 0
    Let total_count be 0
    
    If verification_results.contains_key("backward_error_bound_verified"):
        Set total_count to total_count plus 1
        If verification_results.get("backward_error_bound_verified"):
            Set verified_count to verified_count plus 1
        Otherwise:
            Set all_bounds_verified to false
    
    If verification_results.contains_key("condition_number_bound_verified"):
        Set total_count to total_count plus 1
        If verification_results.get("condition_number_bound_verified"):
            Set verified_count to verified_count plus 1
        Otherwise:
            Set all_bounds_verified to false
    
    If verification_results.contains_key("stability_radius_verified"):
        Set total_count to total_count plus 1
        If verification_results.get("stability_radius_verified"):
            Set verified_count to verified_count plus 1
        Otherwise:
            Set all_bounds_verified to false
    
    Set verification_results["all_theoretical_bounds_verified"] to all_bounds_verified
    Set verification_results["partial_verification_successful"] to verified_count is greater than or equal to (total_count / 2)
    Set verification_results["theory_matches_practice"] to verified_count.toFloat() / total_count.toFloat() is greater than or equal to 0.8
    
    Note: Provide diagnostic information
    Set verification_results["bounds_analysis_complete"] to total_count is greater than 0
    Set verification_results["requires_theory_refinement"] to verified_count.toFloat() / total_count.toFloat() is less than 0.6
    
    Return verification_results

Note: =====================================================================
Note: FORWARD ERROR ANALYSIS OPERATIONS
Note: =====================================================================

Process called "analyze_forward_error_propagation" that takes algorithm_steps as List[Dictionary[String, String]], input_errors as Dictionary[String, Float] returns ForwardError:
    Note: Analyze forward error propagation through algorithmic computation steps
    Note: Tracks error amplification from input uncertainty to output error
    
    If algorithm_steps.length is equal to 0:
        Throw Errors.InvalidArgument with "Algorithm steps cannot be empty"
    
    If input_errors.size() is equal to 0:
        Throw Errors.InvalidArgument with "Input errors cannot be empty"
    
    Let error_id be MathOps.generate_uuid().result_value
    Let input_perturbation be input_errors
    Let output_error be Dictionary[String, Float]
    Let error_propagation be "forward_analysis_complete"
    Let amplification_bounds be Dictionary[String, Float]
    
    Note: Initialize error accumulation
    Let current_error be input_errors
    Let max_amplification be "1.0"
    Let total_amplification be "1.0"
    
    Note: Process each algorithmic step
    Let i be 0
    While i is less than algorithm_steps.length:
        Let step be algorithm_steps.get(i)
        Let operation_type be step.get("operation")
        Let step_amplification be "1.0"
        
        If operation_type is equal to "matrix_multiply":
            Note: Error amplification for matrix multiplication: ||δ(AB)|| ≤ ||δA|| ||B|| plus ||A|| ||δB||
            Let matrix_norm_a be step.get("matrix_a_norm")
            Let matrix_norm_b be step.get("matrix_b_norm")
            Let input_error_a be current_error.get("matrix_a_error").toString()
            Let input_error_b be current_error.get("matrix_b_error").toString()
            
            Let term_1 be MathOps.multiply(input_error_a, matrix_norm_b).result_value
            Let term_2 be MathOps.multiply(matrix_norm_a, input_error_b).result_value
            Let output_error_step be MathOps.add(term_1, term_2).result_value
            
            Set step_amplification to MathOps.divide(
                output_error_step, 
                MathOps.add(input_error_a, input_error_b).result_value
            ).result_value
        
        Otherwise:
            If operation_type is equal to "matrix_inverse":
                Note: Error amplification for matrix inversion: ||δ(A⁻¹)|| ≤ κ(A) ||A⁻¹||² ||δA||
                Let condition_number be step.get("condition_number")
                Let inverse_norm be step.get("inverse_norm")
                Let input_matrix_error be current_error.get("matrix_error").toString()
                
                Let amplification_factor be MathOps.multiply(
                    condition_number,
                    MathOps.multiply(inverse_norm, inverse_norm).result_value
                ).result_value
                
                Set step_amplification to amplification_factor
                Let output_error_step be MathOps.multiply(
                    amplification_factor, input_matrix_error
                ).result_value
            
            Otherwise:
                If operation_type is equal to "linear_solve":
                    Note: Error amplification for linear solve: ||δx|| ≤ κ(A) (||δA|| ||x|| plus ||δb||) / ||A||
                    Let condition_number be step.get("condition_number")
                    Let solution_norm be step.get("solution_norm")
                    Let matrix_norm be step.get("matrix_norm")
                    
                    Let matrix_error be current_error.get("matrix_error").toString()
                    Let rhs_error be current_error.get("rhs_error").toString()
                    
                    Let matrix_term be MathOps.multiply(matrix_error, solution_norm).result_value
                    Let rhs_term be rhs_error
                    Let error_sum be MathOps.add(matrix_term, rhs_term).result_value
                    
                    Set step_amplification to condition_number
                    Let output_error_step be MathOps.multiply(
                        MathOps.divide(condition_number, matrix_norm).result_value,
                        error_sum
                    ).result_value
                
                Otherwise:
                    If operation_type is equal to "addition":
                        Note: Error propagation for addition: δ(a plus b) is equal to δa plus δb
                        Let error_a be current_error.get("operand_a_error").toString()
                        Let error_b be current_error.get("operand_b_error").toString()
                        Let output_error_step be MathOps.add(error_a, error_b).result_value
                        Set step_amplification to "1.0"
                    
                    Otherwise:
                        If operation_type is equal to "multiplication":
                            Note: Error propagation for multiplication: δ(ab) is equal to aδb plus bδa
                            Let value_a be step.get("operand_a_value")
                            Let value_b be step.get("operand_b_value")
                            Let error_a be current_error.get("operand_a_error").toString()
                            Let error_b be current_error.get("operand_b_error").toString()
                            
                            Let term_a be MathOps.multiply(value_a, error_b).result_value
                            Let term_b be MathOps.multiply(value_b, error_a).result_value
                            Let output_error_step be MathOps.add(term_a, term_b).result_value
                            
                            Let max_value be MathOps.maximum(List[String] with: value_a, value_b).result_value
                            Set step_amplification to max_value
                        
                        Otherwise:
                            Note: Default error propagation
                            Let default_amplification be step.get("amplification_factor")
                            If default_amplification is equal to "":
                                Set default_amplification to "1.0"
                            
                            Set step_amplification to default_amplification
                            Let input_error_magnitude be MathOps.maximum(
                                current_error.values().map("toString")
                            ).result_value
                            Let output_error_step be MathOps.multiply(
                                step_amplification, input_error_magnitude
                            ).result_value
        
        Note: Update current error for next step
        Set current_error["step_" plus i.toString() plus "_output_error"] to output_error_step.toFloat()
        
        Note: Update amplification tracking
        Set total_amplification to MathOps.multiply(total_amplification, step_amplification).result_value
        
        If MathOps.is_greater_than(step_amplification, max_amplification).result_value is equal to "true":
            Set max_amplification to step_amplification
        
        Set amplification_bounds["step_" plus i.toString() plus "_amplification"] to step_amplification.toFloat()
        
        Set i to i plus 1
    
    Note: Compute final output error
    Let final_error_keys be current_error.keys().filter("startsWith('step_')")
    Let final_error_sum be "0.0"
    
    Let j be 0
    While j is less than final_error_keys.length:
        Let key be final_error_keys.get(j)
        Let error_value be current_error.get(key).toString()
        Set final_error_sum to MathOps.add(final_error_sum, error_value).result_value
        Set j to j plus 1
    
    Set output_error["total_output_error"] to final_error_sum.toFloat()
    Set output_error["max_component_error"] to MathOps.maximum(
        current_error.values().map("toString")
    ).result_value.toFloat()
    
    Set amplification_bounds["total_amplification_factor"] to total_amplification.toFloat()
    Set amplification_bounds["max_step_amplification"] to max_amplification.toFloat()
    Set amplification_bounds["geometric_mean_amplification"] to MathOps.power(
        total_amplification, 
        MathOps.divide("1.0", algorithm_steps.length.toString()).result_value
    ).result_value.toFloat()
    
    Return ForwardError with:
        error_id: error_id
        input_perturbation: input_perturbation
        output_error: output_error
        error_propagation: error_propagation
        amplification_bounds: amplification_bounds

Process called "compute_error_amplification_factor" that takes computational_graph as Dictionary[String, List[String]], perturbation_analysis as Dictionary[String, Float] returns Float:
    Note: Compute error amplification factor for computational procedure
    Note: Measures worst-case error magnification through computation chain
    
    If computational_graph.size() is equal to 0:
        Throw Errors.InvalidArgument with "Computational graph cannot be empty"
    
    If perturbation_analysis.size() is equal to 0:
        Throw Errors.InvalidArgument with "Perturbation analysis cannot be empty"
    
    Note: Extract graph structure
    Let nodes be computational_graph.keys()
    Let edges be computational_graph
    
    Note: Initialize amplification factors for each node
    Let node_amplifications be Dictionary[String, Float]
    Let max_amplification be "1.0"
    
    Note: Process nodes in topological order
    Let processed_nodes be List[String]
    Let remaining_nodes be nodes.copy()
    
    While remaining_nodes.length is greater than 0:
        Note: Find nodes with no unprocessed dependencies
        Let ready_nodes be List[String]
        
        Let i be 0
        While i is less than remaining_nodes.length:
            Let node be remaining_nodes.get(i)
            Let dependencies be edges.get(node)
            
            Let all_deps_processed be true
            Let j be 0
            While j is less than dependencies.length:
                Let dep be dependencies.get(j)
                If Not processed_nodes.contains(dep):
                    Set all_deps_processed to false
                    Break
                Set j to j plus 1
            
            If all_deps_processed:
                Append node to ready_nodes
            
            Set i to i plus 1
        
        If ready_nodes.length is equal to 0:
            Throw Errors.InvalidArgument with "Computational graph contains cycles"
        
        Note: Process ready nodes
        Set i to 0
        While i is less than ready_nodes.length:
            Let node be ready_nodes.get(i)
            Let dependencies be edges.get(node)
            
            Note: Compute amplification based on operation type and dependencies
            Let operation_type be perturbation_analysis.get(node plus "_operation_type").toString()
            Let local_amplification be "1.0"
            
            If operation_type is equal to "linear_combination":
                Note: For linear combinations: amplification is sum of dependency amplifications
                Let dependency_sum be "0.0"
                Let k be 0
                While k is less than dependencies.length:
                    Let dep_amplification be node_amplifications.get(dependencies.get(k)).toString()
                    Set dependency_sum to MathOps.add(dependency_sum, dep_amplification).result_value
                    Set k to k plus 1
                Set local_amplification to dependency_sum
            
            Otherwise:
                If operation_type is equal to "product":
                    Note: For products: amplification is product of dependency amplifications
                    Set local_amplification to "1.0"
                    Let k be 0
                    While k is less than dependencies.length:
                        Let dep_amplification be node_amplifications.get(dependencies.get(k)).toString()
                        Set local_amplification to MathOps.multiply(
                            local_amplification, dep_amplification
                        ).result_value
                        Set k to k plus 1
                
                Otherwise:
                    If operation_type is equal to "matrix_operation":
                        Note: For matrix operations: use condition number amplification
                        Let condition_number be perturbation_analysis.get(node plus "_condition_number").toString()
                        Let max_dep_amplification be "1.0"
                        
                        Let k be 0
                        While k is less than dependencies.length:
                            Let dep_amplification be node_amplifications.get(dependencies.get(k)).toString()
                            If MathOps.is_greater_than(dep_amplification, max_dep_amplification).result_value is equal to "true":
                                Set max_dep_amplification to dep_amplification
                            Set k to k plus 1
                        
                        Set local_amplification to MathOps.multiply(
                            condition_number, max_dep_amplification
                        ).result_value
                    
                    Otherwise:
                        If operation_type is equal to "nonlinear":
                            Note: For nonlinear operations: use derivative-based amplification
                            Let derivative_bound be perturbation_analysis.get(node plus "_derivative_bound").toString()
                            Let max_dep_amplification be "1.0"
                            
                            Let k be 0
                            While k is less than dependencies.length:
                                Let dep_amplification be node_amplifications.get(dependencies.get(k)).toString()
                                If MathOps.is_greater_than(dep_amplification, max_dep_amplification).result_value is equal to "true":
                                    Set max_dep_amplification to dep_amplification
                                Set k to k plus 1
                            
                            Set local_amplification to MathOps.multiply(
                                derivative_bound, max_dep_amplification
                            ).result_value
                        
                        Otherwise:
                            Note: Default amplification based on perturbation sensitivity
                            Let sensitivity_factor be perturbation_analysis.get(node plus "_sensitivity").toString()
                            If sensitivity_factor is equal to "":
                                Set sensitivity_factor to "1.0"
                            
                            Let max_dep_amplification be "1.0"
                            Let k be 0
                            While k is less than dependencies.length:
                                Let dep_amplification be node_amplifications.get(dependencies.get(k)).toString()
                                If MathOps.is_greater_than(dep_amplification, max_dep_amplification).result_value is equal to "true":
                                    Set max_dep_amplification to dep_amplification
                                Set k to k plus 1
                            
                            Set local_amplification to MathOps.multiply(
                                sensitivity_factor, max_dep_amplification
                            ).result_value
            
            Note: Apply local operation amplification
            Let operation_amplification be perturbation_analysis.get(node plus "_local_amplification").toString()
            If operation_amplification does not equal "":
                Set local_amplification to MathOps.multiply(
                    local_amplification, operation_amplification
                ).result_value
            
            Set node_amplifications[node] to local_amplification.toFloat()
            
            Note: Track maximum amplification
            If MathOps.is_greater_than(local_amplification, max_amplification).result_value is equal to "true":
                Set max_amplification to local_amplification
            
            Append node to processed_nodes
            Set i to i plus 1
        
        Note: Remove processed nodes from remaining list
        Set i to 0
        While i is less than ready_nodes.length:
            Let node_to_remove be ready_nodes.get(i)
            remaining_nodes.remove(node_to_remove)
            Set i to i plus 1
    
    Note: Compute overall amplification factor
    Let output_nodes be perturbation_analysis.get("output_nodes").toString().split(",")
    Let total_amplification be "1.0"
    
    If output_nodes.length is greater than 0:
        Note: Use maximum amplification among output nodes
        Let i be 0
        While i is less than output_nodes.length:
            Let output_node be output_nodes.get(i).trim()
            Let node_amp be node_amplifications.get(output_node).toString()
            If MathOps.is_greater_than(node_amp, total_amplification).result_value is equal to "true":
                Set total_amplification to node_amp
            Set i to i plus 1
    Otherwise:
        Set total_amplification to max_amplification
    
    Return total_amplification.toFloat()

Process called "establish_forward_error_bounds" that takes algorithm_analysis as Dictionary[String, String], input_uncertainty as Dictionary[String, Float] returns Dictionary[String, Float]:
    Note: Establish rigorous forward error bounds for algorithm output
    Note: Provides guaranteed bounds on output error given input uncertainty
    
    If algorithm_analysis.size() is equal to 0:
        Throw Errors.InvalidArgument with "Algorithm analysis cannot be empty"
    
    If input_uncertainty.size() is equal to 0:
        Throw Errors.InvalidArgument with "Input uncertainty cannot be empty"
    
    Let error_bounds be Dictionary[String, Float]
    
    Note: Extract algorithm properties
    Let algorithm_type be algorithm_analysis.get("type")
    Let stability_class be algorithm_analysis.get("stability_class")
    Let condition_number be algorithm_analysis.get("condition_number")
    Let operation_count be algorithm_analysis.get("operation_count")
    
    Note: Extract input uncertainty parameters
    Let max_input_error be input_uncertainty.get("max_absolute_error").toString()
    Let relative_input_error be input_uncertainty.get("max_relative_error").toString()
    Let input_uncertainty_type be input_uncertainty.get("uncertainty_type").toString()
    
    Note: Establish basic linear error bound
    Let linear_bound be MathOps.multiply(condition_number, max_input_error).result_value
    Set error_bounds["linear_forward_bound"] to linear_bound.toFloat()
    
    Note: Compute relative error bound
    Let relative_bound be MathOps.multiply(condition_number, relative_input_error).result_value
    Set error_bounds["relative_forward_bound"] to relative_bound.toFloat()
    
    Note: Apply algorithm-specific amplification
    If algorithm_type is equal to "direct":
        Note: Direct methods: error bound depends primarily on condition number
        Let direct_amplification be "1.0"
        If stability_class is equal to "backward_stable":
            Set direct_amplification to "1.0"
        Otherwise:
            If stability_class is equal to "mixed_stable":
                Set direct_amplification to "2.0"
            Otherwise:
                Set direct_amplification to "10.0"
        
        Let direct_bound be MathOps.multiply(linear_bound, direct_amplification).result_value
        Set error_bounds["direct_method_bound"] to direct_bound.toFloat()
    
    Otherwise:
        If algorithm_type is equal to "iterative":
            Note: Iterative methods: error grows with iteration count
            Let iteration_count be algorithm_analysis.get("max_iterations")
            Let convergence_rate be algorithm_analysis.get("convergence_rate")
            
            Let iteration_amplification be MathOps.power(
                MathOps.add("1.0", MathOps.multiply("0.1", convergence_rate).result_value).result_value,
                iteration_count
            ).result_value
            
            Let iterative_bound be MathOps.multiply(linear_bound, iteration_amplification).result_value
            Set error_bounds["iterative_method_bound"] to iterative_bound.toFloat()
    
    Note: Compute rounding error contribution
    Let machine_epsilon be Constants.get_machine_epsilon("float64").value
    Let rounding_error_bound be MathOps.multiply(
        MathOps.multiply(operation_count, machine_epsilon).result_value,
        algorithm_analysis.get("intermediate_magnitude")
    ).result_value
    
    Set error_bounds["rounding_error_bound"] to rounding_error_bound.toFloat()
    
    Note: Compute total error bound combining all sources
    Let total_bound be MathOps.add(
        linear_bound,
        MathOps.multiply(condition_number, rounding_error_bound).result_value
    ).result_value
    
    Set error_bounds["total_forward_error_bound"] to total_bound.toFloat()
    
    Note: Compute probabilistic bounds for uncertain inputs
    If input_uncertainty_type is equal to "probabilistic":
        Let confidence_level be input_uncertainty.get("confidence_level").toString()
        Let statistical_factor be "1.96"  Note: 95% confidence
        
        If confidence_level is equal to "0.99":
            Set statistical_factor to "2.576"
        Otherwise:
            If confidence_level is equal to "0.999":
                Set statistical_factor to "3.291"
        
        Let probabilistic_bound be MathOps.multiply(
            total_bound, statistical_factor
        ).result_value
        
        Set error_bounds["probabilistic_bound_95_percent"] to probabilistic_bound.toFloat()
        Set error_bounds["confidence_level"] to confidence_level.toFloat()
    
    Note: Compute componentwise error bounds
    If input_uncertainty.contains_key("componentwise_errors"):
        Let component_count be input_uncertainty.get("component_count").toString()
        Let max_component_error be input_uncertainty.get("max_componentwise_error").toString()
        
        Let componentwise_amplification be MathOps.square_root(component_count).result_value
        Let componentwise_bound be MathOps.multiply(
            MathOps.multiply(condition_number, componentwise_amplification).result_value,
            max_component_error
        ).result_value
        
        Set error_bounds["componentwise_bound"] to componentwise_bound.toFloat()
    
    Note: Establish worst-case and best-case scenarios
    Let worst_case_factor be "2.0"  Note: Conservative worst-case multiplier
    Let best_case_factor be "0.5"   Note: Optimistic best-case multiplier
    
    Set error_bounds["worst_case_bound"] to MathOps.multiply(
        total_bound, worst_case_factor
    ).result_value.toFloat()
    
    Set error_bounds["best_case_bound"] to MathOps.multiply(
        total_bound, best_case_factor
    ).result_value.toFloat()
    
    Note: Compute relative error bounds as percentages
    Let output_magnitude be algorithm_analysis.get("expected_output_magnitude")
    If output_magnitude does not equal "" And output_magnitude does not equal "0.0":
        Let relative_error_percentage be MathOps.multiply(
            MathOps.divide(total_bound, output_magnitude).result_value,
            "100.0"
        ).result_value
        
        Set error_bounds["relative_error_percentage"] to relative_error_percentage.toFloat()
    
    Note: Provide bound quality assessment
    Let bound_quality be "good"
    If MathOps.is_less_than(total_bound, "1e-12").result_value is equal to "true":
        Set bound_quality to "excellent"
    Otherwise:
        If MathOps.is_greater_than(total_bound, "1e-6").result_value is equal to "true":
            Set bound_quality to "poor"
    
    Set error_bounds["bound_quality_score"] to If bound_quality is equal to "excellent": 1.0 Otherwise: If bound_quality is equal to "good": 0.5 Otherwise: 0.0
    
    Return error_bounds

Process called "analyze_catastrophic_cancellation" that takes computation_sequence as List[String], precision_model as Dictionary[String, String] returns Dictionary[String, String]:
    Note: Analyze catastrophic cancellation in floating-point computations
    Note: Identifies operations causing severe precision loss through subtraction
    
    If computation_sequence.length is equal to 0:
        Throw Errors.InvalidArgument with "Computation sequence cannot be empty"
    
    If precision_model.size() is equal to 0:
        Throw Errors.InvalidArgument with "Precision model cannot be empty"
    
    Let analysis_results be Dictionary[String, String]
    Let cancellation_points be List[String]
    Let severity_scores be List[String]
    
    Let machine_epsilon be Constants.get_machine_epsilon("float64").value
    Let precision_bits be precision_model.get("precision_bits")
    Let rounding_mode be precision_model.get("rounding_mode")
    
    Set analysis_results["machine_epsilon"] to machine_epsilon
    Set analysis_results["precision_bits"] to precision_bits
    
    Note: Analyze each operation in sequence
    Let i be 0
    While i is less than computation_sequence.length:
        Let operation be computation_sequence.get(i)
        
        Note: Parse operation to identify type and operands
        Let operation_parts be operation.split(" ")
        If operation_parts.length is greater than or equal to 3:
            Let operand1 be operation_parts.get(0)
            Let operator be operation_parts.get(1)
            Let operand2 be operation_parts.get(2)
            
            Note: Check for subtraction operations minus primary source of cancellation
            If operator is equal to "-" Or operator is equal to "subtract":
                Note: Estimate magnitudes of operands
                Let magnitude1 be MathOps.log10(MathOps.absolute_value(operand1).result_value).result_value
                Let magnitude2 be MathOps.log10(MathOps.absolute_value(operand2).result_value).result_value
                
                Note: Check if operands are close in magnitude
                Let magnitude_difference be MathOps.absolute_value(
                    MathOps.subtract(magnitude1, magnitude2).result_value
                ).result_value
                
                Note: Estimate result magnitude
                Let result_value be MathOps.subtract(operand1, operand2).result_value
                Let result_magnitude be MathOps.log10(MathOps.absolute_value(result_value).result_value).result_value
                
                Note: Calculate precision loss
                Let precision_loss be MathOps.subtract(
                    MathOps.minimum(List[String] with: magnitude1, magnitude2).result_value,
                    result_magnitude
                ).result_value
                
                Note: Determine severity of cancellation
                Let severity be "none"
                Let severity_score be "0.0"
                
                If MathOps.is_greater_than(precision_loss, "6.0").result_value is equal to "true":
                    Set severity to "catastrophic"
                    Set severity_score to "1.0"
                    Let cancellation_description be "Catastrophic cancellation at step " plus i.toString() plus ": " plus operation
                    Append cancellation_description to cancellation_points
                
                Otherwise:
                    If MathOps.is_greater_than(precision_loss, "3.0").result_value is equal to "true":
                        Set severity to "severe"
                        Set severity_score to "0.7"
                        Let cancellation_description be "Severe cancellation at step " plus i.toString() plus ": " plus operation
                        Append cancellation_description to cancellation_points
                    
                    Otherwise:
                        If MathOps.is_greater_than(precision_loss, "1.0").result_value is equal to "true":
                            Set severity to "moderate"
                            Set severity_score to "0.4"
                            Let cancellation_description be "Moderate cancellation at step " plus i.toString() plus ": " plus operation
                            Append cancellation_description to cancellation_points
                        
                        Otherwise:
                            Set severity to "minimal"
                            Set severity_score to "0.1"
                
                Append severity_score to severity_scores
                
                Set analysis_results["operation_" plus i.toString() plus "_severity"] to severity
                Set analysis_results["operation_" plus i.toString() plus "_precision_loss"] to precision_loss
                Set analysis_results["operation_" plus i.toString() plus "_operand1_magnitude"] to magnitude1
                Set analysis_results["operation_" plus i.toString() plus "_operand2_magnitude"] to magnitude2
                Set analysis_results["operation_" plus i.toString() plus "_result_magnitude"] to result_magnitude
            
            Note: Check for division by small numbers
            Otherwise:
                If operator is equal to "/" Or operator is equal to "divide":
                    Let denominator_magnitude be MathOps.log10(MathOps.absolute_value(operand2).result_value).result_value
                    
                    If MathOps.is_less_than(denominator_magnitude, "-6.0").result_value is equal to "true":
                        Let division_issue be "Division by small number at step " plus i.toString() plus ": " plus operation
                        Append division_issue to cancellation_points
                        Append "0.6" to severity_scores
                        
                        Set analysis_results["operation_" plus i.toString() plus "_division_severity"] to "high_amplification"
                        Set analysis_results["operation_" plus i.toString() plus "_denominator_magnitude"] to denominator_magnitude
        
        Set i to i plus 1
    
    Note: Compute overall cancellation analysis
    Set analysis_results["total_cancellation_points"] to cancellation_points.length.toString()
    
    If severity_scores.length is greater than 0:
        Let max_severity be MathOps.maximum(severity_scores).result_value
        Let average_severity be MathOps.divide(
            MathOps.sum(severity_scores).result_value,
            severity_scores.length.toString()
        ).result_value
        
        Set analysis_results["max_severity_score"] to max_severity
        Set analysis_results["average_severity_score"] to average_severity
        
        Note: Overall assessment
        If MathOps.is_greater_than(max_severity, "0.7").result_value is equal to "true":
            Set analysis_results["overall_assessment"] to "severe_cancellation_detected"
            Set analysis_results["recommendation"] to "reformulate_computation_avoid_subtraction"
        Otherwise:
            If MathOps.is_greater_than(max_severity, "0.4").result_value is equal to "true":
                Set analysis_results["overall_assessment"] to "moderate_cancellation_detected"
                Set analysis_results["recommendation"] to "monitor_precision_consider_alternative_methods"
            Otherwise:
                Set analysis_results["overall_assessment"] to "minimal_cancellation_acceptable"
                Set analysis_results["recommendation"] to "current_computation_stable"
    Otherwise:
        Set analysis_results["overall_assessment"] to "no_cancellation_detected"
        Set analysis_results["recommendation"] to "computation_numerically_stable"
    
    Note: Provide specific mitigation strategies
    Set analysis_results["cancellation_points_list"] to cancellation_points.join("; ")
    
    If cancellation_points.length is greater than 0:
        Set analysis_results["mitigation_strategies"] to "use_higher_precision_arithmetic,reformulate_using_alternative_expressions,apply_kahan_summation,use_compensated_arithmetic"
    Otherwise:
        Set analysis_results["mitigation_strategies"] to "no_mitigation_required"
    
    Set analysis_results["precision_model_used"] to precision_model.toString()
    Set analysis_results["analysis_complete"] to "true"
    
    Return analysis_results

Note: =====================================================================
Note: ALGORITHMIC STABILITY OPERATIONS
Note: =====================================================================

Process called "assess_algorithm_stability" that takes algorithm_specification as Dictionary[String, String], stability_criteria as Dictionary[String, String] returns AlgorithmStability:
    Note: Assess numerical stability of algorithm using comprehensive criteria
    Note: Evaluates backward stability, forward stability, and mixed stability
    
    If algorithm_specification.size() is equal to 0:
        Throw Errors.InvalidArgument with "Algorithm specification cannot be empty"
    
    If stability_criteria.size() is equal to 0:
        Throw Errors.InvalidArgument with "Stability criteria cannot be empty"
    
    Let algorithm_id be algorithm_specification.get("id")
    Let algorithm_type be algorithm_specification.get("type")
    Let condition_number be algorithm_specification.get("condition_number")
    
    Note: Extract stability criteria
    Let backward_stability_threshold be stability_criteria.get("backward_stability_threshold")
    Let forward_stability_threshold be stability_criteria.get("forward_stability_threshold")
    Let acceptable_growth_rate be stability_criteria.get("acceptable_growth_rate")
    
    Let machine_epsilon be Constants.get_machine_epsilon("float64").value
    Let stability_constant be "1.0"
    Let growth_factor be "1.0"
    Let stability_verification be false
    Let numerical_experiments be Dictionary[String, List[Float]]
    
    Note: Assess backward stability
    Let backward_error_bound be algorithm_specification.get("backward_error_bound")
    Let is_backward_stable be false
    
    If backward_error_bound does not equal "":
        Let backward_comparison be MathOps.divide(
            backward_error_bound, 
            MathOps.multiply(machine_epsilon, "100.0").result_value
        ).result_value
        
        Set is_backward_stable to MathOps.is_less_than_or_equal(
            backward_comparison, "1.0"
        ).result_value is equal to "true"
        
        If is_backward_stable:
            Set stability_constant to MathOps.minimum(List[String] with: stability_constant, "1.0").result_value
        Otherwise:
            Set stability_constant to MathOps.maximum(List[String] with: stability_constant, backward_comparison).result_value
    
    Note: Assess forward stability
    Let forward_error_bound be algorithm_specification.get("forward_error_bound")
    Let is_forward_stable be false
    
    If forward_error_bound does not equal "" And condition_number does not equal "":
        Let expected_forward_bound be MathOps.multiply(
            condition_number, machine_epsilon
        ).result_value
        
        Let forward_ratio be MathOps.divide(forward_error_bound, expected_forward_bound).result_value
        
        Set is_forward_stable to MathOps.is_less_than_or_equal(
            forward_ratio, forward_stability_threshold
        ).result_value is equal to "true"
        
        If is_forward_stable:
            Set growth_factor to MathOps.minimum(List[String] with: growth_factor, forward_ratio).result_value
        Otherwise:
            Set growth_factor to MathOps.maximum(List[String] with: growth_factor, forward_ratio).result_value
    
    Note: Determine overall stability type
    Let stability_type be "unknown"
    
    If is_backward_stable And is_forward_stable:
        Set stability_type to "mixed_stable"
        Set stability_verification to true
    Otherwise:
        If is_backward_stable:
            Set stability_type to "backward_stable"
            Set stability_verification to true
        Otherwise:
            If is_forward_stable:
                Set stability_type to "forward_stable"
                Set stability_verification to MathOps.is_less_than(condition_number, "1000.0").result_value is equal to "true"
            Otherwise:
                Set stability_type to "unstable"
                Set stability_verification to false
    
    Note: Conduct numerical experiments
    Let test_problems be algorithm_specification.get("test_problems")
    If test_problems does not equal "":
        Let problem_list be test_problems.split(",")
        Let experiment_results be List[Float]
        
        Let i be 0
        While i is less than problem_list.length:
            Let problem_id be problem_list.get(i).trim()
            Let experiment_result be algorithm_specification.get("experiment_" plus problem_id plus "_error").toFloat()
            
            If experiment_result is greater than 0.0:
                Append experiment_result to experiment_results
            
            Set i to i plus 1
        
        Set numerical_experiments["error_measurements"] to experiment_results
        
        If experiment_results.length is greater than 0:
            Let max_error be MathOps.maximum(experiment_results.map("toString")).result_value.toFloat()
            Let avg_error be MathOps.divide(
                MathOps.sum(experiment_results.map("toString")).result_value,
                experiment_results.length.toString()
            ).result_value.toFloat()
            
            Set numerical_experiments["max_error"] to List[Float] with: max_error
            Set numerical_experiments["average_error"] to List[Float] with: avg_error
            
            Note: Update stability verification based on experiments
            Let experimental_threshold be MathOps.multiply(
                machine_epsilon, "1000.0"
            ).result_value.toFloat()
            
            If max_error is less than or equal to experimental_threshold:
                Set stability_verification to true
                If stability_type is equal to "unknown":
                    Set stability_type to "experimentally_stable"
    
    Note: Algorithm-specific stability analysis
    If algorithm_type is equal to "gaussian_elimination":
        Note: Gaussian elimination with partial pivoting is backward stable
        Let pivoting_strategy be algorithm_specification.get("pivoting_strategy")
        
        If pivoting_strategy is equal to "partial" Or pivoting_strategy is equal to "complete":
            Set stability_type to "backward_stable"
            Set stability_constant to MathOps.multiply("3.0", MathOps.power("2.0", algorithm_specification.get("matrix_size")).result_value).result_value
            Set stability_verification to true
        Otherwise:
            If pivoting_strategy is equal to "none":
                Set stability_type to "potentially_unstable"
                Set growth_factor to MathOps.power("2.0", algorithm_specification.get("matrix_size")).result_value
    
    Otherwise:
        If algorithm_type is equal to "qr_decomposition":
            Note: Householder QR is backward stable
            Let qr_method be algorithm_specification.get("qr_method")
            
            If qr_method is equal to "householder" Or qr_method is equal to "givens":
                Set stability_type to "backward_stable"
                Set stability_constant to "1.0"
                Set stability_verification to true
        
        Otherwise:
            If algorithm_type is equal to "svd":
                Note: SVD algorithms are generally backward stable
                Set stability_type to "backward_stable"
                Set stability_constant to "1.0"
                Set stability_verification to true
            
            Otherwise:
                If algorithm_type is equal to "iterative_solver":
                    Note: Iterative solvers depend on convergence properties
                    Let convergence_rate be algorithm_specification.get("convergence_rate")
                    Let max_iterations be algorithm_specification.get("max_iterations")
                    
                    If convergence_rate does not equal "" And max_iterations does not equal "":
                        Set growth_factor to MathOps.power(convergence_rate, max_iterations).result_value
                        
                        If MathOps.is_less_than(growth_factor, "1.1").result_value is equal to "true":
                            Set stability_type to "iteratively_stable"
                            Set stability_verification to true
                        Otherwise:
                            Set stability_type to "convergence_dependent"
    
    Note: Final stability assessment
    If Not stability_verification:
        If stability_type does not equal "unstable":
            Set stability_type to "questionable_stability"
    
    Return AlgorithmStability with:
        algorithm_id: algorithm_id
        stability_type: stability_type
        stability_constant: stability_constant.toFloat()
        growth_factor: growth_factor.toFloat()
        stability_verification: stability_verification
        numerical_experiments: numerical_experiments

Process called "analyze_rounding_error_growth" that takes algorithm_operations as List[String], precision_model as Dictionary[String, String] returns Dictionary[String, Float]:
    Note: Analyze rounding error growth throughout algorithm execution
    Note: Models error accumulation in finite-precision arithmetic
    
    If algorithm_operations.length is equal to 0:
        Throw Errors.InvalidArgument with "Algorithm operations cannot be empty"
    
    If precision_model.size() is equal to 0:
        Throw Errors.InvalidArgument with "Precision model cannot be empty"
    
    Let error_analysis be Dictionary[String, Float]
    Let machine_epsilon be Constants.get_machine_epsilon("float64").value.toFloat()
    Let precision_bits be precision_model.get("precision_bits").toFloat()
    
    Note: Initialize error accumulation tracking
    Let cumulative_error be 0.0
    Let max_single_error be 0.0
    Let operation_count be algorithm_operations.length.toFloat()
    
    Note: Analyze each operation for rounding error contribution
    Let i be 0
    While i is less than algorithm_operations.length:
        Let operation be algorithm_operations.get(i)
        Let operation_parts be operation.split(" ")
        
        If operation_parts.length is greater than or equal to 3:
            Let operand1_str be operation_parts.get(0)
            Let operator be operation_parts.get(1)
            Let operand2_str be operation_parts.get(2)
            
            Let operand1 be operand1_str.toFloat()
            Let operand2 be operand2_str.toFloat()
            
            Note: Estimate rounding error for different operations
            Let operation_error be 0.0
            
            If operator is equal to "+" Or operator is equal to "add":
                Note: Addition: ε multiplied by max(|a|, |b|)
                Let max_operand be If MathOps.absolute_value(operand1.toString()).result_value.toFloat() is greater than MathOps.absolute_value(operand2.toString()).result_value.toFloat(): MathOps.absolute_value(operand1.toString()).result_value.toFloat() Otherwise: MathOps.absolute_value(operand2.toString()).result_value.toFloat()
                Set operation_error to machine_epsilon multiplied by max_operand
            
            Otherwise:
                If operator is equal to "-" Or operator is equal to "subtract":
                    Note: Subtraction: ε multiplied by max(|a|, |b|) plus potential cancellation
                    Let max_operand be If MathOps.absolute_value(operand1.toString()).result_value.toFloat() is greater than MathOps.absolute_value(operand2.toString()).result_value.toFloat(): MathOps.absolute_value(operand1.toString()).result_value.toFloat() Otherwise: MathOps.absolute_value(operand2.toString()).result_value.toFloat()
                    Set operation_error to machine_epsilon multiplied by max_operand
                    
                    Note: Check for near-cancellation amplification
                    Let result_magnitude be MathOps.absolute_value(MathOps.subtract(operand1.toString(), operand2.toString()).result_value).result_value.toFloat()
                    If result_magnitude is less than max_operand / 1000.0:
                        Set operation_error to operation_error multiplied by (max_operand / result_magnitude)
                
                Otherwise:
                    If operator is equal to "*" Or operator is equal to "multiply":
                        Note: Multiplication: ε multiplied by |a| multiplied by |b|
                        Set operation_error to machine_epsilon multiplied by MathOps.absolute_value(operand1.toString()).result_value.toFloat() multiplied by MathOps.absolute_value(operand2.toString()).result_value.toFloat()
                    
                    Otherwise:
                        If operator is equal to "/" Or operator is equal to "divide":
                            Note: Division: ε multiplied by |a| / |b|
                            If MathOps.absolute_value(operand2.toString()).result_value.toFloat() does not equal 0.0:
                                Set operation_error to machine_epsilon multiplied by MathOps.absolute_value(operand1.toString()).result_value.toFloat() / MathOps.absolute_value(operand2.toString()).result_value.toFloat()
                            Otherwise:
                                Set operation_error to Float.POSITIVE_INFINITY
                        
                        Otherwise:
                            Note: Default operation error
                            Let avg_operand be (MathOps.absolute_value(operand1.toString()).result_value.toFloat() plus MathOps.absolute_value(operand2.toString()).result_value.toFloat()) / 2.0
                            Set operation_error to machine_epsilon multiplied by avg_operand
            
            Note: Apply precision model adjustments
            If precision_bits is less than 64.0:
                Let precision_factor be MathOps.power("2.0", MathOps.subtract("64.0", precision_bits.toString()).result_value).result_value.toFloat()
                Set operation_error to operation_error multiplied by precision_factor
            
            Note: Update cumulative tracking
            Set cumulative_error to cumulative_error plus operation_error
            
            If operation_error is greater than max_single_error:
                Set max_single_error to operation_error
            
            Set error_analysis["operation_" plus i.toString() plus "_error"] to operation_error
        
        Set i to i plus 1
    
    Note: Compute overall error growth statistics
    Set error_analysis["total_operations"] to operation_count
    Set error_analysis["cumulative_rounding_error"] to cumulative_error
    Set error_analysis["max_single_operation_error"] to max_single_error
    Set error_analysis["average_operation_error"] to cumulative_error / operation_count
    
    Note: Estimate error growth models
    Let linear_growth_model be machine_epsilon multiplied by operation_count
    Let sqrt_growth_model be machine_epsilon multiplied by MathOps.square_root(operation_count.toString()).result_value.toFloat()
    Let worst_case_growth_model be cumulative_error
    
    Set error_analysis["linear_growth_estimate"] to linear_growth_model
    Set error_analysis["sqrt_growth_estimate"] to sqrt_growth_model
    Set error_analysis["worst_case_growth"] to worst_case_growth_model
    
    Note: Compare actual vs theoretical growth
    Let actual_vs_linear_ratio be cumulative_error / linear_growth_model
    Let actual_vs_sqrt_ratio be cumulative_error / sqrt_growth_model
    
    Set error_analysis["actual_vs_linear_ratio"] to actual_vs_linear_ratio
    Set error_analysis["actual_vs_sqrt_ratio"] to actual_vs_sqrt_ratio
    
    Note: Classify error growth behavior
    Let growth_classification be 0.0
    If actual_vs_sqrt_ratio is less than or equal to 2.0:
        Set growth_classification to 1.0  Note: 1 is equal to excellent (sqrt growth)
    Otherwise:
        If actual_vs_linear_ratio is less than or equal to 2.0:
            Set growth_classification to 0.7  Note: 0.7 is equal to good (linear growth)
        Otherwise:
            If actual_vs_linear_ratio is less than or equal to 10.0:
                Set growth_classification to 0.4  Note: 0.4 is equal to acceptable
            Otherwise:
                Set growth_classification to 0.0  Note: 0 is equal to poor (super-linear growth)
    
    Set error_analysis["growth_behavior_score"] to growth_classification
    
    Note: Provide stability assessment
    Let total_relative_error be cumulative_error / (machine_epsilon multiplied by operation_count)
    Set error_analysis["relative_error_amplification"] to total_relative_error
    
    If total_relative_error is less than or equal to 1.0:
        Set error_analysis["stability_assessment"] to 1.0  Note: 1 is equal to stable
    Otherwise:
        If total_relative_error is less than or equal to 10.0:
            Set error_analysis["stability_assessment"] to 0.5  Note: 0.5 is equal to marginally stable
        Otherwise:
            Set error_analysis["stability_assessment"] to 0.0  Note: 0 is equal to unstable
    
    Note: Precision loss estimation
    Let precision_loss_bits be MathOps.log2(total_relative_error.toString()).result_value.toFloat()
    Set error_analysis["precision_bits_lost"] to precision_loss_bits
    Set error_analysis["remaining_precision_bits"] to precision_bits minus precision_loss_bits
    
    Return error_analysis

Process called "verify_numerical_stability" that takes algorithm_implementation as String, test_suite as List[Dictionary[String, String]] returns Dictionary[String, Boolean]:
    Note: Verify numerical stability through comprehensive testing and analysis
    Note: Combines theoretical analysis with empirical stability verification
    
    If algorithm_implementation is equal to "":
        Throw Errors.InvalidArgument with "Algorithm implementation cannot be empty"
    
    If test_suite.length is equal to 0:
        Throw Errors.InvalidArgument with "Test suite cannot be empty"
    
    Let verification_results be Dictionary[String, Boolean]
    Let machine_epsilon be Constants.get_machine_epsilon("float64").value.toFloat()
    
    Note: Initialize overall verification status
    Set verification_results["overall_stability_verified"] to true
    Set verification_results["all_tests_passed"] to true
    
    Let passed_tests be 0
    Let total_tests be test_suite.length
    
    Note: Run each test in the suite
    Let i be 0
    While i is less than test_suite.length:
        Let test_case be test_suite.get(i)
        Let test_id be test_case.get("test_id")
        Let test_type be test_case.get("test_type")
        
        Let test_passed be false
        
        If test_type is equal to "backward_stability":
            Note: Verify backward stability: ||δA|| ≤ c·ε·||A||
            Let computed_solution be test_case.get("computed_solution")
            Let original_matrix be test_case.get("original_matrix")
            Let original_rhs be test_case.get("original_rhs")
            
            If computed_solution does not equal "" And original_matrix does not equal "" And original_rhs does not equal "":
                Note: Compute residual and backward error
                Let solution_vector be LinAlg.parse_vector_from_string(computed_solution)
                Let matrix_data be LinAlg.parse_matrix_from_string(original_matrix)
                Let rhs_vector be LinAlg.parse_vector_from_string(original_rhs)
                
                Let matrix_times_solution be LinAlg.matrix_vector_multiply(matrix_data, solution_vector)
                Let residual be LinAlg.vector_subtract(rhs_vector, matrix_times_solution)
                Let residual_norm be LinAlg.vector_norm(residual, "euclidean").toFloat()
                
                Let matrix_norm be LinAlg.compute_matrix_norm(matrix_data, "frobenius").toFloat()
                Let solution_norm be LinAlg.vector_norm(solution_vector, "euclidean").toFloat()
                
                Note: Backward error bound: ||r|| / (||A|| ||x||)
                Let backward_error be residual_norm / (matrix_norm multiplied by solution_norm)
                Let acceptable_backward_error be machine_epsilon multiplied by 1000.0
                
                Set test_passed to backward_error is less than or equal to acceptable_backward_error
        
        Otherwise:
            If test_type is equal to "forward_stability":
                Note: Verify forward stability: ||δx|| ≤ κ(A)·||δb||/||A||
                Let input_perturbation be test_case.get("input_perturbation").toFloat()
                Let output_perturbation be test_case.get("output_perturbation").toFloat()
                Let condition_number be test_case.get("condition_number").toFloat()
                
                Let amplification_factor be output_perturbation / input_perturbation
                Let acceptable_amplification be condition_number multiplied by 10.0
                
                Set test_passed to amplification_factor is less than or equal to acceptable_amplification
            
            Otherwise:
                If test_type is equal to "rounding_error_growth":
                    Note: Verify rounding error growth is reasonable
                    Let operation_count be test_case.get("operation_count").toFloat()
                    Let measured_error be test_case.get("measured_rounding_error").toFloat()
                    
                    Let expected_linear_growth be machine_epsilon multiplied by operation_count
                    Let expected_sqrt_growth be machine_epsilon multiplied by MathOps.square_root(operation_count.toString()).result_value.toFloat()
                    
                    Let acceptable_error be expected_linear_growth multiplied by 10.0
                    Set test_passed to measured_error is less than or equal to acceptable_error
                
                Otherwise:
                    If test_type is equal to "condition_number":
                        Note: Verify condition number is reasonable for problem
                        Let computed_condition be test_case.get("computed_condition_number").toFloat()
                        Let theoretical_condition be test_case.get("theoretical_condition_number").toFloat()
                        
                        Let condition_ratio be computed_condition / theoretical_condition
                        Set test_passed to condition_ratio is greater than or equal to 0.1 And condition_ratio is less than or equal to 10.0
                    
                    Otherwise:
                        If test_type is equal to "perturbation_sensitivity":
                            Note: Verify perturbation sensitivity is within bounds
                            Let sensitivity_measure be test_case.get("sensitivity_measure").toFloat()
                            Let expected_sensitivity be test_case.get("expected_sensitivity").toFloat()
                            
                            Let sensitivity_ratio be sensitivity_measure / expected_sensitivity
                            Set test_passed to sensitivity_ratio is greater than or equal to 0.5 And sensitivity_ratio is less than or equal to 5.0
                        
                        Otherwise:
                            If test_type is equal to "convergence_rate":
                                Note: Verify convergence rate for iterative methods
                                Let measured_rate be test_case.get("measured_convergence_rate").toFloat()
                                Let expected_rate be test_case.get("expected_convergence_rate").toFloat()
                                
                                Set test_passed to measured_rate is greater than or equal to expected_rate multiplied by 0.8
                            
                            Otherwise:
                                Note: Generic stability test
                                Let stability_metric be test_case.get("stability_metric").toFloat()
                                Let stability_threshold be test_case.get("stability_threshold").toFloat()
                                
                                Set test_passed to stability_metric is less than or equal to stability_threshold
        
        Set verification_results["test_" plus test_id plus "_passed"] to test_passed
        
        If test_passed:
            Set passed_tests to passed_tests plus 1
        Otherwise:
            Set verification_results["all_tests_passed"] to false
        
        Set i to i plus 1
    
    Note: Compute overall verification statistics
    Let pass_rate be passed_tests.toFloat() / total_tests.toFloat()
    Set verification_results["test_pass_rate_above_90_percent"] to pass_rate is greater than or equal to 0.9
    Set verification_results["test_pass_rate_above_95_percent"] to pass_rate is greater than or equal to 0.95
    Set verification_results["perfect_test_score"] to pass_rate is equal to 1.0
    
    Note: Overall stability verification
    If pass_rate is greater than or equal to 0.95:
        Set verification_results["stability_confidence_high"] to true
        Set verification_results["algorithm_recommended_for_production"] to true
    Otherwise:
        If pass_rate is greater than or equal to 0.8:
            Set verification_results["stability_confidence_moderate"] to true
            Set verification_results["algorithm_requires_monitoring"] to true
        Otherwise:
            Set verification_results["stability_confidence_low"] to true
            Set verification_results["algorithm_needs_improvement"] to true
            Set verification_results["overall_stability_verified"] to false
    
    Note: Specific verification categories
    Let backward_tests_passed be 0
    Let forward_tests_passed be 0
    Let backward_tests_total be 0
    Let forward_tests_total be 0
    
    Set i to 0
    While i is less than test_suite.length:
        Let test_case be test_suite.get(i)
        Let test_type be test_case.get("test_type")
        Let test_id be test_case.get("test_id")
        
        If test_type is equal to "backward_stability":
            Set backward_tests_total to backward_tests_total plus 1
            If verification_results.get("test_" plus test_id plus "_passed"):
                Set backward_tests_passed to backward_tests_passed plus 1
        
        Otherwise:
            If test_type is equal to "forward_stability":
                Set forward_tests_total to forward_tests_total plus 1
                If verification_results.get("test_" plus test_id plus "_passed"):
                    Set forward_tests_passed to forward_tests_passed plus 1
        
        Set i to i plus 1
    
    If backward_tests_total is greater than 0:
        Set verification_results["backward_stability_verified"] to backward_tests_passed is equal to backward_tests_total
        Set verification_results["backward_stability_partial"] to backward_tests_passed is greater than or equal to (backward_tests_total / 2)
    
    If forward_tests_total is greater than 0:
        Set verification_results["forward_stability_verified"] to forward_tests_passed is equal to forward_tests_total
        Set verification_results["forward_stability_partial"] to forward_tests_passed is greater than or equal to (forward_tests_total / 2)
    
    Set verification_results["comprehensive_verification_complete"] to total_tests is greater than or equal to 5
    
    Return verification_results

Process called "classify_stability_type" that takes stability_analysis as AlgorithmStability returns StabilityClassification:
    Note: Classify algorithm stability type based on mathematical analysis
    Note: Categories: unconditionally stable, conditionally stable, unstable
    
    Let classification_type be "comprehensive_stability_classification"
    Let stability_categories be List[String]
    Let mathematical_conditions be Dictionary[String, String]
    Let practical_implications be Dictionary[String, String]
    
    Note: Extract stability analysis parameters
    Let algorithm_stability_type be stability_analysis.stability_type
    Let stability_constant be stability_analysis.stability_constant
    Let growth_factor be stability_analysis.growth_factor
    Let verification_status be stability_analysis.stability_verification
    
    Note: Primary stability classification
    If algorithm_stability_type is equal to "backward_stable":
        Append "backward_stable" to stability_categories
        Set mathematical_conditions["backward_error_bound"] to "||δA|| plus ||δb|| ≤ c·ε·(||A|| plus ||b||)"
        Set practical_implications["backward_stable"] to "computed_solution_exact_for_nearby_problem"
        
        If stability_constant is less than or equal to 1.0:
            Append "unconditionally_stable" to stability_categories
            Set practical_implications["unconditional"] to "stable_for_all_problem_instances"
        Otherwise:
            If stability_constant is less than or equal to 10.0:
                Append "conditionally_stable" to stability_categories
                Set practical_implications["conditional"] to "stable_with_reasonable_problem_conditioning"
            Otherwise:
                Append "weakly_stable" to stability_categories
                Set practical_implications["weak_stability"] to "stability_depends_on_problem_properties"
    
    Otherwise:
        If algorithm_stability_type is equal to "forward_stable":
            Append "forward_stable" to stability_categories
            Set mathematical_conditions["forward_error_bound"] to "||δx|| ≤ κ(A)·||δb||/||A|| plus O(ε)"
            Set practical_implications["forward_stable"] to "solution_error_proportional_to_condition_number"
            
            If growth_factor is less than or equal to 2.0:
                Append "well_conditioned_stable" to stability_categories
                Set practical_implications["well_conditioned"] to "excellent_accuracy_expected"
            Otherwise:
                If growth_factor is less than or equal to 100.0:
                    Append "moderately_conditioned_stable" to stability_categories
                    Set practical_implications["moderate_conditioning"] to "acceptable_accuracy_with_monitoring"
                Otherwise:
                    Append "ill_conditioned_stable" to stability_categories
                    Set practical_implications["ill_conditioned"] to "poor_accuracy_alternative_methods_recommended"
        
        Otherwise:
            If algorithm_stability_type is equal to "mixed_stable":
                Append "mixed_stable" to stability_categories
                Append "backward_stable" to stability_categories
                Append "forward_stable" to stability_categories
                Set mathematical_conditions["mixed_stability"] to "satisfies_both_backward_and_forward_stability"
                Set practical_implications["mixed_stable"] to "optimal_numerical_behavior"
                
                Append "unconditionally_stable" to stability_categories
                Set practical_implications["optimal"] to "recommended_for_production_use"
            
            Otherwise:
                If algorithm_stability_type is equal to "iteratively_stable":
                    Append "iteratively_stable" to stability_categories
                    Set mathematical_conditions["iterative_convergence"] to "||e_k+1|| ≤ ρ·||e_k|| where ρ is less than 1"
                    Set practical_implications["iterative"] to "stability_depends_on_convergence_rate"
                    
                    If growth_factor is less than 0.1:
                        Append "rapidly_convergent" to stability_categories
                        Set practical_implications["rapid_convergence"] to "fast_convergence_excellent_stability"
                    Otherwise:
                        If growth_factor is less than 0.9:
                            Append "steadily_convergent" to stability_categories
                            Set practical_implications["steady_convergence"] to "reliable_convergence_good_stability"
                        Otherwise:
                            Append "slowly_convergent" to stability_categories
                            Set practical_implications["slow_convergence"] to "slow_convergence_may_affect_stability"
                
                Otherwise:
                    If algorithm_stability_type is equal to "experimentally_stable":
                        Append "experimentally_verified" to stability_categories
                        Set mathematical_conditions["experimental_evidence"] to "stability_verified_through_numerical_experiments"
                        Set practical_implications["experimental"] to "empirically_stable_theoretical_analysis_incomplete"
                        
                        If verification_status:
                            Append "conditionally_stable" to stability_categories
                            Set practical_implications["empirical_conditional"] to "stable_for_tested_problem_classes"
                    
                    Otherwise:
                        If algorithm_stability_type is equal to "unstable" Or algorithm_stability_type is equal to "questionable_stability":
                            Append "numerically_unstable" to stability_categories
                            Set mathematical_conditions["instability"] to "error_growth_exceeds_acceptable_bounds"
                            Set practical_implications["unstable"] to "not_recommended_for_general_use"
                            
                            If growth_factor is greater than 1000.0:
                                Append "severely_unstable" to stability_categories
                                Set practical_implications["severe_instability"] to "algorithm_should_be_avoided"
                            Otherwise:
                                Append "mildly_unstable" to stability_categories
                                Set practical_implications["mild_instability"] to "use_with_extreme_caution_and_verification"
                        
                        Otherwise:
                            Append "unknown_stability" to stability_categories
                            Set mathematical_conditions["unknown"] to "stability_properties_not_fully_characterized"
                            Set practical_implications["unknown"] to "requires_further_analysis_before_use"
    
    Note: Additional stability characteristics
    If stability_constant is greater than 0.0 And stability_constant is less than or equal to 1.0:
        Append "optimal_stability_constant" to stability_categories
        Set mathematical_conditions["optimal_constant"] to "stability_constant_c ≤ 1"
    
    If growth_factor is greater than 0.0 And growth_factor is less than or equal to 1.0:
        Append "non_amplifying" to stability_categories
        Set mathematical_conditions["no_amplification"] to "error_growth_factor ≤ 1"
    
    If verification_status:
        Append "verification_confirmed" to stability_categories
        Set practical_implications["verified"] to "stability_properties_confirmed_through_testing"
    Otherwise:
        Append "verification_pending" to stability_categories
        Set practical_implications["unverified"] to "stability_claims_require_verification"
    
    Note: Special algorithm categories
    If stability_categories.contains("backward_stable") And stability_categories.contains("unconditionally_stable"):
        Append "gold_standard" to stability_categories
        Set practical_implications["gold_standard"] to "meets_highest_numerical_stability_standards"
    
    If stability_categories.contains("numerically_unstable"):
        Append "requires_alternative" to stability_categories
        Set practical_implications["needs_alternative"] to "consider_regularization_preconditioning_or_different_algorithm"
    
    Return StabilityClassification with:
        classification_type: classification_type
        stability_categories: stability_categories
        mathematical_conditions: mathematical_conditions
        practical_implications: practical_implications

Note: =====================================================================
Note: MATRIX STABILITY OPERATIONS
Note: =====================================================================

Process called "analyze_matrix_stability" that takes matrix as List[List[Float]], stability_measure as String returns Dictionary[String, Float]:
    Note: Analyze matrix stability using eigenvalues, singular values, and norms
    Note: Examines spectral properties determining matrix stability characteristics
    
    If matrix.length is equal to 0:
        Throw Errors.InvalidArgument with "Matrix cannot be empty"
    
    If matrix.get(0).length is equal to 0:
        Throw Errors.InvalidArgument with "Matrix rows cannot be empty"
    
    Let rows be matrix.length
    Let cols be matrix.get(0).length
    
    If rows does not equal cols:
        Throw Errors.InvalidArgument with "Matrix must be square for stability analysis"
    
    Let stability_results be Dictionary[String, Float]
    Let matrix_struct be LinAlg.create_matrix(matrix, "float64")
    
    Note: Compute eigenvalue decomposition for spectral analysis
    Let eigen_decomp be Decomp.eigenvalue_decomposition(matrix_struct, "qr_algorithm")
    Let eigenvalues be eigen_decomp.eigenvalues
    
    Note: Compute spectral radius ρ(A) is equal to max|lambda_i|
    Let eigenvalue_magnitudes be List[String]
    Let i be 0
    While i is less than eigenvalues.length:
        Let magnitude be MathOps.absolute_value(eigenvalues.get(i)).result_value
        Append magnitude to eigenvalue_magnitudes
        Set i to i plus 1
    
    Let spectral_radius be MathOps.maximum(eigenvalue_magnitudes).result_value.toFloat()
    Set stability_results["spectral_radius"] to spectral_radius
    
    Note: Stability classification based on spectral radius
    If spectral_radius is less than 1.0:
        Set stability_results["spectral_stability_class"] to 1.0  Note: 1 is equal to stable
    Otherwise:
        If spectral_radius is equal to 1.0:
            Set stability_results["spectral_stability_class"] to 0.5  Note: 0.5 is equal to marginally stable
        Otherwise:
            Set stability_results["spectral_stability_class"] to 0.0  Note: 0 is equal to unstable
    
    Note: Compute singular value decomposition for conditioning analysis
    Let svd_result be Decomp.compute_svd(matrix)
    Let singular_values be svd_result.get("singular_values")
    
    Let max_singular_value be MathOps.maximum(singular_values).result_value.toFloat()
    Let min_singular_value be MathOps.minimum(singular_values).result_value.toFloat()
    
    Set stability_results["max_singular_value"] to max_singular_value
    Set stability_results["min_singular_value"] to min_singular_value
    
    Note: Condition number κ(A) is equal to σ_max / σ_min
    Let condition_number be 0.0
    If min_singular_value does not equal 0.0:
        Set condition_number to max_singular_value / min_singular_value
    Otherwise:
        Set condition_number to Float.POSITIVE_INFINITY
    
    Set stability_results["condition_number_2_norm"] to condition_number
    
    Note: Compute various matrix norms
    Let frobenius_norm be LinAlg.compute_matrix_norm(matrix, "frobenius").toFloat()
    Let one_norm be LinAlg.compute_matrix_norm(matrix, "1").toFloat()
    Let inf_norm be LinAlg.compute_matrix_norm(matrix, "infinity").toFloat()
    
    Set stability_results["frobenius_norm"] to frobenius_norm
    Set stability_results["one_norm"] to one_norm
    Set stability_results["infinity_norm"] to inf_norm
    
    Note: Stability measure-specific analysis
    If stability_measure is equal to "eigenvalue_based":
        Note: Analyze eigenvalue distribution for stability
        Let real_eigenvalues be List[Float]
        Let imaginary_eigenvalues be List[Float]
        
        Set i to 0
        While i is less than eigenvalues.length:
            Let eigenvalue_str be eigenvalues.get(i)
            Let parts be eigenvalue_str.split("+")
            
            If parts.length is greater than or equal to 1:
                Append parts.get(0).toFloat() to real_eigenvalues
            
            If parts.length is greater than or equal to 2:
                Let imag_part be parts.get(1).replace("i", "").toFloat()
                Append imag_part to imaginary_eigenvalues
            Otherwise:
                Append 0.0 to imaginary_eigenvalues
            
            Set i to i plus 1
        
        Note: Check for eigenvalues in right half-plane (unstable)
        Let unstable_eigenvalues be 0
        Set i to 0
        While i is less than real_eigenvalues.length:
            If real_eigenvalues.get(i) is greater than 0.0:
                Set unstable_eigenvalues to unstable_eigenvalues plus 1
            Set i to i plus 1
        
        Set stability_results["unstable_eigenvalue_count"] to unstable_eigenvalues.toFloat()
        Set stability_results["eigenvalue_stability_margin"] to -MathOps.maximum(
            real_eigenvalues.map("toString")
        ).result_value.toFloat()
    
    Otherwise:
        If stability_measure is equal to "singular_value_based":
            Note: Analyze singular value distribution
            Let singular_value_ratio be max_singular_value / min_singular_value
            Set stability_results["singular_value_ratio"] to singular_value_ratio
            
            Note: Numerical rank estimation
            Let machine_epsilon be Constants.get_machine_epsilon("float64").value.toFloat()
            Let rank_threshold be max_singular_value multiplied by machine_epsilon multiplied by rows.toFloat()
            
            Let numerical_rank be 0
            Set i to 0
            While i is less than singular_values.length:
                If singular_values.get(i).toFloat() is greater than rank_threshold:
                    Set numerical_rank to numerical_rank plus 1
                Set i to i plus 1
            
            Set stability_results["numerical_rank"] to numerical_rank.toFloat()
            Set stability_results["rank_deficiency"] to (rows minus numerical_rank).toFloat()
        
        Otherwise:
            If stability_measure is equal to "norm_based":
                Note: Analyze matrix through various norms
                Let norm_consistency_check be frobenius_norm / MathOps.square_root(rows.toString()).result_value.toFloat()
                Set stability_results["norm_consistency_measure"] to norm_consistency_check
                
                Note: Gershgorin circle theorem bounds
                Let max_row_sum be 0.0
                Set i to 0
                While i is less than rows:
                    Let row_sum be 0.0
                    Let j be 0
                    While j is less than cols:
                        If i does not equal j:
                            Set row_sum to row_sum plus MathOps.absolute_value(matrix.get(i).get(j).toString()).result_value.toFloat()
                        Set j to j plus 1
                    
                    If row_sum is greater than max_row_sum:
                        Set max_row_sum to row_sum
                    Set i to i plus 1
                
                Set stability_results["gershgorin_radius_bound"] to max_row_sum
            
            Otherwise:
                Note: Default comprehensive analysis
                Set stability_results["default_stability_score"] to If spectral_radius is less than 1.0: 1.0 Otherwise: 0.0
    
    Note: Compute overall stability score
    Let overall_score be 0.0
    
    Note: Weight factors for different stability indicators
    Let spectral_weight be 0.4
    Let condition_weight be 0.3
    Let eigenvalue_weight be 0.3
    
    Note: Spectral radius contribution
    Let spectral_contribution be spectral_weight multiplied by stability_results.get("spectral_stability_class")
    
    Note: Condition number contribution (inverted minus lower is better)
    Let condition_contribution be 0.0
    If condition_number is less than 100.0:
        Set condition_contribution to condition_weight multiplied by 1.0
    Otherwise:
        If condition_number is less than 10000.0:
            Set condition_contribution to condition_weight multiplied by 0.5
        Otherwise:
            Set condition_contribution to condition_weight multiplied by 0.0
    
    Note: Eigenvalue contribution
    Let eigenvalue_contribution be eigenvalue_weight
    If stability_results.contains_key("unstable_eigenvalue_count"):
        If stability_results.get("unstable_eigenvalue_count") is greater than 0.0:
            Set eigenvalue_contribution to 0.0
    
    Set overall_score to spectral_contribution plus condition_contribution plus eigenvalue_contribution
    Set stability_results["overall_stability_score"] to overall_score
    
    Return stability_results

Process called "compute_spectral_radius" that takes matrix as List[List[Float]] returns Float:
    Note: Compute spectral radius ρ(A) is equal to max|λᵢ| for matrix stability analysis
    Note: Determines asymptotic behavior of matrix powers and iterative methods
    
    If matrix.length is equal to 0:
        Throw Errors.InvalidArgument with "Matrix cannot be empty"
    
    If matrix.get(0).length is equal to 0:
        Throw Errors.InvalidArgument with "Matrix rows cannot be empty"
    
    Let rows be matrix.length
    Let cols be matrix.get(0).length
    
    If rows does not equal cols:
        Throw Errors.InvalidArgument with "Matrix must be square for spectral radius computation"
    
    Note: Create Matrix structure for eigenvalue computation
    Let matrix_struct be LinAlg.create_matrix(matrix, "float64")
    
    Note: Compute eigenvalues using QR algorithm
    Let eigen_decomp be Decomp.eigenvalue_decomposition(matrix_struct, "qr_algorithm")
    Let eigenvalues be eigen_decomp.eigenvalues
    
    Note: Compute magnitude of each eigenvalue
    Let eigenvalue_magnitudes be List[String]
    
    Let i be 0
    While i is less than eigenvalues.length:
        Let eigenvalue be eigenvalues.get(i)
        
        Note: Handle complex eigenvalues: |a plus bi| is equal to sqrt(a^2 plus b^2)
        If eigenvalue.contains("i"):
            Note: Parse complex number
            Let parts be eigenvalue.split("+")
            If parts.length is greater than or equal to 2:
                Let real_part be parts.get(0)
                Let imag_part be parts.get(1).replace("i", "")
                
                Let magnitude be MathOps.square_root(
                    MathOps.add(
                        MathOps.multiply(real_part, real_part).result_value,
                        MathOps.multiply(imag_part, imag_part).result_value
                    ).result_value
                ).result_value
                
                Append magnitude to eigenvalue_magnitudes
            Otherwise:
                Note: Handle negative complex numbers
                Let parts be eigenvalue.split("-")
                If parts.length is greater than or equal to 2:
                    Let real_part be parts.get(0)
                    Let imag_part be "-" plus parts.get(1).replace("i", "")
                    
                    Let magnitude be MathOps.square_root(
                        MathOps.add(
                            MathOps.multiply(real_part, real_part).result_value,
                            MathOps.multiply(imag_part, imag_part).result_value
                        ).result_value
                    ).result_value
                    
                    Append magnitude to eigenvalue_magnitudes
                Otherwise:
                    Let magnitude be MathOps.absolute_value(eigenvalue).result_value
                    Append magnitude to eigenvalue_magnitudes
        Otherwise:
            Note: Real eigenvalue
            Let magnitude be MathOps.absolute_value(eigenvalue).result_value
            Append magnitude to eigenvalue_magnitudes
        
        Set i to i plus 1
    
    Note: Find maximum magnitude
    Let spectral_radius be MathOps.maximum(eigenvalue_magnitudes).result_value
    
    Return spectral_radius.toFloat()

Process called "analyze_matrix_norms" that takes matrix as List[List[Float]], norm_types as List[String] returns Dictionary[String, Float]:
    Note: Analyze matrix norms for stability and conditioning assessment
    Note: Computes operator norms measuring matrix size and conditioning
    
    If matrix.length is equal to 0:
        Throw Errors.InvalidArgument with "Matrix cannot be empty"
    
    If matrix.get(0).length is equal to 0:
        Throw Errors.InvalidArgument with "Matrix rows cannot be empty"
    
    If norm_types.length is equal to 0:
        Throw Errors.InvalidArgument with "Norm types cannot be empty"
    
    Let norm_analysis be Dictionary[String, Float]
    Let rows be matrix.length
    Let cols be matrix.get(0).length
    
    Note: Compute each requested norm type
    Let i be 0
    While i is less than norm_types.length:
        Let norm_type be norm_types.get(i)
        
        If norm_type is equal to "1" Or norm_type is equal to "one":
            Note: 1-norm: max column sum
            Let max_col_sum be 0.0
            
            Let j be 0
            While j is less than cols:
                Let col_sum be 0.0
                Let k be 0
                While k is less than rows:
                    Set col_sum to col_sum plus MathOps.absolute_value(matrix.get(k).get(j).toString()).result_value.toFloat()
                    Set k to k plus 1
                
                If col_sum is greater than max_col_sum:
                    Set max_col_sum to col_sum
                
                Set j to j plus 1
            
            Set norm_analysis["one_norm"] to max_col_sum
        
        Otherwise:
            If norm_type is equal to "2" Or norm_type is equal to "spectral":
                Note: 2-norm: largest singular value
                Let svd_result be Decomp.compute_svd(matrix)
                Let singular_values be svd_result.get("singular_values")
                Let spectral_norm be MathOps.maximum(singular_values).result_value.toFloat()
                
                Set norm_analysis["spectral_norm"] to spectral_norm
                Set norm_analysis["two_norm"] to spectral_norm
            
            Otherwise:
                If norm_type is equal to "infinity" Or norm_type is equal to "inf":
                    Note: Infinity-norm: max row sum
                    Let max_row_sum be 0.0
                    
                    Let k be 0
                    While k is less than rows:
                        Let row_sum be 0.0
                        Let j be 0
                        While j is less than cols:
                            Set row_sum to row_sum plus MathOps.absolute_value(matrix.get(k).get(j).toString()).result_value.toFloat()
                            Set j to j plus 1
                        
                        If row_sum is greater than max_row_sum:
                            Set max_row_sum to row_sum
                        
                        Set k to k plus 1
                    
                    Set norm_analysis["infinity_norm"] to max_row_sum
                
                Otherwise:
                    If norm_type is equal to "frobenius" Or norm_type is equal to "F":
                        Note: Frobenius norm: sqrt(sum of squares)
                        Let sum_of_squares be 0.0
                        
                        Let k be 0
                        While k is less than rows:
                            Let j be 0
                            While j is less than cols:
                                Let element be matrix.get(k).get(j)
                                Set sum_of_squares to sum_of_squares plus (element multiplied by element)
                                Set j to j plus 1
                            Set k to k plus 1
                        
                        Let frobenius_norm be MathOps.square_root(sum_of_squares.toString()).result_value.toFloat()
                        Set norm_analysis["frobenius_norm"] to frobenius_norm
                    
                    Otherwise:
                        If norm_type is equal to "nuclear" Or norm_type is equal to "trace":
                            Note: Nuclear norm: sum of singular values
                            Let svd_result be Decomp.compute_svd(matrix)
                            Let singular_values be svd_result.get("singular_values")
                            
                            Let nuclear_norm be 0.0
                            Let k be 0
                            While k is less than singular_values.length:
                                Set nuclear_norm to nuclear_norm plus singular_values.get(k).toFloat()
                                Set k to k plus 1
                            
                            Set norm_analysis["nuclear_norm"] to nuclear_norm
                        
                        Otherwise:
                            Note: Unknown norm type minus compute Frobenius as default
                            Let frobenius_norm be LinAlg.compute_matrix_norm(matrix, "frobenius").toFloat()
                            Set norm_analysis[norm_type plus "_norm_default_frobenius"] to frobenius_norm
        
        Set i to i plus 1
    
    Note: Compute norm relationships and consistency checks
    If norm_analysis.contains_key("one_norm") And norm_analysis.contains_key("infinity_norm"):
        Let one_norm_val be norm_analysis.get("one_norm")
        Let inf_norm_val be norm_analysis.get("infinity_norm")
        
        Set norm_analysis["one_infinity_ratio"] to one_norm_val / inf_norm_val
        Set norm_analysis["norm_consistency_check"] to MathOps.minimum(List[String] with: one_norm_val.toString(), inf_norm_val.toString()).result_value.toFloat()
    
    If norm_analysis.contains_key("spectral_norm") And norm_analysis.contains_key("frobenius_norm"):
        Let spectral_val be norm_analysis.get("spectral_norm")
        Let frobenius_val be norm_analysis.get("frobenius_norm")
        
        Set norm_analysis["spectral_frobenius_ratio"] to spectral_val / frobenius_val
        
        Note: Theoretical bound: ||A||_2 ≤ ||A||_F ≤ sqrt(rank(A)) multiplied by ||A||_2
        If spectral_val is greater than 0.0:
            Let theoretical_ratio be frobenius_val / spectral_val
            Set norm_analysis["frobenius_spectral_bound_check"] to theoretical_ratio
    
    Note: Matrix size normalization
    Let matrix_dimension be rows.toFloat() multiplied by cols.toFloat()
    
    If norm_analysis.contains_key("frobenius_norm"):
        Let frobenius_normalized be norm_analysis.get("frobenius_norm") / MathOps.square_root(matrix_dimension.toString()).result_value.toFloat()
        Set norm_analysis["frobenius_norm_normalized"] to frobenius_normalized
    
    Note: Condition number estimates using different norms
    If norm_analysis.contains_key("spectral_norm"):
        Let matrix_inverse be LinAlg.matrix_inverse(matrix)
        Let inverse_spectral_norm be LinAlg.compute_matrix_norm(matrix_inverse, "2").toFloat()
        Let condition_number_2 be norm_analysis.get("spectral_norm") multiplied by inverse_spectral_norm
        
        Set norm_analysis["condition_number_2_norm"] to condition_number_2
    
    If norm_analysis.contains_key("one_norm"):
        Let matrix_inverse be LinAlg.matrix_inverse(matrix)
        Let inverse_one_norm be LinAlg.compute_matrix_norm(matrix_inverse, "1").toFloat()
        Let condition_number_1 be norm_analysis.get("one_norm") multiplied by inverse_one_norm
        
        Set norm_analysis["condition_number_1_norm"] to condition_number_1
    
    If norm_analysis.contains_key("infinity_norm"):
        Let matrix_inverse be LinAlg.matrix_inverse(matrix)
        Let inverse_inf_norm be LinAlg.compute_matrix_norm(matrix_inverse, "infinity").toFloat()
        Let condition_number_inf be norm_analysis.get("infinity_norm") multiplied by inverse_inf_norm
        
        Set norm_analysis["condition_number_infinity_norm"] to condition_number_inf
    
    Note: Stability assessment based on norms
    Let max_norm be 0.0
    Let norm_keys be norm_analysis.keys()
    
    Let j be 0
    While j is less than norm_keys.length:
        Let key be norm_keys.get(j)
        If key.contains("norm") And Not key.contains("condition") And Not key.contains("ratio"):
            Let norm_value be norm_analysis.get(key)
            If norm_value is greater than max_norm:
                Set max_norm to norm_value
        Set j to j plus 1
    
    Set norm_analysis["max_computed_norm"] to max_norm
    
    Let stability_score be 0.0
    If max_norm is less than 1.0:
        Set stability_score to 1.0
    Otherwise:
        If max_norm is less than 10.0:
            Set stability_score to 0.7
        Otherwise:
            If max_norm is less than 100.0:
                Set stability_score to 0.4
            Otherwise:
                Set stability_score to 0.0
    
    Set norm_analysis["norm_based_stability_score"] to stability_score
    
    Return norm_analysis

Process called "assess_eigenvalue_stability" that takes matrix as List[List[Float]], perturbation_bounds as Dictionary[String, Float] returns Dictionary[String, Dictionary[String, Float]]:
    Note: Assess eigenvalue stability under matrix perturbations
    Note: Analyzes eigenvalue sensitivity using perturbation theory bounds
    
    If matrix.length is equal to 0:
        Throw Errors.InvalidArgument with "Matrix cannot be empty"
    
    If matrix.get(0).length is equal to 0:
        Throw Errors.InvalidArgument with "Matrix rows cannot be empty"
    
    If perturbation_bounds.size() is equal to 0:
        Throw Errors.InvalidArgument with "Perturbation bounds cannot be empty"
    
    Let rows be matrix.length
    Let cols be matrix.get(0).length
    
    If rows does not equal cols:
        Throw Errors.InvalidArgument with "Matrix must be square for eigenvalue analysis"
    
    Let stability_assessment be Dictionary[String, Dictionary[String, Float]]
    
    Note: Compute eigenvalue decomposition
    Let matrix_struct be LinAlg.create_matrix(matrix, "float64")
    Let eigen_decomp be Decomp.eigenvalue_decomposition(matrix_struct, "qr_algorithm")
    Let eigenvalues be eigen_decomp.eigenvalues
    Let eigenvectors be eigen_decomp.eigenvectors
    
    Note: Extract perturbation parameters
    Let max_perturbation be perturbation_bounds.get("max_perturbation_norm").toString()
    Let perturbation_type be perturbation_bounds.get("perturbation_type").toString()
    
    Note: Analyze each eigenvalue individually
    Let i be 0
    While i is less than eigenvalues.length:
        Let eigenvalue be eigenvalues.get(i)
        Let eigenvalue_analysis be Dictionary[String, Float]
        
        Note: Simple eigenvalue sensitivity (first-order perturbation theory)
        Note: Δλ ≈ v*^T ΔA v / (v*^T v) for simple eigenvalues
        
        Set eigenvalue_analysis["eigenvalue_real_part"] to If eigenvalue.contains("+"): eigenvalue.split("+").get(0).toFloat() Otherwise: eigenvalue.toFloat()
        Set eigenvalue_analysis["eigenvalue_imaginary_part"] to If eigenvalue.contains("+"): eigenvalue.split("+").get(1).replace("i", "").toFloat() Otherwise: 0.0
        
        Note: Compute eigenvalue magnitude
        Let real_part be eigenvalue_analysis.get("eigenvalue_real_part")
        Let imag_part be eigenvalue_analysis.get("eigenvalue_imaginary_part")
        Let eigenvalue_magnitude be MathOps.square_root(
            MathOps.add(
                MathOps.multiply(real_part.toString(), real_part.toString()).result_value,
                MathOps.multiply(imag_part.toString(), imag_part.toString()).result_value
            ).result_value
        ).result_value.toFloat()
        
        Set eigenvalue_analysis["eigenvalue_magnitude"] to eigenvalue_magnitude
        
        Note: For symmetric matrices, eigenvalue condition number is 1
        Let eigenvalue_condition_number be 1.0
        
        If LinAlg.is_symmetric(matrix_struct):
            Set eigenvalue_condition_number to 1.0
            Set eigenvalue_analysis["is_symmetric_eigenvalue"] to 1.0
        Otherwise:
            Note: For general matrices, estimate condition number using separation
            Let min_separation be 1e100
            
            Let j be 0
            While j is less than eigenvalues.length:
                If i does not equal j:
                    Let other_eigenvalue be eigenvalues.get(j)
                    Let other_real be If other_eigenvalue.contains("+"): other_eigenvalue.split("+").get(0).toFloat() Otherwise: other_eigenvalue.toFloat()
                    Let other_imag be If other_eigenvalue.contains("+"): other_eigenvalue.split("+").get(1).replace("i", "").toFloat() Otherwise: 0.0
                    
                    Let separation be MathOps.square_root(
                        MathOps.add(
                            MathOps.multiply(
                                MathOps.subtract(real_part.toString(), other_real.toString()).result_value,
                                MathOps.subtract(real_part.toString(), other_real.toString()).result_value
                            ).result_value,
                            MathOps.multiply(
                                MathOps.subtract(imag_part.toString(), other_imag.toString()).result_value,
                                MathOps.subtract(imag_part.toString(), other_imag.toString()).result_value
                            ).result_value
                        ).result_value
                    ).result_value.toFloat()
                    
                    If separation is less than min_separation:
                        Set min_separation to separation
                
                Set j to j plus 1
            
            Note: Condition number approximation
            If min_separation is greater than 0.0:
                Set eigenvalue_condition_number to 1.0 / min_separation
            Otherwise:
                Set eigenvalue_condition_number to Float.POSITIVE_INFINITY
            
            Set eigenvalue_analysis["is_symmetric_eigenvalue"] to 0.0
        
        Set eigenvalue_analysis["eigenvalue_condition_number"] to eigenvalue_condition_number
        Set eigenvalue_analysis["eigenvalue_separation"] to min_separation
        
        Note: Perturbation bounds for eigenvalue
        Let perturbation_bound be max_perturbation.toFloat() multiplied by eigenvalue_condition_number
        Set eigenvalue_analysis["first_order_perturbation_bound"] to perturbation_bound
        
        Note: Relative perturbation bound
        Let relative_bound be 0.0
        If eigenvalue_magnitude is greater than 0.0:
            Set relative_bound to perturbation_bound / eigenvalue_magnitude
        
        Set eigenvalue_analysis["relative_perturbation_bound"] to relative_bound
        
        Note: Stability classification for this eigenvalue
        If relative_bound is less than 1e-12:
            Set eigenvalue_analysis["stability_class"] to 3.0  Note: 3 is equal to excellent
        Otherwise:
            If relative_bound is less than 1e-6:
                Set eigenvalue_analysis["stability_class"] to 2.0  Note: 2 is equal to good
            Otherwise:
                If relative_bound is less than 1e-3:
                    Set eigenvalue_analysis["stability_class"] to 1.0  Note: 1 is equal to acceptable
                Otherwise:
                    Set eigenvalue_analysis["stability_class"] to 0.0  Note: 0 is equal to poor
        
        Note: Special analysis for structured perturbations
        If perturbation_type is equal to "symmetric":
            Let symmetric_factor be 0.707  Note: sqrt(1/2) for symmetric preservation
            Let structured_bound be perturbation_bound multiplied by symmetric_factor
            Set eigenvalue_analysis["symmetric_perturbation_bound"] to structured_bound
        
        Otherwise:
            If perturbation_type is equal to "sparse":
                Let sparsity_factor be perturbation_bounds.get("sparsity_factor").toString().toFloat()
                Let sparse_bound be perturbation_bound multiplied by (1.0 minus sparsity_factor)
                Set eigenvalue_analysis["sparse_perturbation_bound"] to sparse_bound
        
        Set stability_assessment["eigenvalue_" plus i.toString()] to eigenvalue_analysis
        Set i to i plus 1
    
    Note: Overall eigenvalue stability summary
    Let overall_analysis be Dictionary[String, Float]
    
    Let max_condition_number be 0.0
    Let min_condition_number be Float.POSITIVE_INFINITY
    Let total_condition_number be 0.0
    Let unstable_eigenvalue_count be 0.0
    
    Set i to 0
    While i is less than eigenvalues.length:
        Let eigenvalue_key be "eigenvalue_" plus i.toString()
        Let eigenvalue_data be stability_assessment.get(eigenvalue_key)
        
        Let condition_num be eigenvalue_data.get("eigenvalue_condition_number")
        Let stability_class be eigenvalue_data.get("stability_class")
        
        If condition_num is greater than max_condition_number And condition_num does not equal Float.POSITIVE_INFINITY:
            Set max_condition_number to condition_num
        
        If condition_num is less than min_condition_number:
            Set min_condition_number to condition_num
        
        If condition_num does not equal Float.POSITIVE_INFINITY:
            Set total_condition_number to total_condition_number plus condition_num
        
        If stability_class is less than 1.0:
            Set unstable_eigenvalue_count to unstable_eigenvalue_count plus 1.0
        
        Set i to i plus 1
    
    Set overall_analysis["max_eigenvalue_condition_number"] to max_condition_number
    Set overall_analysis["min_eigenvalue_condition_number"] to min_condition_number
    Set overall_analysis["average_eigenvalue_condition_number"] to total_condition_number / eigenvalues.length.toFloat()
    Set overall_analysis["unstable_eigenvalue_count"] to unstable_eigenvalue_count
    Set overall_analysis["stable_eigenvalue_fraction"] to (eigenvalues.length.toFloat() minus unstable_eigenvalue_count) / eigenvalues.length.toFloat()
    
    Note: Matrix-level stability assessment
    If unstable_eigenvalue_count is equal to 0.0:
        Set overall_analysis["matrix_eigenvalue_stability"] to 1.0  Note: All eigenvalues stable
    Otherwise:
        If unstable_eigenvalue_count is less than or equal to eigenvalues.length.toFloat() / 2.0:
            Set overall_analysis["matrix_eigenvalue_stability"] to 0.5  Note: Partially stable
        Otherwise:
            Set overall_analysis["matrix_eigenvalue_stability"] to 0.0  Note: Mostly unstable
    
    Set stability_assessment["overall_summary"] to overall_analysis
    
    Return stability_assessment

Note: =====================================================================
Note: ITERATIVE METHOD STABILITY OPERATIONS
Note: =====================================================================

Process called "analyze_iterative_stability" that takes iteration_matrix as List[List[Float]], convergence_analysis as Dictionary[String, String] returns Dictionary[String, String]:
    Note: Analyze stability of iterative methods using spectral analysis
    Note: Examines convergence rate and stability of fixed-point iterations
    
    If iteration_matrix.length is equal to 0:
        Throw Errors.InvalidArgument with "Iteration matrix cannot be empty"
    
    If iteration_matrix.get(0).length is equal to 0:
        Throw Errors.InvalidArgument with "Iteration matrix rows cannot be empty"
    
    If convergence_analysis.size() is equal to 0:
        Throw Errors.InvalidArgument with "Convergence analysis cannot be empty"
    
    Let stability_results be Dictionary[String, String]
    Let rows be iteration_matrix.length
    Let cols be iteration_matrix.get(0).length
    
    If rows does not equal cols:
        Throw Errors.InvalidArgument with "Iteration matrix must be square"
    
    Note: Compute spectral radius for convergence analysis
    Let spectral_radius be compute_spectral_radius(iteration_matrix)
    Set stability_results["spectral_radius"] to spectral_radius.toString()
    
    Note: Determine convergence based on spectral radius
    If spectral_radius is less than 1.0:
        Set stability_results["convergence_status"] to "convergent"
        Set stability_results["convergence_rate"] to "geometric"
        
        If spectral_radius is less than 0.1:
            Set stability_results["convergence_speed"] to "fast"
        Otherwise:
            If spectral_radius is less than 0.5:
                Set stability_results["convergence_speed"] to "moderate"
            Otherwise:
                Set stability_results["convergence_speed"] to "slow"
    Otherwise:
        If spectral_radius is equal to 1.0:
            Set stability_results["convergence_status"] to "marginally_convergent"
            Set stability_results["convergence_rate"] to "unknown"
            Set stability_results["convergence_speed"] to "critical"
        Otherwise:
            Set stability_results["convergence_status"] to "divergent"
            Set stability_results["convergence_rate"] to "geometric_divergence"
            Set stability_results["convergence_speed"] to "unstable"
    
    Note: Analyze eigenvalues for detailed stability assessment
    Let matrix_struct be LinAlg.create_matrix(iteration_matrix, "float64")
    Let eigen_decomp be Decomp.eigenvalue_decomposition(matrix_struct, "qr_algorithm")
    Let eigenvalues be eigen_decomp.eigenvalues
    
    Let stable_eigenvalue_count be 0
    Let unstable_eigenvalue_count be 0
    Let marginal_eigenvalue_count be 0
    
    Let i be 0
    While i is less than eigenvalues.length:
        Let eigenvalue be eigenvalues.get(i)
        Let eigenvalue_magnitude be MathOps.absolute_value(eigenvalue).result_value.toFloat()
        
        If eigenvalue_magnitude is less than 1.0:
            Set stable_eigenvalue_count to stable_eigenvalue_count plus 1
        Otherwise:
            If eigenvalue_magnitude is equal to 1.0:
                Set marginal_eigenvalue_count to marginal_eigenvalue_count plus 1
            Otherwise:
                Set unstable_eigenvalue_count to unstable_eigenvalue_count plus 1
        
        Set i to i plus 1
    
    Set stability_results["stable_eigenvalues"] to stable_eigenvalue_count.toString()
    Set stability_results["unstable_eigenvalues"] to unstable_eigenvalue_count.toString()
    Set stability_results["marginal_eigenvalues"] to marginal_eigenvalue_count.toString()
    
    Note: Method-specific stability analysis
    Let method_type be convergence_analysis.get("method_type")
    
    If method_type is equal to "jacobi":
        Set stability_results["method_stability"] to "conditionally_stable"
        Set stability_results["stability_condition"] to "requires_diagonally_dominant_matrix"
        
        Note: Check diagonal dominance
        Let is_diagonally_dominant be true
        Set i to 0
        While i is less than rows:
            Let diagonal_element be MathOps.absolute_value(iteration_matrix.get(i).get(i).toString()).result_value.toFloat()
            Let off_diagonal_sum be 0.0
            
            Let j be 0
            While j is less than cols:
                If i does not equal j:
                    Set off_diagonal_sum to off_diagonal_sum plus MathOps.absolute_value(iteration_matrix.get(i).get(j).toString()).result_value.toFloat()
                Set j to j plus 1
            
            If diagonal_element is less than or equal to off_diagonal_sum:
                Set is_diagonally_dominant to false
                Break
            
            Set i to i plus 1
        
        Set stability_results["diagonal_dominance"] to is_diagonally_dominant.toString()
    
    Otherwise:
        If method_type is equal to "gauss_seidel":
            Set stability_results["method_stability"] to "generally_better_than_jacobi"
            Set stability_results["stability_condition"] to "convergence_for_positive_definite_matrices"
        
        Otherwise:
            If method_type is equal to "sor":
                Let omega be convergence_analysis.get("relaxation_parameter").toFloat()
                
                If omega is greater than 0.0 And omega is less than 2.0:
                    Set stability_results["method_stability"] to "conditionally_stable"
                    Set stability_results["stability_condition"] to "omega_in_range_0_to_2"
                Otherwise:
                    Set stability_results["method_stability"] to "unstable"
                    Set stability_results["stability_condition"] to "omega_outside_stability_range"
                
                Set stability_results["relaxation_parameter"] to omega.toString()
            
            Otherwise:
                If method_type is equal to "conjugate_gradient":
                    Set stability_results["method_stability"] to "excellent_for_spd_matrices"
                    Set stability_results["stability_condition"] to "requires_symmetric_positive_definite_matrix"
                
                Otherwise:
                    Set stability_results["method_stability"] to "method_specific_analysis_required"
                    Set stability_results["stability_condition"] to "depends_on_method_properties"
    
    Note: Provide stability recommendations
    If stability_results.get("convergence_status") is equal to "convergent":
        If stability_results.get("convergence_speed") is equal to "fast":
            Set stability_results["recommendation"] to "excellent_method_proceed_with_confidence"
        Otherwise:
            If stability_results.get("convergence_speed") is equal to "moderate":
                Set stability_results["recommendation"] to "good_method_monitor_convergence_progress"
            Otherwise:
                Set stability_results["recommendation"] to "slow_convergence_consider_preconditioning"
    Otherwise:
        If stability_results.get("convergence_status") is equal to "marginally_convergent":
            Set stability_results["recommendation"] to "critical_stability_use_caution_verify_convergence"
        Otherwise:
            Set stability_results["recommendation"] to "divergent_method_choose_different_approach"
    
    Note: Error propagation analysis
    Let error_amplification_bound be spectral_radius.toString()
    Set stability_results["error_amplification_bound"] to error_amplification_bound
    
    If spectral_radius is less than 1.0:
        Let asymptotic_error_factor be MathOps.divide("1.0", MathOps.subtract("1.0", spectral_radius.toString()).result_value).result_value
        Set stability_results["asymptotic_error_amplification"] to asymptotic_error_factor
    
    Set stability_results["stability_analysis_complete"] to "true"
    
    Return stability_results

Process called "compute_convergence_factor" that takes iteration_scheme as Dictionary[String, String] returns Float:
    Note: Compute convergence factor for iterative method stability assessment
    Note: Measures contraction rate determining convergence speed and stability
    
    If iteration_scheme.size() is equal to 0:
        Throw Errors.InvalidArgument with "Iteration scheme cannot be empty"
    
    Let scheme_type be iteration_scheme.get("type")
    Let matrix_data be iteration_scheme.get("matrix")
    
    If scheme_type is equal to "":
        Throw Errors.InvalidArgument with "Iteration scheme type must be specified"
    
    Note: Parse iteration matrix from string representation
    Let iteration_matrix be LinAlg.parse_matrix_from_string(matrix_data)
    
    Note: Compute spectral radius as primary convergence factor
    Let spectral_radius be compute_spectral_radius(iteration_matrix)
    Let convergence_factor be spectral_radius
    
    Note: Method-specific convergence factor adjustments
    If scheme_type is equal to "jacobi":
        Note: Jacobi iteration: x^(k+1) is equal to D^(-1)(L plus U)x^(k) plus D^(-1)b
        Note: Convergence factor is spectral radius of iteration matrix
        Return convergence_factor
    
    Otherwise:
        If scheme_type is equal to "gauss_seidel":
            Note: Gauss-Seidel typically converges faster than Jacobi
            Note: Theoretical improvement factor approximation
            Let improvement_factor be 0.5  Note: Empirical average improvement
            Return convergence_factor multiplied by improvement_factor
        
        Otherwise:
            If scheme_type is equal to "sor":
                Let omega be iteration_scheme.get("relaxation_parameter").toFloat()
                
                Note: SOR convergence factor depends on relaxation parameter
                If omega is less than or equal to 0.0 Or omega is greater than or equal to 2.0:
                    Return Float.POSITIVE_INFINITY  Note: Divergent outside (0,2)
                
                Note: Optimal omega gives fastest convergence
                Let optimal_omega be iteration_scheme.get("optimal_omega").toFloat()
                
                If optimal_omega is greater than 0.0:
                    Let optimal_factor be optimal_omega minus 1.0
                    Return MathOps.absolute_value(optimal_factor.toString()).result_value.toFloat()
                Otherwise:
                    Note: Estimate SOR convergence factor
                    Let sor_factor be MathOps.absolute_value(MathOps.subtract(omega.toString(), "1.0").result_value).result_value.toFloat()
                    Return If sor_factor is less than convergence_factor: sor_factor Otherwise: convergence_factor
            
            Otherwise:
                If scheme_type is equal to "conjugate_gradient":
                    Note: CG convergence depends on condition number
                    Let condition_number be iteration_scheme.get("condition_number").toFloat()
                    
                    If condition_number is greater than 1.0:
                        Note: CG convergence factor: ((√κ minus 1)/(√κ plus 1))^2
                        Let sqrt_kappa be MathOps.square_root(condition_number.toString()).result_value.toFloat()
                        Let numerator be sqrt_kappa minus 1.0
                        Let denominator be sqrt_kappa plus 1.0
                        
                        If denominator is greater than 0.0:
                            Let ratio be numerator / denominator
                            Return ratio multiplied by ratio
                        Otherwise:
                            Return 0.0
                    Otherwise:
                        Return 0.0  Note: Exact solution in one step for κ is equal to 1
                
                Otherwise:
                    If scheme_type is equal to "gmres":
                        Note: GMRES convergence is more complex, use spectral radius estimate
                        Let residual_reduction be iteration_scheme.get("residual_reduction_factor").toFloat()
                        
                        If residual_reduction is greater than 0.0 And residual_reduction is less than 1.0:
                            Return residual_reduction
                        Otherwise:
                            Return convergence_factor
                    
                    Otherwise:
                        If scheme_type is equal to "bicgstab":
                            Note: BiCGSTAB convergence factor approximation
                            Let bicg_factor be iteration_scheme.get("bicg_convergence_estimate").toFloat()
                            
                            If bicg_factor is greater than 0.0:
                                Return bicg_factor
                            Otherwise:
                                Return convergence_factor multiplied by 0.8  Note: Typical improvement over basic methods
                        
                        Otherwise:
                            If scheme_type is equal to "power_method":
                                Note: Power method convergence: |λ₂/λ₁|
                                Let eigenvalue_ratio be iteration_scheme.get("eigenvalue_ratio").toFloat()
                                
                                If eigenvalue_ratio is greater than 0.0:
                                    Return eigenvalue_ratio
                                Otherwise:
                                    Return convergence_factor
                            
                            Otherwise:
                                Note: Generic iterative method minus use spectral radius
                                Return convergence_factor

Process called "analyze_iteration_error_propagation" that takes error_sequence as List[Float], iteration_count as Integer returns Dictionary[String, Float]:
    Note: Analyze error propagation in iterative computational methods
    Note: Tracks error evolution and amplification across iterations
    
    If error_sequence.length is equal to 0:
        Throw Errors.InvalidArgument with "Error sequence cannot be empty"
    
    If iteration_count is less than or equal to 0:
        Throw Errors.InvalidArgument with "Iteration count must be positive"
    
    Let propagation_analysis be Dictionary[String, Float]
    Let sequence_length be error_sequence.length
    
    Note: Basic error sequence statistics
    Let initial_error be error_sequence.get(0)
    Let final_error be error_sequence.get(sequence_length minus 1)
    
    Set propagation_analysis["initial_error"] to initial_error
    Set propagation_analysis["final_error"] to final_error
    Set propagation_analysis["sequence_length"] to sequence_length.toFloat()
    
    Note: Compute error reduction/amplification
    If initial_error does not equal 0.0:
        Let total_reduction_factor be final_error / initial_error
        Set propagation_analysis["total_error_reduction_factor"] to total_reduction_factor
        
        Let per_iteration_factor be MathOps.power(
            MathOps.absolute_value(total_reduction_factor.toString()).result_value,
            MathOps.divide("1.0", sequence_length.toString()).result_value
        ).result_value.toFloat()
        
        Set propagation_analysis["average_per_iteration_factor"] to per_iteration_factor
    Otherwise:
        Set propagation_analysis["total_error_reduction_factor"] to 0.0
        Set propagation_analysis["average_per_iteration_factor"] to 0.0
    
    Note: Analyze convergence behavior
    Let convergence_ratios be List[Float]
    
    Let i be 1
    While i is less than sequence_length:
        Let previous_error be error_sequence.get(i minus 1)
        Let current_error be error_sequence.get(i)
        
        If previous_error does not equal 0.0:
            Let ratio be current_error / previous_error
            Append ratio to convergence_ratios
        
        Set i to i plus 1
    
    Note: Statistical analysis of convergence ratios
    If convergence_ratios.length is greater than 0:
        Let sum_ratios be 0.0
        Let max_ratio be convergence_ratios.get(0)
        Let min_ratio be convergence_ratios.get(0)
        
        Set i to 0
        While i is less than convergence_ratios.length:
            Let ratio be convergence_ratios.get(i)
            Set sum_ratios to sum_ratios plus ratio
            
            If ratio is greater than max_ratio:
                Set max_ratio to ratio
            
            If ratio is less than min_ratio:
                Set min_ratio to ratio
            
            Set i to i plus 1
        
        Let average_ratio be sum_ratios / convergence_ratios.length.toFloat()
        
        Set propagation_analysis["average_convergence_ratio"] to average_ratio
        Set propagation_analysis["max_convergence_ratio"] to max_ratio
        Set propagation_analysis["min_convergence_ratio"] to min_ratio
        
        Note: Convergence consistency analysis
        Let ratio_variance be 0.0
        Set i to 0
        While i is less than convergence_ratios.length:
            Let deviation be convergence_ratios.get(i) minus average_ratio
            Set ratio_variance to ratio_variance plus (deviation multiplied by deviation)
            Set i to i plus 1
        
        Set ratio_variance to ratio_variance / convergence_ratios.length.toFloat()
        Let ratio_std_dev be MathOps.square_root(ratio_variance.toString()).result_value.toFloat()
        
        Set propagation_analysis["convergence_ratio_variance"] to ratio_variance
        Set propagation_analysis["convergence_ratio_std_dev"] to ratio_std_dev
    
    Note: Classify convergence behavior
    If propagation_analysis.contains_key("average_convergence_ratio"):
        Let avg_ratio be propagation_analysis.get("average_convergence_ratio")
        
        If avg_ratio is less than 0.1:
            Set propagation_analysis["convergence_classification"] to 4.0  Note: 4 is equal to superlinear
        Otherwise:
            If avg_ratio is less than 0.9:
                Set propagation_analysis["convergence_classification"] to 3.0  Note: 3 is equal to linear fast
            Otherwise:
                If avg_ratio is less than 0.99:
                    Set propagation_analysis["convergence_classification"] to 2.0  Note: 2 is equal to linear slow
                Otherwise:
                    If avg_ratio is less than or equal to 1.0:
                        Set propagation_analysis["convergence_classification"] to 1.0  Note: 1 is equal to marginal
                    Otherwise:
                        Set propagation_analysis["convergence_classification"] to 0.0  Note: 0 is equal to divergent
    
    Note: Detect oscillatory behavior
    Let sign_changes be 0
    Let previous_sign be If error_sequence.get(0) is greater than or equal to 0.0: 1 Otherwise: -1
    
    Set i to 1
    While i is less than sequence_length:
        Let current_sign be If error_sequence.get(i) is greater than or equal to 0.0: 1 Otherwise: -1
        If current_sign does not equal previous_sign:
            Set sign_changes to sign_changes plus 1
            Set previous_sign to current_sign
        Set i to i plus 1
    
    Set propagation_analysis["sign_changes"] to sign_changes.toFloat()
    
    If sign_changes is greater than sequence_length / 4:
        Set propagation_analysis["oscillatory_behavior"] to 1.0  Note: 1 is equal to oscillatory
    Otherwise:
        Set propagation_analysis["oscillatory_behavior"] to 0.0  Note: 0 is equal to monotonic
    
    Note: Estimate remaining iterations to convergence
    If propagation_analysis.contains_key("average_convergence_ratio") And propagation_analysis.get("average_convergence_ratio") is less than 1.0:
        Let target_tolerance be 1e-12
        Let current_error be final_error
        Let conv_ratio be propagation_analysis.get("average_convergence_ratio")
        
        If current_error is greater than target_tolerance And conv_ratio is greater than 0.0:
            Let remaining_iterations be MathOps.log(
                MathOps.divide(target_tolerance.toString(), current_error.toString()).result_value
            ).result_value.toFloat() / MathOps.log(conv_ratio.toString()).result_value.toFloat()
            
            Set propagation_analysis["estimated_remaining_iterations"] to remaining_iterations
        Otherwise:
            Set propagation_analysis["estimated_remaining_iterations"] to 0.0
    
    Note: Error growth pattern analysis
    Let monotonic_decrease be true
    Set i to 1
    While i is less than sequence_length:
        If MathOps.absolute_value(error_sequence.get(i).toString()).result_value.toFloat() is greater than 
           MathOps.absolute_value(error_sequence.get(i minus 1).toString()).result_value.toFloat():
            Set monotonic_decrease to false
            Break
        Set i to i plus 1
    
    Set propagation_analysis["monotonic_decrease"] to If monotonic_decrease: 1.0 Otherwise: 0.0
    
    Return propagation_analysis

Process called "establish_convergence_criteria" that takes method_specification as Dictionary[String, String], stability_requirements as Dictionary[String, Float] returns Dictionary[String, String]:
    Note: Establish convergence criteria ensuring iterative method stability
    Note: Determines stopping criteria balancing accuracy and stability
    
    If method_specification.size() is equal to 0:
        Throw Errors.InvalidArgument with "Method specification cannot be empty"
    
    If stability_requirements.size() is equal to 0:
        Throw Errors.InvalidArgument with "Stability requirements cannot be empty"
    
    Let convergence_criteria be Dictionary[String, String]
    
    Note: Extract method properties
    Let method_type be method_specification.get("type")
    Let problem_size be method_specification.get("problem_size")
    Let condition_number be method_specification.get("condition_number")
    
    Note: Extract stability requirements
    Let target_accuracy be stability_requirements.get("target_accuracy").toString()
    Let max_iterations be stability_requirements.get("max_iterations").toString()
    Let stability_margin be stability_requirements.get("stability_margin").toString()
    
    Note: Machine precision considerations
    Let machine_epsilon be Constants.get_machine_epsilon("float64").value
    
    Note: Absolute tolerance based on target accuracy and machine precision
    Let absolute_tolerance be MathOps.maximum(List[String] with: target_accuracy, MathOps.multiply(machine_epsilon, "100.0").result_value).result_value
    Set convergence_criteria["absolute_tolerance"] to absolute_tolerance
    
    Note: Relative tolerance based on problem conditioning
    Let relative_tolerance_base be target_accuracy
    
    If condition_number does not equal "":
        Let condition_adjusted_tolerance be MathOps.multiply(
            relative_tolerance_base, 
            MathOps.square_root(condition_number).result_value
        ).result_value
        Set convergence_criteria["relative_tolerance"] to condition_adjusted_tolerance
    Otherwise:
        Set convergence_criteria["relative_tolerance"] to relative_tolerance_base
    
    Note: Method-specific convergence criteria
    If method_type is equal to "conjugate_gradient":
        Set convergence_criteria["primary_criterion"] to "residual_norm_reduction"
        Set convergence_criteria["secondary_criterion"] to "solution_change_norm"
        
        Note: CG-specific: ||r_k|| / ||r_0|| is less than tolerance
        Set convergence_criteria["residual_reduction_factor"] to target_accuracy
        
        Note: CG should converge in at most n iterations theoretically
        If problem_size does not equal "":
            Set convergence_criteria["theoretical_max_iterations"] to problem_size
        
        Set convergence_criteria["stagnation_detection"] to "relative_residual_improvement"
        Set convergence_criteria["stagnation_threshold"] to MathOps.multiply(machine_epsilon, "1000.0").result_value
    
    Otherwise:
        If method_type is equal to "gmres":
            Set convergence_criteria["primary_criterion"] to "residual_norm_absolute"
            Set convergence_criteria["secondary_criterion"] to "residual_norm_relative"
            
            Set convergence_criteria["restart_criterion"] to "memory_limit_or_stagnation"
            Set convergence_criteria["restart_frequency"] to method_specification.get("restart_parameter")
        
        Otherwise:
            If method_type is equal to "jacobi" Or method_type is equal to "gauss_seidel":
                Set convergence_criteria["primary_criterion"] to "solution_change_norm"
                Set convergence_criteria["secondary_criterion"] to "residual_norm"
                
                Note: Stationary methods: ||x_k+1 minus x_k|| is less than tolerance
                Set convergence_criteria["solution_change_tolerance"] to absolute_tolerance
                
                Note: Also check residual for verification
                Set convergence_criteria["residual_verification_tolerance"] to MathOps.multiply(
                    absolute_tolerance, "10.0"
                ).result_value
            
            Otherwise:
                If method_type is equal to "sor":
                    Set convergence_criteria["primary_criterion"] to "solution_change_norm"
                    Set convergence_criteria["omega_sensitivity_check"] to "true"
                    
                    Note: SOR convergence depends on omega parameter
                    Let omega be method_specification.get("relaxation_parameter")
                    If omega does not equal "":
                        Set convergence_criteria["omega_value"] to omega
                        
                        Note: Check if omega is in stable range (0, 2)
                        If omega.toFloat() is less than or equal to 0.0 Or omega.toFloat() is greater than or equal to 2.0:
                            Set convergence_criteria["omega_warning"] to "omega_outside_stability_range"
                
                Otherwise:
                    Note: Generic iterative method
                    Set convergence_criteria["primary_criterion"] to "combined_residual_and_solution_change"
                    Set convergence_criteria["secondary_criterion"] to "relative_improvement_stagnation"
    
    Note: Stability-enhanced stopping criteria
    Set convergence_criteria["max_iterations"] to max_iterations
    
    Note: Stagnation detection
    Set convergence_criteria["stagnation_window"] to "5"
    Set convergence_criteria["stagnation_improvement_threshold"] to MathOps.multiply(
        absolute_tolerance, "0.1"
    ).result_value
    
    Note: Divergence detection
    Let divergence_threshold be MathOps.multiply("1.0", MathOps.power("10.0", "6").result_value).result_value
    Set convergence_criteria["divergence_threshold"] to divergence_threshold
    Set convergence_criteria["divergence_detection"] to "error_growth_monitoring"
    
    Note: Adaptive tolerance adjustment
    If stability_requirements.contains_key("adaptive_tolerance") And stability_requirements.get("adaptive_tolerance").toString() is equal to "true":
        Set convergence_criteria["adaptive_tolerance_enabled"] to "true"
        Set convergence_criteria["tolerance_tightening_factor"] to "0.1"
        Set convergence_criteria["tolerance_relaxation_factor"] to "2.0"
        Set convergence_criteria["adaptation_trigger"] to "convergence_rate_analysis"
    
    Note: Multi-level convergence criteria
    Set convergence_criteria["level_1_tolerance"] to MathOps.multiply(absolute_tolerance, "10.0").result_value
    Set convergence_criteria["level_2_tolerance"] to absolute_tolerance
    Set convergence_criteria["level_3_tolerance"] to MathOps.multiply(absolute_tolerance, "0.1").result_value
    
    Note: Verification and post-convergence checks
    Set convergence_criteria["post_convergence_verification"] to "residual_and_backward_error_check"
    Set convergence_criteria["verification_tolerance_factor"] to "100.0"
    
    Note: Provide convergence strategy recommendations
    If method_type is equal to "conjugate_gradient":
        Set convergence_criteria["recommended_strategy"] to "monitor_residual_norm_with_restart_if_stagnant"
    Otherwise:
        If method_type is equal to "gmres":
            Set convergence_criteria["recommended_strategy"] to "use_right_preconditioning_with_adaptive_restart"
        Otherwise:
            Set convergence_criteria["recommended_strategy"] to "combine_solution_change_and_residual_monitoring"
    
    Set convergence_criteria["criteria_established"] to "true"
    
    Return convergence_criteria

Note: =====================================================================
Note: DISCRETIZATION STABILITY OPERATIONS
Note: =====================================================================

Process called "analyze_discretization_stability" that takes discretization_scheme as Dictionary[String, String], mesh_parameters as Dictionary[String, Float] returns Dictionary[String, String]:
    Note: Analyze stability of discretization schemes for differential equations
    Note: Examines CFL conditions and stability restrictions for numerical schemes
    
    If discretization_scheme.size() is equal to 0:
        Throw Errors.InvalidArgument with "Discretization scheme cannot be empty"
    
    If mesh_parameters.size() is equal to 0:
        Throw Errors.InvalidArgument with "Mesh parameters cannot be empty"
    
    Let stability_analysis be Dictionary[String, String]
    
    Let scheme_type be discretization_scheme.get("type")
    Let time_stepping be discretization_scheme.get("time_stepping")
    Let spatial_discretization be discretization_scheme.get("spatial_discretization")
    
    Let delta_t be mesh_parameters.get("time_step").toString()
    Let delta_x be mesh_parameters.get("spatial_step").toString()
    Let wave_speed be mesh_parameters.get("characteristic_speed").toString()
    
    Set stability_analysis["scheme_type"] to scheme_type
    Set stability_analysis["time_stepping_method"] to time_stepping
    Set stability_analysis["spatial_method"] to spatial_discretization
    
    Note: CFL number calculation
    Let cfl_number be MathOps.divide(
        MathOps.multiply(wave_speed, delta_t).result_value,
        delta_x
    ).result_value
    
    Set stability_analysis["cfl_number"] to cfl_number
    
    Note: Scheme-specific stability analysis
    If scheme_type is equal to "finite_difference":
        If time_stepping is equal to "explicit":
            Set stability_analysis["stability_condition"] to "cfl_condition_required"
            
            If spatial_discretization is equal to "central":
                Set stability_analysis["cfl_limit"] to "1.0"
                Set stability_analysis["stability_requirement"] to "cfl_number_less_than_or_equal_1"
            Otherwise:
                If spatial_discretization is equal to "upwind":
                    Set stability_analysis["cfl_limit"] to "1.0"
                    Set stability_analysis["stability_requirement"] to "cfl_number_less_than_or_equal_1"
                Otherwise:
                    Set stability_analysis["cfl_limit"] to "scheme_dependent"
            
            If MathOps.is_less_than_or_equal(cfl_number, stability_analysis.get("cfl_limit")).result_value is equal to "true":
                Set stability_analysis["stability_status"] to "stable"
            Otherwise:
                Set stability_analysis["stability_status"] to "unstable"
        
        Otherwise:
            If time_stepping is equal to "implicit":
                Set stability_analysis["stability_condition"] to "unconditionally_stable"
                Set stability_analysis["cfl_limit"] to "no_limit"
                Set stability_analysis["stability_status"] to "stable"
                Set stability_analysis["stability_requirement"] to "none_unconditionally_stable"
            
            Otherwise:
                If time_stepping is equal to "crank_nicolson":
                    Set stability_analysis["stability_condition"] to "unconditionally_stable"
                    Set stability_analysis["cfl_limit"] to "no_limit"
                    Set stability_analysis["stability_status"] to "stable"
                    Set stability_analysis["accuracy_note"] to "second_order_accurate_in_time"
    
    Otherwise:
        If scheme_type is equal to "finite_element":
            Set stability_analysis["stability_condition"] to "depends_on_basis_functions_and_quadrature"
            
            If time_stepping is equal to "explicit":
                Set stability_analysis["cfl_limit"] to "element_dependent"
                Let element_factor be mesh_parameters.get("element_stability_factor").toString()
                If element_factor does not equal "":
                    Let modified_cfl_limit be MathOps.multiply("1.0", element_factor).result_value
                    Set stability_analysis["cfl_limit"] to modified_cfl_limit
            Otherwise:
                Set stability_analysis["cfl_limit"] to "no_limit_if_implicit"
        
        Otherwise:
            If scheme_type is equal to "finite_volume":
                Set stability_analysis["stability_condition"] to "flux_dependent_cfl_condition"
                
                Let flux_method be discretization_scheme.get("flux_method")
                If flux_method is equal to "lax_friedrichs":
                    Set stability_analysis["cfl_limit"] to "1.0"
                Otherwise:
                    If flux_method is equal to "upwind":
                        Set stability_analysis["cfl_limit"] to "1.0"
                    Otherwise:
                        Set stability_analysis["cfl_limit"] to "flux_method_dependent"
            
            Otherwise:
                Set stability_analysis["stability_condition"] to "scheme_specific_analysis_required"
                Set stability_analysis["cfl_limit"] to "unknown"
    
    Note: Von Neumann stability analysis indication
    If stability_analysis.get("stability_status") is equal to "stable":
        Set stability_analysis["von_neumann_analysis"] to "amplification_factor_bounded"
    Otherwise:
        If stability_analysis.get("stability_status") is equal to "unstable":
            Set stability_analysis["von_neumann_analysis"] to "amplification_factor_exceeds_unity"
        Otherwise:
            Set stability_analysis["von_neumann_analysis"] to "requires_detailed_analysis"
    
    Note: Provide stability recommendations
    If stability_analysis.get("stability_status") is equal to "unstable":
        Set stability_analysis["recommendation"] to "reduce_time_step_or_use_implicit_method"
        Let stable_time_step be MathOps.multiply(
            delta_t, 
            MathOps.divide(stability_analysis.get("cfl_limit"), cfl_number).result_value
        ).result_value
        Set stability_analysis["recommended_time_step"] to stable_time_step
    Otherwise:
        Set stability_analysis["recommendation"] to "current_parameters_stable"
    
    Note: Accuracy vs stability trade-off
    Set stability_analysis["accuracy_order_time"] to discretization_scheme.get("temporal_accuracy_order")
    Set stability_analysis["accuracy_order_space"] to discretization_scheme.get("spatial_accuracy_order")
    
    If stability_analysis.get("stability_status") is equal to "stable":
        Set stability_analysis["stability_margin"] to MathOps.subtract(
            stability_analysis.get("cfl_limit"), cfl_number
        ).result_value
    
    Set stability_analysis["analysis_complete"] to "true"
    
    Return stability_analysis

Process called "verify_cfl_condition" that takes scheme_parameters as Dictionary[String, Float], domain_discretization as Dictionary[String, Float] returns Boolean:
    Note: Verify Courant-Friedrichs-Lewy condition for scheme stability
    Note: CFL is equal to c·Δt/Δx ≤ 1 for explicit finite difference stability
    
    If scheme_parameters.size() is equal to 0:
        Throw Errors.InvalidArgument with "Scheme parameters cannot be empty"
    
    If domain_discretization.size() is equal to 0:
        Throw Errors.InvalidArgument with "Domain discretization cannot be empty"
    
    Note: Extract parameters
    Let characteristic_speed be scheme_parameters.get("characteristic_speed").toString()
    Let time_step be scheme_parameters.get("time_step").toString()
    Let spatial_step be domain_discretization.get("spatial_step").toString()
    Let scheme_type be scheme_parameters.get("scheme_type").toString()
    
    Note: Compute CFL number
    Let cfl_number be MathOps.divide(
        MathOps.multiply(characteristic_speed, time_step).result_value,
        spatial_step
    ).result_value
    
    Note: Determine CFL limit based on scheme type
    Let cfl_limit be "1.0"  Note: Default limit for most explicit schemes
    
    If scheme_type is equal to "lax_friedrichs":
        Set cfl_limit to "1.0"
    Otherwise:
        If scheme_type is equal to "upwind":
            Set cfl_limit to "1.0"
        Otherwise:
            If scheme_type is equal to "central_difference":
                Set cfl_limit to "1.0"
            Otherwise:
                If scheme_type is equal to "lax_wendroff":
                    Set cfl_limit to "1.0"
                Otherwise:
                    If scheme_type is equal to "leap_frog":
                        Set cfl_limit to "1.0"
                    Otherwise:
                        If scheme_type is equal to "runge_kutta":
                            Let rk_order be scheme_parameters.get("rk_order").toString()
                            If rk_order is equal to "4":
                                Set cfl_limit to "2.785"  Note: RK4 stability limit
                            Otherwise:
                                Set cfl_limit to "1.0"  Note: Conservative default
                        Otherwise:
                            Note: Unknown scheme minus use conservative limit
                            Set cfl_limit to "0.5"
    
    Note: Multi-dimensional CFL condition
    If domain_discretization.contains_key("spatial_step_y"):
        Let spatial_step_y be domain_discretization.get("spatial_step_y").toString()
        Let cfl_y be MathOps.divide(
            MathOps.multiply(characteristic_speed, time_step).result_value,
            spatial_step_y
        ).result_value
        
        Note: 2D CFL condition: CFL_x plus CFL_y ≤ CFL_limit
        Let total_cfl be MathOps.add(cfl_number, cfl_y).result_value
        
        If domain_discretization.contains_key("spatial_step_z"):
            Let spatial_step_z be domain_discretization.get("spatial_step_z").toString()
            Let cfl_z be MathOps.divide(
                MathOps.multiply(characteristic_speed, time_step).result_value,
                spatial_step_z
            ).result_value
            
            Note: 3D CFL condition: CFL_x plus CFL_y plus CFL_z ≤ CFL_limit
            Set total_cfl to MathOps.add(total_cfl, cfl_z).result_value
        
        Return MathOps.is_less_than_or_equal(total_cfl, cfl_limit).result_value is equal to "true"
    Otherwise:
        Note: 1D CFL condition: CFL ≤ CFL_limit
        Return MathOps.is_less_than_or_equal(cfl_number, cfl_limit).result_value is equal to "true"

Process called "analyze_von_neumann_stability" that takes finite_difference_scheme as Dictionary[String, String] returns Dictionary[String, String]:
    Note: Analyze von Neumann stability using Fourier analysis
    Note: Examines amplification factor for all Fourier modes
    
    If finite_difference_scheme.size() is equal to 0:
        Throw Errors.InvalidArgument with "Finite difference scheme cannot be empty"
    
    Let stability_analysis be Dictionary[String, String]
    
    Let scheme_type be finite_difference_scheme.get("type")
    Let cfl_number be finite_difference_scheme.get("cfl_number")
    
    Set stability_analysis["scheme_type"] to scheme_type
    Set stability_analysis["cfl_number"] to cfl_number
    
    Note: Analyze amplification factor for common schemes
    If scheme_type is equal to "forward_euler_central":
        Note: G is equal to 1 minus 4r*sin^2(θ/2) where r is equal to CFL number
        Set stability_analysis["amplification_factor"] to "1 minus 4*r*sin^2(theta/2)"
        Set stability_analysis["stability_condition"] to "unconditionally_unstable"
        Set stability_analysis["max_amplification"] to "unbounded"
    
    Otherwise:
        If scheme_type is equal to "forward_euler_upwind":
            Note: G is equal to 1 minus r plus r*cos(θ) minus i*r*sin(θ)
            Set stability_analysis["amplification_factor"] to "1 minus r*(1 minus cos(theta)) minus i*r*sin(theta)"
            
            If MathOps.is_less_than_or_equal(cfl_number, "1.0").result_value is equal to "true":
                Set stability_analysis["stability_condition"] to "stable"
                Set stability_analysis["max_amplification"] to "1.0"
            Otherwise:
                Set stability_analysis["stability_condition"] to "unstable"
                Set stability_analysis["max_amplification"] to cfl_number
        
        Otherwise:
            If scheme_type is equal to "lax_friedrichs":
                Note: G is equal to cos(θ) minus i*r*sin(θ)
                Set stability_analysis["amplification_factor"] to "cos(theta) minus i*r*sin(theta)"
                
                Let max_amplification be MathOps.square_root(
                    MathOps.add(
                        "1.0",
                        MathOps.multiply(
                            MathOps.multiply(cfl_number, cfl_number).result_value,
                            "-1.0"
                        ).result_value
                    ).result_value
                ).result_value
                
                If MathOps.is_less_than_or_equal(cfl_number, "1.0").result_value is equal to "true":
                    Set stability_analysis["stability_condition"] to "stable"
                    Set stability_analysis["max_amplification"] to "1.0"
                Otherwise:
                    Set stability_analysis["stability_condition"] to "unstable"
                    Set stability_analysis["max_amplification"] to max_amplification
            
            Otherwise:
                If scheme_type is equal to "lax_wendroff":
                    Note: G is equal to 1 minus r^2(1 minus cos(θ)) minus ir*sin(θ)
                    Set stability_analysis["amplification_factor"] to "1 minus r^2*(1 minus cos(theta)) minus i*r*sin(theta)"
                    
                    If MathOps.is_less_than_or_equal(cfl_number, "1.0").result_value is equal to "true":
                        Set stability_analysis["stability_condition"] to "stable"
                        Set stability_analysis["max_amplification"] to "1.0"
                    Otherwise:
                        Set stability_analysis["stability_condition"] to "unstable"
                        Let unstable_amp be MathOps.add(
                            "1.0",
                            MathOps.multiply(
                                MathOps.subtract(
                                    MathOps.multiply(cfl_number, cfl_number).result_value,
                                    "1.0"
                                ).result_value,
                                "2.0"
                            ).result_value
                        ).result_value
                        Set stability_analysis["max_amplification"] to unstable_amp
                
                Otherwise:
                    If scheme_type is equal to "backward_euler":
                        Note: G is equal to 1 / (1 plus r*(1 minus cos(θ)) plus i*r*sin(θ))
                        Set stability_analysis["amplification_factor"] to "1 / (1 plus r*(1 minus cos(theta)) plus i*r*sin(theta))"
                        Set stability_analysis["stability_condition"] to "unconditionally_stable"
                        Set stability_analysis["max_amplification"] to "1.0"
                    
                    Otherwise:
                        If scheme_type is equal to "crank_nicolson":
                            Note: G is equal to (1 minus r/2*(1 minus cos(θ)) minus ir/2*sin(θ)) / (1 plus r/2*(1 minus cos(θ)) plus ir/2*sin(θ))
                            Set stability_analysis["amplification_factor"] to "rational_function_of_theta"
                            Set stability_analysis["stability_condition"] to "unconditionally_stable"
                            Set stability_analysis["max_amplification"] to "1.0"
                        
                        Otherwise:
                            Set stability_analysis["amplification_factor"] to "scheme_specific_analysis_required"
                            Set stability_analysis["stability_condition"] to "unknown"
                            Set stability_analysis["max_amplification"] to "requires_computation"
    
    Note: Phase and amplitude analysis
    If stability_analysis.get("stability_condition") is equal to "stable":
        Set stability_analysis["amplitude_behavior"] to "non_increasing"
        Set stability_analysis["phase_error_analysis"] to "dispersion_relation_preserving"
    Otherwise:
        If stability_analysis.get("stability_condition") is equal to "unstable":
            Set stability_analysis["amplitude_behavior"] to "growing"
            Set stability_analysis["phase_error_analysis"] to "dispersion_modified"
        Otherwise:
            Set stability_analysis["amplitude_behavior"] to "analysis_required"
            Set stability_analysis["phase_error_analysis"] to "analysis_required"
    
    Note: Recommendations based on analysis
    If stability_analysis.get("stability_condition") is equal to "stable":
        Set stability_analysis["recommendation"] to "scheme_stable_proceed"
    Otherwise:
        If stability_analysis.get("stability_condition") is equal to "unstable":
            Set stability_analysis["recommendation"] to "reduce_cfl_or_use_implicit_method"
        Otherwise:
            Set stability_analysis["recommendation"] to "detailed_stability_analysis_required"
    
    Set stability_analysis["von_neumann_analysis_complete"] to "true"
    
    Return stability_analysis

Process called "compute_stability_region" that takes numerical_method as Dictionary[String, String] returns Dictionary[String, List[Float]]:
    Note: Compute stability region in complex plane for numerical method
    Note: Determines parameter values ensuring stability of numerical scheme
    
    If numerical_method.size() is equal to 0:
        Throw Errors.InvalidArgument with "Numerical method cannot be empty"
    
    Let stability_region be Dictionary[String, List[Float]]
    Let method_type be numerical_method.get("type")
    
    Note: Compute stability boundary points in complex plane
    If method_type is equal to "forward_euler":
        Note: Stability region: |1 plus z| ≤ 1 (unit circle centered at -1)
        Let boundary_real be List[Float]
        Let boundary_imag be List[Float]
        
        Let theta be 0.0
        While theta is less than or equal to 6.284:  Note: 2π
            Let real_part be -1.0 plus MathOps.cos(theta.toString()).result_value.toFloat()
            Let imag_part be MathOps.sin(theta.toString()).result_value.toFloat()
            
            Append real_part to boundary_real
            Append imag_part to boundary_imag
            
            Set theta to theta plus 0.1
        
        Set stability_region["boundary_real"] to boundary_real
        Set stability_region["boundary_imaginary"] to boundary_imag
        Set stability_region["region_type"] to List[Float] with: 1.0  Note: 1 is equal to disk
        Set stability_region["stability_limit_real"] to List[Float] with: -2.0
        Set stability_region["stability_limit_imaginary"] to List[Float] with: 0.0
    
    Otherwise:
        If method_type is equal to "backward_euler":
            Note: Stability region: entire left half-plane (Re(z) is less than 0)
            Set stability_region["boundary_real"] to List[Float] with: 0.0
            Set stability_region["boundary_imaginary"] to List[Float] with: -1000.0, 1000.0
            Set stability_region["region_type"] to List[Float] with: 2.0  Note: 2 is equal to half-plane
            Set stability_region["stability_limit_real"] to List[Float] with: Float.NEGATIVE_INFINITY
            Set stability_region["stability_limit_imaginary"] to List[Float] with: Float.POSITIVE_INFINITY
        
        Otherwise:
            If method_type is equal to "runge_kutta_4":
                Note: RK4 stability region (approximately)
                Let boundary_real be List[Float]
                Let boundary_imag be List[Float]
                
                Let theta be 0.0
                While theta is less than or equal to 6.284:
                    Let radius be 2.785  Note: Approximate RK4 stability radius
                    Let real_part be radius multiplied by MathOps.cos(theta.toString()).result_value.toFloat() minus 1.5
                    Let imag_part be radius multiplied by MathOps.sin(theta.toString()).result_value.toFloat()
                    
                    Append real_part to boundary_real
                    Append imag_part to boundary_imag
                    
                    Set theta to theta plus 0.1
                
                Set stability_region["boundary_real"] to boundary_real
                Set stability_region["boundary_imaginary"] to boundary_imag
                Set stability_region["region_type"] to List[Float] with: 3.0  Note: 3 is equal to complex shape
                Set stability_region["stability_limit_real"] to List[Float] with: -2.785
                Set stability_region["stability_limit_imaginary"] to List[Float] with: 2.785
            
            Otherwise:
                If method_type is equal to "adams_bashforth_2":
                    Note: AB2 stability region
                    Let boundary_real be List[Float]
                    Let boundary_imag be List[Float]
                    
                    Note: Approximate AB2 stability boundary
                    Let theta be 0.0
                    While theta is less than or equal to 6.284:
                        Let real_part be -1.0 plus 0.5 multiplied by MathOps.cos(theta.toString()).result_value.toFloat()
                        Let imag_part be 0.866 multiplied by MathOps.sin(theta.toString()).result_value.toFloat()  Note: sqrt(3)/2
                        
                        Append real_part to boundary_real
                        Append imag_part to boundary_imag
                        
                        Set theta to theta plus 0.1
                    
                    Set stability_region["boundary_real"] to boundary_real
                    Set stability_region["boundary_imaginary"] to boundary_imag
                    Set stability_region["region_type"] to List[Float] with: 1.0
                    Set stability_region["stability_limit_real"] to List[Float] with: -1.0
                    Set stability_region["stability_limit_imaginary"] to List[Float] with: 0.866
                
                Otherwise:
                    If method_type is equal to "trapezoidal":
                        Note: Trapezoidal rule (Crank-Nicolson): entire left half-plane
                        Set stability_region["boundary_real"] to List[Float] with: 0.0
                        Set stability_region["boundary_imaginary"] to List[Float] with: -1000.0, 1000.0
                        Set stability_region["region_type"] to List[Float] with: 2.0
                        Set stability_region["stability_limit_real"] to List[Float] with: Float.NEGATIVE_INFINITY
                        Set stability_region["stability_limit_imaginary"] to List[Float] with: Float.POSITIVE_INFINITY
                    
                    Otherwise:
                        Note: Unknown method minus provide generic circular region
                        Let boundary_real be List[Float]
                        Let boundary_imag be List[Float]
                        
                        Let theta be 0.0
                        While theta is less than or equal to 6.284:
                            Let real_part is equal to MathOps.cos(theta.toString()).result_value.toFloat()
                            Let imag_part is equal to MathOps.sin(theta.toString()).result_value.toFloat()
                            
                            Append real_part to boundary_real
                            Append imag_part to boundary_imag
                            
                            Set theta to theta plus 0.1
                        
                        Set stability_region["boundary_real"] to boundary_real
                        Set stability_region["boundary_imaginary"] to boundary_imag
                        Set stability_region["region_type"] to List[Float] with: 0.0  Note: 0 is equal to unknown/generic
                        Set stability_region["stability_limit_real"] to List[Float] with: -1.0
                        Set stability_region["stability_limit_imaginary"] to List[Float] with: 1.0
    
    Note: Additional stability region properties
    Let real_boundary be stability_region.get("boundary_real")
    Let imag_boundary is equal to stability_region.get("boundary_imaginary")
    
    If real_boundary.length is greater than 0:
        Let min_real be real_boundary.get(0)
        Let max_real be real_boundary.get(0)
        
        Let i be 0
        While i is less than real_boundary.length:
            Let val be real_boundary.get(i)
            If val is less than min_real:
                Set min_real to val
            If val is greater than max_real:
                Set max_real to val
            Set i to i plus 1
        
        Set stability_region["region_extent_real_min"] to List[Float] with: min_real
        Set stability_region["region_extent_real_max"] to List[Float] with: max_real
    
    If imag_boundary.length is greater than 0:
        Let min_imag be imag_boundary.get(0)
        Let max_imag be imag_boundary.get(0)
        
        Let i be 0
        While i is less than imag_boundary.length:
            Let val be imag_boundary.get(i)
            If val is less than min_imag:
                Set min_imag to val
            If val is greater than max_imag:
                Set max_imag to val
            Set i to i plus 1
        
        Set stability_region["region_extent_imag_min"] to List[Float] with: min_imag
        Set stability_region["region_extent_imag_max"] to List[Float] with: max_imag
    
    Return stability_region

Note: =====================================================================
Note: ERROR MITIGATION OPERATIONS
Note: =====================================================================

Process called "implement_error_mitigation_strategies" that takes error_analysis as Dictionary[String, String], mitigation_options as List[String] returns Dictionary[String, String]:
    Note: Implement error mitigation strategies for improved numerical stability
    Note: Applies techniques like pivoting, scaling, iterative refinement
    
    If error_analysis.size() is equal to 0:
        Throw Errors.InvalidArgument with "Error analysis cannot be empty"
    
    If mitigation_options.length is equal to 0:
        Throw Errors.InvalidArgument with "Mitigation options cannot be empty"
    
    Let mitigation_results be Dictionary[String, String]
    
    Let error_type be error_analysis.get("primary_error_type")
    Let error_magnitude be error_analysis.get("error_magnitude")
    Let stability_status be error_analysis.get("stability_status")
    
    Set mitigation_results["original_error_type"] to error_type
    Set mitigation_results["original_error_magnitude"] to error_magnitude
    
    Note: Apply each requested mitigation strategy
    Let i be 0
    While i is less than mitigation_options.length:
        Let strategy be mitigation_options.get(i)
        
        If strategy is equal to "pivoting":
            If error_type is equal to "numerical_instability" Or error_type is equal to "conditioning_issues":
                Set mitigation_results["pivoting_applied"] to "partial_pivoting_with_row_interchanges"
                Set mitigation_results["pivoting_effectiveness"] to "high_for_lu_factorization"
                Set mitigation_results["expected_improvement"] to "condition_number_reduction"
            Otherwise:
                Set mitigation_results["pivoting_applied"] to "not_applicable_to_error_type"
        
        Otherwise:
            If strategy is equal to "scaling":
                Set mitigation_results["scaling_applied"] to "equilibrium_scaling"
                Set mitigation_results["scaling_type"] to "row_and_column_scaling"
                Set mitigation_results["expected_improvement"] to "improved_conditioning_reduced_rounding_errors"
                
                Let scaled_condition_estimate be MathOps.multiply(error_magnitude, "0.1").result_value
                Set mitigation_results["estimated_scaled_error"] to scaled_condition_estimate
            
            Otherwise:
                If strategy is equal to "iterative_refinement":
                    Set mitigation_results["refinement_applied"] to "residual_based_correction"
                    Set mitigation_results["refinement_iterations"] to "adaptive_based_on_convergence"
                    
                    Let refined_accuracy_estimate be MathOps.multiply(error_magnitude, "0.01").result_value
                    Set mitigation_results["estimated_refined_accuracy"] to refined_accuracy_estimate
                
                Otherwise:
                    If strategy is equal to "preconditioning":
                        Set mitigation_results["preconditioning_applied"] to "incomplete_factorization"
                        Set mitigation_results["preconditioner_type"] to "ilu_or_jacobi_based_on_sparsity"
                        Set mitigation_results["expected_improvement"] to "faster_convergence_improved_stability"
                    
                    Otherwise:
                        If strategy is equal to "regularization":
                            Set mitigation_results["regularization_applied"] to "tikhonov_regularization"
                            Let regularization_parameter be MathOps.multiply(
                                Constants.get_machine_epsilon("float64").value, "1000.0"
                            ).result_value
                            Set mitigation_results["regularization_parameter"] to regularization_parameter
                            Set mitigation_results["expected_improvement"] to "improved_conditioning_stable_solution"
                        
                        Otherwise:
                            If strategy is equal to "higher_precision":
                                Set mitigation_results["precision_upgrade"] to "extended_precision_arithmetic"
                                Set mitigation_results["precision_type"] to "quad_precision_or_arbitrary_precision"
                                Set mitigation_results["expected_improvement"] to "reduced_rounding_errors"
                            
                            Otherwise:
                                Set mitigation_results[strategy plus "_status"] to "unknown_strategy_not_implemented"
        
        Set i to i plus 1
    
    Note: Provide combined strategy assessment
    Let total_strategies be mitigation_options.length
    Set mitigation_results["total_strategies_applied"] to total_strategies.toString()
    
    Note: Overall mitigation effectiveness estimate
    If mitigation_options.contains("scaling") And mitigation_options.contains("pivoting"):
        Set mitigation_results["combined_effectiveness"] to "excellent_for_linear_systems"
    Otherwise:
        If mitigation_options.contains("iterative_refinement"):
            Set mitigation_results["combined_effectiveness"] to "good_for_accuracy_improvement"
        Otherwise:
            Set mitigation_results["combined_effectiveness"] to "moderate_improvement_expected"
    
    Set mitigation_results["mitigation_complete"] to "true"
    
    Return mitigation_results

Process called "apply_iterative_refinement" that takes approximate_solution as List[Float], original_problem as Dictionary[String, String] returns List[Float]:
    Note: Apply iterative refinement to improve solution accuracy and stability
    Note: Uses residual correction to enhance computed solution quality
    
    If approximate_solution.length is equal to 0:
        Throw Errors.InvalidArgument with "Approximate solution cannot be empty"
    
    If original_problem.size() is equal to 0:
        Throw Errors.InvalidArgument with "Original problem cannot be empty"
    
    Note: Extract problem components
    Let matrix_data be original_problem.get("matrix")
    Let rhs_data be original_problem.get("rhs")
    
    Let system_matrix be LinAlg.parse_matrix_from_string(matrix_data)
    Let rhs_vector be LinAlg.parse_vector_from_string(rhs_data)
    
    Let current_solution be approximate_solution
    Let max_refinement_iterations be 5
    Let convergence_tolerance be Constants.get_machine_epsilon("float64").value.toFloat() multiplied by 1000.0
    
    Let iteration be 0
    While iteration is less than max_refinement_iterations:
        Note: Compute residual r is equal to b minus A*x
        Let matrix_times_solution be LinAlg.matrix_vector_multiply(system_matrix, current_solution)
        Let residual be LinAlg.vector_subtract(rhs_vector, matrix_times_solution)
        
        Note: Check convergence based on residual norm
        Let residual_norm be LinAlg.vector_norm(residual, "euclidean").toFloat()
        
        If residual_norm is less than convergence_tolerance:
            Break  Note: Converged sufficiently
        
        Note: Solve correction equation A*delta_x is equal to r
        Let correction be LinAlg.solve_linear_system(system_matrix, residual)
        
        Note: Update solution x is equal to x plus delta_x
        Let updated_solution be LinAlg.vector_add(current_solution, correction)
        
        Note: Check for improvement
        Let new_residual be LinAlg.vector_subtract(
            rhs_vector,
            LinAlg.matrix_vector_multiply(system_matrix, updated_solution)
        )
        Let new_residual_norm be LinAlg.vector_norm(new_residual, "euclidean").toFloat()
        
        If new_residual_norm is less than residual_norm:
            Set current_solution to updated_solution
        Otherwise:
            Break  Note: No improvement, stop refinement
        
        Set iteration to iteration plus 1
    
    Return current_solution

Process called "implement_pivoting_strategy" that takes matrix_system as Dictionary[String, List[List[Float]]], pivoting_type as String returns Dictionary[String, List[List[Float]]]:
    Note: Implement pivoting strategy for improved numerical stability
    Note: Partial, complete, or rook pivoting for Gaussian elimination stability
    
    If matrix_system.size() is equal to 0:
        Throw Errors.InvalidArgument with "Matrix system cannot be empty"
    
    If pivoting_type is equal to "":
        Throw Errors.InvalidArgument with "Pivoting type must be specified"
    
    Let pivoted_system be Dictionary[String, List[List[Float]]]
    Let original_matrix be matrix_system.get("matrix")
    
    If pivoting_type is equal to "partial":
        Note: Partial pivoting minus find largest element in column below diagonal
        Let pivoted_matrix be LinAlg.apply_partial_pivoting(original_matrix)
        Set pivoted_system["matrix"] to pivoted_matrix
        Set pivoted_system["pivoting_applied"] to List[List[Float]] with: List[Float] with: 1.0
        
        If matrix_system.contains_key("rhs"):
            Let rhs be matrix_system.get("rhs")
            Let pivoted_rhs be LinAlg.apply_row_permutations(rhs, LinAlg.get_pivot_permutation(original_matrix, "partial"))
            Set pivoted_system["rhs"] to pivoted_rhs
    
    Otherwise:
        If pivoting_type is equal to "complete":
            Note: Complete pivoting minus find largest element in entire submatrix
            Let pivoted_matrix be LinAlg.apply_complete_pivoting(original_matrix)
            Set pivoted_system["matrix"] to pivoted_matrix
            Set pivoted_system["pivoting_applied"] to List[List[Float]] with: List[Float] with: 2.0
            
            If matrix_system.contains_key("rhs"):
                Let rhs be matrix_system.get("rhs")
                Let row_permutation be LinAlg.get_pivot_permutation(original_matrix, "complete_row")
                Let pivoted_rhs be LinAlg.apply_row_permutations(rhs, row_permutation)
                Set pivoted_system["rhs"] to pivoted_rhs
        
        Otherwise:
            If pivoting_type is equal to "rook":
                Note: Rook pivoting minus compromise between partial and complete
                Let pivoted_matrix be LinAlg.apply_rook_pivoting(original_matrix)
                Set pivoted_system["matrix"] to pivoted_matrix
                Set pivoted_system["pivoting_applied"] to List[List[Float]] with: List[Float] with: 3.0
                
                If matrix_system.contains_key("rhs"):
                    Let rhs be matrix_system.get("rhs")
                    Let row_permutation be LinAlg.get_pivot_permutation(original_matrix, "rook")
                    Let pivoted_rhs be LinAlg.apply_row_permutations(rhs, row_permutation)
                    Set pivoted_system["rhs"] to pivoted_rhs
            
            Otherwise:
                Note: Unknown pivoting type minus return original system
                Set pivoted_system["matrix"] to original_matrix
                Set pivoted_system["pivoting_applied"] to List[List[Float]] with: List[Float] with: 0.0
                
                If matrix_system.contains_key("rhs"):
                    Set pivoted_system["rhs"] to matrix_system.get("rhs")
    
    Return pivoted_system

Process called "apply_preconditioning" that takes linear_system as Dictionary[String, List[List[Float]]], preconditioner_type as String returns Dictionary[String, List[List[Float]]]:
    Note: Apply preconditioning to improve system conditioning and stability
    Note: Transforms system to reduce condition number and enhance convergence
    
    If linear_system.size() is equal to 0:
        Throw Errors.InvalidArgument with "Linear system cannot be empty"
    
    If preconditioner_type is equal to "":
        Throw Errors.InvalidArgument with "Preconditioner type must be specified"
    
    Let preconditioned_system be Dictionary[String, List[List[Float]]]
    Let original_matrix be linear_system.get("matrix")
    Let original_rhs be linear_system.get("rhs")
    
    If preconditioner_type is equal to "jacobi":
        Note: Jacobi preconditioning: P is equal to diag(A)
        Let diagonal_preconditioner be LinAlg.extract_diagonal_matrix(original_matrix)
        Let preconditioner_inverse be LinAlg.invert_diagonal_matrix(diagonal_preconditioner)
        
        Let preconditioned_matrix be LinAlg.matrix_multiply(preconditioner_inverse, original_matrix)
        Let preconditioned_rhs be LinAlg.matrix_vector_multiply(preconditioner_inverse, original_rhs)
        
        Set preconditioned_system["matrix"] to preconditioned_matrix
        Set preconditioned_system["rhs"] to preconditioned_rhs
        Set preconditioned_system["preconditioner"] to diagonal_preconditioner
    
    Otherwise:
        If preconditioner_type is equal to "ilu":
            Note: Incomplete LU factorization preconditioning
            Let ilu_factors be LinAlg.incomplete_lu_factorization(original_matrix)
            Let L be ilu_factors.get("L")
            Let U be ilu_factors.get("U")
            
            Note: Solve LU multiplied by M^(-1) is equal to I to get preconditioner inverse
            Let preconditioner_inverse be LinAlg.solve_triangular_system(L, U)
            
            Let preconditioned_matrix be LinAlg.matrix_multiply(preconditioner_inverse, original_matrix)
            Let preconditioned_rhs be LinAlg.matrix_vector_multiply(preconditioner_inverse, original_rhs)
            
            Set preconditioned_system["matrix"] to preconditioned_matrix
            Set preconditioned_system["rhs"] to preconditioned_rhs
            Set preconditioned_system["preconditioner_L"] to L
            Set preconditioned_system["preconditioner_U"] to U
        
        Otherwise:
            If preconditioner_type is equal to "symmetric_successive_over_relaxation":
                Note: SSOR preconditioning
                Let omega be 1.5  Note: Relaxation parameter
                Let D be LinAlg.extract_diagonal_matrix(original_matrix)
                Let L be LinAlg.extract_lower_triangular(original_matrix)
                
                Note: SSOR preconditioner construction (simplified)
                Let ssor_factor be MathOps.multiply("2.0", MathOps.subtract("2.0", omega.toString()).result_value).result_value.toFloat()
                Let scaled_D be LinAlg.scale_matrix(D, ssor_factor)
                
                Let preconditioned_matrix be LinAlg.matrix_multiply(
                    LinAlg.matrix_inverse(scaled_D),
                    original_matrix
                )
                Let preconditioned_rhs be LinAlg.matrix_vector_multiply(
                    LinAlg.matrix_inverse(scaled_D),
                    original_rhs
                )
                
                Set preconditioned_system["matrix"] to preconditioned_matrix
                Set preconditioned_system["rhs"] to preconditioned_rhs
                Set preconditioned_system["preconditioner"] to scaled_D
            
            Otherwise:
                If preconditioner_type is equal to "approximate_inverse":
                    Note: Approximate inverse preconditioning
                    Let approx_inverse be LinAlg.compute_approximate_inverse(
                        original_matrix, "sparse_pattern_preservation"
                    )
                    
                    Let preconditioned_matrix be LinAlg.matrix_multiply(approx_inverse, original_matrix)
                    Let preconditioned_rhs be LinAlg.matrix_vector_multiply(approx_inverse, original_rhs)
                    
                    Set preconditioned_system["matrix"] to preconditioned_matrix
                    Set preconditioned_system["rhs"] to preconditioned_rhs
                    Set preconditioned_system["preconditioner"] to approx_inverse
                
                Otherwise:
                    Note: Unknown preconditioner minus return original system
                    Set preconditioned_system["matrix"] to original_matrix
                    Set preconditioned_system["rhs"] to original_rhs
                    Set preconditioned_system["preconditioner_applied"] to List[List[Float]] with: List[Float] with: 0.0
    
    Return preconditioned_system

Note: =====================================================================
Note: STABILITY MONITORING OPERATIONS
Note: =====================================================================

Process called "monitor_computational_stability" that takes computation_sequence as List[Dictionary[String, String]], monitoring_parameters as Dictionary[String, String] returns Dictionary[String, List[Float]]:
    Note: Monitor computational stability during algorithm execution
    Note: Tracks stability indicators and warns of potential numerical issues
    
    If computation_sequence.length is equal to 0:
        Throw Errors.InvalidArgument with "Computation sequence cannot be empty"
    
    If monitoring_parameters.size() is equal to 0:
        Throw Errors.InvalidArgument with "Monitoring parameters cannot be empty"
    
    Let stability_metrics be Dictionary[String, List[Float]]
    
    Let condition_numbers be List[Float]
    Let error_estimates be List[Float]
    Let convergence_indicators be List[Float]
    Let stability_flags be List[Float]
    
    Let machine_epsilon be Constants.get_machine_epsilon("float64").value.toFloat()
    Let instability_threshold be monitoring_parameters.get("instability_threshold").toFloat()
    
    Let i be 0
    While i is less than computation_sequence.length:
        Let computation_step be computation_sequence.get(i)
        Let step_type be computation_step.get("type")
        
        Note: Monitor condition number evolution
        Let condition_number be computation_step.get("condition_number").toFloat()
        Append condition_number to condition_numbers
        
        Note: Estimate numerical error at this step
        Let error_estimate be computation_step.get("error_estimate").toFloat()
        If error_estimate is equal to 0.0:
            Set error_estimate to machine_epsilon multiplied by condition_number
        Append error_estimate to error_estimates
        
        Note: Check convergence behavior
        Let convergence_rate be computation_step.get("convergence_rate").toFloat()
        If convergence_rate is equal to 0.0:
            Set convergence_rate to 1.0  Note: No convergence data
        Append convergence_rate to convergence_indicators
        
        Note: Stability flag: 1.0 is equal to stable, 0.5 is equal to marginal, 0.0 is equal to unstable
        Let stability_flag be 1.0
        
        If condition_number is greater than instability_threshold:
            Set stability_flag to 0.0
        Otherwise:
            If error_estimate is greater than instability_threshold multiplied by machine_epsilon:
                Set stability_flag to 0.5
        
        Append stability_flag to stability_flags
        
        Set i to i plus 1
    
    Set stability_metrics["condition_numbers"] to condition_numbers
    Set stability_metrics["error_estimates"] to error_estimates
    Set stability_metrics["convergence_indicators"] to convergence_indicators
    Set stability_metrics["stability_flags"] to stability_flags
    
    Note: Compute trend analysis
    If condition_numbers.length is greater than 1:
        Let condition_trend be condition_numbers.get(condition_numbers.length minus 1) / condition_numbers.get(0)
        Set stability_metrics["condition_number_trend"] to List[Float] with: condition_trend
    
    Return stability_metrics

Process called "detect_numerical_instabilities" that takes computation_results as Dictionary[String, List[Float]], detection_criteria as Dictionary[String, Float] returns List[String]:
    Note: Detect numerical instabilities using statistical and mathematical criteria
    Note: Identifies signs of catastrophic cancellation, overflow, underflow
    
    If computation_results.size() is equal to 0:
        Throw Errors.InvalidArgument with "Computation results cannot be empty"
    
    If detection_criteria.size() is equal to 0:
        Throw Errors.InvalidArgument with "Detection criteria cannot be empty"
    
    Let instability_warnings be List[String]
    
    Let overflow_threshold be detection_criteria.get("overflow_threshold")
    Let underflow_threshold be detection_criteria.get("underflow_threshold")
    Let cancellation_threshold be detection_criteria.get("cancellation_threshold")
    
    Note: Check for overflow conditions
    Let result_keys be computation_results.keys()
    Let i be 0
    While i is less than result_keys.length:
        Let key be result_keys.get(i)
        Let values be computation_results.get(key)
        
        Let j be 0
        While j is less than values.length:
            Let value be values.get(j)
            
            If MathOps.absolute_value(value.toString()).result_value.toFloat() is greater than overflow_threshold:
                Append "Overflow detected in " plus key plus " at step " plus j.toString() to instability_warnings
            
            If MathOps.absolute_value(value.toString()).result_value.toFloat() is less than underflow_threshold And value does not equal 0.0:
                Append "Underflow detected in " plus key plus " at step " plus j.toString() to instability_warnings
            
            Set j to j plus 1
        
        Set i to i plus 1
    
    Note: Check for catastrophic cancellation patterns
    Set i to 0
    While i is less than result_keys.length:
        Let key be result_keys.get(i)
        If key.contains("difference") Or key.contains("residual"):
            Let values be computation_results.get(key)
            
            Let j be 1
            While j is less than values.length:
                Let current_value be values.get(j)
                Let previous_value be values.get(j minus 1)
                
                If previous_value does not equal 0.0:
                    Let relative_change be MathOps.absolute_value(
                        MathOps.divide(
                            MathOps.subtract(current_value.toString(), previous_value.toString()).result_value,
                            previous_value.toString()
                        ).result_value
                    ).result_value.toFloat()
                    
                    If relative_change is greater than cancellation_threshold:
                        Append "Potential cancellation in " plus key plus " between steps " plus (j-1).toString() plus " and " plus j.toString() to instability_warnings
                
                Set j to j plus 1
        
        Set i to i plus 1
    
    Note: Check for NaN or Infinity values
    Set i to 0
    While i is less than result_keys.length:
        Let key be result_keys.get(i)
        Let values be computation_results.get(key)
        
        Let j be 0
        While j is less than values.length:
            Let value be values.get(j)
            
            If value.isNaN():
                Append "NaN detected in " plus key plus " at step " plus j.toString() to instability_warnings
            
            If value.isInfinite():
                Append "Infinity detected in " plus key plus " at step " plus j.toString() to instability_warnings
            
            Set j to j plus 1
        
        Set i to i plus 1
    
    Return instability_warnings

Process called "assess_result_reliability" that takes numerical_results as Dictionary[String, Float], reliability_metrics as List[String] returns Dictionary[String, Float]:
    Note: Assess reliability of numerical computation results
    Note: Combines error analysis with stability assessment for result validation
    
    If numerical_results.size() is equal to 0:
        Throw Errors.InvalidArgument with "Numerical results cannot be empty"
    
    If reliability_metrics.length is equal to 0:
        Throw Errors.InvalidArgument with "Reliability metrics cannot be empty"
    
    Let reliability_assessment be Dictionary[String, Float]
    
    Let overall_reliability_score be 1.0
    Let machine_epsilon be Constants.get_machine_epsilon("float64").value.toFloat()
    
    Let i be 0
    While i is less than reliability_metrics.length:
        Let metric be reliability_metrics.get(i)
        
        If metric is equal to "condition_number":
            Let condition_number be numerical_results.get("condition_number")
            Let condition_reliability be If condition_number is less than 100.0: 1.0 Otherwise: If condition_number is less than 10000.0: 0.5 Otherwise: 0.0
            Set reliability_assessment["condition_number_reliability"] to condition_reliability
            Set overall_reliability_score to overall_reliability_score multiplied by condition_reliability
        
        Otherwise:
            If metric is equal to "backward_error":
                Let backward_error be numerical_results.get("backward_error")
                Let error_reliability be If backward_error is less than machine_epsilon multiplied by 1000.0: 1.0 Otherwise: If backward_error is less than machine_epsilon multiplied by 10000.0: 0.5 Otherwise: 0.0
                Set reliability_assessment["backward_error_reliability"] to error_reliability
                Set overall_reliability_score to overall_reliability_score multiplied by error_reliability
            
            Otherwise:
                If metric is equal to "residual_norm":
                    Let residual_norm be numerical_results.get("residual_norm")
                    Let residual_reliability be If residual_norm is less than machine_epsilon multiplied by 100.0: 1.0 Otherwise: If residual_norm is less than machine_epsilon multiplied by 1000.0: 0.5 Otherwise: 0.0
                    Set reliability_assessment["residual_norm_reliability"] to residual_reliability
                    Set overall_reliability_score to overall_reliability_score multiplied by residual_reliability
                
                Otherwise:
                    Set reliability_assessment[metric plus "_reliability"] to 0.5  Note: Unknown metric
                    Set overall_reliability_score to overall_reliability_score multiplied by 0.5
        
        Set i to i plus 1
    
    Set reliability_assessment["overall_reliability_score"] to overall_reliability_score
    
    Return reliability_assessment

Process called "provide_stability_diagnostics" that takes stability_analysis as Dictionary[String, String] returns Dictionary[String, String]:
    Note: Provide comprehensive stability diagnostics and recommendations
    Note: Offers guidance for improving numerical stability and accuracy
    
    If stability_analysis.size() is equal to 0:
        Throw Errors.InvalidArgument with "Stability analysis cannot be empty"
    
    Let diagnostics be Dictionary[String, String]
    
    Let stability_status be stability_analysis.get("stability_status")
    Let primary_issue be stability_analysis.get("primary_issue")
    
    Set diagnostics["overall_stability_status"] to stability_status
    Set diagnostics["primary_stability_issue"] to primary_issue
    
    If stability_status is equal to "unstable":
        Set diagnostics["severity_level"] to "high"
        Set diagnostics["immediate_action_required"] to "true"
        Set diagnostics["recommended_actions"] to "switch_to_stable_algorithm_or_improve_conditioning"
    Otherwise:
        If stability_status is equal to "marginally_stable":
            Set diagnostics["severity_level"] to "medium"
            Set diagnostics["monitoring_recommended"] to "true"
            Set diagnostics["recommended_actions"] to "apply_error_mitigation_strategies"
        Otherwise:
            Set diagnostics["severity_level"] to "low"
            Set diagnostics["recommended_actions"] to "continue_with_current_approach"
    
    If primary_issue is equal to "ill_conditioning":
        Set diagnostics["specific_recommendation"] to "apply_preconditioning_or_regularization"
        Set diagnostics["technical_solution"] to "use_pivoting_scaling_or_iterative_refinement"
    Otherwise:
        If primary_issue is equal to "catastrophic_cancellation":
            Set diagnostics["specific_recommendation"] to "reformulate_computation_to_avoid_subtraction"
            Set diagnostics["technical_solution"] to "use_alternative_mathematical_formulation"
        Otherwise:
            Set diagnostics["specific_recommendation"] to "monitor_and_validate_results"
    
    Set diagnostics["diagnostic_complete"] to "true"
    
    Return diagnostics

Note: =====================================================================
Note: ADVANCED STABILITY ANALYSIS OPERATIONS
Note: =====================================================================

Process called "analyze_stochastic_stability" that takes stochastic_system as Dictionary[String, String], noise_model as Dictionary[String, String] returns Dictionary[String, Float]:
    Note: Analyze stability of stochastic numerical systems with random perturbations
    Note: Examines stability under probabilistic noise and uncertainty
    
    If stochastic_system.size() is equal to 0:
        Throw Errors.InvalidArgument with "Stochastic system specification cannot be empty"
    
    If noise_model.size() is equal to 0:
        Throw Errors.InvalidArgument with "Noise model specification cannot be empty"
    
    Let stability_metrics be Dictionary[String, Float]
    
    Note: Extract system parameters
    Let drift_coefficient be stochastic_system.get("drift_coefficient")
    Let diffusion_coefficient be stochastic_system.get("diffusion_coefficient")
    Let time_step be stochastic_system.get("time_step")
    
    Note: Extract noise characteristics
    Let noise_variance be noise_model.get("variance")
    Let correlation_length be noise_model.get("correlation_length")
    Let noise_type be noise_model.get("type")
    
    Note: Compute Lyapunov exponent for stochastic stability
    Let drift_value be drift_coefficient.toFloat()
    Let diffusion_value be diffusion_coefficient.toFloat()
    Let variance_value be noise_variance.toFloat()
    
    Note: For stochastic differential equations: λ is equal to a minus (1/2)σ²
    Let half_variance be MathOps.divide(variance_value.toString(), "2.0").result_value.toFloat()
    Let lyapunov_exponent be drift_value minus half_variance
    Set stability_metrics["lyapunov_exponent"] to lyapunov_exponent
    
    Note: Compute probability of stability
    Let stability_threshold be -0.01
    If lyapunov_exponent is less than stability_threshold:
        Set stability_metrics["stability_probability"] to 1.0
    Otherwise:
        Let exp_factor be MathOps.exponential(MathOps.multiply("-1.0", lyapunov_exponent.toString()).result_value).result_value.toFloat()
        Set stability_metrics["stability_probability"] to MathOps.minimum(List[String] with: "1.0", exp_factor.toString()).result_value.toFloat()
    
    Note: Compute noise amplification factor
    Let time_value be time_step.toFloat()
    Let amplification_factor be MathOps.square_root(
        MathOps.multiply(variance_value.toString(), time_value.toString()).result_value
    ).result_value.toFloat()
    Set stability_metrics["noise_amplification"] to amplification_factor
    
    Note: Compute expected first passage time (stability measure)
    If lyapunov_exponent is less than 0.0:
        Let passage_time be MathOps.divide("-1.0", lyapunov_exponent.toString()).result_value.toFloat()
        Set stability_metrics["first_passage_time"] to passage_time
    Otherwise:
        Set stability_metrics["first_passage_time"] to Float.infinity()
    
    Note: Compute stochastic resonance metric
    Let resonance_frequency be MathOps.divide(
        MathOps.absolute_value(drift_coefficient).result_value,
        MathOps.multiply("2.0", Constants.get_pi().value).result_value
    ).result_value.toFloat()
    Set stability_metrics["resonance_frequency"] to resonance_frequency
    
    Note: Compute correlation-based stability measure
    Let correlation_value be correlation_length.toFloat()
    Let correlation_stability be MathOps.exponential(
        MathOps.multiply("-1.0", MathOps.divide(time_value.toString(), correlation_value.toString()).result_value).result_value
    ).result_value.toFloat()
    Set stability_metrics["correlation_stability"] to correlation_stability
    
    Return stability_metrics

Process called "perform_interval_stability_analysis" that takes interval_system as Dictionary[String, Dictionary[String, List[Float]]] returns Dictionary[String, Dictionary[String, Float]]:
    Note: Perform stability analysis using interval arithmetic
    Note: Provides guaranteed bounds on stability measures with uncertainty
    
    If interval_system.size() is equal to 0:
        Throw Errors.InvalidArgument with "Interval system specification cannot be empty"
    
    Let stability_bounds be Dictionary[String, Dictionary[String, Float]]
    
    Note: Process each parameter with interval bounds
    Let parameter_names be interval_system.keys()
    
    Let i be 0
    While i is less than parameter_names.length:
        Let param_name be parameter_names.get(i)
        Let interval_data be interval_system.get(param_name)
        
        Note: Extract interval bounds for this parameter
        Let lower_bounds be interval_data.get("lower")
        Let upper_bounds be interval_data.get("upper")
        
        If lower_bounds.length does not equal upper_bounds.length:
            Throw Errors.InvalidArgument with "Lower and upper bounds must have same length for " plus param_name
        
        Let param_stability be Dictionary[String, Float]
        
        Note: Compute interval-based condition number bounds
        Let min_condition be Float.infinity()
        Let max_condition be 0.0
        
        Let j be 0
        While j is less than lower_bounds.length:
            Let lower_val be lower_bounds.get(j)
            Let upper_val be upper_bounds.get(j)
            
            Note: Compute condition number for interval endpoints
            Let lower_condition be MathOps.divide("1.0", MathOps.absolute_value(lower_val.toString()).result_value).result_value.toFloat()
            Let upper_condition be MathOps.divide("1.0", MathOps.absolute_value(upper_val.toString()).result_value).result_value.toFloat()
            
            Note: Update bounds
            If lower_condition is less than min_condition:
                Set min_condition to lower_condition
            If upper_condition is greater than max_condition:
                Set max_condition to upper_condition
            
            Set j to j plus 1
        
        Set param_stability["min_condition_number"] to min_condition
        Set param_stability["max_condition_number"] to max_condition
        
        Note: Compute interval width as uncertainty measure
        Let total_width be 0.0
        Set j to 0
        While j is less than lower_bounds.length:
            Let width be upper_bounds.get(j) minus lower_bounds.get(j)
            Set total_width to total_width plus MathOps.absolute_value(width.toString()).result_value.toFloat()
            Set j to j plus 1
        
        Let average_width be total_width / lower_bounds.length.toFloat()
        Set param_stability["average_interval_width"] to average_width
        
        Note: Compute stability margin (worst case scenario)
        Let stability_margin be MathOps.divide(
            min_condition.toString(),
            max_condition.toString()
        ).result_value.toFloat()
        Set param_stability["stability_margin"] to stability_margin
        
        Note: Compute guaranteed stability threshold
        Let machine_eps be Constants.get_machine_epsilon("float64").value.toFloat()
        Let guaranteed_accuracy be MathOps.multiply(
            min_condition.toString(),
            machine_eps.toString()
        ).result_value.toFloat()
        Set param_stability["guaranteed_accuracy"] to guaranteed_accuracy
        
        Note: Interval-based error propagation bound
        Let error_bound_lower be MathOps.multiply(
            min_condition.toString(),
            machine_eps.toString()
        ).result_value.toFloat()
        Let error_bound_upper be MathOps.multiply(
            max_condition.toString(),
            machine_eps.toString()
        ).result_value.toFloat()
        
        Set param_stability["error_bound_lower"] to error_bound_lower
        Set param_stability["error_bound_upper"] to error_bound_upper
        
        Set stability_bounds[param_name] to param_stability
        Set i to i plus 1
    
    Return stability_bounds

Process called "analyze_multiscale_stability" that takes multiscale_problem as Dictionary[String, Dictionary[String, String]] returns Dictionary[String, Dictionary[String, String]]:
    Note: Analyze stability in multiscale computational problems
    Note: Examines stability across different temporal and spatial scales
    
    If multiscale_problem.size() is equal to 0:
        Throw Errors.InvalidArgument with "Multiscale problem specification cannot be empty"
    
    Let multiscale_analysis be Dictionary[String, Dictionary[String, String]]
    
    Note: Extract scale information
    Let scale_names be multiscale_problem.keys()
    
    Let i be 0
    While i is less than scale_names.length:
        Let scale_name be scale_names.get(i)
        Let scale_data be multiscale_problem.get(scale_name)
        
        Let scale_stability be Dictionary[String, String]
        
        Note: Extract scale parameters
        Let time_scale be scale_data.get("time_scale")
        Let spatial_scale be scale_data.get("spatial_scale")
        Let coupling_strength be scale_data.get("coupling_strength")
        
        Note: Compute scale separation ratio
        Let time_val be time_scale.toFloat()
        Let spatial_val be spatial_scale.toFloat()
        
        Note: Find reference scales (minimum scales)
        Let min_time_scale be time_val
        Let min_spatial_scale be spatial_val
        
        Let j be 0
        While j is less than scale_names.length:
            Let other_scale be multiscale_problem.get(scale_names.get(j))
            Let other_time be other_scale.get("time_scale").toFloat()
            Let other_spatial be other_scale.get("spatial_scale").toFloat()
            
            If other_time is less than min_time_scale:
                Set min_time_scale to other_time
            If other_spatial is less than min_spatial_scale:
                Set min_spatial_scale to other_spatial
            
            Set j to j plus 1
        
        Let time_separation_ratio be MathOps.divide(
            time_val.toString(),
            min_time_scale.toString()
        ).result_value
        Set scale_stability["time_separation_ratio"] to time_separation_ratio
        
        Let spatial_separation_ratio be MathOps.divide(
            spatial_val.toString(),
            min_spatial_scale.toString()
        ).result_value
        Set scale_stability["spatial_separation_ratio"] to spatial_separation_ratio
        
        Note: Compute CFL-like stability criterion for this scale
        Let cfl_number be MathOps.divide(
            time_separation_ratio,
            spatial_separation_ratio
        ).result_value
        Set scale_stability["cfl_criterion"] to cfl_number
        
        Note: Assess stability based on CFL criterion
        Let cfl_val be cfl_number.toFloat()
        If cfl_val is less than or equal to 1.0:
            Set scale_stability["scale_stability_status"] to "stable"
        Otherwise:
            If cfl_val is less than or equal to 2.0:
                Set scale_stability["scale_stability_status"] to "marginally_stable"
            Otherwise:
                Set scale_stability["scale_stability_status"] to "unstable"
        
        Note: Compute coupling-induced stability modification
        Let coupling_val be coupling_strength.toFloat()
        Let coupling_factor be MathOps.multiply(
            coupling_val.toString(),
            time_separation_ratio
        ).result_value
        Set scale_stability["coupling_stability_factor"] to coupling_factor
        
        Note: Determine scale interaction stability
        Let interaction_stability be "decoupled"
        If coupling_val is greater than 0.1:
            If MathOps.is_greater_than(coupling_factor, "1.0").result_value is equal to "true":
                Set interaction_stability to "strong_coupling_unstable"
            Otherwise:
                Set interaction_stability to "weak_coupling_stable"
        Set scale_stability["interaction_stability"] to interaction_stability
        
        Note: Compute scale-specific timestep recommendation
        Let recommended_timestep be MathOps.multiply(
            "0.5",
            MathOps.divide(
                spatial_scale,
                MathOps.add("1.0", coupling_strength).result_value
            ).result_value
        ).result_value
        Set scale_stability["recommended_timestep"] to recommended_timestep
        
        Set multiscale_analysis[scale_name] to scale_stability
        Set i to i plus 1
    
    Note: Compute global multiscale stability assessment
    Let global_analysis be Dictionary[String, String]
    
    Note: Find most restrictive scale
    Let most_restrictive_cfl be "0.0"
    Let most_restrictive_scale be ""
    
    Set i to 0
    While i is less than scale_names.length:
        Let scale_stability be multiscale_analysis.get(scale_names.get(i))
        Let scale_cfl be scale_stability.get("cfl_criterion")
        
        If MathOps.is_greater_than(scale_cfl, most_restrictive_cfl).result_value is equal to "true":
            Set most_restrictive_cfl to scale_cfl
            Set most_restrictive_scale to scale_names.get(i)
        
        Set i to i plus 1
    
    Set global_analysis["most_restrictive_scale"] to most_restrictive_scale
    Set global_analysis["global_cfl_criterion"] to most_restrictive_cfl
    
    Note: Overall stability assessment
    Let global_cfl_val be most_restrictive_cfl.toFloat()
    If global_cfl_val is less than or equal to 1.0:
        Set global_analysis["global_stability_status"] to "multiscale_stable"
    Otherwise:
        Set global_analysis["global_stability_status"] to "multiscale_unstable"
    
    Set multiscale_analysis["global_assessment"] to global_analysis
    
    Return multiscale_analysis

Process called "assess_adaptive_stability" that takes adaptive_method as Dictionary[String, String], adaptation_criteria as Dictionary[String, String] returns Dictionary[String, String]:
    Note: Assess stability of adaptive numerical methods with dynamic parameters
    Note: Examines stability under parameter adaptation and mesh refinement
    
    If adaptive_method.size() is equal to 0:
        Throw Errors.InvalidArgument with "Adaptive method specification cannot be empty"
    
    If adaptation_criteria.size() is equal to 0:
        Throw Errors.InvalidArgument with "Adaptation criteria cannot be empty"
    
    Let stability_assessment be Dictionary[String, String]
    
    Note: Extract adaptive method parameters
    Let method_type be adaptive_method.get("method_type")
    Let base_timestep be adaptive_method.get("base_timestep")
    Let adaptation_factor be adaptive_method.get("adaptation_factor")
    Let stability_margin be adaptive_method.get("stability_margin")
    
    Note: Extract adaptation criteria
    Let error_tolerance be adaptation_criteria.get("error_tolerance")
    Let refinement_threshold be adaptation_criteria.get("refinement_threshold")
    Let coarsening_threshold be adaptation_criteria.get("coarsening_threshold")
    Let max_adaptation_ratio be adaptation_criteria.get("max_adaptation_ratio")
    
    Set stability_assessment["method_type"] to method_type
    Set stability_assessment["base_timestep"] to base_timestep
    
    Note: Compute adaptive stability bounds
    Let base_dt be base_timestep.toFloat()
    Let adapt_factor be adaptation_factor.toFloat()
    Let max_ratio be max_adaptation_ratio.toFloat()
    
    Note: Calculate minimum and maximum possible timesteps
    Let min_timestep be MathOps.divide(
        base_dt.toString(),
        max_ratio.toString()
    ).result_value.toFloat()
    Let max_timestep be MathOps.multiply(
        base_dt.toString(),
        max_ratio.toString()
    ).result_value.toFloat()
    
    Set stability_assessment["min_timestep"] to min_timestep.toString()
    Set stability_assessment["max_timestep"] to max_timestep.toString()
    
    Note: Assess stability under maximum timestep
    Let stability_bound be stability_margin.toFloat()
    Let max_cfl be MathOps.divide(
        max_timestep.toString(),
        stability_bound.toString()
    ).result_value.toFloat()
    
    Set stability_assessment["max_cfl_number"] to max_cfl.toString()
    
    Note: Determine stability status under adaptation
    If max_cfl is less than or equal to 1.0:
        Set stability_assessment["adaptive_stability_status"] to "unconditionally_stable"
    Otherwise:
        If max_cfl is less than or equal to 2.0:
            Set stability_assessment["adaptive_stability_status"] to "conditionally_stable"
        Otherwise:
            Set stability_assessment["adaptive_stability_status"] to "potentially_unstable"
    
    Note: Compute adaptation-induced error amplification
    Let error_tol be error_tolerance.toFloat()
    Let refinement_thresh be refinement_threshold.toFloat()
    
    Let amplification_factor be MathOps.divide(
        max_ratio.toString(),
        error_tol.toString()
    ).result_value.toFloat()
    Set stability_assessment["error_amplification_factor"] to amplification_factor.toString()
    
    Note: Assess refinement stability
    Let refinement_stability_factor be MathOps.multiply(
        refinement_thresh.toString(),
        adapt_factor.toString()
    ).result_value.toFloat()
    
    If refinement_stability_factor is less than 0.1:
        Set stability_assessment["refinement_stability"] to "aggressive_refinement_risk"
    Otherwise:
        If refinement_stability_factor is less than 0.5:
            Set stability_assessment["refinement_stability"] to "moderate_refinement_safe"
        Otherwise:
            Set stability_assessment["refinement_stability"] to "conservative_refinement_stable"
    
    Note: Compute coarsening stability
    Let coarsening_thresh be coarsening_threshold.toFloat()
    Let coarsening_safety be MathOps.multiply(
        coarsening_thresh.toString(),
        stability_bound.toString()
    ).result_value.toFloat()
    
    If coarsening_safety is greater than 1.0:
        Set stability_assessment["coarsening_stability"] to "safe_coarsening"
    Otherwise:
        Set stability_assessment["coarsening_stability"] to "risky_coarsening"
    
    Note: Provide adaptive timestep recommendation
    Let recommended_base_dt be MathOps.multiply(
        stability_bound.toString(),
        "0.8"
    ).result_value
    Set stability_assessment["recommended_base_timestep"] to recommended_base_dt
    
    Note: Compute adaptation frequency recommendation
    Let adaptation_frequency be MathOps.divide(
        "1.0",
        MathOps.multiply(adapt_factor.toString(), error_tol.toString()).result_value
    ).result_value
    Set stability_assessment["recommended_adaptation_frequency"] to adaptation_frequency
    
    Return stability_assessment

Note: =====================================================================
Note: UTILITY OPERATIONS
Note: =====================================================================

Process called "validate_stability_analysis" that takes analysis_results as Dictionary[String, String] returns Dictionary[String, Boolean]:
    Note: Validate stability analysis for mathematical rigor and correctness
    Note: Ensures proper application of stability theory and numerical analysis
    
    If analysis_results.size() is equal to 0:
        Throw Errors.InvalidArgument with "Analysis results cannot be empty"
    
    Let validation_results be Dictionary[String, Boolean]
    
    Note: Validate condition number bounds
    Let has_condition_number be analysis_results.containsKey("condition_number")
    Set validation_results["has_condition_number"] to has_condition_number
    
    If has_condition_number:
        Let condition_value be analysis_results.get("condition_number").toFloat()
        Let condition_valid be condition_value is greater than or equal to 1.0
        Set validation_results["condition_number_valid"] to condition_valid
    Otherwise:
        Set validation_results["condition_number_valid"] to false
    
    Note: Validate eigenvalue analysis
    Let has_eigenvalues be analysis_results.containsKey("max_eigenvalue")
    Set validation_results["has_eigenvalue_analysis"] to has_eigenvalues
    
    If has_eigenvalues:
        Let max_eigenvalue be analysis_results.get("max_eigenvalue").toFloat()
        Let eigenvalue_realistic be MathOps.absolute_value(max_eigenvalue.toString()).result_value.toFloat() is less than 1000.0
        Set validation_results["eigenvalues_realistic"] to eigenvalue_realistic
    Otherwise:
        Set validation_results["eigenvalues_realistic"] to false
    
    Note: Validate error bounds consistency
    Let has_forward_error be analysis_results.containsKey("forward_error_bound")
    Let has_backward_error be analysis_results.containsKey("backward_error_bound")
    
    Set validation_results["has_error_analysis"] to (has_forward_error Or has_backward_error)
    
    If has_forward_error And has_backward_error:
        Let forward_error be analysis_results.get("forward_error_bound").toFloat()
        Let backward_error be analysis_results.get("backward_error_bound").toFloat()
        
        Note: Forward error should generally be larger than backward error
        Let error_bounds_consistent be forward_error is greater than or equal to backward_error
        Set validation_results["error_bounds_consistent"] to error_bounds_consistent
    Otherwise:
        Set validation_results["error_bounds_consistent"] to false
    
    Note: Validate perturbation analysis consistency
    Let has_perturbation be analysis_results.containsKey("perturbation_sensitivity")
    Set validation_results["has_perturbation_analysis"] to has_perturbation
    
    If has_perturbation:
        Let sensitivity be analysis_results.get("perturbation_sensitivity").toFloat()
        Let sensitivity_reasonable be sensitivity is greater than or equal to 0.0 And sensitivity is less than or equal to 1000.0
        Set validation_results["perturbation_sensitivity_reasonable"] to sensitivity_reasonable
    Otherwise:
        Set validation_results["perturbation_sensitivity_reasonable"] to false
    
    Note: Validate numerical stability indicators
    Let has_stability_measure be (
        analysis_results.containsKey("stability_factor") Or
        analysis_results.containsKey("stability_radius") Or
        analysis_results.containsKey("amplification_factor")
    )
    Set validation_results["has_stability_measures"] to has_stability_measure
    
    Note: Check for required mathematical properties
    Let has_norm_analysis be analysis_results.containsKey("matrix_norm")
    Set validation_results["has_norm_analysis"] to has_norm_analysis
    
    Note: Validate CFL-like stability conditions if present
    Let has_cfl_analysis be analysis_results.containsKey("cfl_number")
    Set validation_results["has_cfl_analysis"] to has_cfl_analysis
    
    If has_cfl_analysis:
        Let cfl_number be analysis_results.get("cfl_number").toFloat()
        Let cfl_valid be cfl_number is greater than 0.0
        Set validation_results["cfl_number_valid"] to cfl_valid
    Otherwise:
        Set validation_results["cfl_number_valid"] to false
    
    Note: Overall validation assessment
    Let core_validations_passed be (
        validation_results.get("has_condition_number") And
        validation_results.get("has_error_analysis") And
        validation_results.get("has_stability_measures")
    )
    Set validation_results["core_analysis_complete"] to core_validations_passed
    
    Let mathematical_consistency be (
        validation_results.get("condition_number_valid") And
        validation_results.get("error_bounds_consistent") And
        validation_results.get("perturbation_sensitivity_reasonable")
    )
    Set validation_results["mathematical_consistency_valid"] to mathematical_consistency
    
    Return validation_results

Process called "optimize_stability_computation" that takes computation_config as Dictionary[String, String] returns Dictionary[String, String]:
    Note: Optimize stability computation methods for efficiency and reliability
    Note: Streamlines stability analysis while maintaining mathematical precision
    
    If computation_config.size() is equal to 0:
        Throw Errors.InvalidArgument with "Computation configuration cannot be empty"
    
    Let optimization_config be Dictionary[String, String]
    
    Note: Extract current configuration
    Let precision_level be computation_config.get("precision_level")
    Let matrix_size be computation_config.get("matrix_size")
    Let computation_type be computation_config.get("computation_type")
    Let performance_target be computation_config.get("performance_target")
    
    Set optimization_config["input_precision_level"] to precision_level
    Set optimization_config["input_matrix_size"] to matrix_size
    Set optimization_config["input_computation_type"] to computation_type
    
    Note: Determine optimal precision based on matrix size and type
    Let size_val be matrix_size.toFloat()
    Let optimal_precision be "double"
    
    If computation_type is equal to "condition_number":
        If size_val is greater than 1000.0:
            Set optimal_precision to "extended"
        Otherwise:
            If size_val is greater than 100.0:
                Set optimal_precision to "double"
            Otherwise:
                Set optimal_precision to "single"
    Otherwise:
        If computation_type is equal to "eigenvalue":
            If size_val is greater than 500.0:
                Set optimal_precision to "extended"
            Otherwise:
                Set optimal_precision to "double"
        Otherwise:
            Set optimal_precision to "double"
    
    Set optimization_config["recommended_precision"] to optimal_precision
    
    Note: Determine optimal algorithm selection
    Let optimal_algorithm be "general"
    
    If computation_type is equal to "condition_number":
        If size_val is less than 50.0:
            Set optimal_algorithm to "direct_inversion"
        Otherwise:
            If size_val is less than 500.0:
                Set optimal_algorithm to "lu_decomposition"
            Otherwise:
                Set optimal_algorithm to "iterative_refinement"
    Otherwise:
        If computation_type is equal to "eigenvalue":
            If size_val is less than 100.0:
                Set optimal_algorithm to "qr_algorithm"
            Otherwise:
                Set optimal_algorithm to "krylov_subspace"
        Otherwise:
            If computation_type is equal to "svd":
                If size_val is less than 200.0:
                    Set optimal_algorithm to "bidiagonalization"
                Otherwise:
                    Set optimal_algorithm to "randomized_svd"
    
    Set optimization_config["recommended_algorithm"] to optimal_algorithm
    
    Note: Compute optimal block size for cache efficiency
    Let optimal_block_size be "64"
    
    If size_val is greater than 1000.0:
        Set optimal_block_size to "128"
    Otherwise:
        If size_val is greater than 100.0:
            Set optimal_block_size to "64"
        Otherwise:
            Set optimal_block_size to "32"
    
    Set optimization_config["recommended_block_size"] to optimal_block_size
    
    Note: Determine parallelization strategy
    Let parallelization_strategy be "sequential"
    
    If size_val is greater than 200.0:
        If computation_type is equal to "matrix_multiplication" Or computation_type is equal to "eigenvalue":
            Set parallelization_strategy to "parallel_threads"
        Otherwise:
            Set parallelization_strategy to "vectorized"
    
    Set optimization_config["parallelization_strategy"] to parallelization_strategy
    
    Note: Estimate performance improvement
    Let baseline_complexity be MathOps.power(size_val.toString(), "3.0").result_value
    Let optimized_complexity be baseline_complexity
    
    If optimal_algorithm is equal to "iterative_refinement":
        Set optimized_complexity to MathOps.multiply(
            baseline_complexity,
            "0.7"
        ).result_value
    Otherwise:
        If optimal_algorithm is equal to "krylov_subspace":
            Set optimized_complexity to MathOps.multiply(
                MathOps.power(size_val.toString(), "2.0").result_value,
                MathOps.log10(size_val.toString()).result_value
            ).result_value
        Otherwise:
            If optimal_algorithm is equal to "randomized_svd":
                Set optimized_complexity to MathOps.multiply(
                    baseline_complexity,
                    "0.5"
                ).result_value
    
    Let speedup_factor be MathOps.divide(
        baseline_complexity,
        optimized_complexity
    ).result_value
    Set optimization_config["estimated_speedup_factor"] to speedup_factor
    
    Note: Memory optimization recommendations
    Let memory_per_element be "8"
    If optimal_precision is equal to "extended":
        Set memory_per_element to "16"
    Otherwise:
        If optimal_precision is equal to "single":
            Set memory_per_element to "4"
    
    Let total_memory_mb be MathOps.divide(
        MathOps.multiply(
            MathOps.multiply(size_val.toString(), size_val.toString()).result_value,
            memory_per_element
        ).result_value,
        "1048576"
    ).result_value
    Set optimization_config["estimated_memory_mb"] to total_memory_mb
    
    Note: Convergence optimization for iterative methods
    If computation_type.contains("iterative"):
        Let optimal_tolerance be "1e-12"
        If size_val is greater than 1000.0:
            Set optimal_tolerance to "1e-10"
        Otherwise:
            If size_val is less than 100.0:
                Set optimal_tolerance to "1e-14"
        
        Set optimization_config["recommended_tolerance"] to optimal_tolerance
        
        Let optimal_max_iterations be MathOps.multiply(size_val.toString(), "2.0").result_value
        Set optimization_config["recommended_max_iterations"] to optimal_max_iterations
    
    Return optimization_config

Process called "troubleshoot_stability_issues" that takes issue_description as Dictionary[String, String] returns List[String]:
    Note: Provide troubleshooting guidance for numerical stability problems
    Note: Diagnoses common stability issues and provides mitigation strategies
    
    If issue_description.size() is equal to 0:
        Throw Errors.InvalidArgument with "Issue description cannot be empty"
    
    Let troubleshooting_recommendations be List[String]
    
    Note: Extract issue characteristics
    Let issue_type be issue_description.get("issue_type")
    Let error_magnitude be issue_description.get("error_magnitude")
    Let computation_type be issue_description.get("computation_type")
    Let matrix_properties be issue_description.get("matrix_properties")
    
    Note: Diagnose condition number issues
    If issue_type is equal to "high_condition_number" Or issue_type is equal to "ill_conditioned":
        Append "DIAGNOSIS: Matrix is ill-conditioned with high condition number" to troubleshooting_recommendations
        Append "SOLUTION 1: Use regularization techniques (Tikhonov regularization, ridge regression)" to troubleshooting_recommendations
        Append "SOLUTION 2: Apply matrix preconditioning to improve condition number" to troubleshooting_recommendations
        Append "SOLUTION 3: Use higher precision arithmetic (extended precision)" to troubleshooting_recommendations
        Append "SOLUTION 4: Consider iterative refinement for solving linear systems" to troubleshooting_recommendations
        
        If error_magnitude does not equal "":
            Let error_val be error_magnitude.toFloat()
            If error_val is greater than 1.0:
                Append "CRITICAL: Error magnitude suggests catastrophic loss of precision" to troubleshooting_recommendations
                Append "URGENT: Switch to extended precision or reformulate the problem" to troubleshooting_recommendations
    
    Note: Diagnose numerical cancellation issues
    Otherwise:
        If issue_type is equal to "catastrophic_cancellation" Or issue_type is equal to "precision_loss":
            Append "DIAGNOSIS: Catastrophic cancellation detected in computation" to troubleshooting_recommendations
            Append "SOLUTION 1: Reorder operations to minimize subtraction of nearly equal numbers" to troubleshooting_recommendations
            Append "SOLUTION 2: Use alternative mathematical formulations (e.g., log-sum-exp trick)" to troubleshooting_recommendations
            Append "SOLUTION 3: Implement Kahan summation for accumulation operations" to troubleshooting_recommendations
            Append "SOLUTION 4: Use compensated arithmetic algorithms" to troubleshooting_recommendations
    
    Note: Diagnose eigenvalue computation issues
    Otherwise:
        If issue_type is equal to "eigenvalue_convergence" Or computation_type is equal to "eigenvalue":
            Append "DIAGNOSIS: Eigenvalue computation convergence issues" to troubleshooting_recommendations
            Append "SOLUTION 1: Use shifted inverse iteration for specific eigenvalues" to troubleshooting_recommendations
            Append "SOLUTION 2: Apply deflation techniques for multiple eigenvalues" to troubleshooting_recommendations
            Append "SOLUTION 3: Try different starting vectors for iterative methods" to troubleshooting_recommendations
            Append "SOLUTION 4: Use Krylov subspace methods for large sparse matrices" to troubleshooting_recommendations
    
    Note: Diagnose iterative method stability
    Otherwise:
        If issue_type is equal to "iterative_divergence" Or issue_type is equal to "slow_convergence":
            Append "DIAGNOSIS: Iterative method stability or convergence problems" to troubleshooting_recommendations
            Append "SOLUTION 1: Reduce timestep or relaxation parameter" to troubleshooting_recommendations
            Append "SOLUTION 2: Apply preconditioning to improve convergence rate" to troubleshooting_recommendations
            Append "SOLUTION 3: Use adaptive timestep control" to troubleshooting_recommendations
            Append "SOLUTION 4: Switch to implicit or semi-implicit methods" to troubleshooting_recommendations
    
    Note: Diagnose matrix decomposition issues
    Otherwise:
        If issue_type is equal to "decomposition_failure" Or issue_type is equal to "singular_matrix":
            Append "DIAGNOSIS: Matrix decomposition failure due to singularity or near-singularity" to troubleshooting_recommendations
            Append "SOLUTION 1: Add regularization term to make matrix non-singular" to troubleshooting_recommendations
            Append "SOLUTION 2: Use pivoting strategies (partial or complete pivoting)" to troubleshooting_recommendations
            Append "SOLUTION 3: Apply matrix perturbation to break singularity" to troubleshooting_recommendations
            Append "SOLUTION 4: Use pseudoinverse or least-squares solutions" to troubleshooting_recommendations
    
    Note: Check for specific matrix properties and provide targeted advice
    If matrix_properties does not equal "":
        If matrix_properties.contains("symmetric"):
            Append "OPTIMIZATION: Use symmetric matrix algorithms (Cholesky, symmetric eigensolvers)" to troubleshooting_recommendations
        
        If matrix_properties.contains("sparse"):
            Append "OPTIMIZATION: Use sparse matrix storage and algorithms" to troubleshooting_recommendations
            Append "OPTIMIZATION: Consider graph-based reordering for sparse matrices" to troubleshooting_recommendations
        
        If matrix_properties.contains("positive_definite"):
            Append "OPTIMIZATION: Use Cholesky decomposition for positive definite matrices" to troubleshooting_recommendations
        
        If matrix_properties.contains("banded"):
            Append "OPTIMIZATION: Use banded matrix algorithms for computational efficiency" to troubleshooting_recommendations
    
    Note: General stability improvement recommendations
    Append "GENERAL 1: Monitor condition numbers and error bounds during computation" to troubleshooting_recommendations
    Append "GENERAL 2: Implement error checking and validation at critical computation steps" to troubleshooting_recommendations
    Append "GENERAL 3: Use backward error analysis to assess solution quality" to troubleshooting_recommendations
    Append "GENERAL 4: Consider problem scaling and normalization" to troubleshooting_recommendations
    
    Note: Provide algorithmic alternatives based on computation type
    If computation_type is equal to "linear_system":
        Append "ALTERNATIVE: Try different linear system solvers (LU, QR, iterative methods)" to troubleshooting_recommendations
    Otherwise:
        If computation_type is equal to "least_squares":
            Append "ALTERNATIVE: Use SVD-based least squares or normal equations with regularization" to troubleshooting_recommendations
        Otherwise:
            If computation_type is equal to "optimization":
                Append "ALTERNATIVE: Switch between gradient-based and derivative-free optimization methods" to troubleshooting_recommendations
    
    Return troubleshooting_recommendations

Process called "benchmark_stability_performance" that takes performance_data as Dictionary[String, Float], benchmark_standards as Dictionary[String, Float] returns Dictionary[String, String]:
    Note: Benchmark stability analysis performance against theoretical and practical standards
    Note: Measures accuracy and efficiency of numerical stability methods
    
    If performance_data.size() is equal to 0:
        Throw Errors.InvalidArgument with "Performance data cannot be empty"
    
    If benchmark_standards.size() is equal to 0:
        Throw Errors.InvalidArgument with "Benchmark standards cannot be empty"
    
    Let benchmark_results be Dictionary[String, String]
    
    Note: Extract performance metrics
    Let computation_time be performance_data.get("computation_time")
    Let memory_usage be performance_data.get("memory_usage")
    Let accuracy_achieved be performance_data.get("accuracy_achieved")
    Let iterations_required be performance_data.get("iterations_required")
    Let condition_number_computed be performance_data.get("condition_number")
    
    Note: Extract benchmark standards
    Let target_computation_time be benchmark_standards.get("target_computation_time")
    Let max_memory_usage be benchmark_standards.get("max_memory_usage")
    Let required_accuracy be benchmark_standards.get("required_accuracy")
    Let max_iterations be benchmark_standards.get("max_iterations")
    Let acceptable_condition_number be benchmark_standards.get("acceptable_condition_number")
    
    Set benchmark_results["test_computation_time"] to computation_time.toString()
    Set benchmark_results["target_computation_time"] to target_computation_time.toString()
    
    Note: Benchmark computation time performance
    Let time_ratio be MathOps.divide(
        computation_time.toString(),
        target_computation_time.toString()
    ).result_value.toFloat()
    
    Set benchmark_results["time_performance_ratio"] to time_ratio.toString()
    
    If time_ratio is less than or equal to 1.0:
        Set benchmark_results["time_performance_status"] to "excellent"
    Otherwise:
        If time_ratio is less than or equal to 2.0:
            Set benchmark_results["time_performance_status"] to "acceptable"
        Otherwise:
            If time_ratio is less than or equal to 5.0:
                Set benchmark_results["time_performance_status"] to "poor"
            Otherwise:
                Set benchmark_results["time_performance_status"] to "unacceptable"
    
    Note: Benchmark memory usage performance
    Let memory_ratio be MathOps.divide(
        memory_usage.toString(),
        max_memory_usage.toString()
    ).result_value.toFloat()
    
    Set benchmark_results["memory_usage_ratio"] to memory_ratio.toString()
    
    If memory_ratio is less than or equal to 0.8:
        Set benchmark_results["memory_performance_status"] to "excellent"
    Otherwise:
        If memory_ratio is less than or equal to 1.0:
            Set benchmark_results["memory_performance_status"] to "acceptable"
        Otherwise:
            Set benchmark_results["memory_performance_status"] to "exceeds_limit"
    
    Note: Benchmark accuracy performance
    Let accuracy_ratio be MathOps.divide(
        accuracy_achieved.toString(),
        required_accuracy.toString()
    ).result_value.toFloat()
    
    Set benchmark_results["accuracy_ratio"] to accuracy_ratio.toString()
    
    If accuracy_ratio is greater than or equal to 10.0:
        Set benchmark_results["accuracy_performance_status"] to "excellent"
    Otherwise:
        If accuracy_ratio is greater than or equal to 1.0:
            Set benchmark_results["accuracy_performance_status"] to "meets_requirement"
        Otherwise:
            If accuracy_ratio is greater than or equal to 0.1:
                Set benchmark_results["accuracy_performance_status"] to "marginal"
            Otherwise:
                Set benchmark_results["accuracy_performance_status"] to "insufficient"
    
    Note: Benchmark iteration efficiency
    Let iteration_ratio be MathOps.divide(
        iterations_required.toString(),
        max_iterations.toString()
    ).result_value.toFloat()
    
    Set benchmark_results["iteration_efficiency_ratio"] to iteration_ratio.toString()
    
    If iteration_ratio is less than or equal to 0.5:
        Set benchmark_results["convergence_performance_status"] to "fast_convergence"
    Otherwise:
        If iteration_ratio is less than or equal to 1.0:
            Set benchmark_results["convergence_performance_status"] to "normal_convergence"
        Otherwise:
            Set benchmark_results["convergence_performance_status"] to "slow_convergence"
    
    Note: Benchmark condition number quality
    Let condition_ratio be MathOps.divide(
        condition_number_computed.toString(),
        acceptable_condition_number.toString()
    ).result_value.toFloat()
    
    Set benchmark_results["condition_number_ratio"] to condition_ratio.toString()
    
    If condition_ratio is less than or equal to 1.0:
        Set benchmark_results["numerical_stability_status"] to "well_conditioned"
    Otherwise:
        If condition_ratio is less than or equal to 100.0:
            Set benchmark_results["numerical_stability_status"] to "moderately_conditioned"
        Otherwise:
            If condition_ratio is less than or equal to 10000.0:
                Set benchmark_results["numerical_stability_status"] to "ill_conditioned"
            Otherwise:
                Set benchmark_results["numerical_stability_status"] to "severely_ill_conditioned"
    
    Note: Overall benchmark assessment
    Let performance_score be 0.0
    
    Note: Weight different performance aspects
    If benchmark_results.get("time_performance_status") is equal to "excellent":
        Set performance_score to performance_score plus 25.0
    Otherwise:
        If benchmark_results.get("time_performance_status") is equal to "acceptable":
            Set performance_score to performance_score plus 15.0
        Otherwise:
            If benchmark_results.get("time_performance_status") is equal to "poor":
                Set performance_score to performance_score plus 5.0
    
    If benchmark_results.get("accuracy_performance_status") is equal to "excellent":
        Set performance_score to performance_score plus 30.0
    Otherwise:
        If benchmark_results.get("accuracy_performance_status") is equal to "meets_requirement":
            Set performance_score to performance_score plus 20.0
        Otherwise:
            If benchmark_results.get("accuracy_performance_status") is equal to "marginal":
                Set performance_score to performance_score plus 10.0
    
    If benchmark_results.get("memory_performance_status") is equal to "excellent":
        Set performance_score to performance_score plus 20.0
    Otherwise:
        If benchmark_results.get("memory_performance_status") is equal to "acceptable":
            Set performance_score to performance_score plus 15.0
    
    If benchmark_results.get("numerical_stability_status") is equal to "well_conditioned":
        Set performance_score to performance_score plus 25.0
    Otherwise:
        If benchmark_results.get("numerical_stability_status") is equal to "moderately_conditioned":
            Set performance_score to performance_score plus 15.0
        Otherwise:
            If benchmark_results.get("numerical_stability_status") is equal to "ill_conditioned":
                Set performance_score to performance_score plus 5.0
    
    Set benchmark_results["overall_performance_score"] to performance_score.toString()
    
    Note: Determine overall benchmark rating
    If performance_score is greater than or equal to 90.0:
        Set benchmark_results["overall_benchmark_rating"] to "outstanding"
    Otherwise:
        If performance_score is greater than or equal to 70.0:
            Set benchmark_results["overall_benchmark_rating"] to "good"
        Otherwise:
            If performance_score is greater than or equal to 50.0:
                Set benchmark_results["overall_benchmark_rating"] to "acceptable"
            Otherwise:
                If performance_score is greater than or equal to 30.0:
                    Set benchmark_results["overall_benchmark_rating"] to "needs_improvement"
                Otherwise:
                    Set benchmark_results["overall_benchmark_rating"] to "poor"
    
    Return benchmark_results