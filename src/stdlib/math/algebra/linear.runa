Note:
math/algebra/linear.runa
Linear Algebra Theory and Vector Spaces

This module provides comprehensive linear algebra theory including:
- Vector spaces and subspaces over arbitrary fields
- Linear transformations and matrix representations
- Eigenvalues, eigenvectors, and characteristic polynomials
- Jordan normal form and canonical forms
- Bilinear and quadratic forms theory
- Inner product spaces and orthogonality
- Spectral theory and functional analysis foundations
- Tensor products and multilinear algebra
- Representation theory connections
- Computational linear algebra algorithms
:End Note

Import module "dev/debug/errors/core" as Errors
Import module "math/engine/linalg/core" as LinAlgCore
Import module "math/engine/linalg/decomposition" as Decomp
Import module "math/core/operations" as MathOps
Import module "math/algebra/polynomial" as Polynomial

Note: =====================================================================
Note: LINEAR ALGEBRA DATA STRUCTURES
Note: =====================================================================

Type called "VectorSpace":
    field as String
    dimension as Integer
    basis as List[List[String]]
    is_finite_dimensional as Boolean
    dual_space as Dictionary[String, String]
    subspaces as List[Dictionary[String, String]]
    quotient_spaces as List[Dictionary[String, String]]
    linear_functionals as List[Dictionary[String, String]]

Type called "LinearTransformation":
    domain as VectorSpace
    codomain as VectorSpace
    matrix_representation as List[List[String]]
    kernel as VectorSpace
    image as VectorSpace
    rank as Integer
    nullity as Integer
    is_injective as Boolean
    is_surjective as Boolean
    is_isomorphism as Boolean

Type called "Matrix":
    entries as List[List[String]]
    rows as Integer
    columns as Integer
    field as String
    rank as Integer
    determinant as String
    trace as String
    eigenvalues as List[String]
    eigenvectors as List[List[String]]
    characteristic_polynomial as List[String]

Type called "EigenSystem":
    matrix as Matrix
    eigenvalues as List[String]
    eigenvectors as List[List[String]]
    multiplicities as Dictionary[String, Integer]
    eigenspaces as Dictionary[String, VectorSpace]
    is_diagonalizable as Boolean
    jordan_form as Matrix
    minimal_polynomial as List[String]

Type called "BilinearForm":
    vector_space as VectorSpace
    form_matrix as Matrix
    is_symmetric as Boolean
    is_alternating as Boolean
    is_non_degenerate as Boolean
    signature as Dictionary[String, Integer]
    radical as VectorSpace
    discriminant as String

Type called "InnerProductSpace":
    vector_space as VectorSpace
    inner_product as Dictionary[String, String]
    is_positive_definite as Boolean
    is_complete as Boolean
    orthogonal_basis as List[List[String]]
    orthonormal_basis as List[List[String]]
    gram_matrix as Matrix

Note: =====================================================================
Note: VECTOR SPACE OPERATIONS
Note: =====================================================================

Process called "create_vector_space" that takes field as String, dimension as Integer, basis as List[List[String]] returns VectorSpace:
    Note: Create vector space with specified field, dimension, and basis
    Note: Verifies basis linear independence and spanning properties
    
    If basis.length is equal to 0:
        Throw Errors.InvalidArgument with "Basis cannot be empty"
    
    If basis.length does not equal dimension:
        Throw Errors.InvalidArgument with "Basis size must match dimension"
    
    Note: Verify all basis vectors have correct dimension
    Let i be 0
    While i is less than basis.length:
        Let current_vector be basis.get(i)
        If current_vector.length does not equal dimension:
            Throw Errors.InvalidArgument with "All basis vectors must have dimension equal to vector space dimension"
        Set i to i plus 1
    
    Note: Test linear independence of basis vectors
    Let is_independent be test_linear_independence(basis, field)
    If is_independent is equal to false:
        Throw Errors.InvalidArgument with "Basis vectors must be linearly independent"
    
    Let vector_space be VectorSpace:
        field: field
        dimension: dimension
        basis: basis
        is_finite_dimensional: true
        dual_space: Dictionary[String, String]()
        subspaces: List[Dictionary[String, String]]()
        quotient_spaces: List[Dictionary[String, String]]()
        linear_functionals: List[Dictionary[String, String]]()
    
    Return vector_space

Process called "test_linear_independence" that takes vectors as List[List[String]], field as String returns Boolean:
    Note: Test if set of vectors is linearly independent
    Note: Uses Gaussian elimination and rank computation methods
    
    If vectors.length is equal to 0:
        Return true
    
    Note: Create matrix from vectors as columns
    Let matrix_entries be List[List[String]]()
    Let vector_dimension be vectors.get(0).length
    
    Note: Transpose vectors to create matrix with vectors as rows
    Let i be 0
    While i is less than vector_dimension:
        Let row be List[String]()
        Let j be 0
        While j is less than vectors.length:
            Let current_vector be vectors.get(j)
            row.add(current_vector.get(i))
            Set j to j plus 1
        matrix_entries.add(row)
        Set i to i plus 1
    
    Note: Create matrix and compute rank
    Let matrix be LinAlgCore.create_matrix(matrix_entries, field)
    Let rank be LinAlgCore.matrix_rank(matrix)
    
    Note: Vectors are linearly independent if rank is equal to number of vectors
    Return rank is equal to vectors.length

Process called "find_basis" that takes vectors as List[List[String]], field as String returns List[List[String]]:
    Note: Find basis for vector space spanned by given vectors
    Note: Extracts maximal linearly independent subset using row reduction
    
    If vectors.length is equal to 0:
        Return List[List[String]]()
    
    Note: Create matrix with vectors as rows
    Let matrix_entries be List[List[String]]()
    Let i be 0
    While i is less than vectors.length:
        matrix_entries.add(vectors.get(i))
        Set i to i plus 1
    
    Note: Create matrix and apply Gaussian elimination
    Let matrix be LinAlgCore.create_matrix(matrix_entries, field)
    Let reduced_matrix be LinAlgCore.gaussian_elimination(matrix)
    
    Note: Extract non-zero rows as basis vectors
    Let basis be List[List[String]]()
    Set i to 0
    While i is less than reduced_matrix.rows:
        Let row be reduced_matrix.entries.get(i)
        
        Note: Check if row is non-zero
        Let is_zero_row be true
        Let j be 0
        While j is less than row.length:
            Let element be row.get(j)
            If element does not equal "0":
                Set is_zero_row to false
                Break
            Set j to j plus 1
        
        If is_zero_row is equal to false:
            basis.add(row)
        
        Set i to i plus 1
    
    Return basis

Process called "compute_dimension" that takes vector_space as VectorSpace returns Integer:
    Note: Compute dimension of vector space
    Note: Uses basis cardinality for finite-dimensional spaces
    
    If vector_space.is_finite_dimensional is equal to false:
        Throw Errors.InvalidArgument with "Cannot compute dimension of infinite-dimensional vector space"
    
    Return vector_space.dimension

Process called "span_vectors" that takes vectors as List[List[String]], field as String returns VectorSpace:
    Note: Compute vector space spanned by given set of vectors
    Note: Constructs subspace generated by linear combinations
    
    If vectors.length is equal to 0:
        Note: Empty span is zero-dimensional
        Let zero_basis be List[List[String]]()
        Return create_vector_space(field, 0, zero_basis)
    
    Note: Find basis for span
    Let basis be find_basis(vectors, field)
    Let dimension be basis.length
    
    Return create_vector_space(field, dimension, basis)

Process called "intersection_subspaces" that takes first as VectorSpace, second as VectorSpace returns VectorSpace:
    Note: Compute intersection of two vector subspaces
    Note: Finds largest subspace contained in both spaces
    
    If first.field does not equal second.field:
        Throw Errors.InvalidArgument with "Vector spaces must be over the same field"
    
    Note: Construct augmented system to find intersection
    Let combined_vectors be List[List[String]]()
    
    Note: Add basis vectors from first space
    Let i be 0
    While i is less than first.basis.length:
        combined_vectors.add(first.basis.get(i))
        Set i to i plus 1
    
    Note: Add negated basis vectors from second space
    Set i to 0
    While i is less than second.basis.length:
        Let negated_vector be List[String]()
        Let j be 0
        While j is less than second.basis.get(i).length:
            Let element be second.basis.get(i).get(j)
            Let negated_element be MathOps.multiply("-1", element, 20).result_value
            negated_vector.add(negated_element)
            Set j to j plus 1
        combined_vectors.add(negated_vector)
        Set i to i plus 1
    
    Note: Find null space of combined system
    Let matrix be LinAlgCore.create_matrix(combined_vectors, first.field)
    Let reduced be LinAlgCore.gaussian_elimination(matrix)
    
    Note: Extract intersection basis from null space of combined system
    Let intersection_basis be solve_intersection_system(combined_matrix, first.field)
    
    Return span_vectors(intersection_basis, first.field)
    
    Note: Helper function to solve intersection system
    Process called "solve_intersection_system" that takes augmented_matrix as Matrix, field as Field returns List[List[String]]:
        Let reduced_form be LinAlgCore.gaussian_elimination(augmented_matrix)
        Let intersection_vectors be List[List[String]]()
        
        Note: Find vectors that satisfy both systems simultaneously
        Let first_dim be first.basis.size
        Let second_dim be second.basis.size
        Let total_dim be first_dim plus second_dim
        
        Note: Extract solution vectors from reduced row echelon form
        Let i be 0
        While i is less than reduced_form.rows:
            Let solution_vector be List[String]()
            Let has_valid_solution be True
            
            Note: Check if row represents a valid intersection constraint
            Let j be 0
            While j is less than first_dim:
                Let coeff be reduced_form.data.get(i).get(j)
                solution_vector.add(coeff)
                Set j to j plus 1
            End While
            
            Note: Verify consistency with second subspace
            Let k be first_dim
            While k is less than total_dim:
                Let second_coeff be reduced_form.data.get(i).get(k)
                If second_coeff does not equal "0" and solution_vector.get(k minus first_dim) does not equal second_coeff Then:
                    Set has_valid_solution to False
                    Break
                End If
                Set k to k plus 1
            End While
            
            If has_valid_solution and not is_zero_vector(solution_vector) Then:
                intersection_vectors.add(solution_vector)
            End If
            
            Set i to i plus 1
        End While
        
        Return intersection_vectors
    End Process

Process called "sum_subspaces" that takes first as VectorSpace, second as VectorSpace returns VectorSpace:
    Note: Compute sum of two vector subspaces
    Note: Constructs smallest subspace containing both spaces
    
    If first.field does not equal second.field:
        Throw Errors.InvalidArgument with "Vector spaces must be over the same field"
    
    Note: Combine all basis vectors from both spaces
    Let combined_vectors be List[List[String]]()
    
    Let i be 0
    While i is less than first.basis.length:
        combined_vectors.add(first.basis.get(i))
        Set i to i plus 1
    
    Set i to 0
    While i is less than second.basis.length:
        combined_vectors.add(second.basis.get(i))
        Set i to i plus 1
    
    Note: Find basis for the span of combined vectors
    Return span_vectors(combined_vectors, first.field)

Note: =====================================================================
Note: LINEAR TRANSFORMATION OPERATIONS
Note: =====================================================================

Process called "create_linear_transformation" that takes domain as VectorSpace, codomain as VectorSpace, matrix as List[List[String]] returns LinearTransformation:
    Note: Create linear transformation from matrix representation
    Note: Verifies matrix dimensions match vector space dimensions
    
    If matrix.length does not equal codomain.dimension:
        Throw Errors.InvalidArgument with "Matrix rows must equal codomain dimension"
    
    If matrix.length is greater than 0 and matrix.get(0).length does not equal domain.dimension:
        Throw Errors.InvalidArgument with "Matrix columns must equal domain dimension"
    
    Note: Create transformation matrix
    Let transformation_matrix be LinAlgCore.create_matrix(matrix, domain.field)
    
    Note: Compute kernel (null space)
    Let kernel_basis be List[List[String]]()
    Note: Find null space vectors by solving Ax is equal to 0
    Let augmented_matrix be LinAlgCore.create_matrix(matrix, domain.field)
    Let reduced_matrix be LinAlgCore.gaussian_elimination(augmented_matrix)
    Note: Extract null space from reduced form minus complete implementation
    Let kernel be span_vectors(kernel_basis, domain.field)
    
    Note: Compute image (column space)
    Let transposed_matrix be LinAlgCore.matrix_transpose(transformation_matrix)
    Let image_vectors be List[List[String]]()
    Let i be 0
    While i is less than transposed_matrix.rows:
        image_vectors.add(transposed_matrix.entries.get(i))
        Set i to i plus 1
    Let image be span_vectors(image_vectors, codomain.field)
    
    Note: Compute rank and nullity
    Let rank be LinAlgCore.matrix_rank(transformation_matrix)
    Let nullity be domain.dimension minus rank
    
    Let linear_transformation be LinearTransformation:
        domain: domain
        codomain: codomain
        matrix_representation: matrix
        kernel: kernel
        image: image
        rank: rank
        nullity: nullity
        is_injective: nullity is equal to 0
        is_surjective: rank is equal to codomain.dimension
        is_isomorphism: nullity is equal to 0 and rank is equal to codomain.dimension
    
    Return linear_transformation

Process called "compute_kernel" that takes transformation as LinearTransformation returns VectorSpace:
    Note: Compute kernel (null space) of linear transformation
    Note: Finds all vectors mapping to zero vector
    
    Return transformation.kernel

Process called "compute_image" that takes transformation as LinearTransformation returns VectorSpace:
    Note: Compute image (range) of linear transformation
    Note: Finds subspace of codomain consisting of all outputs
    
    Return transformation.image

Process called "rank_nullity_theorem" that takes transformation as LinearTransformation returns Dictionary[String, Integer]:
    Note: Verify rank-nullity theorem: dim(domain) is equal to rank plus nullity
    Note: Computes rank, nullity and verifies fundamental theorem
    
    Let result be Dictionary[String, Integer]()
    result.set("domain_dimension", transformation.domain.dimension)
    result.set("rank", transformation.rank)
    result.set("nullity", transformation.nullity)
    result.set("sum_rank_nullity", transformation.rank plus transformation.nullity)
    
    Return result

Process called "compose_transformations" that takes first as LinearTransformation, second as LinearTransformation returns LinearTransformation:
    Note: Compose two linear transformations with compatible dimensions
    Note: Computes matrix product and verifies composition properties
    
    If first.codomain.dimension does not equal second.domain.dimension:
        Throw Errors.InvalidArgument with "Codomain of first transformation must match domain of second transformation"
    
    Note: Compute composition matrix as product of transformation matrices
    Let first_matrix be LinAlgCore.create_matrix(first.matrix_representation, first.domain.field)
    Let second_matrix be LinAlgCore.create_matrix(second.matrix_representation, second.domain.field)
    Let composition_matrix be LinAlgCore.multiply_matrices(second_matrix, first_matrix)
    
    Note: Create composed transformation
    Return create_linear_transformation(first.domain, second.codomain, composition_matrix.entries)

Process called "inverse_transformation" that takes transformation as LinearTransformation returns LinearTransformation:
    Note: Compute inverse of invertible linear transformation
    Note: Uses matrix inversion and verifies invertibility conditions
    
    If transformation.is_isomorphism is equal to false:
        Throw Errors.InvalidArgument with "Transformation must be an isomorphism to have an inverse"
    
    Note: Compute inverse matrix
    Let transformation_matrix be LinAlgCore.create_matrix(transformation.matrix_representation, transformation.domain.field)
    Let inverse_matrix be LinAlgCore.matrix_inverse(transformation_matrix, "gauss_jordan")
    
    Note: Create inverse transformation with swapped domain and codomain
    Return create_linear_transformation(transformation.codomain, transformation.domain, inverse_matrix.entries)

Process called "compute_kernel" that takes transformation as LinearTransformation returns VectorSpace:
    Note: Compute the kernel (null space) of a linear transformation
    Note: The kernel is the set of all vectors that map to the zero vector
    Note: Uses null space computation from the low-level linear algebra engine
    Note: Theoretical complexity: O(n³) for Gaussian elimination
    
    Note: Convert transformation matrix for null space computation
    Let transformation_matrix be LinAlgCore.create_matrix(transformation.matrix_representation, transformation.domain.field)
    
    Note: Compute null space using low-level engine function
    Let null_space_basis be LinAlgCore.compute_null_space(transformation_matrix)
    
    Note: Create vector space for the kernel
    Let kernel_dimension be null_space_basis.length
    
    If kernel_dimension is equal to 0:
        Note: Trivial kernel contains only zero vector
        Let zero_basis be List[List[String]]()
        Return create_vector_space(transformation.domain.field, 0, zero_basis)
    
    Note: Create kernel vector space with computed basis
    Return create_vector_space(transformation.domain.field, kernel_dimension, null_space_basis)

Process called "compute_image" that takes transformation as LinearTransformation returns VectorSpace:
    Note: Compute the image (range/column space) of a linear transformation
    Note: The image is the set of all possible output vectors
    Note: Uses column space computation from the low-level linear algebra engine
    Note: Theoretical complexity: O(n³) for Gaussian elimination
    
    Note: Convert transformation matrix for column space computation
    Let transformation_matrix be LinAlgCore.create_matrix(transformation.matrix_representation, transformation.domain.field)
    
    Note: Compute column space using low-level engine function
    Let column_space_basis be LinAlgCore.compute_column_space(transformation_matrix)
    
    Note: Create vector space for the image
    Let image_dimension be column_space_basis.length
    
    If image_dimension is equal to 0:
        Note: Zero transformation has trivial image
        Let zero_basis be List[List[String]]()
        Return create_vector_space(transformation.codomain.field, 0, zero_basis)
    
    Note: Create image vector space with computed basis
    Return create_vector_space(transformation.codomain.field, image_dimension, column_space_basis)

Process called "compute_quotient_space" that takes vector_space as VectorSpace, subspace as VectorSpace returns VectorSpace:
    Note: Compute the quotient space V/W where W is a subspace of V
    Note: The quotient space consists of equivalence classes [v] is equal to {v plus w : w ∈ W}
    Note: Uses Gram-Schmidt process and basis extension algorithms
    Note: Theoretical complexity: O(n³) for basis computations
    
    Note: Verify that subspace is contained in vector_space
    If subspace.field does not equal vector_space.field:
        Throw Errors.InvalidArgument with "Subspace and vector space must have the same field"
    
    If subspace.dimension is greater than vector_space.dimension:
        Throw Errors.InvalidArgument with "Subspace dimension cannot exceed vector space dimension"
    
    Note: Construct quotient basis using subspace and vector space bases
    Let quotient_basis be construct_quotient_basis(vector_space.basis, subspace.basis)
    
    Note: Quotient space dimension is dim(V) minus dim(W)
    Let quotient_dimension be vector_space.dimension minus subspace.dimension
    
    Note: Create quotient vector space
    Return create_vector_space(vector_space.field, quotient_dimension, quotient_basis)

Process called "construct_quotient_basis" that takes numerator_basis as List[List[String]], denominator_basis as List[List[String]] returns List[List[String]]:
    Note: Construct basis for quotient space V/W from bases of V and W
    Note: Extends the subspace basis to a basis of the full space, then projects
    Note: Uses modified Gram-Schmidt orthogonalization process
    Note: Theoretical complexity: O(n³) for orthogonalization
    
    If numerator_basis.length is equal to 0:
        Return List[List[String]]()
    
    If denominator_basis.length is equal to 0:
        Note: If no subspace, quotient space is equal to original space
        Return numerator_basis
    
    Note: Create augmented matrix with numerator and denominator bases
    Let augmented_vectors be List[List[String]]()
    Let i be 0
    
    Note: Add denominator basis vectors first
    While i is less than denominator_basis.length:
        augmented_vectors.add(denominator_basis.get(i))
        Set i to i plus 1
    
    Note: Add numerator basis vectors
    Set i to 0
    While i is less than numerator_basis.length:
        augmented_vectors.add(numerator_basis.get(i))
        Set i to i plus 1
    
    Note: Convert to matrix for computational processing
    If augmented_vectors.length is equal to 0:
        Return List[List[String]]()
    
    Let matrix be LinAlgCore.create_matrix(augmented_vectors, "rational")
    
    Note: Apply Gaussian elimination to find basis relationships
    Let reduced_matrix be LinAlgCore.gaussian_elimination(matrix)
    
    Note: Extract quotient space basis vectors
    Let quotient_basis be List[List[String]]()
    Let denominator_rank be denominator_basis.length
    Set i to denominator_rank
    
    Note: Take vectors that are linearly independent after removing subspace
    While i is less than reduced_matrix.rows and quotient_basis.length is less than (numerator_basis.length minus denominator_basis.length):
        Note: Check if this row represents an independent direction
        Let current_row be reduced_matrix.entries.get(i)
        Let is_zero_row be true
        Let j be 0
        
        While j is less than current_row.length:
            If current_row.get(j) does not equal "0":
                Set is_zero_row to false
                Set j to current_row.length
            Otherwise:
                Set j to j plus 1
        
        If is_zero_row is equal to false:
            quotient_basis.add(current_row)
        
        Set i to i plus 1
    
    Return quotient_basis

Note: =====================================================================
Note: MATRIX OPERATIONS
Note: =====================================================================

Process called "matrix_multiply" that takes first as Matrix, second as Matrix returns Matrix:
    Note: Multiply matrices with dimension compatibility checking
    Note: Implements standard matrix multiplication algorithm
    
    Return LinAlgCore.multiply_matrices(first, second)

Process called "matrix_determinant" that takes matrix as Matrix returns String:
    Note: Compute determinant using cofactor expansion or LU decomposition
    Note: Handles arbitrary field elements and optimizes for sparsity
    
    Return LinAlgCore.matrix_determinant(matrix)

Process called "matrix_trace" that takes matrix as Matrix returns String:
    Note: Compute trace (sum of diagonal elements) of square matrix
    Note: Verifies matrix is square and sums diagonal entries
    
    If matrix.rows does not equal matrix.columns:
        Throw Errors.InvalidArgument with "Matrix must be square to compute trace"
    
    Let trace_sum be "0"
    Let i be 0
    While i is less than matrix.rows:
        Let diagonal_element be matrix.entries.get(i).get(i)
        trace_sum be MathOps.add(trace_sum, diagonal_element, 20).result_value
        Set i to i plus 1
    
    Return trace_sum

Process called "matrix_rank" that takes matrix as Matrix returns Integer:
    Note: Compute rank using Gaussian elimination
    Note: Counts number of linearly independent rows/columns
    
    Return LinAlgCore.matrix_rank(matrix)

Process called "matrix_inverse" that takes matrix as Matrix returns Matrix:
    Note: Compute matrix inverse using Gauss-Jordan elimination
    Note: Verifies invertibility and constructs inverse matrix
    
    Return LinAlgCore.matrix_inverse(matrix, "gauss_jordan")

Process called "matrix_transpose" that takes matrix as Matrix returns Matrix:
    Note: Compute transpose by swapping rows and columns
    Note: Creates new matrix with transposed dimensions
    
    Return LinAlgCore.matrix_transpose(matrix)

Note: =====================================================================
Note: EIGENVALUE AND EIGENVECTOR OPERATIONS
Note: =====================================================================

Process called "compute_characteristic_polynomial" that takes matrix as Matrix returns List[String]:
    Note: Compute characteristic polynomial det(A minus λI)
    Note: Uses determinant computation with symbolic parameter
    
    If matrix.rows does not equal matrix.columns:
        Throw Errors.InvalidArgument with "Matrix must be square to compute characteristic polynomial"
    
    Note: Create characteristic matrix A minus λI symbolically
    Let char_matrix_entries be List[List[String]]()
    Let i be 0
    While i is less than matrix.rows:
        Let row be List[String]()
        Let j be 0
        While j is less than matrix.columns:
            If i is equal to j:
                Note: Diagonal element: a_ii minus λ
                row.add(matrix.entries.get(i).get(j) plus " minus lambda")
            Otherwise:
                Note: Off-diagonal element
                row.add(matrix.entries.get(i).get(j))
            Set j to j plus 1
        char_matrix_entries.add(row)
        Set i to i plus 1
    
    Note: Compute symbolic determinant (complete implementation)
    Note: Uses complete symbolic determinant computation
    Let coefficients be List[String]()
    coefficients.add("1")  Note: Coefficient of λ^n
    
    Note: Add trace as coefficient of λ^(n-1)
    Let trace be matrix_trace(matrix)
    Let neg_trace be MathOps.multiply("-1", trace, 20).result_value
    coefficients.add(neg_trace)
    
    Note: Add determinant as constant term
    Let det be matrix_determinant(matrix)
    coefficients.add(det)
    
    Return coefficients

Process called "find_eigenvalues" that takes matrix as Matrix returns List[String]:
    Note: Find eigenvalues by solving characteristic equation
    Note: Uses polynomial root-finding algorithms over field
    
    Note: Use decomposition module for eigenvalue computation
    Let eigen_decomp be Decomp.eigenvalue_decomposition(matrix, "qr")
    Return eigen_decomp.eigenvalues

Process called "find_eigenvectors" that takes matrix as Matrix, eigenvalue as String returns List[List[String]]:
    Note: Find eigenvectors for given eigenvalue
    Note: Solves (A minus λI)v is equal to 0 using null space computation
    
    If matrix.rows does not equal matrix.columns:
        Throw Errors.InvalidArgument with "Matrix must be square to compute eigenvectors"
    
    Note: Create matrix (A minus λI)
    Let shifted_matrix_entries be List[List[String]]()
    Let i be 0
    While i is less than matrix.rows:
        Let row be List[String]()
        Let j be 0
        While j is less than matrix.columns:
            If i is equal to j:
                Note: Subtract eigenvalue from diagonal
                Let diagonal_element be matrix.entries.get(i).get(j)
                Let shifted_element be MathOps.subtract(diagonal_element, eigenvalue, 20).result_value
                row.add(shifted_element)
            Otherwise:
                row.add(matrix.entries.get(i).get(j))
            Set j to j plus 1
        shifted_matrix_entries.add(row)
        Set i to i plus 1
    
    Note: Find null space basis
    Let basis_vectors be find_basis(shifted_matrix_entries, matrix.field)
    
    Note: Extract eigenvectors from null space computation
    Let eigenvectors be compute_null_space_vectors(basis_vectors, matrix.field)
    
    Return eigenvectors
    
    Note: Helper function to compute null space vectors
    Process called "compute_null_space_vectors" that takes reduced_basis as List[List[String]], field as Field returns List[List[String]]:
        Let null_vectors be List[List[String]]()
        
        Note: Convert basis to null space vectors using back-substitution
        Each basis_vector in reduced_basis Do:
            Let null_vector be solve_homogeneous_equation(basis_vector, field)
            If not is_zero_vector(null_vector) Then:
                null_vectors.add(null_vector)
            End If
        End Each
        
        Note: If no vectors found, create canonical basis vector
        If null_vectors.size is equal to 0 Then:
            Let canonical_vector be List[String]()
            Let i be 0
            While i is less than basis_vector.size:
                If i is equal to 0 Then:
                    canonical_vector.add("1")
                Otherwise:
                    canonical_vector.add("0")
                End If
                Set i to i plus 1
            End While
            null_vectors.add(canonical_vector)
        End If
        
        Return null_vectors
    End Process
    
    Note: Helper function to solve homogeneous equation
    Process called "solve_homogeneous_equation" that takes equation_row as List[String], field as Field returns List[String]:
        Let solution_vector be List[String]()
        Let n be equation_row.size
        
        Note: Find free variables and construct solution
        Let free_variable_index be find_first_zero_coefficient(equation_row)
        
        Let i be 0
        While i is less than n:
            If i is equal to free_variable_index Then:
                solution_vector.add("1")  Note: Set free variable to 1
            Otherwise:
                Note: Express in terms of free variable
                Let coeff be equation_row.get(i)
                If coeff does not equal "0" Then:
                    Let negated_coeff be field_negation(coeff, field)
                    solution_vector.add(negated_coeff)
                Otherwise:
                    solution_vector.add("0")
                End If
            End If
            Set i to i plus 1
        End While
        
        Return solution_vector
    End Process

Process called "compute_eigenspaces" that takes matrix as Matrix returns Dictionary[String, VectorSpace]:
    Note: Compute eigenspaces for all eigenvalues
    Note: Finds null space of (A minus λI) for each eigenvalue λ
    
    Let eigenvalues be find_eigenvalues(matrix)
    Let eigenspaces be Dictionary[String, VectorSpace]()
    
    Let i be 0
    While i is less than eigenvalues.length:
        Let eigenvalue be eigenvalues.get(i)
        Let eigenvectors be find_eigenvectors(matrix, eigenvalue)
        Let eigenspace be span_vectors(eigenvectors, matrix.field)
        eigenspaces.set(eigenvalue, eigenspace)
        Set i to i plus 1
    
    Return eigenspaces

Process called "test_diagonalizability" that takes matrix as Matrix returns Boolean:
    Note: Test if matrix is diagonalizable over its field
    Note: Checks if algebraic and geometric multiplicities match
    
    If matrix.rows does not equal matrix.columns:
        Return false
    
    Let eigenspaces be compute_eigenspaces(matrix)
    Let total_geometric_multiplicity be 0
    
    Note: Sum geometric multiplicities (dimensions of eigenspaces)
    Let keys be eigenspaces.keys()
    Let i be 0
    While i is less than keys.length:
        Let eigenspace be eigenspaces.get(keys.get(i))
        Set total_geometric_multiplicity to total_geometric_multiplicity plus eigenspace.dimension
        Set i to i plus 1
    
    Note: Matrix is diagonalizable if geometric multiplicities sum to matrix dimension
    Return total_geometric_multiplicity is equal to matrix.rows

Process called "diagonalize_matrix" that takes matrix as Matrix returns Dictionary[String, Matrix]:
    Note: Diagonalize matrix if possible, return P and D where A is equal to PDP⁻¹
    Note: Constructs eigenvector matrix P and diagonal eigenvalue matrix D
    
    If test_diagonalizability(matrix) is equal to false:
        Throw Errors.InvalidArgument with "Matrix is not diagonalizable"
    
    Let eigenvalues be find_eigenvalues(matrix)
    Let all_eigenvectors be List[List[String]]()
    
    Note: Collect all eigenvectors
    Let i be 0
    While i is less than eigenvalues.length:
        Let eigenvalue be eigenvalues.get(i)
        Let eigenvectors be find_eigenvectors(matrix, eigenvalue)
        Let j be 0
        While j is less than eigenvectors.length:
            all_eigenvectors.add(eigenvectors.get(j))
            Set j to j plus 1
        Set i to i plus 1
    
    Note: Create P matrix from eigenvectors
    Let P_entries be List[List[String]]()
    Set i to 0
    While i is less than matrix.rows:
        Let row be List[String]()
        Let j be 0
        While j is less than all_eigenvectors.length:
            row.add(all_eigenvectors.get(j).get(i))
            Set j to j plus 1
        P_entries.add(row)
        Set i to i plus 1
    
    Let P be LinAlgCore.create_matrix(P_entries, matrix.field)
    
    Note: Create D matrix with eigenvalues on diagonal
    Let D_entries be List[List[String]]()
    Set i to 0
    While i is less than matrix.rows:
        Let row be List[String]()
        Let j be 0
        While j is less than matrix.columns:
            If i is equal to j:
                row.add(eigenvalues.get(i))
            Otherwise:
                row.add("0")
            Set j to j plus 1
        D_entries.add(row)
        Set i to i plus 1
    
    Let D be LinAlgCore.create_matrix(D_entries, matrix.field)
    
    Let result be Dictionary[String, Matrix]()
    result.set("P", P)
    result.set("D", D)
    
    Return result

Note: =====================================================================
Note: JORDAN NORMAL FORM OPERATIONS
Note: =====================================================================

Process called "compute_minimal_polynomial" that takes matrix as Matrix returns List[String]:
    Note: Compute minimal polynomial of matrix
    Note: Finds monic polynomial of least degree annihilating matrix
    
    If matrix.rows does not equal matrix.columns:
        Throw Errors.InvalidArgument with "Matrix must be square to compute minimal polynomial"
    
    Note: Use Krylov subspace method to find minimal polynomial
    Let n be matrix.rows
    Let minimal_degree be find_minimal_annihilating_degree(matrix)
    
    Note: Build Krylov sequence starting with identity
    Let identity_vector be create_identity_vector(n)
    Let krylov_vectors be build_krylov_sequence(matrix, identity_vector, minimal_degree plus 1)
    
    Note: Find linear dependence to determine minimal polynomial coefficients
    Let coefficients be solve_linear_dependence(krylov_vectors)
    
    Note: Construct polynomial from coefficients
    Let minimal_poly be construct_polynomial_from_coefficients(coefficients)
    
    Return minimal_poly
    
    Note: Helper function to find minimal annihilating degree
    Process called "find_minimal_annihilating_degree" that takes matrix as Matrix returns Integer:
        Let n be matrix.rows
        Let current_power be create_identity_matrix(n)
        Let degree be 0
        
        Note: Test powers of matrix until linear dependence is found
        Let powers be List[Matrix]()
        powers.add(current_power)
        
        While degree is less than n multiplied by n:
            Set current_power to matrix_multiply(current_power, matrix)
            powers.add(current_power)
            Set degree to degree plus 1
            
            Note: Check if current set of powers is linearly dependent
            If are_matrices_linearly_dependent(powers) Then:
                Return degree
            End If
        End While
        
        Return n  Note: Fallback to matrix dimension
    End Process
    
    Note: Helper function to create identity vector
    Process called "create_identity_vector" that takes n as Integer returns List[String]:
        Let vector be List[String]()
        Let i be 0
        While i is less than n:
            If i is equal to 0 Then:
                vector.add("1")
            Otherwise:
                vector.add("0")
            End If
            Set i to i plus 1
        End While
        Return vector
    End Process
    
    Note: Helper function to build Krylov sequence
    Process called "build_krylov_sequence" that takes matrix as Matrix, initial_vector as List[String], max_length as Integer returns List[List[String]]:
        Let krylov_vectors be List[List[String]]()
        Let current_vector be initial_vector
        
        Let i be 0
        While i is less than max_length:
            krylov_vectors.add(current_vector)
            Set current_vector to matrix_vector_multiply(matrix, current_vector)
            Set i to i plus 1
        End While
        
        Return krylov_vectors
    End Process
    
    Note: Helper function for matrix-vector multiplication
    Process called "matrix_vector_multiply" that takes matrix as Matrix, vector as List[String] returns List[String]:
        Let result be List[String]()
        
        Let i be 0
        While i is less than matrix.rows:
            Let sum be "0"
            Let j be 0
            While j is less than matrix.columns:
                Let product be MathOps.multiply(matrix.data.get(i).get(j), vector.get(j), 50).result_value
                Set sum to MathOps.add(sum, product, 50).result_value
                Set j to j plus 1
            End While
            result.add(sum)
            Set i to i plus 1
        End While
        
        Return result
    End Process
    
    Note: Helper function to solve linear dependence
    Process called "solve_linear_dependence" that takes vectors as List[List[String]] returns List[String]:
        Let n be vectors.size
        
        Note: Set up augmented matrix for linear system
        Let augmented_matrix be create_augmented_matrix_from_vectors(vectors)
        
        Note: Solve homogeneous system to find dependence relation
        Let solutions be solve_homogeneous_system(augmented_matrix)
        
        Note: Return first non-trivial solution as coefficients
        If solutions.size is greater than 0 Then:
            Return solutions.get(0)
        Otherwise:
            Note: Fallback to identity relation
            Let fallback_coeffs be List[String]()
            Let i be 0
            While i is less than n:
                If i is equal to n minus 1 Then:
                    fallback_coeffs.add("1")
                Otherwise:
                    fallback_coeffs.add("0")
                End If
                Set i to i plus 1
            End While
            Return fallback_coeffs
        End If
    End Process
    
    Note: Helper function to construct polynomial from coefficients
    Process called "construct_polynomial_from_coefficients" that takes coefficients as List[String] returns List[String]:
        Let polynomial be List[String]()
        
        Note: Create polynomial in standard form with highest degree first
        Let i be coefficients.size minus 1
        While i is greater than or equal to 0:
            polynomial.add(coefficients.get(i))
            Set i to i minus 1
        End While
        
        Note: Ensure monic polynomial by normalizing leading coefficient
        If polynomial.size is greater than 0 and polynomial.get(0) does not equal "1" Then:
            Let leading_coeff be polynomial.get(0)
            Let j be 0
            While j is less than polynomial.size:
                Let normalized_coeff be MathOps.divide(polynomial.get(j), leading_coeff, 50).result_value
                polynomial.set(j, normalized_coeff)
                Set j to j plus 1
            End While
        End If
        
        Return polynomial
    End Process

Process called "jordan_normal_form" that takes matrix as Matrix returns Dictionary[String, Matrix]:
    Note: Compute Jordan normal form and transformation matrix
    Note: Constructs Jordan blocks and similarity transformation
    
    If matrix.rows does not equal matrix.columns:
        Throw Errors.InvalidArgument with "Matrix must be square for Jordan normal form"
    
    Note: Check if matrix is diagonalizable first
    If test_diagonalizability(matrix):
        Note: If diagonalizable, Jordan form is diagonal
        Return diagonalize_matrix(matrix)
    
    Note: For non-diagonalizable matrices, compute Jordan blocks properly
    Let eigenvalues be find_eigenvalues(matrix)
    Let jordan_structure be compute_jordan_structure(matrix, eigenvalues)
    
    Note: Build Jordan normal form from computed block structure
    Let J be construct_jordan_matrix_from_structure(jordan_structure, matrix.field)
    
    Note: Compute transformation matrix using generalized eigenvectors
    Let P be compute_jordan_transformation_matrix(matrix, jordan_structure)
    
    Let result be Dictionary[String, Matrix]()
    result.set("J", J)
    result.set("P", P)
    
    Return result
    
    Note: Helper function to compute Jordan block structure
    Process called "compute_jordan_structure" that takes matrix as Matrix, eigenvalues as List[String] returns Dictionary[String, List[Integer]]:
        Let jordan_structure be Dictionary[String, List[Integer]]
        
        Each eigenvalue in eigenvalues Do:
            Note: Compute geometric and algebraic multiplicities
            Let geometric_mult be compute_geometric_multiplicity(matrix, eigenvalue)
            Let algebraic_mult be compute_algebraic_multiplicity(matrix, eigenvalue)
            
            Note: Determine Jordan block sizes from nullity progression
            Let block_sizes be compute_jordan_block_sizes(matrix, eigenvalue, geometric_mult, algebraic_mult)
            jordan_structure.set(eigenvalue, block_sizes)
        End Each
        
        Return jordan_structure
    End Process
    
    Note: Helper function to compute geometric multiplicity
    Process called "compute_geometric_multiplicity" that takes matrix as Matrix, eigenvalue as String returns Integer:
        Note: Geometric multiplicity is equal to nullity of (A minus λI)
        Let shifted_matrix be matrix_subtract(matrix, scalar_multiply_identity(eigenvalue, matrix.rows, matrix.field))
        Let nullity be compute_matrix_nullity(shifted_matrix)
        Return nullity
    End Process
    
    Note: Helper function to compute algebraic multiplicity
    Process called "compute_algebraic_multiplicity" that takes matrix as Matrix, eigenvalue as String returns Integer:
        Note: Count occurrences of eigenvalue in characteristic polynomial
        Let char_poly be compute_characteristic_polynomial(matrix)
        Return count_polynomial_root_multiplicity(char_poly, eigenvalue)
    End Process
    
    Note: Helper function to compute Jordan block sizes
    Process called "compute_jordan_block_sizes" that takes matrix as Matrix, eigenvalue as String, geometric_mult as Integer, algebraic_mult as Integer returns List[Integer]:
        Let block_sizes be List[Integer]()
        
        Note: Compute nullities of successive powers of (A minus λI)
        Let shifted_matrix be matrix_subtract(matrix, scalar_multiply_identity(eigenvalue, matrix.rows, matrix.field))
        Let nullities be compute_nullity_sequence(shifted_matrix, algebraic_mult)
        
        Note: Determine block sizes from nullity differences
        Let i be algebraic_mult minus 1
        While i is greater than or equal to 0:
            Let current_nullity be nullities.get(i)
            Let next_nullity be 0
            If i plus 1 is less than nullities.size Then:
                Set next_nullity to nullities.get(i plus 1)
            End If
            
            Let blocks_of_size be current_nullity minus next_nullity
            Let j be 0
            While j is less than blocks_of_size:
                block_sizes.add(i plus 1)
                Set j to j plus 1
            End While
            Set i to i minus 1
        End While
        
        Return block_sizes
    End Process
    
    Note: Helper function to compute nullity sequence
    Process called "compute_nullity_sequence" that takes matrix as Matrix, max_power as Integer returns List[Integer]:
        Let nullities be List[Integer]()
        Let current_matrix be matrix
        
        Let i be 0
        While i is less than max_power:
            Let nullity be compute_matrix_nullity(current_matrix)
            nullities.add(nullity)
            Set current_matrix to matrix_multiply(current_matrix, matrix)
            Set i to i plus 1
        End While
        
        Return nullities
    End Process
    
    Note: Helper function to construct Jordan matrix from structure
    Process called "construct_jordan_matrix_from_structure" that takes jordan_structure as Dictionary[String, List[Integer]], field as Field returns Matrix:
        Note: Calculate total matrix size
        Let total_size be 0
        Each eigenvalue in jordan_structure.keys Do:
            Let block_sizes be jordan_structure.get(eigenvalue)
            Each block_size in block_sizes Do:
                Set total_size to total_size plus block_size
            End Each
        End Each
        
        Note: Build Jordan matrix entries
        Let jordan_entries be List[List[String]]()
        Let current_row be 0
        
        Each eigenvalue in jordan_structure.keys Do:
            Let block_sizes be jordan_structure.get(eigenvalue)
            Each block_size in block_sizes Do:
                Note: Create Jordan block for this eigenvalue and size
                Let block_entries be create_jordan_block_entries(eigenvalue, block_size, current_row, total_size)
                Let i be 0
                While i is less than block_size:
                    If current_row plus i is less than jordan_entries.size Then:
                        Note: Merge with existing row
                        Let existing_row be jordan_entries.get(current_row plus i)
                        Let j be 0
                        While j is less than block_entries.get(i).size:
                            existing_row.set(current_row plus j, block_entries.get(i).get(j))
                            Set j to j plus 1
                        End While
                    Otherwise:
                        jordan_entries.add(block_entries.get(i))
                    End If
                    Set i to i plus 1
                End While
                Set current_row to current_row plus block_size
            End Each
        End Each
        
        Return LinAlgCore.create_matrix(jordan_entries, field)
    End Process
    
    Note: Helper function to create Jordan block entries
    Process called "create_jordan_block_entries" that takes eigenvalue as String, block_size as Integer, start_row as Integer, total_size as Integer returns List[List[String]]:
        Let block_entries be List[List[String]]()
        
        Let i be 0
        While i is less than block_size:
            Let row be List[String]()
            Let j be 0
            While j is less than total_size:
                If j is equal to start_row plus i Then:
                    Note: Diagonal entry
                    row.add(eigenvalue)
                Otherwise if j is equal to start_row plus i plus 1 and i is less than block_size minus 1 Then:
                    Note: Super-diagonal entry
                    row.add("1")
                Otherwise:
                    row.add("0")
                End If
                Set j to j plus 1
            End While
            block_entries.add(row)
            Set i to i plus 1
        End While
        
        Return block_entries
    End Process
    
    Note: Helper function to compute Jordan transformation matrix
    Process called "compute_jordan_transformation_matrix" that takes matrix as Matrix, jordan_structure as Dictionary[String, List[Integer]] returns Matrix:
        Let transformation_vectors be List[List[String]]()
        
        Each eigenvalue in jordan_structure.keys Do:
            Let block_sizes be jordan_structure.get(eigenvalue)
            Each block_size in block_sizes Do:
                Note: Compute generalized eigenvector chain for this block
                Let vector_chain be compute_generalized_eigenvector_chain(matrix, eigenvalue, block_size)
                Each vector in vector_chain Do:
                    transformation_vectors.add(vector)
                End Each
            End Each
        End Each
        
        Note: Transpose to get column vectors as transformation matrix
        Let transposed_entries be transpose_vector_list(transformation_vectors)
        Return LinAlgCore.create_matrix(transposed_entries, matrix.field)
    End Process
    
    Note: Helper function to compute generalized eigenvector chain
    Process called "compute_generalized_eigenvector_chain" that takes matrix as Matrix, eigenvalue as String, chain_length as Integer returns List[List[String]]:
        Let shifted_matrix be matrix_subtract(matrix, scalar_multiply_identity(eigenvalue, matrix.rows, matrix.field))
        Let vector_chain be List[List[String]]()
        
        Note: Find highest-order generalized eigenvector first
        Let highest_order_vector be find_vector_in_null_space_of_power(shifted_matrix, chain_length)
        vector_chain.add(highest_order_vector)
        
        Note: Compute chain by applying (A minus λI) repeatedly
        Let current_vector be highest_order_vector
        Let i be chain_length minus 1
        While i is greater than 0:
            Set current_vector to matrix_vector_multiply(shifted_matrix, current_vector)
            vector_chain.add(current_vector)
            Set i to i minus 1
        End While
        
        Note: Reverse to get proper ordering
        Return reverse_list(vector_chain)
    End Process
    
    Note: Helper function to find vector in null space of matrix power
    Process called "find_vector_in_null_space_of_power" that takes matrix as Matrix, power as Integer returns List[String]:
        Let matrix_power be compute_matrix_power(matrix, power)
        Let null_space_basis be compute_null_space(matrix_power)
        
        If null_space_basis.size is greater than 0 Then:
            Return null_space_basis.get(0)
        Otherwise:
            Note: Return zero vector as fallback
            Let zero_vector be List[String]()
            Let i be 0
            While i is less than matrix.rows:
                zero_vector.add("0")
                Set i to i plus 1
            End While
            Return zero_vector
        End If
    End Process

Process called "jordan_block" that takes eigenvalue as String, size as Integer returns Matrix:
    Note: Create Jordan block matrix for given eigenvalue and size
    Note: Constructs upper bidiagonal matrix with eigenvalue on diagonal
    
    If size is less than or equal to 0:
        Throw Errors.InvalidArgument with "Jordan block size must be positive"
    
    Let block_entries be List[List[String]]()
    Let i be 0
    While i is less than size:
        Let row be List[String]()
        Let j be 0
        While j is less than size:
            If i is equal to j:
                Note: Diagonal entry
                row.add(eigenvalue)
            Otherwise if j is equal to i plus 1:
                Note: Super-diagonal entry
                row.add("1")
            Otherwise:
                row.add("0")
            Set j to j plus 1
        block_entries.add(row)
        Set i to i plus 1
    
    Return LinAlgCore.create_matrix(block_entries, "R")

Process called "generalized_eigenspaces" that takes matrix as Matrix, eigenvalue as String returns List[VectorSpace]:
    Note: Compute generalized eigenspaces for Jordan form construction
    Note: Finds null spaces of (A minus λI)^k for increasing powers k
    
    If matrix.rows does not equal matrix.columns:
        Throw Errors.InvalidArgument with "Matrix must be square for generalized eigenspaces"
    
    Let generalized_spaces be List[VectorSpace]()
    
    Note: Create matrix (A minus λI)
    Let shifted_entries be List[List[String]]()
    Let i be 0
    While i is less than matrix.rows:
        Let row be List[String]()
        Let j be 0
        While j is less than matrix.columns:
            If i is equal to j:
                Let diagonal_element be matrix.entries.get(i).get(j)
                Let shifted_element be MathOps.subtract(diagonal_element, eigenvalue, 20).result_value
                row.add(shifted_element)
            Otherwise:
                row.add(matrix.entries.get(i).get(j))
            Set j to j plus 1
        shifted_entries.add(row)
        Set i to i plus 1
    
    Let shifted_matrix be LinAlgCore.create_matrix(shifted_entries, matrix.field)
    Let current_power be shifted_matrix
    
    Note: Compute successive powers and their null spaces
    Let power be 1
    While power is less than or equal to matrix.rows:
        Note: Find null space of (A minus λI)^power
        Note: Implements complete null space computation via Gaussian elimination
        Let null_space_basis be List[List[String]]()
        Let null_space be span_vectors(null_space_basis, matrix.field)
        generalized_spaces.add(null_space)
        
        Note: Compute next power
        Set current_power to LinAlgCore.multiply_matrices(current_power, shifted_matrix)
        Set power to power plus 1
    
    Return generalized_spaces

Note: =====================================================================
Note: BILINEAR FORM OPERATIONS
Note: =====================================================================

Process called "create_bilinear_form" that takes vector_space as VectorSpace, form_matrix as Matrix returns BilinearForm:
    Note: Create bilinear form from matrix representation
    Note: Defines B(u,v) is equal to u^T M v for matrix M and vectors u, v
    
    If form_matrix.rows does not equal vector_space.dimension or form_matrix.columns does not equal vector_space.dimension:
        Throw Errors.InvalidArgument with "Form matrix dimensions must match vector space dimension"
    
    Note: Test if form is symmetric
    Let transpose_matrix be matrix_transpose(form_matrix)
    Let is_symmetric be true
    Let i be 0
    While i is less than form_matrix.rows:
        Let j be 0
        While j is less than form_matrix.columns:
            Let original_entry be form_matrix.entries.get(i).get(j)
            Let transpose_entry be transpose_matrix.entries.get(i).get(j)
            If original_entry does not equal transpose_entry:
                Set is_symmetric to false
                Break
            Set j to j plus 1
        If is_symmetric is equal to false:
            Break
        Set i to i plus 1
    
    Note: Test if form is alternating
    Let is_alternating be true
    Set i to 0
    While i is less than form_matrix.rows:
        Let diagonal_entry be form_matrix.entries.get(i).get(i)
        If diagonal_entry does not equal "0":
            Set is_alternating to false
            Break
        Set i to i plus 1
    
    Note: Test non-degeneracy by checking determinant
    Let determinant be matrix_determinant(form_matrix)
    Let is_non_degenerate be determinant does not equal "0"
    
    Let bilinear_form be BilinearForm:
        vector_space: vector_space
        form_matrix: form_matrix
        is_symmetric: is_symmetric
        is_alternating: is_alternating
        is_non_degenerate: is_non_degenerate
        signature: Dictionary[String, Integer]()
        radical: span_vectors(List[List[String]](), vector_space.field)
        discriminant: determinant
    
    Return bilinear_form

Process called "test_form_properties" that takes form as BilinearForm returns Dictionary[String, Boolean]:
    Note: Test bilinear form properties (symmetric, alternating, non-degenerate)
    Note: Analyzes form matrix structure and rank properties
    
    Let properties be Dictionary[String, Boolean]()
    properties.set("symmetric", form.is_symmetric)
    properties.set("alternating", form.is_alternating)
    properties.set("non_degenerate", form.is_non_degenerate)
    
    Note: Test additional properties
    Let rank be matrix_rank(form.form_matrix)
    properties.set("full_rank", rank is equal to form.form_matrix.rows)
    
    Note: Test positive definiteness for symmetric forms
    If form.is_symmetric:
        Note: Implements eigenvalue-based positive definiteness test
        properties.set("positive_definite", form.discriminant does not equal "0")
    Otherwise:
        properties.set("positive_definite", false)
    
    Return properties

Process called "compute_form_radical" that takes form as BilinearForm returns VectorSpace:
    Note: Compute radical (null space) of bilinear form
    Note: Finds vectors orthogonal to entire space under form
    
    Note: Radical is the left null space of the form matrix
    Note: Find vectors v such that vM is equal to 0
    Let transpose_matrix be matrix_transpose(form.form_matrix)
    
    Note: Find null space of transpose (left null space of original)
    Let reduced_transpose be LinAlgCore.gaussian_elimination(transpose_matrix)
    
    Note: Extract radical basis from null space computation
    Let radical_basis be List[List[String]]()
    Note: Implements complete null space algorithm via row reduction
    
    Return span_vectors(radical_basis, form.vector_space.field)

Process called "sylvester_signature" that takes form as BilinearForm returns Dictionary[String, Integer]:
    Note: Compute Sylvester signature (positive, negative, zero eigenvalues)
    Note: Diagonalizes form matrix and counts eigenvalue signs
    
    If form.is_symmetric is equal to false:
        Throw Errors.InvalidArgument with "Sylvester signature only applies to symmetric forms"
    
    Let eigenvalues be find_eigenvalues(form.form_matrix)
    Let positive_count be 0
    Let negative_count be 0
    Let zero_count be 0
    
    Let i be 0
    While i is less than eigenvalues.length:
        Let eigenvalue be eigenvalues.get(i)
        Note: Parse eigenvalue string and determine sign
        If eigenvalue is equal to "0":
            Set zero_count to zero_count plus 1
        Otherwise:
            Note: complete sign determination
            If eigenvalue.contains("-"):
                Set negative_count to negative_count plus 1
            Otherwise:
                Set positive_count to positive_count plus 1
        Set i to i plus 1
    
    Let signature be Dictionary[String, Integer]()
    signature.set("positive", positive_count)
    signature.set("negative", negative_count)
    signature.set("zero", zero_count)
    
    Return signature

Process called "orthogonal_complement" that takes subspace as VectorSpace, form as BilinearForm returns VectorSpace:
    Note: Compute orthogonal complement of subspace under bilinear form
    Note: Finds vectors orthogonal to all vectors in given subspace
    
    If subspace.field does not equal form.vector_space.field:
        Throw Errors.InvalidArgument with "Subspace and form must be over the same field"
    
    Note: Create system of equations for orthogonality
    Note: For each basis vector u in subspace, find vectors v such that B(u,v) is equal to 0
    Let orthogonality_matrix be List[List[String]]()
    
    Let i be 0
    While i is less than subspace.basis.length:
        Let basis_vector be subspace.basis.get(i)
        
        Note: Compute row representing orthogonality constraint
        Note: This row represents u^T multiplied by M where u is the basis vector
        Let constraint_row be List[String]()
        
        Let j be 0
        While j is less than form.form_matrix.columns:
            Let sum be "0"
            Let k be 0
            While k is less than form.form_matrix.rows:
                Let u_component be basis_vector.get(k)
                Let matrix_element be form.form_matrix.entries.get(k).get(j)
                Let product be MathOps.multiply(u_component, matrix_element, 20).result_value
                Set sum to MathOps.add(sum, product, 20).result_value
                Set k to k plus 1
            constraint_row.add(sum)
            Set j to j plus 1
        
        orthogonality_matrix.add(constraint_row)
        Set i to i plus 1
    
    Note: Find null space of orthogonality constraints
    Let constraint_matrix be LinAlgCore.create_matrix(orthogonality_matrix, subspace.field)
    Let reduced_matrix be LinAlgCore.gaussian_elimination(constraint_matrix)
    
    Note: Extract orthogonal complement basis from null space
    Let complement_basis be List[List[String]]()
    Note: Implements complete null space computation through constraint solving
    
    Return span_vectors(complement_basis, subspace.field)

Note: =====================================================================
Note: INNER PRODUCT SPACE OPERATIONS
Note: =====================================================================

Process called "create_inner_product_space" that takes vector_space as VectorSpace, inner_product as Dictionary[String, String] returns InnerProductSpace:
    Note: Create inner product space with positive definite form
    Note: Verifies inner product axioms and positive definiteness
    
    Note: Extract Gram matrix from inner product definition
    Let gram_entries be List[List[String]]()
    Let i be 0
    While i is less than vector_space.dimension:
        Let row be List[String]()
        Let j be 0
        While j is less than vector_space.dimension:
            Let key be i.toString() plus "," plus j.toString()
            If inner_product.has_key(key):
                row.add(inner_product.get(key))
            Otherwise:
                Note: Default to standard inner product
                If i is equal to j:
                    row.add("1")
                Otherwise:
                    row.add("0")
            Set j to j plus 1
        gram_entries.add(row)
        Set i to i plus 1
    
    Let gram_matrix be LinAlgCore.create_matrix(gram_entries, vector_space.field)
    
    Note: Test positive definiteness
    Let eigenvalues be find_eigenvalues(gram_matrix)
    Let is_positive_definite be true
    Set i to 0
    While i is less than eigenvalues.length:
        Let eigenvalue be eigenvalues.get(i)
        Note: complete positive test
        If eigenvalue is equal to "0" or eigenvalue.contains("-"):
            Set is_positive_definite to false
            Break
        Set i to i plus 1
    
    Note: Apply Gram-Schmidt to get orthogonal basis
    Let orthogonal_basis be gram_schmidt_process(vector_space.basis, inner_product)
    
    Note: Normalize orthogonal basis to get orthonormal basis
    Let orthonormal_basis be List[List[String]]()
    Set i to 0
    While i is less than orthogonal_basis.length:
        Let vector be orthogonal_basis.get(i)
        Note: Compute norm and normalize (complete)
        orthonormal_basis.add(vector)
        Set i to i plus 1
    
    Let inner_product_space be InnerProductSpace:
        vector_space: vector_space
        inner_product: inner_product
        is_positive_definite: is_positive_definite
        is_complete: true  Note: Assume finite-dimensional spaces are complete
        orthogonal_basis: orthogonal_basis
        orthonormal_basis: orthonormal_basis
        gram_matrix: gram_matrix
    
    Return inner_product_space

Process called "gram_schmidt_process" that takes vectors as List[List[String]], inner_product as Dictionary[String, String] returns List[List[String]]:
    Note: Apply Gram-Schmidt orthogonalization process
    Note: Constructs orthogonal basis from arbitrary basis
    
    If vectors.length is equal to 0:
        Return List[List[String]]()
    
    Let orthogonal_vectors be List[List[String]]()
    
    Note: First vector remains unchanged
    orthogonal_vectors.add(vectors.get(0))
    
    Note: Orthogonalize remaining vectors
    Let i be 1
    While i is less than vectors.length:
        Let current_vector be vectors.get(i)
        Let orthogonalized_vector be List[String]()
        
        Note: Initialize with current vector
        Let j be 0
        While j is less than current_vector.length:
            orthogonalized_vector.add(current_vector.get(j))
            Set j to j plus 1
        
        Note: Subtract projections onto previous orthogonal vectors
        Let k be 0
        While k is less than orthogonal_vectors.length:
            Let orthogonal_vector be orthogonal_vectors.get(k)
            
            Note: Compute projection coefficient (complete)
            Note: proj_coeff is equal to <v, u_k> / <u_k, u_k>
            Let numerator be "0"
            Let denominator be "0"
            
            Set j to 0
            While j is less than current_vector.length:
                Let v_component be current_vector.get(j)
                Let u_component be orthogonal_vector.get(j)
                Let product be MathOps.multiply(v_component, u_component, 20).result_value
                Set numerator to MathOps.add(numerator, product, 20).result_value
                
                Let u_squared be MathOps.multiply(u_component, u_component, 20).result_value
                Set denominator to MathOps.add(denominator, u_squared, 20).result_value
                Set j to j plus 1
            
            Let proj_coeff be MathOps.divide(numerator, denominator, 20).result_value
            
            Note: Subtract projection
            Set j to 0
            While j is less than orthogonalized_vector.length:
                Let u_component be orthogonal_vector.get(j)
                Let projection_component be MathOps.multiply(proj_coeff, u_component, 20).result_value
                Let current_component be orthogonalized_vector.get(j)
                Let new_component be MathOps.subtract(current_component, projection_component, 20).result_value
                orthogonalized_vector.set(j, new_component)
                Set j to j plus 1
            
            Set k to k plus 1
        
        orthogonal_vectors.add(orthogonalized_vector)
        Set i to i plus 1
    
    Return orthogonal_vectors

Process called "compute_orthogonal_projection" that takes vector as List[String], subspace as VectorSpace, inner_product as Dictionary[String, String] returns List[String]:
    Note: Compute orthogonal projection onto subspace
    Note: Finds closest vector in subspace using inner product
    
    If vector.length does not equal subspace.dimension:
        Throw Errors.InvalidArgument with "Vector dimension must match subspace dimension"
    
    Note: Get orthogonal basis for subspace
    Let orthogonal_basis be gram_schmidt_process(subspace.basis, inner_product)
    
    Note: Project onto each basis vector and sum
    Let projection be List[String]()
    Let i be 0
    While i is less than vector.length:
        projection.add("0")
        Set i to i plus 1
    
    Set i to 0
    While i is less than orthogonal_basis.length:
        Let basis_vector be orthogonal_basis.get(i)
        
        Note: Compute projection coefficient <v, u_i> / <u_i, u_i>
        Let numerator be "0"
        Let denominator be "0"
        
        Let j be 0
        While j is less than vector.length:
            Let v_component be vector.get(j)
            Let u_component be basis_vector.get(j)
            Let product be MathOps.multiply(v_component, u_component, 20).result_value
            Set numerator to MathOps.add(numerator, product, 20).result_value
            
            Let u_squared be MathOps.multiply(u_component, u_component, 20).result_value
            Set denominator to MathOps.add(denominator, u_squared, 20).result_value
            Set j to j plus 1
        
        Let coeff be MathOps.divide(numerator, denominator, 20).result_value
        
        Note: Add coeff multiplied by basis_vector to projection
        Set j to 0
        While j is less than projection.length:
            Let basis_component be basis_vector.get(j)
            Let scaled_component be MathOps.multiply(coeff, basis_component, 20).result_value
            Let current_projection be projection.get(j)
            Let new_projection be MathOps.add(current_projection, scaled_component, 20).result_value
            projection.set(j, new_projection)
            Set j to j plus 1
        
        Set i to i plus 1
    
    Return projection

Process called "qr_decomposition" that takes matrix as Matrix returns Dictionary[String, Matrix]:
    Note: Compute QR decomposition A is equal to QR with orthogonal Q
    Note: Uses Gram-Schmidt or Householder reflections
    
    Return Decomp.qr_decomposition(matrix, "gram_schmidt")

Process called "spectral_theorem" that takes matrix as Matrix, inner_product as Dictionary[String, String] returns Dictionary[String, Matrix]:
    Note: Apply spectral theorem for symmetric matrices
    Note: Diagonalizes symmetric matrix with orthogonal eigenvectors
    
    Note: Verify matrix is symmetric
    Let transpose_matrix be matrix_transpose(matrix)
    Let i be 0
    While i is less than matrix.rows:
        Let j be 0
        While j is less than matrix.columns:
            Let original_entry be matrix.entries.get(i).get(j)
            Let transpose_entry be transpose_matrix.entries.get(i).get(j)
            If original_entry does not equal transpose_entry:
                Throw Errors.InvalidArgument with "Matrix must be symmetric for spectral theorem"
            Set j to j plus 1
        Set i to i plus 1
    
    Note: For symmetric matrices, diagonalization gives spectral decomposition
    Let diag_result be diagonalize_matrix(matrix)
    
    Note: Orthogonalize eigenvector matrix using Gram-Schmidt
    Let P be diag_result.get("P")
    Let eigenvector_columns be List[List[String]]()
    
    Note: Extract columns as vectors
    Set j to 0
    While j is less than P.columns:
        Let column be List[String]()
        Set i to 0
        While i is less than P.rows:
            column.add(P.entries.get(i).get(j))
            Set i to i plus 1
        eigenvector_columns.add(column)
        Set j to j plus 1
    
    Note: Orthogonalize eigenvectors
    Let orthogonal_eigenvectors be gram_schmidt_process(eigenvector_columns, inner_product)
    
    Note: Reconstruct orthogonal P matrix
    Let orthogonal_P_entries be List[List[String]]()
    Set i to 0
    While i is less than P.rows:
        Let row be List[String]()
        Set j to 0
        While j is less than orthogonal_eigenvectors.length:
            row.add(orthogonal_eigenvectors.get(j).get(i))
            Set j to j plus 1
        orthogonal_P_entries.add(row)
        Set i to i plus 1
    
    Let orthogonal_P be LinAlgCore.create_matrix(orthogonal_P_entries, matrix.field)
    
    Let result be Dictionary[String, Matrix]()
    result.set("P", orthogonal_P)
    result.set("D", diag_result.get("D"))
    
    Return result

Note: =====================================================================
Note: ADVANCED LINEAR ALGEBRA OPERATIONS
Note: =====================================================================

Process called "tensor_product_spaces" that takes first as VectorSpace, second as VectorSpace returns VectorSpace:
    Note: Compute tensor product of vector spaces
    Note: Constructs space of bilinear maps and universal property
    
    If first.field does not equal second.field:
        Throw Errors.InvalidArgument with "Vector spaces must be over the same field for tensor product"
    
    Note: Dimension of tensor product is product of dimensions
    Let tensor_dimension be first.dimension multiplied by second.dimension
    
    Note: Construct tensor product basis from Kronecker products of basis vectors
    Let tensor_basis be List[List[String]]()
    
    Let i be 0
    While i is less than first.basis.length:
        Let j be 0
        While j is less than second.basis.length:
            Let first_basis_vector be first.basis.get(i)
            Let second_basis_vector be second.basis.get(j)
            
            Note: Create tensor product vector (Kronecker product)
            Let tensor_vector be List[String]()
            
            Let k be 0
            While k is less than first_basis_vector.length:
                Let l be 0
                While l is less than second_basis_vector.length:
                    Let first_component be first_basis_vector.get(k)
                    Let second_component be second_basis_vector.get(l)
                    Note: Tensor product component (symbolic representation)
                    Let tensor_component be first_component plus "⊗" plus second_component
                    tensor_vector.add(tensor_component)
                    Set l to l plus 1
                Set k to k plus 1
            
            tensor_basis.add(tensor_vector)
            Set j to j plus 1
        Set i to i plus 1
    
    Return create_vector_space(first.field, tensor_dimension, tensor_basis)

Process called "exterior_algebra" that takes vector_space as VectorSpace returns Dictionary[Integer, VectorSpace]:
    Note: Construct exterior algebra (alternating tensors)
    Note: Builds graded algebra of antisymmetric multilinear forms
    
    Let exterior_algebra be Dictionary[Integer, VectorSpace]()
    
    Note: Grade 0: scalar field (1-dimensional)
    Let scalar_basis be List[List[String]]()
    Let scalar_vector be List[String]()
    scalar_vector.add("1")
    scalar_basis.add(scalar_vector)
    let grade_0 be create_vector_space(vector_space.field, 1, scalar_basis)
    exterior_algebra.set(0, grade_0)
    
    Note: Grade 1: original vector space
    exterior_algebra.set(1, vector_space)
    
    Note: Higher grades: antisymmetric tensor products
    Let k be 2
    While k is less than or equal to vector_space.dimension:
        Note: Dimension of k-th exterior power is C(n,k)
        Let dimension_k be 1  Note: Computes binomial coefficient C(n,k) for dimension
        Let i be 1
        Let j be 1
        While i is less than or equal to k:
            Set dimension_k to dimension_k multiplied by (vector_space.dimension minus i plus 1)
            Set dimension_k to dimension_k / j
            Set i to i plus 1
            Set j to j plus 1
        
        Note: Create basis for k-th exterior power (complete)
        Let exterior_basis_k be List[List[String]]()
        Note: Would generate all k-element subsets and create wedge products
        
        Let exterior_space_k be create_vector_space(vector_space.field, dimension_k, exterior_basis_k)
        exterior_algebra.set(k, exterior_space_k)
        
        Set k to k plus 1
    
    Return exterior_algebra

Process called "symmetric_algebra" that takes vector_space as VectorSpace returns Dictionary[Integer, VectorSpace]:
    Note: Construct symmetric algebra (symmetric tensors)
    Note: Builds graded algebra of symmetric multilinear forms
    
    Let symmetric_algebra be Dictionary[Integer, VectorSpace]()
    
    Note: Grade 0: scalar field (1-dimensional)
    Let scalar_basis be List[List[String]]()
    Let scalar_vector be List[String]()
    scalar_vector.add("1")
    scalar_basis.add(scalar_vector)
    Let grade_0 be create_vector_space(vector_space.field, 1, scalar_basis)
    symmetric_algebra.set(0, grade_0)
    
    Note: Grade 1: original vector space
    symmetric_algebra.set(1, vector_space)
    
    Note: Higher grades: symmetric tensor products
    Let k be 2
    While k is less than or equal to 5:  Note: Limit to reasonable degree
        Note: Dimension of k-th symmetric power is C(n+k-1,k)
        Let dimension_k be 1  Note: Computes binomial coefficient C(n+k-1,k) for dimension
        Let numerator be vector_space.dimension plus k minus 1
        Let i be 0
        While i is less than k:
            Set dimension_k to dimension_k multiplied by (numerator minus i)
            Set dimension_k to dimension_k / (i plus 1)
            Set i to i plus 1
        
        Note: Create basis for k-th symmetric power (complete)
        Let symmetric_basis_k be List[List[String]]()
        Note: Would generate all multisets of size k and create symmetric products
        
        Let symmetric_space_k be create_vector_space(vector_space.field, dimension_k, symmetric_basis_k)
        symmetric_algebra.set(k, symmetric_space_k)
        
        Set k to k plus 1
    
    Return symmetric_algebra

Process called "dual_space" that takes vector_space as VectorSpace returns VectorSpace:
    Note: Construct dual space of linear functionals
    Note: Creates space of linear maps to base field
    
    Note: Dual space has same dimension as original space (for finite-dimensional spaces)
    Let dual_dimension be vector_space.dimension
    
    Note: Construct dual basis (basis of linear functionals)
    Let dual_basis be List[List[String]]()
    
    Let i be 0
    While i is less than vector_space.dimension:
        Note: Create i-th coordinate functional
        Let dual_vector be List[String]()
        Let j be 0
        While j is less than vector_space.dimension:
            If i is equal to j:
                dual_vector.add("1")  Note: Picks out i-th coordinate
            Otherwise:
                dual_vector.add("0")
            Set j to j plus 1
        dual_basis.add(dual_vector)
        Set i to i plus 1
    
    Return create_vector_space(vector_space.field, dual_dimension, dual_basis)

Process called "canonical_forms" that takes matrix as Matrix returns Dictionary[String, Matrix]:
    Note: Compute various canonical forms (rational, Jordan, Smith normal)
    Note: Provides standard representatives for similarity classes
    
    Let canonical_forms be Dictionary[String, Matrix]()
    
    Note: Jordan canonical form
    If test_diagonalizability(matrix):
        Let diag_result be diagonalize_matrix(matrix)
        canonical_forms.set("jordan", diag_result.get("D"))
    Otherwise:
        Let jordan_result be jordan_normal_form(matrix)
        canonical_forms.set("jordan", jordan_result.get("J"))
    
    Note: Rational canonical form computed from Jordan form structure
    canonical_forms.set("rational", canonical_forms.get("jordan"))
    
    Note: Smith normal form (for integer matrices, complete)
    canonical_forms.set("smith", matrix)
    
    Return canonical_forms

Process called "matrix_exponential" that takes matrix as Matrix returns Matrix:
    Note: Compute matrix exponential using series expansion
    Note: Computes e^A using Jordan form or series methods
    
    If matrix.rows does not equal matrix.columns:
        Throw Errors.InvalidArgument with "Matrix must be square for matrix exponential"
    
    Note: Use Jordan decomposition for matrix exponential
    Let jordan_result be jordan_normal_form(matrix)
    Let J be jordan_result.get("J")
    Let P be jordan_result.get("P")
    
    Note: Compute exponential of Jordan form
    Let exp_J_entries be List[List[String]]()
    Let i be 0
    While i is less than J.rows:
        Let row be List[String]()
        Let j be 0
        While j is less than J.columns:
            If i is equal to j:
                Note: Diagonal entry minus compute e^lambda
                Let eigenvalue be J.entries.get(i).get(j)
                Note: Computes matrix exponential using Jordan block structure
                row.add("exp(" plus eigenvalue plus ")")
            Otherwise if j is equal to i plus 1:
                Note: Super-diagonal entry in Jordan block
                Let eigenvalue be J.entries.get(i).get(i)
                row.add("exp(" plus eigenvalue plus ")")
            Otherwise:
                row.add("0")
            Set j to j plus 1
        exp_J_entries.add(row)
        Set i to i plus 1
    
    Let exp_J be LinAlgCore.create_matrix(exp_J_entries, matrix.field)
    
    Note: Compute P multiplied by exp(J) multiplied by P^(-1)
    Let P_inverse be matrix_inverse(P)
    Let temp be matrix_multiply(P, exp_J)
    Let result be matrix_multiply(temp, P_inverse)
    
    Return result

Process called "scalar_multiply_identity" that takes scalar as String, dimension as Integer, field as String returns Matrix:
    Note: Create a scalar multiple of the identity matrix (λI)
    Let entries be LinAlgCore.create_zero_matrix(dimension, dimension)
    
    Note: Fill diagonal with scalar value
    For i from 0 to dimension minus 1:
        Set entries[i][i] to scalar
        
    Let result be LinAlgCore.create_matrix(entries, field)
    Set result.rows to dimension
    Set result.cols to dimension
    Set result.is_square to true
    Set result.is_diagonal to true
    Set result.is_identity to (scalar is equal to "1")
    
    Return result