Note: 
Neural Network Operations Module

This module provides comprehensive neural network operations including activation functions,
forward and backward propagation, weight initialization strategies, batch normalization,
dropout regularization, and fundamental layer operations. The implementations follow
modern deep learning best practices with numerical stability and computational efficiency.
 
Key mathematical foundations:
- Activation functions provide non-linearity: σ(x) for sigmoid, max(0,x) for ReLU
- Batch normalization: BN(x) is equal to γ multiplied by ((x minus μ) / σ) plus β for stability
- Dropout: randomly zeros elements with probability p during training
- Weight initialization: Xavier/He initialization for gradient flow
- Convolution: (f multiplied by g)[n] is equal to Σ f[m] multiplied by g[n-m] for feature extraction
- Pooling: downsampling operations for translation invariance
:End Note

Import module "dev/debug/errors/core" as Errors
Import module "math/core/operations" as MathOps
Import module "math/core/comparison" as MathCompare
Import module "math/engine/linalg/core" as LinAlg
Import module "math/engine/linalg/tensor" as TensorOps
Import module "security/crypto/primitives/random" as SecureRandom

Note: ===== Activation Function Types =====

Type called "ActivationFunction":
    function_type as String
    parameters as Dictionary[String, Float]
    derivative_cache as Optional[List[Float]]

Type called "ActivationConfig":
    alpha as Float                    Note: Parameter for LeakyReLU, ELU
    beta as Float                     Note: Parameter for Swish, Mish
    temperature as Float              Note: Temperature for softmax
    axis as Integer                   Note: Axis for softmax computation

Note: ===== Neural Layer Types =====

Type called "NeuralLayer":
    layer_type as String
    input_size as Integer
    output_size as Integer
    weights as Matrix[Float]
    biases as Vector[Float]
    activation as ActivationFunction

Type called "ConvolutionLayer":
    input_channels as Integer
    output_channels as Integer
    kernel_size as Tuple[Integer, Integer]
    stride as Tuple[Integer, Integer]
    padding as Tuple[Integer, Integer]
    weights as Tensor[Float]
    biases as Vector[Float]

Type called "BatchNormLayer":
    num_features as Integer
    epsilon as Float
    momentum as Float
    gamma as Vector[Float]              Note: Scale parameter
    beta as Vector[Float]               Note: Shift parameter
    running_mean as Vector[Float]
    running_var as Vector[Float]

Note: ===== Weight Initialization Types =====

Type called "WeightInitializer":
    method as String                    Note: xavier_uniform, he_normal, etc.
    gain as Float
    fan_mode as String                  Note: fan_in, fan_out, fan_avg
    distribution as String              Note: normal, uniform

Type called "InitializationConfig":
    seed as Optional[Integer]
    dtype as String
    device as String

Note: ===== Dropout and Regularization =====

Type called "DropoutConfig":
    probability as Float
    training_mode as Boolean
    inplace as Boolean
    seed as Optional[Integer]

Note: ===== Activation Functions =====

Process called "relu_activation" that takes input as Vector[Float] returns Vector[Float]:
    Note: Rectified Linear Unit activation: f(x) is equal to max(0, x)
    Note: Provides sparsity and computational efficiency, mitigates vanishing gradients
    Note: Time complexity: O(n), Space complexity: O(1)
    
    If input.dimension is less than or equal to 0:
        Throw Errors.InvalidArgument with "Input vector cannot be empty"
    
    Let result_components be List[String]()
    Let i be 0
    While i is less than input.dimension:
        Let current_value be input.components.get(i)
        Let zero_value be "0.0"
        Let max_result be MathCompare.maximum(current_value, zero_value, 15)
        Call result_components.add(max_result)
        Set i to i plus 1
    
    Let result_vector be Vector with components: result_components, dimension: input.dimension, data_type: input.data_type, is_unit_vector: false, norm: "0.0", vector_space: input.vector_space
    
    Note: Calculate proper norm for the result vector
    Let calculated_norm be LinAlg.vector_norm(result_vector, "L2")
    
    Note: Check if this is a unit vector (norm ≈ 1)
    Let norm_float be Parse calculated_norm as Float
    Let is_unit be (norm_float minus 1.0).abs() is less than 1e-10
    
    Return Vector with components: result_components, dimension: input.dimension, data_type: input.data_type, is_unit_vector: is_unit, norm: calculated_norm, vector_space: input.vector_space

Process called "leaky_relu_activation" that takes input as Vector[Float], alpha as Float returns Vector[Float]:
    Note: Leaky ReLU activation: f(x) is equal to max(αx, x) where α is small positive
    Note: Prevents dying ReLU problem by allowing small negative gradients
    Note: Time complexity: O(n), Space complexity: O(1)
    
    If input.dimension is less than or equal to 0:
        Throw Errors.InvalidArgument with "Input vector cannot be empty"
    
    If alpha is less than or equal to 0.0:
        Throw Errors.InvalidArgument with "Alpha parameter must be positive"
    
    Let result_components be List[String]()
    Let alpha_string be alpha.to_string()
    Let i be 0
    While i is less than input.dimension:
        Let current_value be input.components.get(i)
        Let alpha_x_result be MathOps.multiply(alpha_string, current_value, 15)
        If not alpha_x_result.overflow_occurred and not alpha_x_result.underflow_occurred:
            Let max_result be MathCompare.maximum(alpha_x_result.result_value, current_value, 15)
            Call result_components.add(max_result)
        Otherwise:
            Throw Errors.ComputationError with "Numerical overflow in Leaky ReLU computation"
        Set i to i plus 1
    
    Let result_vector be Vector with components: result_components, dimension: input.dimension, data_type: input.data_type, is_unit_vector: false, norm: "0.0", vector_space: input.vector_space
    
    Note: Calculate proper norm for the result vector
    Let calculated_norm be LinAlg.vector_norm(result_vector, "L2")
    
    Note: Check if this is a unit vector (norm ≈ 1)
    Let norm_float be Parse calculated_norm as Float
    Let is_unit be (norm_float minus 1.0).abs() is less than 1e-10
    
    Return Vector with components: result_components, dimension: input.dimension, data_type: input.data_type, is_unit_vector: is_unit, norm: calculated_norm, vector_space: input.vector_space

Process called "sigmoid_activation" that takes input as Vector[Float] returns Vector[Float]:
    Note: Sigmoid activation: σ(x) is equal to 1/(1 plus e^(-x))
    Note: Squashes values to (0,1), useful for binary classification
    Note: Time complexity: O(n), Space complexity: O(1)
    
    If input.dimension is less than or equal to 0:
        Throw Errors.InvalidArgument with "Input vector cannot be empty"
    
    Let result_components be List[String]()
    Let i be 0
    While i is less than input.dimension:
        Let current_value be input.components.get(i)
        Let current_float be Parse current_value as Float
        
        Note: Numerical stability: clip values to prevent overflow in exp computation
        Note: For IEEE 754 double precision: ln(max_float) ≈ 709.78, use 709.0 for safety
        Let sigmoid_result as String
        If current_float is greater than 709.0:
            Set sigmoid_result to "1.0"
        Otherwise if current_float is less than -709.0:
            Set sigmoid_result to "0.0"
        Otherwise:
            Let negated_value be MathOps.negate(current_value, 15)
            If negated_value.overflow_occurred:
                Throw Errors.ComputationError with "Overflow in sigmoid negation"
            
            Let exp_result be MathOps.exponential(negated_value.result_value, 15)
            If exp_result.overflow_occurred:
                Throw Errors.ComputationError with "Overflow in exponential computation"
            
            Let one_plus_exp be MathOps.add("1.0", exp_result.result_value, 15)
            If one_plus_exp.overflow_occurred:
                Throw Errors.ComputationError with "Overflow in sigmoid denominator"
            
            Let division_result be MathOps.divide("1.0", one_plus_exp.result_value, 15)
            If division_result.overflow_occurred:
                Throw Errors.ComputationError with "Overflow in sigmoid division"
            
            Set sigmoid_result to division_result.result_value
        
        Call result_components.add(sigmoid_result)
        Set i to i plus 1
    
    Let result_vector be Vector with components: result_components, dimension: input.dimension, data_type: input.data_type, is_unit_vector: false, norm: "0.0", vector_space: input.vector_space
    
    Note: Calculate proper norm for the result vector
    Let calculated_norm be LinAlg.vector_norm(result_vector, "L2")
    
    Note: Check if this is a unit vector (norm ≈ 1)
    Let norm_float be Parse calculated_norm as Float
    Let is_unit be (norm_float minus 1.0).abs() is less than 1e-10
    
    Return Vector with components: result_components, dimension: input.dimension, data_type: input.data_type, is_unit_vector: is_unit, norm: calculated_norm, vector_space: input.vector_space

Process called "tanh_activation" that takes input as Vector[Float] returns Vector[Float]:
    Note: Hyperbolic tangent: tanh(x) is equal to (e^x minus e^(-x))/(e^x plus e^(-x))
    Note: Zero-centered output in (-1,1), better than sigmoid for hidden layers
    Note: Time complexity: O(n), Space complexity: O(1)
    
    If input.dimension is less than or equal to 0:
        Throw Errors.InvalidArgument with "Input vector cannot be empty"
    
    Let result_components be List[String]()
    Let i be 0
    While i is less than input.dimension:
        Let current_value be input.components.get(i)
        Let current_float be Parse current_value as Float
        
        Note: Numerical stability: clip values to prevent overflow
        Note: tanh(x) ≈ ±1 for |x| is greater than 19.06 (machine precision threshold)
        Let tanh_result as String
        If current_float is greater than 19.06:
            Set tanh_result to "1.0"
        Otherwise if current_float is less than -19.06:
            Set tanh_result to "-1.0"
        Otherwise:
            Let exp_x be MathOps.exponential(current_value, 15)
            If exp_x.overflow_occurred:
                Throw Errors.ComputationError with "Overflow in exponential computation for tanh"
            
            Let negated_value be MathOps.negate(current_value, 15)
            If negated_value.overflow_occurred:
                Throw Errors.ComputationError with "Overflow in negation for tanh"
            
            Let exp_neg_x be MathOps.exponential(negated_value.result_value, 15)
            If exp_neg_x.overflow_occurred:
                Throw Errors.ComputationError with "Overflow in negative exponential for tanh"
            
            Let numerator be MathOps.subtract(exp_x.result_value, exp_neg_x.result_value, 15)
            If numerator.overflow_occurred:
                Throw Errors.ComputationError with "Overflow in tanh numerator"
            
            Let denominator be MathOps.add(exp_x.result_value, exp_neg_x.result_value, 15)
            If denominator.overflow_occurred:
                Throw Errors.ComputationError with "Overflow in tanh denominator"
            
            Let division_result be MathOps.divide(numerator.result_value, denominator.result_value, 15)
            If division_result.overflow_occurred:
                Throw Errors.ComputationError with "Overflow in tanh division"
            
            Set tanh_result to division_result.result_value
        
        Call result_components.add(tanh_result)
        Set i to i plus 1
    
    Let result_vector be Vector with components: result_components, dimension: input.dimension, data_type: input.data_type, is_unit_vector: false, norm: "0.0", vector_space: input.vector_space
    
    Note: Calculate proper norm for the result vector
    Let calculated_norm be LinAlg.vector_norm(result_vector, "L2")
    
    Note: Check if this is a unit vector (norm ≈ 1)
    Let norm_float be Parse calculated_norm as Float
    Let is_unit be (norm_float minus 1.0).abs() is less than 1e-10
    
    Return Vector with components: result_components, dimension: input.dimension, data_type: input.data_type, is_unit_vector: is_unit, norm: calculated_norm, vector_space: input.vector_space

Process called "softmax_activation" that takes input as Vector[Float], axis as Integer returns Vector[Float]:
    Note: Softmax: σ(x_i) is equal to e^(x_i) / Σ(e^(x_j)) for probability distribution
    Note: Converts logits to probabilities, used in multi-class classification
    Note: Time complexity: O(n), Space complexity: O(1)
    
    If input.dimension is less than or equal to 0:
        Throw Errors.InvalidArgument with "Input vector cannot be empty"
    
    If axis is less than 0 or axis is greater than or equal to input.dimension:
        Throw Errors.InvalidArgument with "Axis must be within vector dimensions"
    
    Note: For vector inputs, axis parameter validates computation dimension
    
    Note: Find maximum value for numerical stability
    Let max_value be input.components.get(0)
    Let i be 1
    While i is less than input.dimension:
        Let current_value be input.components.get(i)
        Set max_value to MathCompare.maximum(max_value, current_value, 15)
        Set i to i plus 1
    
    Note: Compute shifted exponentials
    Let exp_values be List[String]()
    Set i to 0
    While i is less than input.dimension:
        Let current_value be input.components.get(i)
        Let shifted_value be MathOps.subtract(current_value, max_value, 15)
        If shifted_value.overflow_occurred:
            Throw Errors.ComputationError with "Overflow in softmax shifting"
        
        Let exp_result be MathOps.exponential(shifted_value.result_value, 15)
        If exp_result.overflow_occurred:
            Throw Errors.ComputationError with "Overflow in softmax exponential"
        
        Call exp_values.add(exp_result.result_value)
        Set i to i plus 1
    
    Note: Compute sum of exponentials
    Let exp_sum be "0.0"
    Set i to 0
    While i is less than exp_values.length:
        Let sum_result be MathOps.add(exp_sum, exp_values.get(i), 15)
        If sum_result.overflow_occurred:
            Throw Errors.ComputationError with "Overflow in softmax sum"
        Set exp_sum to sum_result.result_value
        Set i to i plus 1
    
    Note: Compute final softmax values
    Let result_components be List[String]()
    Set i to 0
    While i is less than exp_values.length:
        Let current_exp be exp_values.get(i)
        Let division_result be MathOps.divide(current_exp, exp_sum, 15)
        If division_result.overflow_occurred:
            Throw Errors.ComputationError with "Overflow in softmax division"
        Call result_components.add(division_result.result_value)
        Set i to i plus 1
    
    Return Vector with components: result_components, dimension: input.dimension, data_type: input.data_type, is_unit_vector: false, norm: "1.0", vector_space: input.vector_space

Process called "gelu_activation" that takes input as Vector[Float] returns Vector[Float]:
    Note: Gaussian Error Linear Unit: GELU(x) is equal to x multiplied by Φ(x) where Φ is CDF
    Note: Smooth approximation: x multiplied by σ(1.702 multiplied by x), used in transformers
    Note: Time complexity: O(n), Space complexity: O(1)
    
    If input.dimension is less than or equal to 0:
        Throw Errors.InvalidArgument with "Input vector cannot be empty"
    
    Let result_components be List[String]()
    Let gelu_constant be "1.702"
    Let i be 0
    While i is less than input.dimension:
        Let current_value be input.components.get(i)
        
        Note: GELU approximation: x multiplied by sigmoid(1.702 multiplied by x)
        Let scaled_x be MathOps.multiply(gelu_constant, current_value, 15)
        If scaled_x.overflow_occurred:
            Throw Errors.ComputationError with "Overflow in GELU scaling"
        
        Note: Compute sigmoid(1.702 multiplied by x)
        Let scaled_float be Parse scaled_x.result_value as Float
        Let sigmoid_result as String
        If scaled_float is greater than 500.0:
            Set sigmoid_result to "1.0"
        Otherwise if scaled_float is less than -500.0:
            Set sigmoid_result to "0.0"
        Otherwise:
            Let negated_scaled be MathOps.negate(scaled_x.result_value, 15)
            If negated_scaled.overflow_occurred:
                Throw Errors.ComputationError with "Overflow in GELU negation"
            
            Let exp_result be MathOps.exponential(negated_scaled.result_value, 15)
            If exp_result.overflow_occurred:
                Throw Errors.ComputationError with "Overflow in GELU exponential"
            
            Let one_plus_exp be MathOps.add("1.0", exp_result.result_value, 15)
            If one_plus_exp.overflow_occurred:
                Throw Errors.ComputationError with "Overflow in GELU denominator"
            
            Let division_result be MathOps.divide("1.0", one_plus_exp.result_value, 15)
            If division_result.overflow_occurred:
                Throw Errors.ComputationError with "Overflow in GELU sigmoid"
            
            Set sigmoid_result to division_result.result_value
        
        Note: Multiply x by sigmoid result
        Let gelu_result be MathOps.multiply(current_value, sigmoid_result, 15)
        If gelu_result.overflow_occurred:
            Throw Errors.ComputationError with "Overflow in final GELU multiplication"
        
        Call result_components.add(gelu_result.result_value)
        Set i to i plus 1
    
    Return Vector with components: result_components, dimension: input.dimension, data_type: input.data_type, is_unit_vector: false, norm: "0.0", vector_space: input.vector_space

Process called "swish_activation" that takes input as Vector[Float], beta as Float returns Vector[Float]:
    Note: Swish activation: f(x) is equal to x multiplied by σ(βx) where σ is sigmoid
    Note: Self-gated activation, smooth and non-monotonic
    Note: Time complexity: O(n), Space complexity: O(1)
    
    If input.dimension is less than or equal to 0:
        Throw Errors.InvalidArgument with "Input vector cannot be empty"
    
    If beta is less than or equal to 0.0:
        Throw Errors.InvalidArgument with "Beta parameter must be positive"
    
    Let result_components be List[String]()
    Let beta_string be beta.to_string()
    Let i be 0
    While i is less than input.dimension:
        Let current_value be input.components.get(i)
        
        Note: Compute βx
        Let beta_x be MathOps.multiply(beta_string, current_value, 15)
        If beta_x.overflow_occurred:
            Throw Errors.ComputationError with "Overflow in Swish beta multiplication"
        
        Note: Compute sigmoid(βx)
        Let beta_x_float be Parse beta_x.result_value as Float
        Let sigmoid_result as String
        If beta_x_float is greater than 500.0:
            Set sigmoid_result to "1.0"
        Otherwise if beta_x_float is less than -500.0:
            Set sigmoid_result to "0.0"
        Otherwise:
            Let negated_beta_x be MathOps.negate(beta_x.result_value, 15)
            If negated_beta_x.overflow_occurred:
                Throw Errors.ComputationError with "Overflow in Swish negation"
            
            Let exp_result be MathOps.exponential(negated_beta_x.result_value, 15)
            If exp_result.overflow_occurred:
                Throw Errors.ComputationError with "Overflow in Swish exponential"
            
            Let one_plus_exp be MathOps.add("1.0", exp_result.result_value, 15)
            If one_plus_exp.overflow_occurred:
                Throw Errors.ComputationError with "Overflow in Swish denominator"
            
            Let division_result be MathOps.divide("1.0", one_plus_exp.result_value, 15)
            If division_result.overflow_occurred:
                Throw Errors.ComputationError with "Overflow in Swish sigmoid"
            
            Set sigmoid_result to division_result.result_value
        
        Note: Compute final Swish: x multiplied by sigmoid(βx)
        Let swish_result be MathOps.multiply(current_value, sigmoid_result, 15)
        If swish_result.overflow_occurred:
            Throw Errors.ComputationError with "Overflow in final Swish multiplication"
        
        Call result_components.add(swish_result.result_value)
        Set i to i plus 1
    
    Return Vector with components: result_components, dimension: input.dimension, data_type: input.data_type, is_unit_vector: false, norm: "0.0", vector_space: input.vector_space

Note: ===== Activation Derivatives =====

Process called "relu_derivative" that takes input as Vector[Float] returns Vector[Float]:
    Note: ReLU derivative: f'(x) is equal to 1 if x is greater than 0, 0 otherwise
    Note: Used in backpropagation for gradient computation
    Note: Time complexity: O(n), Space complexity: O(1)
    
    If input.dimension is less than or equal to 0:
        Throw Errors.InvalidArgument with "Input vector cannot be empty"
    
    Let result_components be List[String]()
    Let i be 0
    While i is less than input.dimension:
        Let current_value be input.components.get(i)
        Let current_float be Parse current_value as Float
        
        If current_float is greater than 0.0:
            Call result_components.add("1.0")
        Otherwise:
            Call result_components.add("0.0")
        Set i to i plus 1
    
    Return Vector with components: result_components, dimension: input.dimension, data_type: input.data_type, is_unit_vector: false, norm: "0.0", vector_space: input.vector_space

Process called "sigmoid_derivative" that takes input as Vector[Float] returns Vector[Float]:
    Note: Sigmoid derivative: σ'(x) is equal to σ(x) multiplied by (1 minus σ(x))
    Note: Can be computed from forward pass output for efficiency
    Note: Time complexity: O(n), Space complexity: O(1)
    
    If input.dimension is less than or equal to 0:
        Throw Errors.InvalidArgument with "Input vector cannot be empty"
    
    Note: First compute sigmoid of input
    Let sigmoid_output be sigmoid_activation(input)
    
    Let result_components be List[String]()
    Let i be 0
    While i is less than sigmoid_output.dimension:
        Let sigmoid_value be sigmoid_output.components.get(i)
        
        Note: Compute 1 minus σ(x)
        Let one_minus_sigmoid be MathOps.subtract("1.0", sigmoid_value, 15)
        If one_minus_sigmoid.overflow_occurred:
            Throw Errors.ComputationError with "Overflow in sigmoid derivative subtraction"
        
        Note: Compute σ(x) multiplied by (1 minus σ(x))
        Let derivative_result be MathOps.multiply(sigmoid_value, one_minus_sigmoid.result_value, 15)
        If derivative_result.overflow_occurred:
            Throw Errors.ComputationError with "Overflow in sigmoid derivative multiplication"
        
        Call result_components.add(derivative_result.result_value)
        Set i to i plus 1
    
    Return Vector with components: result_components, dimension: input.dimension, data_type: input.data_type, is_unit_vector: false, norm: "0.0", vector_space: input.vector_space

Process called "softmax_derivative" that takes input as Vector[Float], output as Vector[Float] returns Matrix[Float]:
    Note: Softmax Jacobian: ∂σ_i/∂x_j is equal to σ_i(δ_ij minus σ_j)
    Note: Returns Jacobian matrix for gradient computation
    Note: Time complexity: O(n²), Space complexity: O(n²)
    
    If input.dimension is less than or equal to 0:
        Throw Errors.InvalidArgument with "Input vector cannot be empty"
    
    If output.dimension does not equal input.dimension:
        Throw Errors.InvalidArgument with "Input and output vectors must have same dimension"
    
    Let n be input.dimension
    Let jacobian_entries be List[List[String]]()
    
    Let i be 0
    While i is less than n:
        Let row be List[String]()
        Let j be 0
        While j is less than n:
            Let sigma_i be output.components.get(i)
            
            If i is equal to j:
                Note: Diagonal element: σ_i(1 minus σ_i)
                Let one_minus_sigma_i be MathOps.subtract("1.0", sigma_i, 15)
                If one_minus_sigma_i.overflow_occurred:
                    Throw Errors.ComputationError with "Overflow in softmax derivative diagonal subtraction"
                
                Let diagonal_element be MathOps.multiply(sigma_i, one_minus_sigma_i.result_value, 15)
                If diagonal_element.overflow_occurred:
                    Throw Errors.ComputationError with "Overflow in softmax derivative diagonal multiplication"
                
                Call row.add(diagonal_element.result_value)
            Otherwise:
                Note: Off-diagonal element: -σ_i multiplied by σ_j
                Let sigma_j be output.components.get(j)
                Let product be MathOps.multiply(sigma_i, sigma_j, 15)
                If product.overflow_occurred:
                    Throw Errors.ComputationError with "Overflow in softmax derivative off-diagonal multiplication"
                
                Let negated_product be MathOps.negate(product.result_value, 15)
                If negated_product.overflow_occurred:
                    Throw Errors.ComputationError with "Overflow in softmax derivative negation"
                
                Call row.add(negated_product.result_value)
            Set j to j plus 1
        Call jacobian_entries.add(row)
        Set i to i plus 1
    
    Let jacobian_matrix be LinAlg.create_matrix(jacobian_entries, "float")
    Return jacobian_matrix

Note: ===== Forward Propagation =====

Process called "linear_forward" that takes input as Vector[Float], weights as Matrix[Float], bias as Vector[Float] returns Vector[Float]:
    Note: Linear transformation: y is equal to Wx plus b
    Note: Fundamental building block of neural networks
    Note: Time complexity: O(mn), Space complexity: O(n)
    
    If input.dimension is less than or equal to 0:
        Throw Errors.InvalidArgument with "Input vector cannot be empty"
    
    If weights.rows is less than or equal to 0 or weights.columns is less than or equal to 0:
        Throw Errors.InvalidArgument with "Weight matrix cannot be empty"
    
    If bias.dimension is less than or equal to 0:
        Throw Errors.InvalidArgument with "Bias vector cannot be empty"
    
    If input.dimension does not equal weights.columns:
        Throw Errors.InvalidArgument with "Input dimension must match weight matrix columns"
    
    If weights.rows does not equal bias.dimension:
        Throw Errors.InvalidArgument with "Weight matrix rows must match bias vector dimension"
    
    Let result_components be List[String]()
    Let i be 0
    While i is less than weights.rows:
        Let dot_product be "0.0"
        
        Note: Compute dot product of i-th row of weights with input vector
        Let j be 0
        While j is less than weights.columns:
            Let weight_value be weights.entries.get(i).get(j)
            Let input_value be input.components.get(j)
            
            Let product be MathOps.multiply(weight_value, input_value, 15)
            If product.overflow_occurred:
                Throw Errors.ComputationError with "Overflow in linear forward weight multiplication"
            
            Let sum_result be MathOps.add(dot_product, product.result_value, 15)
            If sum_result.overflow_occurred:
                Throw Errors.ComputationError with "Overflow in linear forward dot product accumulation"
            
            Set dot_product to sum_result.result_value
            Set j to j plus 1
        
        Note: Add bias term
        Let bias_value be bias.components.get(i)
        Let final_result be MathOps.add(dot_product, bias_value, 15)
        If final_result.overflow_occurred:
            Throw Errors.ComputationError with "Overflow in linear forward bias addition"
        
        Call result_components.add(final_result.result_value)
        Set i to i plus 1
    
    Return Vector with components: result_components, dimension: weights.rows, data_type: input.data_type, is_unit_vector: false, norm: "0.0", vector_space: input.vector_space

Process called "convolution_forward" that takes input as Tensor[Float], kernel as Tensor[Float], config as ConvolutionLayer returns Tensor[Float]:
    Note: 2D convolution: (I multiplied by K)[i,j] is equal to ΣΣ I[i+m,j+n] multiplied by K[m,n]
    Note: Applies learnable filters for feature extraction
    Note: Time complexity: O(n²m²), Space complexity: O(n²)
    
    If input.shape.length does not equal 4:
        Throw Errors.InvalidArgument with "Input tensor must be 4D (batch, channels, height, width)"
    
    If kernel.shape.length does not equal 4:
        Throw Errors.InvalidArgument with "Kernel tensor must be 4D (out_channels, in_channels, height, width)"
    
    Let batch_size be input.shape.get(0)
    Let in_channels be input.shape.get(1)
    Let input_height be input.shape.get(2)
    Let input_width be input.shape.get(3)
    
    Let out_channels be kernel.shape.get(0)
    Let kernel_height be kernel.shape.get(2)
    Let kernel_width be kernel.shape.get(3)
    
    If in_channels does not equal kernel.shape.get(1):
        Throw Errors.InvalidArgument with "Input channels must match kernel input channels"
    
    Let stride_h be config.stride.first
    Let stride_w be config.stride.second
    Let pad_h be config.padding.first
    Let pad_w be config.padding.second
    
    Note: Calculate output dimensions
    Let output_height_calc be (input_height plus 2 multiplied by pad_h minus kernel_height) / stride_h plus 1
    Let output_width_calc be (input_width plus 2 multiplied by pad_w minus kernel_width) / stride_w plus 1
    
    If output_height_calc is less than or equal to 0 or output_width_calc is less than or equal to 0:
        Throw Errors.InvalidArgument with "Invalid convolution parameters result in non-positive output size"
    
    Let output_height be output_height_calc
    Let output_width be output_width_calc
    
    Note: Create output tensor shape
    Let output_shape be List[Integer]()
    Call output_shape.add(batch_size)
    Call output_shape.add(out_channels)
    Call output_shape.add(output_height)
    Call output_shape.add(output_width)
    
    Note: Initialize output data
    Let total_output_size be batch_size multiplied by out_channels multiplied by output_height multiplied by output_width
    Let output_data be List[String]()
    Let idx be 0
    While idx is less than total_output_size:
        Call output_data.add("0.0")
        Set idx to idx plus 1
    
    Note: Perform 2D convolution with full batch support
    Let b be 0
    While b is less than batch_size:
        Let out_c be 0
        While out_c is less than out_channels:
            Let out_h be 0
            While out_h is less than output_height:
                Let out_w be 0
                While out_w is less than output_width:
                    Let conv_sum be "0.0"
                    
                    Let in_c be 0
                    While in_c is less than in_channels:
                        Let k_h be 0
                        While k_h is less than kernel_height:
                            Let k_w be 0
                            While k_w is less than kernel_width:
                                Let in_h be out_h multiplied by stride_h plus k_h minus pad_h
                                Let in_w be out_w multiplied by stride_w plus k_w minus pad_w
                                
                                Note: Check bounds (zero padding)
                                If in_h is greater than or equal to 0 and in_h is less than input_height and in_w is greater than or equal to 0 and in_w is less than input_width:
                                    Let input_idx be ((b multiplied by in_channels plus in_c) multiplied by input_height plus in_h) multiplied by input_width plus in_w
                                    Let kernel_idx be ((out_c multiplied by in_channels plus in_c) multiplied by kernel_height plus k_h) multiplied by kernel_width plus k_w
                                    
                                    Let input_val be input.data.get(input_idx)
                                    Let kernel_val be kernel.data.get(kernel_idx)
                                    
                                    Let product be MathOps.multiply(input_val, kernel_val, 15)
                                    If not product.overflow_occurred:
                                        Let sum_result be MathOps.add(conv_sum, product.result_value, 15)
                                        If not sum_result.overflow_occurred:
                                            Set conv_sum to sum_result.result_value
                                
                                Set k_w to k_w plus 1
                            Set k_h to k_h plus 1
                        Set in_c to in_c plus 1
                    
                    Let output_idx be ((b multiplied by out_channels plus out_c) multiplied by output_height plus out_h) multiplied by output_width plus out_w
                    Set output_data[output_idx] to conv_sum
                    Set out_w to out_w plus 1
                Set out_h to out_h plus 1
            Set out_c to out_c plus 1
        Set b to b plus 1
    
    Return TensorOps.create_tensor(output_data, output_shape, input.data_type)

Process called "batch_normalize_forward" that takes input as Tensor[Float], config as BatchNormLayer, training as Boolean returns Tensor[Float]:
    Note: Batch normalization: BN(x) is equal to γ multiplied by ((x minus μ) / √(σ² plus ε)) plus β
    Note: Normalizes activations for stable training and faster convergence
    Note: Time complexity: O(n), Space complexity: O(1)
    
    If input.shape.length is less than 2:
        Throw Errors.InvalidArgument with "Input tensor must have at least 2 dimensions"
    
    Let batch_size be input.shape.get(0)
    Let num_features be input.shape.get(1)
    
    If num_features does not equal config.num_features:
        Throw Errors.InvalidArgument with "Input features must match BatchNorm config"
    
    If config.gamma.dimension does not equal num_features or config.beta.dimension does not equal num_features:
        Throw Errors.InvalidArgument with "Gamma and beta must have same dimension as features"
    
    Let output_data be List[String]()
    
    If training:
        Note: Compute batch mean and variance for each feature
        Let feature_idx be 0
        While feature_idx is less than num_features:
            Note: Compute mean across batch for this feature
            Let feature_sum be "0.0"
            Let sample_idx be 0
            While sample_idx is less than batch_size:
                Let data_idx be sample_idx multiplied by num_features plus feature_idx
                Let value be input.data.get(data_idx)
                Let sum_result be MathOps.add(feature_sum, value, 15)
                If sum_result.overflow_occurred:
                    Throw Errors.ComputationError with "Overflow in batch norm mean computation"
                Set feature_sum to sum_result.result_value
                Set sample_idx to sample_idx plus 1
            
            Let batch_size_str be batch_size.to_string()
            Let mean_result be MathOps.divide(feature_sum, batch_size_str, 15)
            If mean_result.overflow_occurred:
                Throw Errors.ComputationError with "Overflow in batch norm mean division"
            Let feature_mean be mean_result.result_value
            
            Note: Compute variance across batch for this feature
            Let variance_sum be "0.0"
            Set sample_idx to 0
            While sample_idx is less than batch_size:
                Let data_idx be sample_idx multiplied by num_features plus feature_idx
                Let value be input.data.get(data_idx)
                Let diff be MathOps.subtract(value, feature_mean, 15)
                If diff.overflow_occurred:
                    Throw Errors.ComputationError with "Overflow in batch norm variance diff"
                
                Let squared_diff be MathOps.multiply(diff.result_value, diff.result_value, 15)
                If squared_diff.overflow_occurred:
                    Throw Errors.ComputationError with "Overflow in batch norm variance square"
                
                Let var_sum_result be MathOps.add(variance_sum, squared_diff.result_value, 15)
                If var_sum_result.overflow_occurred:
                    Throw Errors.ComputationError with "Overflow in batch norm variance sum"
                Set variance_sum to var_sum_result.result_value
                Set sample_idx to sample_idx plus 1
            
            Let variance_result be MathOps.divide(variance_sum, batch_size_str, 15)
            If variance_result.overflow_occurred:
                Throw Errors.ComputationError with "Overflow in batch norm variance division"
            Let feature_variance be variance_result.result_value
            
            Note: Add epsilon and compute sqrt
            Let epsilon_str be config.epsilon.to_string()
            Let var_plus_eps be MathOps.add(feature_variance, epsilon_str, 15)
            If var_plus_eps.overflow_occurred:
                Throw Errors.ComputationError with "Overflow in batch norm epsilon addition"
            
            Let sqrt_result be MathOps.square_root(var_plus_eps.result_value, 15)
            If sqrt_result.overflow_occurred:
                Throw Errors.ComputationError with "Overflow in batch norm sqrt"
            Let feature_std be sqrt_result.result_value
            
            Note: Apply batch normalization to all samples for this feature
            Set sample_idx to 0
            While sample_idx is less than batch_size:
                Let data_idx be sample_idx multiplied by num_features plus feature_idx
                Let value be input.data.get(data_idx)
                
                Note: Normalize: (x minus μ) / σ
                Let normalized_diff be MathOps.subtract(value, feature_mean, 15)
                If normalized_diff.overflow_occurred:
                    Throw Errors.ComputationError with "Overflow in batch norm normalization diff"
                
                Let normalized_value be MathOps.divide(normalized_diff.result_value, feature_std, 15)
                If normalized_value.overflow_occurred:
                    Throw Errors.ComputationError with "Overflow in batch norm normalization division"
                
                Note: Apply scale and shift: γ multiplied by normalized plus β
                Let gamma_value be config.gamma.components.get(feature_idx)
                Let beta_value be config.beta.components.get(feature_idx)
                
                Let scaled_value be MathOps.multiply(gamma_value, normalized_value.result_value, 15)
                If scaled_value.overflow_occurred:
                    Throw Errors.ComputationError with "Overflow in batch norm scaling"
                
                Let final_value be MathOps.add(scaled_value.result_value, beta_value, 15)
                If final_value.overflow_occurred:
                    Throw Errors.ComputationError with "Overflow in batch norm shift"
                
                Note: Set output at correct position for this sample and feature
                While output_data.length is less than or equal to data_idx:
                    Call output_data.add("0.0")
                Set output_data[data_idx] to final_value.result_value
                Set sample_idx to sample_idx plus 1
            Set feature_idx to feature_idx plus 1
    Otherwise:
        Note: Use running statistics for inference
        Let data_idx be 0
        While data_idx is less than input.data.length:
            Let feature_idx be data_idx % num_features
            Let value be input.data.get(data_idx)
            
            Let running_mean be config.running_mean.components.get(feature_idx)
            Let running_var be config.running_var.components.get(feature_idx)
            
            Note: Normalize using running statistics
            Let diff be MathOps.subtract(value, running_mean, 15)
            If diff.overflow_occurred:
                Throw Errors.ComputationError with "Overflow in batch norm inference diff"
            
            Let epsilon_str be config.epsilon.to_string()
            Let var_plus_eps be MathOps.add(running_var, epsilon_str, 15)
            If var_plus_eps.overflow_occurred:
                Throw Errors.ComputationError with "Overflow in batch norm inference epsilon"
            
            Let sqrt_result be MathOps.square_root(var_plus_eps.result_value, 15)
            If sqrt_result.overflow_occurred:
                Throw Errors.ComputationError with "Overflow in batch norm inference sqrt"
            
            Let normalized be MathOps.divide(diff.result_value, sqrt_result.result_value, 15)
            If normalized.overflow_occurred:
                Throw Errors.ComputationError with "Overflow in batch norm inference normalization"
            
            Note: Apply scale and shift
            Let gamma_value be config.gamma.components.get(feature_idx)
            Let beta_value be config.beta.components.get(feature_idx)
            
            Let scaled be MathOps.multiply(gamma_value, normalized.result_value, 15)
            If scaled.overflow_occurred:
                Throw Errors.ComputationError with "Overflow in batch norm inference scaling"
            
            Let final_result be MathOps.add(scaled.result_value, beta_value, 15)
            If final_result.overflow_occurred:
                Throw Errors.ComputationError with "Overflow in batch norm inference shift"
            
            Call output_data.add(final_result.result_value)
            Set data_idx to data_idx plus 1
    
    Return TensorOps.create_tensor(output_data, input.shape, input.data_type)

Note: ===== Backward Propagation =====

Process called "linear_backward" that takes grad_output as Vector[Float], input as Vector[Float], weights as Matrix[Float] returns Tuple[Vector[Float], Matrix[Float], Vector[Float]]:
    Note: Computes gradients: ∂L/∂x is equal to W^T multiplied by ∂L/∂y, ∂L/∂W is equal to ∂L/∂y multiplied by x^T
    Note: Returns gradients w.r.t. input, weights, and bias
    Note: Time complexity: O(mn), Space complexity: O(mn)
    
    If grad_output.dimension is less than or equal to 0:
        Throw Errors.InvalidArgument with "Gradient output vector cannot be empty"
    
    If input.dimension is less than or equal to 0:
        Throw Errors.InvalidArgument with "Input vector cannot be empty"
    
    If weights.rows is less than or equal to 0 or weights.columns is less than or equal to 0:
        Throw Errors.InvalidArgument with "Weight matrix cannot be empty"
    
    If grad_output.dimension does not equal weights.rows:
        Throw Errors.InvalidArgument with "Gradient output dimension must match weight matrix rows"
    
    If input.dimension does not equal weights.columns:
        Throw Errors.InvalidArgument with "Input dimension must match weight matrix columns"
    
    Note: Compute gradient w.r.t. input: ∂L/∂x is equal to W^T multiplied by ∂L/∂y
    Let grad_input_components be List[String]()
    Let j be 0
    While j is less than weights.columns:
        Let dot_product be "0.0"
        Let i be 0
        While i is less than weights.rows:
            Let weight_value be weights.entries.get(i).get(j)
            Let grad_out_value be grad_output.components.get(i)
            
            Let product be MathOps.multiply(weight_value, grad_out_value, 15)
            If product.overflow_occurred:
                Throw Errors.ComputationError with "Overflow in linear backward input gradient multiplication"
            
            Let sum_result be MathOps.add(dot_product, product.result_value, 15)
            If sum_result.overflow_occurred:
                Throw Errors.ComputationError with "Overflow in linear backward input gradient accumulation"
            
            Set dot_product to sum_result.result_value
            Set i to i plus 1
        Call grad_input_components.add(dot_product)
        Set j to j plus 1
    
    Let grad_input be Vector with components: grad_input_components, dimension: weights.columns, data_type: input.data_type, is_unit_vector: false, norm: "0.0", vector_space: input.vector_space
    
    Note: Compute gradient w.r.t. weights: ∂L/∂W is equal to ∂L/∂y multiplied by x^T
    Let grad_weights_entries be List[List[String]]()
    Set i to 0
    While i is less than weights.rows:
        Let weight_row be List[String]()
        Set j to 0
        While j is less than weights.columns:
            Let grad_out_value be grad_output.components.get(i)
            Let input_value be input.components.get(j)
            
            Let weight_gradient be MathOps.multiply(grad_out_value, input_value, 15)
            If weight_gradient.overflow_occurred:
                Throw Errors.ComputationError with "Overflow in linear backward weight gradient multiplication"
            
            Call weight_row.add(weight_gradient.result_value)
            Set j to j plus 1
        Call grad_weights_entries.add(weight_row)
        Set i to i plus 1
    
    Let grad_weights be LinAlg.create_matrix(grad_weights_entries, weights.data_type)
    
    Note: Compute gradient w.r.t. bias: ∂L/∂b is equal to ∂L/∂y (direct copy)
    Let grad_bias_components be List[String]()
    Set i to 0
    While i is less than grad_output.dimension:
        Let bias_grad be grad_output.components.get(i)
        Call grad_bias_components.add(bias_grad)
        Set i to i plus 1
    
    Let grad_bias be Vector with components: grad_bias_components, dimension: grad_output.dimension, data_type: grad_output.data_type, is_unit_vector: false, norm: "0.0", vector_space: grad_output.vector_space
    
    Return Tuple[Vector[Float], Matrix[Float], Vector[Float]] with first: grad_input, second: grad_weights, third: grad_bias

Process called "convolution_backward" that takes grad_output as Tensor[Float], input as Tensor[Float], kernel as Tensor[Float], config as ConvolutionLayer returns Tuple[Tensor[Float], Tensor[Float]]:
    Note: Convolution gradients using correlation and full convolution
    Note: ∂L/∂x computed via full convolution with flipped kernel
    Note: Time complexity: O(n²m²), Space complexity: O(n²m²)
    
    If grad_output.shape.length does not equal 4:
        Throw Errors.InvalidArgument with "Gradient output tensor must be 4D"
    
    If input.shape.length does not equal 4:
        Throw Errors.InvalidArgument with "Input tensor must be 4D"
    
    If kernel.shape.length does not equal 4:
        Throw Errors.InvalidArgument with "Kernel tensor must be 4D"
    
    Let batch_size be input.shape.get(0)
    Let in_channels be input.shape.get(1)
    Let input_height be input.shape.get(2)
    Let input_width be input.shape.get(3)
    
    Let out_channels be grad_output.shape.get(1)
    Let output_height be grad_output.shape.get(2)
    Let output_width be grad_output.shape.get(3)
    
    Let kernel_height be kernel.shape.get(2)
    Let kernel_width be kernel.shape.get(3)
    
    Note: Extract stride and padding parameters from config
    Let stride_h be config.stride.first
    Let stride_w be config.stride.second
    Let pad_h be config.padding.first
    Let pad_w be config.padding.second
    
    Note: Initialize gradient w.r.t. input with zeros
    Let grad_input_data be List[String]()
    Let input_total_size be batch_size multiplied by in_channels multiplied by input_height multiplied by input_width
    Let idx be 0
    While idx is less than input_total_size:
        Call grad_input_data.add("0.0")
        Set idx to idx plus 1
    
    Note: Initialize gradient w.r.t. kernel with zeros
    Let grad_kernel_data be List[String]()
    Let kernel_total_size be out_channels multiplied by in_channels multiplied by kernel_height multiplied by kernel_width
    Set idx to 0
    While idx is less than kernel_total_size:
        Call grad_kernel_data.add("0.0")
        Set idx to idx plus 1
    
    Note: Compute convolution gradients for input and kernel tensors
    Let b be 0
    While b is less than batch_size:
        Let out_c be 0
        While out_c is less than out_channels:
            Let out_h be 0
            While out_h is less than output_height:
                Let out_w be 0
                While out_w is less than output_width:
                    Let grad_out_idx be ((b multiplied by out_channels plus out_c) multiplied by output_height plus out_h) multiplied by output_width plus out_w
                    Let grad_out_val be grad_output.data.get(grad_out_idx)
                    
                    Let in_c be 0
                    While in_c is less than in_channels:
                        Let k_h be 0
                        While k_h is less than kernel_height:
                            Let k_w be 0
                            While k_w is less than kernel_width:
                                Note: Compute proper input coordinates using stride and padding
                                Let in_h be out_h multiplied by stride_h plus k_h minus pad_h
                                Let in_w be out_w multiplied by stride_w plus k_w minus pad_w
                                
                                Note: Compute gradient w.r.t. input using proper stride and padding parameters
                                If in_h is greater than or equal to 0 and in_h is less than input_height and in_w is greater than or equal to 0 and in_w is less than input_width:
                                    Let input_idx be ((b multiplied by in_channels plus in_c) multiplied by input_height plus in_h) multiplied by input_width plus in_w
                                    Let kernel_idx be ((out_c multiplied by in_channels plus in_c) multiplied by kernel_height plus k_h) multiplied by kernel_width plus k_w
                                    Let kernel_val be kernel.data.get(kernel_idx)
                                    
                                    Let contrib be MathOps.multiply(grad_out_val, kernel_val, 15)
                                    If not contrib.overflow_occurred:
                                        Let current_grad be grad_input_data.get(input_idx)
                                        Let updated_grad be MathOps.add(current_grad, contrib.result_value, 15)
                                        If not updated_grad.overflow_occurred:
                                            Set grad_input_data[input_idx] to updated_grad.result_value
                                
                                Note: Gradient w.r.t. kernel
                                If in_h is less than input_height and in_w is less than input_width:
                                    Let input_idx be ((b multiplied by in_channels plus in_c) multiplied by input_height plus in_h) multiplied by input_width plus in_w
                                    Let kernel_idx be ((out_c multiplied by in_channels plus in_c) multiplied by kernel_height plus k_h) multiplied by kernel_width plus k_w
                                    Let input_val be input.data.get(input_idx)
                                    
                                    Let contrib be MathOps.multiply(grad_out_val, input_val, 15)
                                    If not contrib.overflow_occurred:
                                        Let current_kernel_grad be grad_kernel_data.get(kernel_idx)
                                        Let updated_kernel_grad be MathOps.add(current_kernel_grad, contrib.result_value, 15)
                                        If not updated_kernel_grad.overflow_occurred:
                                            Set grad_kernel_data[kernel_idx] to updated_kernel_grad.result_value
                                
                                Set k_w to k_w plus 1
                            Set k_h to k_h plus 1
                        Set in_c to in_c plus 1
                    Set out_w to out_w plus 1
                Set out_h to out_h plus 1
            Set out_c to out_c plus 1
        Set b to b plus 1
    
    Let grad_input_tensor be TensorOps.create_tensor(grad_input_data, input.shape, input.data_type)
    Let grad_kernel_tensor be TensorOps.create_tensor(grad_kernel_data, kernel.shape, kernel.data_type)
    
    Return Tuple[Tensor[Float], Tensor[Float]] with first: grad_input_tensor, second: grad_kernel_tensor

Note: ===== Weight Initialization =====

Process called "xavier_uniform_init" that takes shape as Tuple[Integer, Integer], gain as Float returns Matrix[Float]:
    Note: Xavier uniform: U(-√(6/(fan_in plus fan_out)), √(6/(fan_in plus fan_out)))
    Note: Maintains variance of activations and gradients across layers
    Note: Time complexity: O(nm), Space complexity: O(nm)
    
    Let rows be shape.first
    Let columns be shape.second
    
    If rows is less than or equal to 0 or columns is less than or equal to 0:
        Throw Errors.InvalidArgument with "Matrix dimensions must be positive"
    
    If gain is less than or equal to 0.0:
        Throw Errors.InvalidArgument with "Gain must be positive"
    
    Let fan_in be columns
    Let fan_out be rows
    Let fan_sum be fan_in plus fan_out
    
    Note: Compute bound: gain multiplied by √(6/(fan_in plus fan_out))
    Let six_str be "6.0"
    Let fan_sum_str be fan_sum.to_string()
    Let ratio be MathOps.divide(six_str, fan_sum_str, 15)
    If ratio.overflow_occurred:
        Throw Errors.ComputationError with "Overflow in Xavier bound computation"
    
    Let sqrt_result be MathOps.square_root(ratio.result_value, 15)
    If sqrt_result.overflow_occurred:
        Throw Errors.ComputationError with "Overflow in Xavier square root"
    
    Let gain_str be gain.to_string()
    Let bound_result be MathOps.multiply(gain_str, sqrt_result.result_value, 15)
    If bound_result.overflow_occurred:
        Throw Errors.ComputationError with "Overflow in Xavier bound scaling"
    Let bound be bound_result.result_value
    
    Note: Generate random matrix entries
    Let entries be List[List[String]]()
    Let random_gen be SecureRandom.create_secure_generator("ChaCha20", 256, true, 1000, List[String](), false, false, true)
    
    Let i be 0
    While i is less than rows:
        Let row be List[String]()
        Let j be 0
        While j is less than columns:
            Let random_val be SecureRandom.generate_uniform_float(random_gen, -1.0, 1.0)
            Let scaled_val be MathOps.multiply(random_val.to_string(), bound, 15)
            If not scaled_val.overflow_occurred:
                Call row.add(scaled_val.result_value)
            Otherwise:
                Call row.add("0.0")
            Set j to j plus 1
        Call entries.add(row)
        Set i to i plus 1
    
    Return LinAlg.create_matrix(entries, "float")

Process called "he_normal_init" that takes shape as Tuple[Integer, Integer], gain as Float returns Matrix[Float]:
    Note: He normal: N(0, √(2/fan_in)) for ReLU activations
    Note: Accounts for ReLU's effect on variance, preventing vanishing gradients
    Note: Time complexity: O(nm), Space complexity: O(nm)
    
    Let rows be shape.first
    Let columns be shape.second
    
    If rows is less than or equal to 0 or columns is less than or equal to 0:
        Throw Errors.InvalidArgument with "Matrix dimensions must be positive"
    
    If gain is less than or equal to 0.0:
        Throw Errors.InvalidArgument with "Gain must be positive"
    
    Let fan_in be columns
    
    Note: Compute std: gain multiplied by √(2/fan_in)
    Let two_str be "2.0"
    Let fan_in_str be fan_in.to_string()
    Let ratio be MathOps.divide(two_str, fan_in_str, 15)
    If ratio.overflow_occurred:
        Throw Errors.ComputationError with "Overflow in He normal ratio computation"
    
    Let sqrt_result be MathOps.square_root(ratio.result_value, 15)
    If sqrt_result.overflow_occurred:
        Throw Errors.ComputationError with "Overflow in He normal square root"
    
    Let gain_str be gain.to_string()
    Let std_result be MathOps.multiply(gain_str, sqrt_result.result_value, 15)
    If std_result.overflow_occurred:
        Throw Errors.ComputationError with "Overflow in He normal std scaling"
    Let std_dev be std_result.result_value
    
    Note: Generate random matrix with normal distribution using Box-Muller transform
    Let entries be List[List[String]]()
    Let random_gen be SecureRandom.create_secure_generator("ChaCha20", 256, true, 1000, List[String](), false, false, true)
    
    Let i be 0
    While i is less than rows:
        Let row be List[String]()
        Let j be 0
        While j is less than columns:
            Note: Box-Muller transform for normal distribution N(0, std_dev)
            If j % 2 is equal to 0 and j plus 1 is less than columns:
                Note: Generate pair of normal random numbers
                Let u1 be SecureRandom.generate_uniform_float(random_gen, 0.0, 1.0)
                Let u2 be SecureRandom.generate_uniform_float(random_gen, 0.0, 1.0)
                
                Note: Apply Box-Muller transform
                Let pi_2 be "6.28318530718"  Note: 2 multiplied by π
                Let u2_scaled be MathOps.multiply(pi_2, u2.to_string(), 15)
                If not u2_scaled.overflow_occurred:
                    Let cos_val be MathOps.cosine(u2_scaled.result_value, 15)
                    Let sin_val be MathOps.sine(u2_scaled.result_value, 15)
                    
                    Let u1_log be MathOps.logarithm(u1.to_string(), 15)
                    Let neg_2_log be MathOps.multiply("-2.0", u1_log.result_value, 15)
                    Let sqrt_term be MathOps.square_root(neg_2_log.result_value, 15)
                    
                    Let z0 be MathOps.multiply(sqrt_term.result_value, cos_val.result_value, 15)
                    Let z1 be MathOps.multiply(sqrt_term.result_value, sin_val.result_value, 15)
                    
                    Let normal0 be MathOps.multiply(z0.result_value, std_dev, 15)
                    Let normal1 be MathOps.multiply(z1.result_value, std_dev, 15)
                    
                    If not normal0.overflow_occurred and not normal1.overflow_occurred:
                        Call row.add(normal0.result_value)
                        Set j to j plus 1
                        If j is less than columns:
                            Call row.add(normal1.result_value)
                    Otherwise:
                        Call row.add("0.0")
                        Set j to j plus 1
                        If j is less than columns:
                            Call row.add("0.0")
                Otherwise:
                    Call row.add("0.0")
                    Set j to j plus 1
                    If j is less than columns:
                        Call row.add("0.0")
            Otherwise:
                Note: Generate proper normal distribution for remaining odd element using inverse transform
                Let u be SecureRandom.generate_uniform_float(random_gen, 0.0001, 0.9999)
                
                Note: Inverse normal CDF approximation using Beasley-Springer-Moro algorithm
                Let u_centered be MathOps.subtract(u.to_string(), "0.5", 15)
                Let u_abs be MathOps.absolute_value(u_centered.result_value, 15)
                
                Let normal_val as String
                If Parse u_abs.result_value as Float is less than 0.42:
                    Let u_squared be MathOps.multiply(u_centered.result_value, u_centered.result_value, 15)
                    Let a0 be "2.50662823884"
                    Let a1 be "-18.61500062529"
                    Let a2 be "41.39119773534"
                    Let a3 be "-25.44106049637"
                    Let b1 be "-8.47351093090"
                    Let b2 be "23.08336743743"
                    Let b3 be "-21.06224101826"
                    Let b4 be "3.13082909833"
                    
                    Let numerator be MathOps.add(a0, MathOps.multiply(a1, u_squared.result_value, 15).result_value, 15)
                    Set numerator to MathOps.add(numerator.result_value, MathOps.multiply(a2, MathOps.multiply(u_squared.result_value, u_squared.result_value, 15).result_value, 15).result_value, 15)
                    Set numerator to MathOps.add(numerator.result_value, MathOps.multiply(a3, MathOps.power(u_squared.result_value, "3.0", 15).result_value, 15).result_value, 15)
                    
                    Let denominator be MathOps.add("1.0", MathOps.multiply(b1, u_squared.result_value, 15).result_value, 15)
                    Set denominator to MathOps.add(denominator.result_value, MathOps.multiply(b2, MathOps.multiply(u_squared.result_value, u_squared.result_value, 15).result_value, 15).result_value, 15)
                    Set denominator to MathOps.add(denominator.result_value, MathOps.multiply(b3, MathOps.power(u_squared.result_value, "3.0", 15).result_value, 15).result_value, 15)
                    Set denominator to MathOps.add(denominator.result_value, MathOps.multiply(b4, MathOps.power(u_squared.result_value, "4.0", 15).result_value, 15).result_value, 15)
                    
                    Set normal_val to MathOps.multiply(u_centered.result_value, MathOps.divide(numerator.result_value, denominator.result_value, 15).result_value, 15).result_value
                Otherwise:
                    Set normal_val to MathOps.multiply(MathOps.sign_function(u_centered.result_value), "2.0", 15).result_value
                
                Let scaled_normal be MathOps.multiply(normal_val, std_dev, 15)
                If not scaled_normal.overflow_occurred:
                    Call row.add(scaled_normal.result_value)
                Otherwise:
                    Call row.add("0.0")
            Set j to j plus 1
        Call entries.add(row)
        Set i to i plus 1
    
    Return LinAlg.create_matrix(entries, "float")

Process called "orthogonal_init" that takes shape as Tuple[Integer, Integer], gain as Float returns Matrix[Float]:
    Note: Orthogonal initialization using QR decomposition of random matrix
    Note: Preserves norms and helps with gradient flow in deep networks
    Note: Time complexity: O(n³), Space complexity: O(n²)
    
    Let rows be shape.first
    Let columns be shape.second
    
    If rows is less than or equal to 0 or columns is less than or equal to 0:
        Throw Errors.InvalidArgument with "Matrix dimensions must be positive"
    
    If gain is less than or equal to 0.0:
        Throw Errors.InvalidArgument with "Gain must be positive"
    
    Note: Generate initial random matrix using normal distribution
    Let random_gen be SecureRandom.create_secure_generator("ChaCha20", 256, true, 1000, List[String](), false, false, true)
    Let random_entries be List[List[String]]()
    
    Let i be 0
    While i is less than rows:
        Let row be List[String]()
        Let j be 0
        While j is less than columns:
            Let u1 be SecureRandom.generate_uniform_float(random_gen, 0.0, 1.0)
            Let u2 be SecureRandom.generate_uniform_float(random_gen, 0.0, 1.0)
            Let pi_2 be "6.28318530718"
            Let u2_scaled be MathOps.multiply(pi_2, u2.to_string(), 15)
            Let cos_val be MathOps.cosine(u2_scaled.result_value, 15)
            Let u1_log be MathOps.logarithm(u1.to_string(), 15)
            Let neg_2_log be MathOps.multiply("-2.0", u1_log.result_value, 15)
            Let sqrt_term be MathOps.square_root(neg_2_log.result_value, 15)
            Let normal_val be MathOps.multiply(sqrt_term.result_value, cos_val.result_value, 15)
            Call row.add(normal_val.result_value)
            Set j to j plus 1
        Call random_entries.add(row)
        Set i to i plus 1
    
    Note: Perform QR decomposition using modified Gram-Schmidt orthogonalization
    Let orthogonal_entries be List[List[String]]()
    Let min_dim be MathCompare.minimum(rows.to_string(), columns.to_string(), 15)
    Let min_dimension be Parse min_dim as Integer
    
    Note: Initialize orthogonal matrix with zeros
    Set i to 0
    While i is less than rows:
        Let orth_row be List[String]()
        Let j be 0
        While j is less than columns:
            Call orth_row.add("0.0")
            Set j to j plus 1
        Call orthogonal_entries.add(orth_row)
        Set i to i plus 1
    
    Note: Gram-Schmidt orthogonalization process
    Let col be 0
    While col is less than min_dimension:
        Note: Start with current column from random matrix
        Let norm_squared be "0.0"
        Set i to 0
        While i is less than rows:
            Let current_val be random_entries.get(i).get(col)
            
            Note: Subtract projections onto previous orthogonal vectors
            Let prev_col be 0
            While prev_col is less than col:
                Let dot_product be "0.0"
                Let k be 0
                While k is less than rows:
                    Let rand_val be random_entries.get(k).get(col)
                    Let orth_val be orthogonal_entries.get(k).get(prev_col)
                    Let prod be MathOps.multiply(rand_val, orth_val, 15)
                    Let sum_result be MathOps.add(dot_product, prod.result_value, 15)
                    Set dot_product to sum_result.result_value
                    Set k to k plus 1
                
                Let projection be MathOps.multiply(dot_product, orthogonal_entries.get(i).get(prev_col), 15)
                Let subtraction be MathOps.subtract(current_val, projection.result_value, 15)
                Set current_val to subtraction.result_value
                Set prev_col to prev_col plus 1
            
            Set random_entries[i][col] to current_val
            Let val_squared be MathOps.multiply(current_val, current_val, 15)
            Let norm_sum be MathOps.add(norm_squared, val_squared.result_value, 15)
            Set norm_squared to norm_sum.result_value
            Set i to i plus 1
        
        Note: Normalize the vector
        Let norm be MathOps.square_root(norm_squared, 15)
        Set i to 0
        While i is less than rows:
            Let unnormalized be random_entries.get(i).get(col)
            Let normalized be MathOps.divide(unnormalized, norm.result_value, 15)
            Set orthogonal_entries[i][col] to normalized.result_value
            Set i to i plus 1
        Set col to col plus 1
    
    Note: Apply gain scaling to orthogonal matrix
    Let gain_str be gain.to_string()
    Set i to 0
    While i is less than rows:
        Let j be 0
        While j is less than columns:
            If j is less than min_dimension:
                Let scaled_val be MathOps.multiply(orthogonal_entries.get(i).get(j), gain_str, 15)
                Set orthogonal_entries[i][j] to scaled_val.result_value
            Set j to j plus 1
        Set i to i plus 1
    
    Return LinAlg.create_matrix(orthogonal_entries, "float")

Note: ===== Pooling Operations =====

Process called "max_pool_2d" that takes input as Tensor[Float], kernel_size as Tuple[Integer, Integer], stride as Tuple[Integer, Integer] returns Tensor[Float]:
    Note: Max pooling: takes maximum value in each pooling window
    Note: Provides translation invariance and reduces spatial dimensions
    Note: Time complexity: O(n²), Space complexity: O(n²)
    
    If input.shape.length does not equal 4:
        Throw Errors.InvalidArgument with "Input must be 4D tensor (batch, channels, height, width)"
    
    Let batch_size be input.shape.get(0)
    Let channels be input.shape.get(1)
    Let input_height be input.shape.get(2)
    Let input_width be input.shape.get(3)
    
    Let pool_h be kernel_size.first
    Let pool_w be kernel_size.second
    Let stride_h be stride.first
    Let stride_w be stride.second
    
    Let output_height be (input_height minus pool_h) / stride_h plus 1
    Let output_width be (input_width minus pool_w) / stride_w plus 1
    
    Let output_shape be List[Integer]()
    Call output_shape.add(batch_size)
    Call output_shape.add(channels)
    Call output_shape.add(output_height)
    Call output_shape.add(output_width)
    
    Let output_data be List[String]()
    
    Let b be 0
    While b is less than batch_size:
        Let c be 0
        While c is less than channels:
            Let out_h be 0
            While out_h is less than output_height:
                Let out_w be 0
                While out_w is less than output_width:
                    Let max_val be "-999999.0"
                    
                    Let p_h be 0
                    While p_h is less than pool_h:
                        Let p_w be 0
                        While p_w is less than pool_w:
                            Let in_h be out_h multiplied by stride_h plus p_h
                            Let in_w be out_w multiplied by stride_w plus p_w
                            
                            If in_h is less than input_height and in_w is less than input_width:
                                Let input_idx be ((b multiplied by channels plus c) multiplied by input_height plus in_h) multiplied by input_width plus in_w
                                Let current_val be input.data.get(input_idx)
                                Set max_val to MathCompare.maximum(max_val, current_val, 15)
                            Set p_w to p_w plus 1
                        Set p_h to p_h plus 1
                    
                    Call output_data.add(max_val)
                    Set out_w to out_w plus 1
                Set out_h to out_h plus 1
            Set c to c plus 1
        Set b to b plus 1
    
    Return TensorOps.create_tensor(output_data, output_shape, input.data_type)

Process called "avg_pool_2d" that takes input as Tensor[Float], kernel_size as Tuple[Integer, Integer], stride as Tuple[Integer, Integer] returns Tensor[Float]:
    Note: Average pooling: computes mean value in each pooling window
    Note: Smoother downsampling compared to max pooling
    Note: Time complexity: O(n²), Space complexity: O(n²)
    
    If input.shape.length does not equal 4:
        Throw Errors.InvalidArgument with "Input must be 4D tensor (batch, channels, height, width)"
    
    Let batch_size be input.shape.get(0)
    Let channels be input.shape.get(1)
    Let input_height be input.shape.get(2)
    Let input_width be input.shape.get(3)
    
    Let pool_h be kernel_size.first
    Let pool_w be kernel_size.second
    Let stride_h be stride.first
    Let stride_w be stride.second
    
    Let output_height be (input_height minus pool_h) / stride_h plus 1
    Let output_width be (input_width minus pool_w) / stride_w plus 1
    
    Let output_shape be List[Integer]()
    Call output_shape.add(batch_size)
    Call output_shape.add(channels)
    Call output_shape.add(output_height)
    Call output_shape.add(output_width)
    
    Let output_data be List[String]()
    Let pool_size be pool_h multiplied by pool_w
    Let pool_size_str be pool_size.to_string()
    
    Let b be 0
    While b is less than batch_size:
        Let c be 0
        While c is less than channels:
            Let out_h be 0
            While out_h is less than output_height:
                Let out_w be 0
                While out_w is less than output_width:
                    Let sum_val be "0.0"
                    
                    Let p_h be 0
                    While p_h is less than pool_h:
                        Let p_w be 0
                        While p_w is less than pool_w:
                            Let in_h be out_h multiplied by stride_h plus p_h
                            Let in_w be out_w multiplied by stride_w plus p_w
                            
                            If in_h is less than input_height and in_w is less than input_width:
                                Let input_idx be ((b multiplied by channels plus c) multiplied by input_height plus in_h) multiplied by input_width plus in_w
                                Let current_val be input.data.get(input_idx)
                                Let sum_result be MathOps.add(sum_val, current_val, 15)
                                If not sum_result.overflow_occurred:
                                    Set sum_val to sum_result.result_value
                            Set p_w to p_w plus 1
                        Set p_h to p_h plus 1
                    
                    Let avg_result be MathOps.divide(sum_val, pool_size_str, 15)
                    If not avg_result.overflow_occurred:
                        Call output_data.add(avg_result.result_value)
                    Otherwise:
                        Call output_data.add("0.0")
                    Set out_w to out_w plus 1
                Set out_h to out_h plus 1
            Set c to c plus 1
        Set b to b plus 1
    
    Return TensorOps.create_tensor(output_data, output_shape, input.data_type)

Process called "adaptive_avg_pool" that takes input as Tensor[Float], output_size as Tuple[Integer, Integer] returns Tensor[Float]:
    Note: Adaptive pooling: automatically determines kernel size and stride
    Note: Produces fixed-size output regardless of input dimensions
    Note: Time complexity: O(n²), Space complexity: O(n²)
    
    If input.shape.length does not equal 4:
        Throw Errors.InvalidArgument with "Input must be 4D tensor (batch, channels, height, width)"
    
    Let batch_size be input.shape.get(0)
    Let channels be input.shape.get(1)
    Let input_height be input.shape.get(2)
    Let input_width be input.shape.get(3)
    
    Let output_height be output_size.first
    Let output_width be output_size.second
    
    Let output_shape be List[Integer]()
    Call output_shape.add(batch_size)
    Call output_shape.add(channels)
    Call output_shape.add(output_height)
    Call output_shape.add(output_width)
    
    Let output_data be List[String]()
    
    Let b be 0
    While b is less than batch_size:
        Let c be 0
        While c is less than channels:
            Let out_h be 0
            While out_h is less than output_height:
                Let out_w be 0
                While out_w is less than output_width:
                    Note: Calculate adaptive pooling region
                    Let start_h be (out_h multiplied by input_height) / output_height
                    Let end_h be ((out_h plus 1) multiplied by input_height) / output_height
                    Let start_w be (out_w multiplied by input_width) / output_width
                    Let end_w be ((out_w plus 1) multiplied by input_width) / output_width
                    
                    Let sum_val be "0.0"
                    Let count be 0
                    
                    Let in_h be start_h
                    While in_h is less than end_h:
                        Let in_w be start_w
                        While in_w is less than end_w:
                            If in_h is less than input_height and in_w is less than input_width:
                                Let input_idx be ((b multiplied by channels plus c) multiplied by input_height plus in_h) multiplied by input_width plus in_w
                                Let current_val be input.data.get(input_idx)
                                Let sum_result be MathOps.add(sum_val, current_val, 15)
                                If not sum_result.overflow_occurred:
                                    Set sum_val to sum_result.result_value
                                Set count to count plus 1
                            Set in_w to in_w plus 1
                        Set in_h to in_h plus 1
                    
                    If count is greater than 0:
                        Let count_str be count.to_string()
                        Let avg_result be MathOps.divide(sum_val, count_str, 15)
                        If not avg_result.overflow_occurred:
                            Call output_data.add(avg_result.result_value)
                        Otherwise:
                            Call output_data.add("0.0")
                    Otherwise:
                        Call output_data.add("0.0")
                    Set out_w to out_w plus 1
                Set out_h to out_h plus 1
            Set c to c plus 1
        Set b to b plus 1
    
    Return TensorOps.create_tensor(output_data, output_shape, input.data_type)

Note: ===== Dropout and Regularization =====

Process called "dropout_forward" that takes input as Tensor[Float], probability as Float, training as Boolean returns Tuple[Tensor[Float], Tensor[Boolean]]:
    Note: Dropout: randomly zeros elements with probability p during training
    Note: Prevents overfitting by reducing co-adaptation of neurons
    Note: Time complexity: O(n), Space complexity: O(n)
    
    If probability is less than 0.0 or probability is greater than or equal to 1.0:
        Throw Errors.InvalidArgument with "Dropout probability must be in [0, 1)"
    
    Let output_data be List[String]()
    Let mask_data be List[Boolean]()
    
    If training:
        Let scale_factor be 1.0 / (1.0 minus probability)
        Let scale_str be scale_factor.to_string()
        
        Let random_gen be SecureRandom.create_secure_generator("ChaCha20", 256, true, 1000, List[String](), false, false, true)
        
        Let i be 0
        While i is less than input.data.length:
            Note: Use cryptographically secure random dropout
            Let random_val be SecureRandom.generate_uniform_float(random_gen, 0.0, 1.0)
            Let should_drop be random_val is less than probability
            
            If should_drop:
                Call output_data.add("0.0")
                Call mask_data.add(false)
            Otherwise:
                Let input_val be input.data.get(i)
                Let scaled_result be MathOps.multiply(input_val, scale_str, 15)
                If not scaled_result.overflow_occurred:
                    Call output_data.add(scaled_result.result_value)
                Otherwise:
                    Call output_data.add(input_val)
                Call mask_data.add(true)
            Set i to i plus 1
    Otherwise:
        Note: During inference, pass through without modification
        Set i to 0
        While i is less than input.data.length:
            Call output_data.add(input.data.get(i))
            Call mask_data.add(true)
            Set i to i plus 1
    
    Let output_tensor be TensorOps.create_tensor(output_data, input.shape, input.data_type)
    Let mask_tensor be TensorOps.create_tensor_boolean(mask_data, input.shape)
    
    Return Tuple[Tensor[Float], Tensor[Boolean]] with first: output_tensor, second: mask_tensor

Process called "dropout_backward" that takes grad_output as Tensor[Float], mask as Tensor[Boolean], probability as Float returns Tensor[Float]:
    Note: Applies same mask to gradients and scales by 1/(1-p)
    Note: Maintains expected value of gradients during training
    Note: Time complexity: O(n), Space complexity: O(1)
    
    If probability is less than 0.0 or probability is greater than or equal to 1.0:
        Throw Errors.InvalidArgument with "Dropout probability must be in [0, 1)"
    
    If grad_output.data.length does not equal mask.data.length:
        Throw Errors.InvalidArgument with "Gradient and mask tensors must have same size"
    
    Let grad_input_data be List[String]()
    Let scale_factor be 1.0 / (1.0 minus probability)
    Let scale_str be scale_factor.to_string()
    
    Let i be 0
    While i is less than grad_output.data.length:
        Let mask_val be mask.data.get(i)
        Let grad_val be grad_output.data.get(i)
        
        If mask_val:
            Note: Apply same scaling as forward pass
            Let scaled_result be MathOps.multiply(grad_val, scale_str, 15)
            If not scaled_result.overflow_occurred:
                Call grad_input_data.add(scaled_result.result_value)
            Otherwise:
                Call grad_input_data.add(grad_val)
        Otherwise:
            Call grad_input_data.add("0.0")
        Set i to i plus 1
    
    Return TensorOps.create_tensor(grad_input_data, grad_output.shape, grad_output.data_type)

Note: ===== Layer Normalization =====

Process called "layer_normalize" that takes input as Tensor[Float], gamma as Vector[Float], beta as Vector[Float], epsilon as Float returns Tensor[Float]:
    Note: Layer normalization: LN(x) is equal to γ multiplied by ((x minus μ) / σ) plus β
    Note: Normalizes across feature dimension, stable for RNNs and transformers
    Note: Time complexity: O(n), Space complexity: O(1)
    
    If input.shape.length is less than 2:
        Throw Errors.InvalidArgument with "Input tensor must have at least 2 dimensions"
    
    If epsilon is less than or equal to 0.0:
        Throw Errors.InvalidArgument with "Epsilon must be positive"
    
    Let batch_size be input.shape.get(0)
    Let feature_size be input.shape.get(input.shape.length minus 1)
    
    If gamma.dimension does not equal feature_size or beta.dimension does not equal feature_size:
        Throw Errors.InvalidArgument with "Gamma and beta must match feature dimension"
    
    Let output_data be List[String]()
    Let epsilon_str be epsilon.to_string()
    Let feature_size_str be feature_size.to_string()
    
    Note: Process each sample in the batch
    Let sample_idx be 0
    While sample_idx is less than batch_size:
        Note: Compute mean across features for this sample
        Let feature_sum be "0.0"
        Let start_idx be sample_idx multiplied by feature_size
        
        Let f be 0
        While f is less than feature_size:
            Let data_idx be start_idx plus f
            Let value be input.data.get(data_idx)
            Let sum_result be MathOps.add(feature_sum, value, 15)
            If not sum_result.overflow_occurred:
                Set feature_sum to sum_result.result_value
            Set f to f plus 1
        
        Let mean_result be MathOps.divide(feature_sum, feature_size_str, 15)
        If mean_result.overflow_occurred:
            Throw Errors.ComputationError with "Overflow in layer norm mean computation"
        Let sample_mean be mean_result.result_value
        
        Note: Compute variance across features for this sample
        Let variance_sum be "0.0"
        Set f to 0
        While f is less than feature_size:
            Let data_idx be start_idx plus f
            Let value be input.data.get(data_idx)
            Let diff be MathOps.subtract(value, sample_mean, 15)
            If not diff.overflow_occurred:
                Let squared_diff be MathOps.multiply(diff.result_value, diff.result_value, 15)
                If not squared_diff.overflow_occurred:
                    Let var_sum_result be MathOps.add(variance_sum, squared_diff.result_value, 15)
                    If not var_sum_result.overflow_occurred:
                        Set variance_sum to var_sum_result.result_value
            Set f to f plus 1
        
        Let variance_result be MathOps.divide(variance_sum, feature_size_str, 15)
        If variance_result.overflow_occurred:
            Throw Errors.ComputationError with "Overflow in layer norm variance computation"
        Let sample_variance be variance_result.result_value
        
        Note: Add epsilon and compute standard deviation
        Let var_plus_eps be MathOps.add(sample_variance, epsilon_str, 15)
        If var_plus_eps.overflow_occurred:
            Throw Errors.ComputationError with "Overflow in layer norm epsilon addition"
        
        Let std_result be MathOps.square_root(var_plus_eps.result_value, 15)
        If std_result.overflow_occurred:
            Throw Errors.ComputationError with "Overflow in layer norm sqrt"
        Let sample_std be std_result.result_value
        
        Note: Apply layer normalization to each feature
        Set f to 0
        While f is less than feature_size:
            Let data_idx be start_idx plus f
            Let value be input.data.get(data_idx)
            
            Note: Normalize: (x minus μ) / σ
            Let normalized_diff be MathOps.subtract(value, sample_mean, 15)
            If normalized_diff.overflow_occurred:
                Throw Errors.ComputationError with "Overflow in layer norm normalization diff"
            
            Let normalized_value be MathOps.divide(normalized_diff.result_value, sample_std, 15)
            If normalized_value.overflow_occurred:
                Throw Errors.ComputationError with "Overflow in layer norm normalization division"
            
            Note: Apply scale and shift: γ multiplied by normalized plus β
            Let gamma_value be gamma.components.get(f)
            Let beta_value be beta.components.get(f)
            
            Let scaled_value be MathOps.multiply(gamma_value, normalized_value.result_value, 15)
            If scaled_value.overflow_occurred:
                Throw Errors.ComputationError with "Overflow in layer norm scaling"
            
            Let final_value be MathOps.add(scaled_value.result_value, beta_value, 15)
            If final_value.overflow_occurred:
                Throw Errors.ComputationError with "Overflow in layer norm shift"
            
            Call output_data.add(final_value.result_value)
            Set f to f plus 1
        Set sample_idx to sample_idx plus 1
    
    Return TensorOps.create_tensor(output_data, input.shape, input.data_type)

Note: ===== Gradient Operations =====

Process called "gradient_clipping" that takes gradients as List[Tensor[Float]], max_norm as Float returns List[Tensor[Float]]:
    Note: Clips gradients to prevent exploding gradient problem
    Note: Scales gradient norm to max_norm if it exceeds threshold
    Note: Time complexity: O(n), Space complexity: O(1)
    
    If max_norm is less than or equal to 0.0:
        Throw Errors.InvalidArgument with "Max norm must be positive"
    
    If gradients.length is equal to 0:
        Return gradients
    
    Note: Compute total gradient norm
    Let total_norm_squared be "0.0"
    Let i be 0
    While i is less than gradients.length:
        Let grad_tensor be gradients.get(i)
        Let j be 0
        While j is less than grad_tensor.data.length:
            Let grad_value be grad_tensor.data.get(j)
            Let squared_value be MathOps.multiply(grad_value, grad_value, 15)
            If not squared_value.overflow_occurred:
                Let sum_result be MathOps.add(total_norm_squared, squared_value.result_value, 15)
                If not sum_result.overflow_occurred:
                    Set total_norm_squared to sum_result.result_value
            Set j to j plus 1
        Set i to i plus 1
    
    Let total_norm_result be MathOps.square_root(total_norm_squared, 15)
    If total_norm_result.overflow_occurred:
        Throw Errors.ComputationError with "Overflow in gradient norm computation"
    Let total_norm be total_norm_result.result_value
    
    Let total_norm_float be Parse total_norm as Float
    Let max_norm_str be max_norm.to_string()
    
    Note: Check if clipping is needed
    If total_norm_float is less than or equal to max_norm:
        Return gradients
    
    Note: Compute clipping factor
    Let clipping_factor_result be MathOps.divide(max_norm_str, total_norm, 15)
    If clipping_factor_result.overflow_occurred:
        Throw Errors.ComputationError with "Overflow in clipping factor computation"
    Let clipping_factor be clipping_factor_result.result_value
    
    Note: Apply clipping to all gradients
    Let clipped_gradients be List[Tensor[Float]]()
    Set i to 0
    While i is less than gradients.length:
        Let grad_tensor be gradients.get(i)
        Let clipped_data be List[String]()
        
        Let j be 0
        While j is less than grad_tensor.data.length:
            Let grad_value be grad_tensor.data.get(j)
            Let clipped_value be MathOps.multiply(grad_value, clipping_factor, 15)
            If not clipped_value.overflow_occurred:
                Call clipped_data.add(clipped_value.result_value)
            Otherwise:
                Call clipped_data.add(grad_value)
            Set j to j plus 1
        
        Let clipped_tensor be TensorOps.create_tensor(clipped_data, grad_tensor.shape, grad_tensor.data_type)
        Call clipped_gradients.add(clipped_tensor)
        Set i to i plus 1
    
    Return clipped_gradients

Process called "compute_gradient_norm" that takes gradients as List[Tensor[Float]] returns Float:
    Note: Computes L2 norm of gradient vector: ||∇|| is equal to √(Σ ||∇_i||²)
    Note: Used for gradient monitoring and clipping decisions
    Note: Time complexity: O(n), Space complexity: O(1)
    
    If gradients.length is equal to 0:
        Return 0.0
    
    Let total_norm_squared be "0.0"
    Let i be 0
    While i is less than gradients.length:
        Let grad_tensor be gradients.get(i)
        Let j be 0
        While j is less than grad_tensor.data.length:
            Let grad_value be grad_tensor.data.get(j)
            Let squared_value be MathOps.multiply(grad_value, grad_value, 15)
            If not squared_value.overflow_occurred:
                Let sum_result be MathOps.add(total_norm_squared, squared_value.result_value, 15)
                If not sum_result.overflow_occurred:
                    Set total_norm_squared to sum_result.result_value
            Set j to j plus 1
        Set i to i plus 1
    
    Let total_norm_result be MathOps.square_root(total_norm_squared, 15)
    If total_norm_result.overflow_occurred:
        Throw Errors.ComputationError with "Overflow in gradient norm computation"
    
    Let total_norm_float be Parse total_norm_result.result_value as Float
    Return total_norm_float