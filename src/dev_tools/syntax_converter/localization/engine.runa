Note:
Localization Engine for Runa surface syntax

Translates canonical tokens/phrases between languages while preserving strings,
annotations, and comments. Uses per-language catalogs for robust mapping.
:End Note

Import "./catalogs/en" as CatEN
Import "./catalogs/ja" as CatJA
Import "./catalogs/es" as CatES
Import "./catalogs/hi" as CatHI
Import "./catalogs/zh" as CatZH
Import "./catalogs/ru" as CatRU
Import "../../../stdlib/string/regex" as Regex

Type called "Catalog":
    to_canonical as Dictionary[String, String]
    from_canonical as Dictionary[String, String]
    ordered_from_canonical as List[String]  Note: keys ordered longest-first
    ordered_to_canonical as List[String]

Process called "supported_language" that takes lang as String returns Boolean:
    Let code be lowercase(lang)
    Return code is equal to "en" or code is equal to "ja" or code is equal to "es" or code is equal to "hi" or code is equal to "zh" or code is equal to "ru"

Process called "load_catalog" that takes lang as String returns Catalog:
    Let code be lowercase(lang)
    Match code:
        When "en": Return build_catalog(CatEN.to_canonical(), CatEN.from_canonical())
        When "ja": Return build_catalog(CatJA.to_canonical(), CatJA.from_canonical())
        When "es": Return build_catalog(CatES.to_canonical(), CatES.from_canonical())
        When "hi": Return build_catalog(CatHI.to_canonical(), CatHI.from_canonical())
        When "zh": Return build_catalog(CatZH.to_canonical(), CatZH.from_canonical())
        When "ru": Return build_catalog(CatRU.to_canonical(), CatRU.from_canonical())
        Otherwise: Return build_catalog(CatEN.to_canonical(), CatEN.from_canonical())

Process called "build_catalog" that takes to_c as Dictionary[String, String] and from_c as Dictionary[String, String] returns Catalog:
    Let ordered_from be sort_keys_by_length_desc(from_c)
    Let ordered_to be sort_keys_by_length_desc(to_c)
    Return Catalog with:
        to_canonical as to_c
        from_canonical as from_c
        ordered_from_canonical as ordered_from
        ordered_to_canonical as ordered_to

Process called "sort_keys_by_length_desc" that takes d as Dictionary[String, String] returns List[String]:
    Let keys be list of keys in d
    Sort keys by length descending
    Return keys

Process called "detect_language" that takes source as String returns Optional[String]:
    Note: Naive detection by token score
    Let scores be dictionary containing
    For each lang in list containing "en","ja","es","hi","zh","ru":
        Let cat be load_catalog(lang)
        Set scores[lang] to score_text_against(cat, source)
    Let best_lang be "en"
    Let best_score be -1
    For each lang and s in scores:
        If s > best_score:
            Set best_score to s
            Set best_lang to lang
    If best_score <= 0: Return none
    Return best_lang

Process called "score_text_against" that takes catalog as Catalog and text as String returns Integer:
    Let score be 0
    For each key in catalog.ordered_from_canonical:
        If key length is greater than 0 and contains_word(text, key):
            Set score to score plus 1
    Return score

Process called "contains_word" that takes text as String and phrase as String returns Boolean:
    Let pattern be word_boundary_pattern(phrase)
    Return Regex.match(text, pattern)

Process called "word_boundary_pattern" that takes phrase as String returns String:
    Note: Escape regex special chars in phrase
    Let escaped be Regex.escape(phrase)
    Return "(?i)(?<![A-Za-z0-9_])" plus escaped plus "(?![A-Za-z0-9_])"

Process called "translate_source" that takes source as String and from_lang as String and to_lang as String returns String:
    If from_lang is equal to to_lang: Return source
    Let from_cat be load_catalog(from_lang)
    Let to_cat be load_catalog(to_lang)
    
    Let segments be split_protected_segments(source)
    Let out be ""
    For each seg in segments:
        If seg["type"] is equal to "code":
            Let normalized be replace_tokens(seg["text"], from_cat.from_canonical, from_cat.ordered_from_canonical)
            Let rendered be replace_tokens(normalized, to_cat.from_canonical, to_cat.ordered_from_canonical)  Note: in case to_lang also maps to canonical; no-op for canonical keys
            Let final be replace_from_canonical(rendered, to_cat.from_canonical, to_cat.ordered_from_canonical, to_cat)
            Set out to out plus final
        Otherwise:
            Set out to out plus seg["text"]
    Return out

Process called "replace_tokens" that takes text as String and mapping as Dictionary[String, String] and ordered_keys as List[String] returns String:
    Let out be text
    For each key in ordered_keys:
        Let val be mapping[key]
        Let pattern be word_boundary_pattern(key)
        Set out to Regex.replace_all(out, pattern, val)
    Return out

Process called "replace_from_canonical" that takes text as String and mapping as Dictionary[String, String] and ordered_keys as List[String] and cat as Catalog returns String:
    Note: Replace canonical to target using from_canonical inverted
    Let inverted be invert_dictionary(cat.to_canonical)  Note: canonical -> lang
    Let ordered_can be sort_keys_by_length_desc(inverted)
    Let out be text
    For each can_key in ordered_can:
        Let target_val be inverted[can_key]
        Let pattern be word_boundary_pattern(can_key)
        Set out to Regex.replace_all(out, pattern, target_val)
    Return out

Process called "invert_dictionary" that takes d as Dictionary[String, String] returns Dictionary[String, String]:
    Let inv be dictionary containing
    For each k and v in d:
        Set inv[v] to k
    Return inv

Process called "split_protected_segments" that takes text as String returns List[Dictionary[String, String]]:
    Note: Split into code and protected segments (strings, comments)
    Let segments be list containing nothing
    Let i be 0
    Let n be length of text
    While i < n:
        Let ch be char_at(text, i)
        If ch is equal to '"' or ch is equal to '\'':
            Let (lit, j) be scan_string(text, i)
            Add dictionary with "type" as "string" and "text" as lit to segments
            Set i to j
        Otherwise if starts_with_at(text, i, "Note:"):
            Let (comment, j) be scan_comment(text, i)
            Add dictionary with "type" as "comment" and "text" as comment to segments
            Set i to j
        Otherwise:
            Let (code, j) be scan_code_run(text, i)
            Add dictionary with "type" as "code" and "text" as code to segments
            Set i to j
    Return segments

Process called "scan_string" that takes text as String and start as Integer returns Tuple[String, Integer]:
    Let quote be char_at(text, start)
    Let i be start
    Set i to i plus 1
    While i < length of text:
        Let ch be char_at(text, i)
        If ch is equal to '\\':
            Set i to i plus 2
            Continue
        If ch is equal to quote:
            Set i to i plus 1
            Break
        Set i to i plus 1
    Return substring(text, start, i), i

Process called "scan_comment" that takes text as String and start as Integer returns Tuple[String, Integer]:
    Note: Supports single line 'Note:' and block up to ':End Note'
    Let i be start
    If starts_with_at(text, i, "Note:") and find_next_line_starting(text, i, ":End Note") >= 0:
        Let end_pos be index_of(text, ":End Note", i)
        If end_pos >= 0:
            Set end_pos to end_pos plus length of ":End Note"
            Return substring(text, start, end_pos), end_pos
    Note: fallback to single line until newline
    While i < length of text and char_at(text, i) is not equal to '\n':
        Set i to i plus 1
    If i < length of text: Set i to i plus 1
    Return substring(text, start, i), i

Process called "scan_code_run" that takes text as String and start as Integer returns Tuple[String, Integer]:
    Let i be start
    While i < length of text:
        Let ch be char_at(text, i)
        If ch is equal to '"' or ch is equal to '\'' or starts_with_at(text, i, "Note:"):
            Break
        Set i to i plus 1
    Return substring(text, start, i), i

Process called "char_at" that takes s as String and idx as Integer returns String:
    Return s substring from idx to idx plus 1

Process called "starts_with_at" that takes s as String and idx as Integer and prefix as String returns Boolean:
    If idx plus length of prefix > length of s: Return false
    Return (substring(s, idx, idx plus length of prefix) is equal to prefix)

Process called "index_of" that takes s as String and needle as String and start as Optional[Integer] returns Integer:
    Note: Simple forward search
    Let pos be 0
    If start: Set pos to start
    While pos <= length of s minus length of needle:
        If substring(s, pos, pos plus length of needle) is equal to needle:
            Return pos
        Set pos to pos plus 1
    Return -1

Process called "find_next_line_starting" that takes s as String and start as Integer and marker as String returns Integer:
    Let i be start
    While i < length of s:
        If starts_with_at(s, i, marker): Return i
        If char_at(s, i) is equal to '\n':
            If starts_with_at(s, i plus 1, marker): Return i plus 1
        Set i to i plus 1
    Return -1

