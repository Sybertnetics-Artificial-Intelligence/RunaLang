Note:
Runa Canonical Mode Processor - The New Writeable Standard

This is the NEW canonical mode that replaces the old viewer mode as the 
primary writeable form. Canonical Runa syntax serves as:
- The standard writeable interface (replaces old --viewer writeable mode)
- The direct compilation target 
- The intermediate form for conversions between modes
- The authoritative syntax representation

CORRECTED ARCHITECTURE:
- --canon: THIS FILE - writeable canonical Runa (NEW standard)
- --developer: Technical syntax (writeable, unchanged)  
- --viewer: Natural language display (READ-ONLY, for comprehension)

Features:
- Standard Runa syntax (`Process called "name"`, `Let x be y`, etc.)
- Full writeable capability with validation
- Direct compilation without conversion
- Serves as hub for mode conversions
- Format validation and normalization
:End Note

Import "../compiler/semantic/semantic_analyzer" as SemanticAnalyzer
Import "../compiler/lexer/enhanced_lexer" as Lexer
Import "../compiler/parser/enhanced_parser" as Parser
Import "utilities/common" as Common

Note: Core processing engine for canonical mode
Type called "CanonicalModeProcessor":
    source_code as String
    validated_ast as ASTNode
    processing_options as Dictionary[String, Any]
    validation_results as List[ValidationMessage]
    format_corrections as List[FormatCorrection]

Type called "ValidationMessage":
    message as String
    severity as String
    line_number as Integer
    suggestion as Optional[String]

Type called "FormatCorrection":
    original_text as String
    corrected_text as String
    correction_type as String
    line_number as Integer

Note: Main processing entry point
Process called "run_canonical_mode" that takes source_file as String and output_file as Optional[String] and options as Dictionary[String, Any] returns Boolean:
    Note: Main entry point for canonical mode processing
    Try:
        Let source_code be read_canonical_file with path as source_file
        Let processed_result be process_canonical_syntax with source_code as source_code and options as options
        
        If output_file is not None:
            Call write_canonical_file with path as output_file and content as processed_result.processed_code
            Display "Canonical mode processing complete: " plus output_file
        Otherwise:
            Display processed_result.processed_code
        
        Note: Show any validation messages or corrections made
        If length of processed_result.validation_messages is greater than 0:
            Display ""
            Display "ðŸ“‹ Validation Results:"
            For message in processed_result.validation_messages:
                Display "  " plus message.severity plus ": " plus message.message plus " (line " plus string_from_integer(message.line_number) plus ")"
        
        If length of processed_result.format_corrections is greater than 0:
            Display ""
            Display "ðŸ”§ Format Corrections Applied:"
            For correction in processed_result.format_corrections:
                Display "  Line " plus string_from_integer(correction.line_number) plus ": " plus correction.correction_type
        
        Return True
        
    Catch file_error:
        Display "Error reading canonical file: " plus file_error.message
        Return False
    Catch processing_error:
        Display "Error processing canonical syntax: " plus processing_error.message
        Return False

Process called "process_canonical_syntax" that takes source_code as String and options as Dictionary[String, Any] returns CanonicalProcessingResult:
    Note: Process and validate canonical Runa syntax
    Let processor be create_canonical_processor with source as source_code and options as options
    
    Note: Step 1: Syntax validation
    Let validation_result be validate_canonical_syntax with processor as processor
    If not validation_result.is_valid and options.get("validate_syntax", True):
        Throw ProcessingError with message as "Canonical syntax validation failed: " plus validation_result.error_summary
    
    Note: Step 2: Format normalization (if requested)
    Let normalized_code be source_code
    If options.get("normalize_style", False):
        Set normalized_code to normalize_canonical_formatting with code as source_code and options as options
    
    Note: Step 3: Comment preservation
    Let final_code be normalized_code
    If options.get("preserve_comments", True):
        Set final_code to preserve_comment_formatting with code as normalized_code
    
    Return CanonicalProcessingResult with:
        processed_code: final_code
        validation_messages: validation_result.messages
        format_corrections: processor.format_corrections
        processing_success: True

Process called "create_canonical_processor" that takes source as String and options as Dictionary[String, Any] returns CanonicalModeProcessor:
    Note: Initialize canonical mode processor with options
    Return CanonicalModeProcessor with:
        source_code: source
        validated_ast: Optional.None
        processing_options: options
        validation_results: Empty List[ValidationMessage]
        format_corrections: Empty List[FormatCorrection]

Process called "validate_canonical_syntax" that takes processor as CanonicalModeProcessor returns ValidationResult:
    Note: Validate that source code follows canonical Runa syntax
    Try:
        Let lexer be Lexer.create_lexer with source as processor.source_code
        Let tokens be Lexer.tokenize with lexer as lexer
        Let parser be Parser.create_parser with tokens as tokens
        Let ast be Parser.parse with parser as parser
        
        Note: Canonical syntax specific validations
        Let canonical_validation be validate_canonical_patterns with ast as ast
        Let semantic_validation be validate_semantic_correctness with ast as ast
        
        If canonical_validation.is_valid and semantic_validation.is_valid:
            Return ValidationResult with:
                is_valid: True
                messages: Empty List[ValidationMessage]
                error_summary: ""
        Otherwise:
            Let combined_messages be combine_validation_messages with 
                canonical_messages as canonical_validation.messages and 
                semantic_messages as semantic_validation.messages
            Return ValidationResult with:
                is_valid: False
                messages: combined_messages
                error_summary: generate_error_summary with messages as combined_messages
                
    Catch parse_error:
        Return ValidationResult with:
            is_valid: False
            messages: List with ValidationMessage with:
                message: "Parse error: " plus parse_error.message
                severity: "error"
                line_number: parse_error.line_number
                suggestion: None
            error_summary: "Failed to parse canonical Runa syntax"

Process called "validate_canonical_patterns" that takes ast as ASTNode returns PatternValidationResult:
    Note: Validate canonical Runa specific syntax patterns
    Let validation_messages be List[ValidationMessage]
    
    Note: Check for proper Process declarations
    Let process_nodes be find_nodes_by_type with ast as ast and node_type as "ProcessDeclaration"
    For process_node in process_nodes:
        If not validate_process_declaration with node as process_node:
            Add ValidationMessage with:
                message: "Process declaration doesn't follow canonical pattern"
                severity: "warning"
                line_number: process_node.line_number
                suggestion: Some("Use 'Process called \"name\" that takes ... returns ...'")
            to validation_messages
    
    Note: Check for proper variable declarations
    Let variable_nodes be find_nodes_by_type with ast as ast and node_type as "VariableDeclaration"
    For variable_node in variable_nodes:
        If not validate_variable_declaration with node as variable_node:
            Add ValidationMessage with:
                message: "Variable declaration should use canonical 'Let ... be ...' pattern"
                severity: "info"
                line_number: variable_node.line_number
                suggestion: Some("Use 'Let variable_name be value'")
            to validation_messages
    
    Return PatternValidationResult with:
        is_valid: length of validation_messages is equal to 0
        messages: validation_messages

Process called "normalize_canonical_formatting" that takes code as String and options as Dictionary[String, Any] returns String:
    Note: Normalize canonical Runa formatting to standard style
    Let normalized be code
    Let indent_size be options.get("indent_size", 4)
    
    Note: Normalize indentation
    Set normalized to normalize_indentation with text as normalized and size as indent_size
    
    Note: Normalize spacing around operators
    Set normalized to normalize_operator_spacing with text as normalized
    
    Note: Normalize line breaks and structure
    Set normalized to normalize_line_structure with text as normalized
    
    Return normalized

Process called "convert_from_developer_to_canonical" that takes source_code as String and options as Dictionary[String, Any] returns String:
    Note: Convert developer syntax to canonical Runa syntax
    Import "syntax_converter" as SyntaxConverter
    
    Try:
        Let conversion_result be SyntaxConverter.convert_between_modes with 
            source_code as source_code and 
            from_mode as "developer" and 
            to_mode as "canonical" and 
            options as options
        
        If conversion_result.conversion_success:
            Return conversion_result.converted_code
        Otherwise:
            Note: Fall back to original code if conversion fails
            Return source_code
    Catch error:
        Note: Fall back to original code on error
        Return source_code

Process called "convert_constructor_syntax_to_canonical" that takes code as String returns String:
    Note: Convert technical constructor syntax to canonical form
    Let converted be code
    
    Note: Convert new TypeName() to Let var be a value of type TypeName
    Set converted to regex_replace_all with 
        text as converted and 
        pattern as "let\\s+([a-zA-Z_][a-zA-Z0-9_]*)\\s*=\\s*new\\s+([a-zA-Z_][a-zA-Z0-9_]*)\\(\\)" and 
        replacement as "Let $1 be a value of type $2"
    
    Note: Convert new TypeName({fields}) to Let var be TypeName with fields End TypeName
    Set converted to regex_replace_all with 
        text as converted and 
        pattern as "let\\s+([a-zA-Z_][a-zA-Z0-9_]*)\\s*=\\s*new\\s+([a-zA-Z_][a-zA-Z0-9_]*)\\(\\{([^}]*)\\}\\)" and 
        replacement as "Let $1 be $2 with$3End $2"
    
    Note: Convert basic assignments
    Set converted to regex_replace_all with 
        text as converted and 
        pattern as "([a-zA-Z_][a-zA-Z0-9_.]*)\\s*=\\s*([^;\\n]+)" and 
        replacement as "Set $1 to $2"
    
    Note: Convert let declarations (non-constructor)
    Set converted to regex_replace_all with 
        text as converted and 
        pattern as "let\\s+([a-zA-Z_][a-zA-Z0-9_]*)\\s*=\\s*([^;\\n]+)" and 
        replacement as "Let $1 be $2"
    
    Return converted

Process called "regex_replace_all" that takes text as String and pattern as String and replacement as String returns String:
    Note: Replace all occurrences of pattern in text with replacement
    Import "regex" as Regex
    
    Try:
        Let regex be Regex.compile with pattern as pattern
        Return Regex.replace_all with regex as regex and text as text and replacement as replacement
    Catch error:
        Note: Return original text if regex fails
        Return text

Process called "preserve_comment_formatting" that takes code as String returns String:
    Note: Ensure comments are properly formatted in canonical style
    Let lines be split_lines with text as code
    Let processed_lines be List[String]
    
    For line in lines:
        If line starts with "Note:":
            Note: This is a canonical Runa comment - preserve as-is
            Add line to processed_lines
        Else if line contains "Note:":
            Note: Inline comment - ensure proper formatting
            Let processed_line be format_inline_comment with line as line
            Add processed_line to processed_lines
        Otherwise:
            Add line to processed_lines
    
    Return join_lines with lines as processed_lines

Note: Supporting types for canonical processing
Type called "CanonicalProcessingResult":
    processed_code as String
    validation_messages as List[ValidationMessage]
    format_corrections as List[FormatCorrection]
    processing_success as Boolean

Type called "ValidationResult":
    is_valid as Boolean
    messages as List[ValidationMessage]
    error_summary as String

Type called "PatternValidationResult":
    is_valid as Boolean
    messages as List[ValidationMessage]

Note: File I/O operations
Process called "read_canonical_file" that takes path as String returns String:
    Note: Read canonical Runa source file
    Try:
        Import "io"
        Return io.read_text_file with path as path
    Catch error:
        Throw FileError with message as "Could not read canonical file: " plus path

Process called "write_canonical_file" that takes path as String and content as String returns None:
    Note: Write canonical Runa source file
    Try:
        Import "io"
        Call io.write_text_file with path as path and content as content
    Catch error:
        Throw FileError with message as "Could not write canonical file: " plus path

Note: Utility functions for canonical processing
Process called "validate_process_declaration" that takes node as ASTNode returns Boolean:
    Note: Check if process declaration follows canonical pattern
    If node.node_type is not equal to "ProcessDeclaration":
        Return False
    
    Note: Should have "Process called" pattern
    Let declaration_text be get_node_text with node as node
    Return declaration_text contains "Process called" and declaration_text contains "that takes" and declaration_text contains "returns"

Process called "validate_variable_declaration" that takes node as ASTNode returns Boolean:
    Note: Check if variable declaration follows canonical pattern
    If node.node_type is not equal to "VariableDeclaration":
        Return False
    
    Note: Should have "Let ... be ..." pattern
    Let declaration_text be get_node_text with node as node
    Return declaration_text contains "Let " and declaration_text contains " be "

Process called "find_nodes_by_type" that takes ast as ASTNode and node_type as String returns List[ASTNode]:
    Note: Find all nodes of specified type in AST
    Let matching_nodes be List[ASTNode]
    Call traverse_for_type with ast as ast and target_type as node_type and results as matching_nodes
    Return matching_nodes

Process called "traverse_for_type" that takes ast as ASTNode and target_type as String and results as List[ASTNode] returns None:
    Note: Recursively traverse AST to find nodes of target type
    If ast.node_type is equal to target_type:
        Add ast to results
    
    For child in ast.children:
        Call traverse_for_type with ast as child and target_type as target_type and results as results

Process called "get_node_text" that takes node as ASTNode returns String:
    Note: Extract text representation of AST node
    If node.node_type is equal to "Identifier":
        Return node.value as String
    Else if node.node_type is equal to "Literal":
        Return node.value as String
    Otherwise:
        Note: Reconstruct from children or metadata
        Return node.source_text

Process called "combine_validation_messages" that takes canonical_messages as List[ValidationMessage] and semantic_messages as List[ValidationMessage] returns List[ValidationMessage]:
    Note: Combine validation messages from different sources
    Let combined be List[ValidationMessage]
    For message in canonical_messages:
        Add message to combined
    For message in semantic_messages:
        Add message to combined
    Return combined

Process called "generate_error_summary" that takes messages as List[ValidationMessage] returns String:
    Note: Generate summary of validation errors
    Let error_count be 0
    Let warning_count be 0
    
    For message in messages:
        If message.severity is equal to "error":
            Set error_count to error_count plus 1
        Else if message.severity is equal to "warning":
            Set warning_count to warning_count plus 1
    
    If error_count is greater than 0:
        Return string_from_integer(error_count) plus " errors, " plus string_from_integer(warning_count) plus " warnings"
    Else if warning_count is greater than 0:
        Return string_from_integer(warning_count) plus " warnings"
    Otherwise:
        Return "No issues found"

Process called "validate_semantic_correctness" that takes ast as ASTNode returns ValidationResult:
    Note: Perform semantic validation using semantic analyzer
    Try:
        Let analyzer be SemanticAnalyzer.create_analyzer()
        Let semantic_result be SemanticAnalyzer.analyze with analyzer as analyzer and ast as ast
        
        If semantic_result.has_errors:
            Let validation_messages be convert_semantic_errors_to_messages with errors as semantic_result.errors
            Return ValidationResult with:
                is_valid: False
                messages: validation_messages
                error_summary: "Semantic validation failed"
        Otherwise:
            Return ValidationResult with:
                is_valid: True
                messages: Empty List[ValidationMessage]
                error_summary: ""
                
    Catch semantic_error:
        Return ValidationResult with:
            is_valid: False
            messages: List with ValidationMessage with:
                message: "Semantic analysis error: " plus semantic_error.message
                severity: "error"
                line_number: 0
                suggestion: None
            error_summary: "Semantic analysis failed"

Process called "convert_semantic_errors_to_messages" that takes errors as List[SemanticError] returns List[ValidationMessage]:
    Note: Convert semantic errors to validation messages
    Let messages be List[ValidationMessage]
    For error in errors:
        Add ValidationMessage with:
            message: error.message
            severity: "error"
            line_number: error.line_number
            suggestion: error.suggestion
        to messages
    Return messages

Note: String manipulation utilities
Process called "normalize_indentation" that takes text as String and size as Integer returns String:
    Note: Normalize indentation to specified size
    Let lines be split_lines with text as text
    Let normalized_lines be List[String]
    
    For line in lines:
        Let normalized_line be fix_line_indentation with line as line and indent_size as size
        Add normalized_line to normalized_lines
    
    Return join_lines with lines as normalized_lines

Process called "normalize_operator_spacing" that takes text as String returns String:
    Note: Normalize spacing around operators for canonical style
    Let normalized be text
    
    Note: Ensure proper spacing around 'be'
    Set normalized to replace_pattern with text as normalized and pattern as " be " and replacement as " be "
    
    Note: Ensure proper spacing around 'as'
    Set normalized to replace_pattern with text as normalized and pattern as " as " and replacement as " as "
    
    Note: Ensure proper spacing around 'is'
    Set normalized to replace_pattern with text as normalized and pattern as " is " and replacement as " is "
    
    Return normalized

Process called "normalize_line_structure" that takes text as String returns String:
    Note: Normalize line breaks and structural formatting
    Let lines be split_lines with text as text
    Let structured_lines be List[String]
    
    For line in lines:
        Let trimmed be trim_whitespace with text as line
        If length of trimmed is greater than 0:
            Add trimmed to structured_lines
    
    Return join_lines with lines as structured_lines

Process called "format_inline_comment" that takes line as String returns String:
    Note: Format inline comments to canonical style
    If line contains "Note:":
        Let parts be split_on_first with text as line and delimiter as "Note:"
        If length of parts is equal to 2:
            Return trim_whitespace with text as parts[0] plus "Note:" plus parts[1]
    Return line

Process called "split_lines" that takes text as String returns List[String]:
    Note: Split text into lines
    Return split with text as text and delimiter as "\n"

Process called "join_lines" that takes lines as List[String] returns String:
    Note: Join lines with newline separators
    Return join with strings as lines and separator as "\n"

Process called "split_on_first" that takes text as String and delimiter as String returns List[String]:
    Note: Split text on first occurrence of delimiter
    Let index be find_first with text as text and search as delimiter
    If index is greater than -1:
        Let before be substring with text as text and start as 0 and end as index
        Let after be substring with text as text and start as index plus length of delimiter
        Return List with before and after
    Otherwise:
        Return List with text

Process called "trim_whitespace" that takes text as String returns String:
    Note: Remove leading and trailing whitespace
    Let trimmed be text
    
    Note: Remove leading whitespace
    While length of trimmed is greater than 0 and character_at with text as trimmed and position as 0 is equal to " ":
        Set trimmed to substring with text as trimmed and start as 1
    
    Note: Remove trailing whitespace  
    While length of trimmed is greater than 0 and character_at with text as trimmed and position as length of trimmed minus 1 is equal to " ":
        Set trimmed to substring with text as trimmed and start as 0 and end as length of trimmed minus 1
    
    Return trimmed

Process called "replace_pattern" that takes text as String and pattern as String and replacement as String returns String:
    Note: Replace all occurrences of pattern with replacement
    Let result be text
    Let search_index be find_first with text as result and search as pattern
    
    While search_index is greater than -1:
        Let before be substring with text as result and start as 0 and end as search_index
        Let after be substring with text as result and start as search_index plus length of pattern
        Set result to before plus replacement plus after
        Set search_index to find_first with text as result and search as pattern
    
    Return result

Process called "find_first" that takes text as String and search as String returns Integer:
    Note: Find first occurrence of search string in text
    Let text_length be length of text
    Let search_length be length of search
    
    For i from 0 to text_length minus search_length:
        Let matches be True
        For j from 0 to search_length minus 1:
            If character_at with text as text and position as i plus j is not equal to character_at with text as search and position as j:
                Set matches to False
                Break
        If matches:
            Return i
    
    Return -1

Process called "substring" that takes text as String and start as Integer and end as Optional[Integer] returns String:
    Note: Extract substring from text
    Let actual_end be if end is not None then end else length of text
    If start is less than 0:
        Set start to 0
    If actual_end is greater than length of text:
        Set actual_end to length of text
    
    Let result be ""
    For i from start to actual_end minus 1:
        Set result to result plus character_at with text as text and position as i
    
    Return result

Process called "character_at" that takes text as String and position as Integer returns String:
    Note: Get character at position in string
    If position is less than 0 or position is greater than or equal to length of text:
        Return ""
    
    Note: Convert to character array and access by index
    Let chars be text as List[String]
    Return chars at position

Process called "fix_line_indentation" that takes line as String and indent_size as Integer returns String:
    Note: Fix indentation for a single line
    Let trimmed be trim_whitespace with text as line
    If length of trimmed is equal to 0:
        Return ""
    
    Note: Calculate proper indentation level (simplified)
    Let current_indent be calculate_current_indent with line as line
    Let proper_indent be calculate_proper_indent with line as trimmed and current as current_indent and size as indent_size
    
    Return create_indent_string with level as proper_indent and size as indent_size plus trimmed

Process called "calculate_current_indent" that takes line as String returns Integer:
    Note: Count current indentation spaces
    Let count be 0
    While count is less than length of line and character_at with text as line and position as count is equal to " ":
        Set count to count plus 1
    Return count

Process called "calculate_proper_indent" that takes line as String and current as Integer and size as Integer returns Integer:
    Note: Calculate proper indentation level (simplified heuristic)
    If line starts with "Process called" or line starts with "Type called":
        Return 0
    Else if line starts with "Note:" and not line starts with "    Note:":
        Return 0  
    Else if line contains ":End Note":
        Return 0
    Otherwise:
        Return current divided by size multiplied by size Note: Round to nearest indent level

Process called "create_indent_string" that takes level as Integer and size as Integer returns String:
    Note: Create indentation string with specified spaces
    Let indent be ""
    For i from 0 to level minus 1:
        Set indent to indent plus " "
    Return indent

Process called "string_from_integer" that takes number as Integer returns String:
    Note: Convert integer to string representation
    Return number as String

Process called "split" that takes text as String and delimiter as String returns List[String]:
    Note: Split text on delimiter
    Let parts be List[String]
    Let current be ""
    Let delimiter_length be length of delimiter
    Let text_length be length of text
    
    Let i be 0
    While i is less than text_length:
        Let found_delimiter be True
        For j from 0 to delimiter_length minus 1:
            If i plus j is greater than or equal to text_length or character_at with text as text and position as i plus j is not equal to character_at with text as delimiter and position as j:
                Set found_delimiter to False
                Break
        
        If found_delimiter:
            Add current to parts
            Set current to ""
            Set i to i plus delimiter_length
        Otherwise:
            Set current to current plus character_at with text as text and position as i
            Set i to i plus 1
    
    Add current to parts
    Return parts

Process called "join" that takes strings as List[String] and separator as String returns String:
    Note: Join strings with separator
    If length of strings is equal to 0:
        Return ""
    
    Let result be strings[0]
    For i from 1 to length of strings minus 1:
        Set result to result plus separator plus strings[i]
    Return result