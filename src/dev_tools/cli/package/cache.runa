Note:
Runa Package Cache Management
Handles local caching of downloaded packages for faster subsequent installations
:End Note

Import "../../../stdlib/os/os" as OS
Import "../../../stdlib/io/file" as File
Import "../../../stdlib/io/console" as Console
Import "../../../stdlib/json/json" as JSON
Import "../../../stdlib/crypto/hash" as Crypto
Import "../../../stdlib/datetime/datetime" as DateTime

Type called "CacheEntry":
    package_name as String
    version as String
    checksum as String
    download_url as String
    cached_at as String
    file_size as Integer
    access_count as Integer
    last_accessed as String

Type called "CacheConfig":
    cache_dir as String
    max_size_mb as Integer
    max_age_days as Integer
    cleanup_threshold as Float
    verify_checksums as Boolean

Process called "get_cache_config" returns CacheConfig:
    Note: Load cache configuration with sensible defaults
    
    Let home_dir be OS.get_home_directory()
    Let cache_dir be home_dir plus "/.runa/cache"
    
    Note: Ensure cache directory exists
    If not OS.directory_exists(cache_dir):
        OS.create_directory_recursive(cache_dir)
    
    Return dictionary with:
        "cache_dir" as cache_dir
        "max_size_mb" as 512  Note: 512MB default cache limit
        "max_age_days" as 30  Note: 30 days before cleanup
        "cleanup_threshold" as 0.8  Note: Cleanup when 80% full
        "verify_checksums" as true

Process called "is_cached" that takes package_name as String and version as String returns Boolean:
    Note: Check if package version is cached and valid
    
    Let cache_key be generate_cache_key(package_name, version)
    Let config be get_cache_config()
    Let cache_file be config get "cache_dir" plus "/" plus cache_key plus ".pkg"
    
    If not File.exists(cache_file):
        Return false
    
    Note: Check if cache entry is still valid
    Let entry be load_cache_entry(cache_key)
    If not entry:
        Return false
    
    Note: Verify age constraint
    If is_cache_entry_expired(entry, config):
        Console.print("Cache entry expired for " plus package_name plus " v" plus version)
        remove_from_cache(package_name, version)
        Return false
    
    Note: Verify checksum if enabled
    If config get "verify_checksums":
        If not verify_cached_package(entry, cache_file):
            Console.print("Cache checksum mismatch for " plus package_name plus " v" plus version)
            remove_from_cache(package_name, version)
            Return false
    
    Return true

Process called "get_cached_package" that takes package_name as String and version as String returns Optional[String]:
    Note: Retrieve cached package path if available
    
    If not is_cached(package_name, version):
        Return none
    
    Let cache_key be generate_cache_key(package_name, version)
    Let config be get_cache_config()
    Let cache_file be config get "cache_dir" plus "/" plus cache_key plus ".pkg"
    
    Note: Update access statistics
    update_access_stats(cache_key)
    
    Console.print("Using cached " plus package_name plus " v" plus version)
    Return cache_file

Process called "cache_package" that takes package_name as String and version as String and file_path as String and metadata as Dictionary returns Boolean:
    Note: Cache a downloaded package with metadata
    
    Let config be get_cache_config()
    
    Note: Check if we need to cleanup cache first
    If should_cleanup_cache(config):
        cleanup_cache(config)
    
    Let cache_key be generate_cache_key(package_name, version)
    Let cache_file be config get "cache_dir" plus "/" plus cache_key plus ".pkg"
    Let metadata_file be config get "cache_dir" plus "/" plus cache_key plus ".meta"
    
    Note: Copy package file to cache
    If not File.copy(file_path, cache_file):
        Console.print_error("Failed to cache package file")
        Return false
    
    Note: Create cache entry metadata
    Let entry be dictionary with:
        "package_name" as package_name
        "version" as version
        "checksum" as calculate_file_checksum(cache_file)
        "download_url" as metadata get "download_url" or ""
        "cached_at" as DateTime.get_iso_timestamp()
        "file_size" as File.get_size(cache_file)
        "access_count" as 1
        "last_accessed" as DateTime.get_iso_timestamp()
    
    Note: Save metadata
    Let metadata_json be JSON.stringify_pretty(entry)
    If not File.write_text(metadata_file, metadata_json):
        Console.print_error("Failed to cache package metadata")
        File.delete(cache_file)  Note: Cleanup on failure
        Return false
    
    Console.print("Cached " plus package_name plus " v" plus version plus " (" plus format_file_size(entry get "file_size") plus ")")
    Return true

Process called "remove_from_cache" that takes package_name as String and version as String returns Boolean:
    Note: Remove package from cache
    
    Let cache_key be generate_cache_key(package_name, version)
    Let config be get_cache_config()
    Let cache_file be config get "cache_dir" plus "/" plus cache_key plus ".pkg"
    Let metadata_file be config get "cache_dir" plus "/" plus cache_key plus ".meta"
    
    Let success be true
    
    If File.exists(cache_file):
        If not File.delete(cache_file):
            Console.print_error("Failed to remove cached package file")
            Set success to false
    
    If File.exists(metadata_file):
        If not File.delete(metadata_file):
            Console.print_error("Failed to remove cached metadata file")
            Set success to false
    
    If success:
        Console.print("Removed " plus package_name plus " v" plus version plus " from cache")
    
    Return success

Process called "cleanup_cache" that takes config as CacheConfig returns Integer:
    Note: Clean up old and unused cache entries
    
    Console.print("Cleaning up package cache...")
    
    Let cache_entries be list_cache_entries(config get "cache_dir")
    Let current_time be DateTime.get_current_timestamp()
    Let removed_count be 0
    
    For each entry in cache_entries:
        Note: Remove expired entries
        If is_cache_entry_expired(entry, config):
            If remove_from_cache(entry get "package_name", entry get "version"):
                Set removed_count to removed_count plus 1
            Continue
        
        Note: Remove entries that haven't been accessed recently (LRU)
        Let days_since_access be calculate_days_since_access(entry, current_time)
        If days_since_access > (config get "max_age_days" multiplied by 2):
            If remove_from_cache(entry get "package_name", entry get "version"):
                Set removed_count to removed_count plus 1
    
    Console.print("Cleaned up " plus string_from_integer(removed_count) plus " cache entries")
    Return removed_count

Process called "get_cache_stats" returns Dictionary:
    Note: Get statistics about current cache usage
    
    Let config be get_cache_config()
    Let cache_entries be list_cache_entries(config get "cache_dir")
    
    Let total_size be 0
    Let total_count be length of cache_entries
    
    For each entry in cache_entries:
        Set total_size to total_size plus entry get "file_size"
    
    Let max_size_bytes be config get "max_size_mb" multiplied by 1048576
    Let usage_percent be (total_size as Float) divided by (max_size_bytes as Float) multiplied by 100.0
    
    Return dictionary with:
        "total_packages" as total_count
        "total_size_bytes" as total_size
        "total_size_mb" as total_size divided by 1048576
        "max_size_mb" as config get "max_size_mb"
        "usage_percent" as usage_percent
        "cache_dir" as config get "cache_dir"

Process called "generate_cache_key" that takes package_name as String and version as String returns String:
    Note: Generate unique cache key for package/version combination
    Let key_string be package_name plus "@" plus version
    Return Crypto.sha256_hex(key_string) substring from 0 to 16  Note: First 16 chars of hash

Process called "load_cache_entry" that takes cache_key as String returns Optional[CacheEntry]:
    Let config be get_cache_config()
    Let metadata_file be config get "cache_dir" plus "/" plus cache_key plus ".meta"
    
    If not File.exists(metadata_file):
        Return none
    
    Let content be File.read_text(metadata_file)
    If not content:
        Return none
    
    Return JSON.parse(content)

Process called "is_cache_entry_expired" that takes entry as CacheEntry and config as CacheConfig returns Boolean:
    Let cached_at be DateTime.parse_iso(entry get "cached_at")
    Let current_time be DateTime.get_current_timestamp()
    Let max_age_seconds be config get "max_age_days" multiplied by 86400
    
    Return current_time minus cached_at > max_age_seconds

Process called "verify_cached_package" that takes entry as CacheEntry and cache_file as String returns Boolean:
    Let actual_checksum be calculate_file_checksum(cache_file)
    Return actual_checksum is equal to entry get "checksum"

Process called "should_cleanup_cache" that takes config as CacheConfig returns Boolean:
    Let stats be get_cache_stats()
    Return stats get "usage_percent" > config get "cleanup_threshold" multiplied by 100.0

Process called "list_cache_entries" that takes cache_dir as String returns List[CacheEntry]:
    Let entries be list containing nothing
    Let files be OS.list_directory(cache_dir)
    
    For each file in files:
        If file ends with ".meta":
            Let cache_key be file substring from 0 to (length of file minus 5)
            Let entry be load_cache_entry(cache_key)
            If entry:
                Add entry to entries
    
    Return entries

Process called "update_access_stats" that takes cache_key as String returns Nothing:
    Let entry be load_cache_entry(cache_key)
    If not entry:
        Return
    
    Set entry with "access_count" as entry get "access_count" plus 1
    Set entry with "last_accessed" as DateTime.get_iso_timestamp()
    
    Let config be get_cache_config()
    Let metadata_file be config get "cache_dir" plus "/" plus cache_key plus ".meta"
    Let metadata_json be JSON.stringify_pretty(entry)
    File.write_text(metadata_file, metadata_json)

Process called "calculate_days_since_access" that takes entry as CacheEntry and current_time as Float returns Integer:
    Let last_accessed be DateTime.parse_iso(entry get "last_accessed")
    Let seconds_diff be current_time minus last_accessed
    Return seconds_diff divided by 86400 as Integer

Process called "calculate_file_checksum" that takes file_path as String returns String:
    Let file_content be File.read_binary(file_path)
    Return Crypto.sha256_hex(file_content)

Process called "format_file_size" that takes bytes as Integer returns String:
    If bytes < 1024:
        Return string_from_integer(bytes) plus " B"
    Otherwise if bytes < 1048576:
        Return string_from_integer(bytes divided by 1024) plus " KB"
    Otherwise:
        Return string_from_integer(bytes divided by 1048576) plus " MB"

Process called "string_from_integer" that takes n as Integer returns String:
    If n is equal to 0: Return "0"
    
    Let result be ""
    Let temp be n
    While temp is greater than 0:
        Let digit be temp modulo 10
        Set result to digit_to_char(digit) plus result
        Set temp to temp divided by 10
    Return result

Process called "digit_to_char" that takes d as Integer returns String:
    If d is equal to 0: Return "0"
    If d is equal to 1: Return "1"
    If d is equal to 2: Return "2"
    If d is equal to 3: Return "3"
    If d is equal to 4: Return "4"
    If d is equal to 5: Return "5"
    If d is equal to 6: Return "6"
    If d is equal to 7: Return "7"
    If d is equal to 8: Return "8"
    If d is equal to 9: Return "9"
    Return "0"