Note:
compiler/frontend/lexical/keywords.runa
Language Keyword Recognition and Management

This module provides comprehensive keyword functionality including:
- Natural language keyword recognition ("Let", "Process called", etc.)
- Multi-word keyword detection and validation
- Context-sensitive keyword classification
- Keyword precedence and disambiguation
- Integration with lexer for token classification
- Performance optimized keyword matching
:End Note

Import "compiler/internal/collections" as Collections
Import "compiler/internal/primitives" as Primitives

Note: =====================================================================
Note: KEYWORD DEFINITIONS
Note: =====================================================================

@Reasoning
    We define all Runa keywords using the canonical natural language form.
    The lexer will recognize these and create appropriate tokens.
    Multi-word keywords are handled specially to avoid ambiguity.
@End Reasoning

Note: Core language keywords
Process called "get_all_keywords" returns Collections.Set:
    Let keywords be Collections.create_set()
    
    Note: Declaration keywords
    Collections.set_add(keywords, "Let")
    Collections.set_add(keywords, "Set")
    Collections.set_add(keywords, "Define")
    Collections.set_add(keywords, "Process")
    Collections.set_add(keywords, "Type")
    Collections.set_add(keywords, "Import")
    Collections.set_add(keywords, "Export")
    Collections.set_add(keywords, "External")
    Collections.set_add(keywords, "Primitive")
    Collections.set_add(keywords, "Constant")
    Collections.set_add(keywords, "Mutable")
    Collections.set_add(keywords, "Static")
    Collections.set_add(keywords, "Public")
    Collections.set_add(keywords, "Private")
    Collections.set_add(keywords, "Interface")
    Collections.set_add(keywords, "Implementation")
    Collections.set_add(keywords, "Enum")
    
    Note: Control flow keywords
    Collections.set_add(keywords, "If")
    Collections.set_add(keywords, "Otherwise")
    Collections.set_add(keywords, "Unless")
    Collections.set_add(keywords, "When")
    Collections.set_add(keywords, "Match")
    Collections.set_add(keywords, "For")
    Collections.set_add(keywords, "While")
    Collections.set_add(keywords, "Loop")
    Collections.set_add(keywords, "Break")
    Collections.set_add(keywords, "Continue")
    Collections.set_add(keywords, "Return")
    Collections.set_add(keywords, "Yield")
    
    Note: Exception handling keywords
    Collections.set_add(keywords, "Try")
    Collections.set_add(keywords, "Catch")
    Collections.set_add(keywords, "Finally")
    Collections.set_add(keywords, "Throw")
    Collections.set_add(keywords, "Assert")
    Collections.set_add(keywords, "Alert")
    
    Note: Async keywords
    Collections.set_add(keywords, "Async")
    Collections.set_add(keywords, "Await")
    Collections.set_add(keywords, "Send")
    Collections.set_add(keywords, "Receive")
    Collections.set_add(keywords, "Spawn")
    
    Note: Contextual keywords
    Collections.set_add(keywords, "called")
    Collections.set_add(keywords, "that")
    Collections.set_add(keywords, "takes")
    Collections.set_add(keywords, "returns")
    Collections.set_add(keywords, "as")
    Collections.set_add(keywords, "from")
    Collections.set_add(keywords, "to")
    Collections.set_add(keywords, "by")
    Collections.set_add(keywords, "in")
    Collections.set_add(keywords, "of")
    Collections.set_add(keywords, "with")
    Collections.set_add(keywords, "be")
    Collections.set_add(keywords, "is")
    Collections.set_add(keywords, "a")
    Collections.set_add(keywords, "value")
    Collections.set_add(keywords, "type")
    Collections.set_add(keywords, "are")
    Collections.set_add(keywords, "has")
    Collections.set_add(keywords, "have")
    
    Note: Boolean literals
    Collections.set_add(keywords, "True")
    Collections.set_add(keywords, "False")
    Collections.set_add(keywords, "None")
    Collections.set_add(keywords, "Null")
    Collections.set_add(keywords, "Nil")
    
    Note: End keywords
    Collections.set_add(keywords, "End")
    Collections.set_add(keywords, "Each")
    
    Note: Logical operators as keywords
    Collections.set_add(keywords, "And")
    Collections.set_add(keywords, "Or")
    Collections.set_add(keywords, "Not")
    
    Note: Arithmetic operators as keywords (canonical form)
    Collections.set_add(keywords, "plus")
    Collections.set_add(keywords, "minus")
    Collections.set_add(keywords, "multiplied")
    Collections.set_add(keywords, "divided")
    Collections.set_add(keywords, "modulo")
    Collections.set_add(keywords, "power")
    
    Note: Comparison operators as keywords (canonical form)
    Collections.set_add(keywords, "equal")
    Collections.set_add(keywords, "equals")
    Collections.set_add(keywords, "greater")
    Collections.set_add(keywords, "less")
    Collections.set_add(keywords, "than")
    Collections.set_add(keywords, "contains")
    
    Note: Action keywords
    Collections.set_add(keywords, "Display")
    Collections.set_add(keywords, "Delete")
    Collections.set_add(keywords, "New")
    
    Note: Protocol keywords
    Collections.set_add(keywords, "Protocol")
    Collections.set_add(keywords, "With")
    
    Note: Comment keywords
    Collections.set_add(keywords, "Note:")
    Collections.set_add(keywords, ":End")
    
    Return keywords
End Process

Note: =====================================================================
Note: MULTI-WORD KEYWORD DEFINITIONS
Note: =====================================================================

@Reasoning
    Multi-word keywords need special handling to avoid parsing ambiguity.
    We define them as patterns that the lexer can recognize.
@End Reasoning

Type called "MultiWordKeyword":
    pattern as Collections.List  Note: List of words that form the keyword
    token_type as String         Note: The token type to emit
End Type

Process called "get_multi_word_keywords" returns Collections.List:
    Let patterns be Collections.create_list()
    
    Note: Process declaration pattern
    Let process_called be MultiWordKeyword with
        pattern as create_word_list(["Process", "called"]),
        token_type as "PROCESS_CALLED"
    End MultiWordKeyword
    Collections.list_append(patterns, process_called)
    
    Note: Type declaration pattern
    Let type_called be MultiWordKeyword with
        pattern as create_word_list(["Type", "called"]),
        token_type as "TYPE_CALLED"
    End MultiWordKeyword
    Collections.list_append(patterns, type_called)
    
    Note: For Each loop pattern
    Let for_each be MultiWordKeyword with
        pattern as create_word_list(["For", "Each"]),
        token_type as "FOR_EACH"
    End MultiWordKeyword
    Collections.list_append(patterns, for_each)
    
    Note: End block patterns
    Let end_process be MultiWordKeyword with
        pattern as create_word_list(["End", "Process"]),
        token_type as "END_PROCESS"
    End MultiWordKeyword
    Collections.list_append(patterns, end_process)
    
    Let end_type be MultiWordKeyword with
        pattern as create_word_list(["End", "Type"]),
        token_type as "END_TYPE"
    End MultiWordKeyword
    Collections.list_append(patterns, end_type)
    
    Let end_if be MultiWordKeyword with
        pattern as create_word_list(["End", "If"]),
        token_type as "END_IF"
    End MultiWordKeyword
    Collections.list_append(patterns, end_if)
    
    Let end_while be MultiWordKeyword with
        pattern as create_word_list(["End", "While"]),
        token_type as "END_WHILE"
    End MultiWordKeyword
    Collections.list_append(patterns, end_while)
    
    Let end_for be MultiWordKeyword with
        pattern as create_word_list(["End", "For"]),
        token_type as "END_FOR"
    End MultiWordKeyword
    Collections.list_append(patterns, end_for)
    
    Let end_match be MultiWordKeyword with
        pattern as create_word_list(["End", "Match"]),
        token_type as "END_MATCH"
    End MultiWordKeyword
    Collections.list_append(patterns, end_match)
    
    Let end_note be MultiWordKeyword with
        pattern as create_word_list([":End", "Note"]),
        token_type as "END_NOTE"
    End MultiWordKeyword
    Collections.list_append(patterns, end_note)
    
    Note: Constructor patterns
    Let a_value_of_type be MultiWordKeyword with
        pattern as create_word_list(["a", "value", "of", "type"]),
        token_type as "A VALUE OF TYPE"
    End MultiWordKeyword
    Collections.list_append(patterns, a_value_of_type)
    
    Let of_type be MultiWordKeyword with
        pattern as create_word_list(["of", "type"]),
        token_type as "OF TYPE"
    End MultiWordKeyword
    Collections.list_append(patterns, of_type)
    
    Note: Comparison patterns
    Let is_equal_to be MultiWordKeyword with
        pattern as create_word_list(["is", "equal", "to"]),
        token_type as "IS_EQUAL_TO"
    End MultiWordKeyword
    Collections.list_append(patterns, is_equal_to)
    
    Let is_not_equal_to be MultiWordKeyword with
        pattern as create_word_list(["is", "not", "equal", "to"]),
        token_type as "IS_NOT_EQUAL_TO"
    End MultiWordKeyword
    Collections.list_append(patterns, is_not_equal_to)
    
    Let is_greater_than be MultiWordKeyword with
        pattern as create_word_list(["is", "greater", "than"]),
        token_type as "IS_GREATER_THAN"
    End MultiWordKeyword
    Collections.list_append(patterns, is_greater_than)
    
    Let is_less_than be MultiWordKeyword with
        pattern as create_word_list(["is", "less", "than"]),
        token_type as "IS_LESS_THAN"
    End MultiWordKeyword
    Collections.list_append(patterns, is_less_than)
    
    Let is_greater_than_or_equal_to be MultiWordKeyword with
        pattern as create_word_list(["is", "greater", "than", "or", "equal", "to"]),
        token_type as "IS_GREATER_THAN_OR_EQUAL_TO"
    End MultiWordKeyword
    Collections.list_append(patterns, is_greater_than_or_equal_to)
    
    Let is_less_than_or_equal_to be MultiWordKeyword with
        pattern as create_word_list(["is", "less", "than", "or", "equal", "to"]),
        token_type as "IS_LESS_THAN_OR_EQUAL_TO"
    End MultiWordKeyword
    Collections.list_append(patterns, is_less_than_or_equal_to)
    
    Note: Arithmetic patterns
    Let multiplied_by be MultiWordKeyword with
        pattern as create_word_list(["multiplied", "by"]),
        token_type as "MULTIPLIED_BY"
    End MultiWordKeyword
    Collections.list_append(patterns, multiplied_by)
    
    Let divided_by be MultiWordKeyword with
        pattern as create_word_list(["divided", "by"]),
        token_type as "DIVIDED_BY"
    End MultiWordKeyword
    Collections.list_append(patterns, divided_by)
    
    Return patterns
End Process

Process called "create_word_list" that takes words as Array[String] returns Collections.List:
    Let list be Collections.create_list()
    For Each word in words:
        Collections.list_append(list, word)
    End For
    Return list
End Process

Note: =====================================================================
Note: KEYWORD RECOGNITION
Note: =====================================================================

@Reasoning
    The main interface for checking if a word is a keyword.
    Used by the lexer during tokenization.
@End Reasoning

Note: Cache for performance
Let keyword_set be get_all_keywords()
Let multi_word_patterns be get_multi_word_keywords()

Process called "is_keyword" that takes word as String returns Boolean:
    Return Collections.set_contains(keyword_set, word)
End Process

Process called "is_reserved_word" that takes word as String returns Boolean:
    Note: Same as is_keyword but more explicit name
    Return is_keyword(word)
End Process

Process called "check_multi_word_keyword" that takes words as Collections.List returns String:
    Note: Check if a sequence of words forms a multi-word keyword
    
    For i from 0 to Collections.list_length(multi_word_patterns) minus 1:
        Let pattern_obj be Collections.list_get(multi_word_patterns, i)
        Let pattern be pattern_obj.pattern
        
        If Collections.list_length(words) is equal to Collections.list_length(pattern):
            Let matches be True
            
            For j from 0 to Collections.list_length(pattern) minus 1:
                Let expected_word be Collections.list_get(pattern, j)
                Let actual_word be Collections.list_get(words, j)
                
                If Not Primitives.string_equals(expected_word, actual_word):
                    Set matches to False
                    Break
                End If
            End For
            
            If matches:
                Return pattern_obj.token_type
            End If
        End If
    End For
    
    Return ""  Note: No match found
End Process

Note: =====================================================================
Note: KEYWORD CLASSIFICATION
Note: =====================================================================

@Reasoning
    Classify keywords by their role in the language.
    This helps the parser understand context.
@End Reasoning

Process called "classify_keyword" that takes keyword as String returns String:
    Note: Declaration keywords
    If keyword is equal to "Let" Or keyword is equal to "Set" Or keyword is equal to "Define":
        Return "DECLARATION"
    End If
    
    If keyword is equal to "Process" Or keyword is equal to "Type" Or keyword is equal to "External":
        Return "DEFINITION"
    End If
    
    If keyword is equal to "Import" Or keyword is equal to "Export":
        Return "MODULE"
    End If
    
    Note: Control flow keywords
    If keyword is equal to "If" Or keyword is equal to "Otherwise" Or keyword is equal to "Unless":
        Return "CONDITIONAL"
    End If
    
    If keyword is equal to "For" Or keyword is equal to "While" Or keyword is equal to "Loop":
        Return "LOOP"
    End If
    
    If keyword is equal to "Match" Or keyword is equal to "When":
        Return "PATTERN_MATCH"
    End If
    
    If keyword is equal to "Break" Or keyword is equal to "Continue" Or keyword is equal to "Return":
        Return "CONTROL_TRANSFER"
    End If
    
    Note: Exception keywords
    If keyword is equal to "Try" Or keyword is equal to "Catch" Or keyword is equal to "Finally":
        Return "EXCEPTION"
    End If
    
    If keyword is equal to "Throw" Or keyword is equal to "Assert" Or keyword is equal to "Alert":
        Return "ERROR_HANDLING"
    End If
    
    Note: Async keywords
    If keyword is equal to "Async" Or keyword is equal to "Await" Or keyword is equal to "Spawn":
        Return "ASYNC"
    End If
    
    Note: Contextual keywords
    If keyword is equal to "called" Or keyword is equal to "that" Or keyword is equal to "takes":
        Return "CONTEXTUAL"
    End If
    
    If keyword is equal to "as" Or keyword is equal to "from" Or keyword is equal to "to":
        Return "PREPOSITION"
    End If
    
    Note: Boolean literals
    If keyword is equal to "True" Or keyword is equal to "False" Or keyword is equal to "None":
        Return "LITERAL"
    End If
    
    Note: End keywords
    If keyword is equal to "End" Or keyword is equal to "Each":
        Return "TERMINATOR"
    End If
    
    Note: Operators as keywords
    If keyword is equal to "And" Or keyword is equal to "Or" Or keyword is equal to "Not":
        Return "LOGICAL_OPERATOR"
    End If
    
    If keyword is equal to "plus" Or keyword is equal to "minus" Or keyword is equal to "multiplied":
        Return "ARITHMETIC_OPERATOR"
    End If
    
    If keyword is equal to "equal" Or keyword is equal to "greater" Or keyword is equal to "less":
        Return "COMPARISON_OPERATOR"
    End If
    
    Return "UNKNOWN"
End Process

Note: =====================================================================
Note: KEYWORD PRECEDENCE
Note: =====================================================================

@Reasoning
    Some keywords have precedence in ambiguous contexts.
    This helps resolve parsing conflicts.
@End Reasoning

Process called "get_keyword_precedence" that takes keyword as String returns Integer:
    Note: Higher numbers mean higher precedence
    
    Note: Multi-word keywords have highest precedence
    If keyword is equal to "PROCESS_CALLED" Or keyword is equal to "TYPE_CALLED":
        Return 100
    End If
    
    If keyword is equal to "FOR_EACH":
        Return 90
    End If
    
    Note: End keywords have high precedence
    If Primitives.string_index_of(keyword, "END_") is equal to 0:
        Return 80
    End If
    
    Note: Declaration keywords
    If keyword is equal to "Process" Or keyword is equal to "Type":
        Return 70
    End If
    
    If keyword is equal to "Let" Or keyword is equal to "Set":
        Return 60
    End If
    
    Note: Control flow keywords
    If keyword is equal to "If" Or keyword is equal to "For" Or keyword is equal to "While":
        Return 50
    End If
    
    Note: Contextual keywords have lower precedence
    If keyword is equal to "called" Or keyword is equal to "that" Or keyword is equal to "takes":
        Return 30
    End If
    
    If keyword is equal to "as" Or keyword is equal to "from" Or keyword is equal to "to":
        Return 20
    End If
    
    Note: Default precedence
    Return 10
End Process

Note: =====================================================================
Note: ENCASING KEYWORD SUPPORT
Note: =====================================================================

@Reasoning
    Encasing keywords create natural variable name boundaries.
    "Let my variable be" - everything between Let/be is the identifier.
    "Set my variable to" - everything between Set/to is the identifier.
    These functions help the lexer identify encasing boundaries.
@End Reasoning

Process called "is_encasing_start" that takes keyword as String returns Boolean:
    Note: Keywords that start an encasing pattern
    Return keyword is equal to "Let" Or keyword is equal to "Set" Or 
           keyword is equal to "Define"
End Process

Process called "get_encasing_end" that takes start_keyword as String returns String:
    Note: Return the corresponding end keyword for an encasing pattern
    If start_keyword is equal to "Let":
        Return "be"
    End If
    
    If start_keyword is equal to "Set":
        Return "to"
    End If
    
    If start_keyword is equal to "Define":
        Return "as"
    End If
    
    Return ""  Note: No encasing end for this keyword
End Process

Process called "is_encasing_end" that takes keyword as String returns Boolean:
    Note: Keywords that can end an encasing pattern
    Return keyword is equal to "be" Or keyword is equal to "to" Or 
           keyword is equal to "as"
End Process

Process called "can_be_in_identifier" that takes word as String returns Boolean:
    Note: Check if a word can appear inside an encased identifier
    Note: Most words can, except encasing ends and certain keywords
    
    If is_encasing_end(word):
        Return False  Note: These always end the identifier
    End If
    
    Note: Some keywords should not be part of identifiers
    If word is equal to "Process" Or word is equal to "Type" Or 
       word is equal to "If" Or word is equal to "For" Or
       word is equal to "While" Or word is equal to "Return":
        Return False
    End If
    
    Return True  Note: Most words can be part of identifiers
End Process

Note: =====================================================================
Note: CANON/DEVELOPER MODE CONVERSION
Note: =====================================================================

@Reasoning
    Keywords remain consistent between Canon and Developer modes.
    Only operators and symbols differ between the two modes:
    - Canon mode: Natural language operators ("multiplied by", "is equal to")
    - Developer mode: Symbolic operators ("*", "==")
    Keywords like Public, Private, Process, Type stay the same in both modes.
@End Reasoning

Process called "get_canonical_form" that takes keyword as String, mode as String returns String:
    @Implementation
        Keywords are the same in both Canon and Developer modes.
        This function now just returns the keyword unchanged.
        Operator conversion is handled separately by the operators module.
    @End Implementation
    
    Note: Keywords don't change between modes
    Return keyword
End Process

Note: =====================================================================
Note: OPERATOR AND SYMBOL CONVERSION
Note: =====================================================================

@Reasoning
    Operators and symbols are what change between Canon and Developer modes.
    Canon uses natural language forms while Developer uses symbols.
@End Reasoning

Type called "OperatorMapping":
    canon_form as String                 Note: Natural language form
    developer_form as String              Note: Symbolic form
    operator_type as String               Note: Type of operator
End Type

Process called "get_operator_mappings" returns Collections.List:
    Let mappings be Collections.create_list()
    
    Note: Arithmetic operators
    Collections.list_append(mappings, OperatorMapping with
        canon_form as "plus",
        developer_form as "+",
        operator_type as "ARITHMETIC"
    End OperatorMapping)
    
    Collections.list_append(mappings, OperatorMapping with
        canon_form as "minus",
        developer_form as "-",
        operator_type as "ARITHMETIC"
    End OperatorMapping)
    
    Collections.list_append(mappings, OperatorMapping with
        canon_form as "multiplied by",
        developer_form as "*",
        operator_type as "ARITHMETIC"
    End OperatorMapping)
    
    Collections.list_append(mappings, OperatorMapping with
        canon_form as "divided by",
        developer_form as "/",
        operator_type as "ARITHMETIC"
    End OperatorMapping)
    
    Collections.list_append(mappings, OperatorMapping with
        canon_form as "modulo",
        developer_form as "%",
        operator_type as "ARITHMETIC"
    End OperatorMapping)
    
    Collections.list_append(mappings, OperatorMapping with
        canon_form as "to the power of",
        developer_form as "**",
        operator_type as "ARITHMETIC"
    End OperatorMapping)
    
    Note: Comparison operators
    Collections.list_append(mappings, OperatorMapping with
        canon_form as "is equal to",
        developer_form as "==",
        operator_type as "COMPARISON"
    End OperatorMapping)
    
    Collections.list_append(mappings, OperatorMapping with
        canon_form as "is not equal to",
        developer_form as "!=",
        operator_type as "COMPARISON"
    End OperatorMapping)
    
    Collections.list_append(mappings, OperatorMapping with
        canon_form as "is greater than",
        developer_form as ">",
        operator_type as "COMPARISON"
    End OperatorMapping)
    
    Collections.list_append(mappings, OperatorMapping with
        canon_form as "is less than",
        developer_form as "<",
        operator_type as "COMPARISON"
    End OperatorMapping)
    
    Collections.list_append(mappings, OperatorMapping with
        canon_form as "is greater than or equal to",
        developer_form as ">=",
        operator_type as "COMPARISON"
    End OperatorMapping)
    
    Collections.list_append(mappings, OperatorMapping with
        canon_form as "is less than or equal to",
        developer_form as "<=",
        operator_type as "COMPARISON"
    End OperatorMapping)
    
    Note: Logical operators (note: operators.runa uses "And" not "and")
    Collections.list_append(mappings, OperatorMapping with
        canon_form as "And",
        developer_form as "&&",
        operator_type as "LOGICAL"
    End OperatorMapping)
    
    Collections.list_append(mappings, OperatorMapping with
        canon_form as "Or",
        developer_form as "||",
        operator_type as "LOGICAL"
    End OperatorMapping)
    
    Collections.list_append(mappings, OperatorMapping with
        canon_form as "Not",
        developer_form as "!",
        operator_type as "LOGICAL"
    End OperatorMapping)
    
    Note: Bitwise operators
    Collections.list_append(mappings, OperatorMapping with
        canon_form as "bitwise and",
        developer_form as "&",
        operator_type as "BITWISE"
    End OperatorMapping)
    
    Collections.list_append(mappings, OperatorMapping with
        canon_form as "bitwise or",
        developer_form as "|",
        operator_type as "BITWISE"
    End OperatorMapping)
    
    Collections.list_append(mappings, OperatorMapping with
        canon_form as "bitwise xor",
        developer_form as "^",
        operator_type as "BITWISE"
    End OperatorMapping)
    
    Collections.list_append(mappings, OperatorMapping with
        canon_form as "bitwise not",
        developer_form as "~",
        operator_type as "BITWISE"
    End OperatorMapping)
    
    Collections.list_append(mappings, OperatorMapping with
        canon_form as "shifted left by",
        developer_form as "<<",
        operator_type as "BITWISE"
    End OperatorMapping)
    
    Collections.list_append(mappings, OperatorMapping with
        canon_form as "shifted right by",
        developer_form as ">>",
        operator_type as "BITWISE"
    End OperatorMapping)
    
    Note: Assignment operators
    Collections.list_append(mappings, OperatorMapping with
        canon_form as "equals",
        developer_form as "=",
        operator_type as "ASSIGNMENT"
    End OperatorMapping)
    
    Collections.list_append(mappings, OperatorMapping with
        canon_form as "gets increased by",
        developer_form as "+=",
        operator_type as "ASSIGNMENT"
    End OperatorMapping)
    
    Collections.list_append(mappings, OperatorMapping with
        canon_form as "gets decreased by",
        developer_form as "-=",
        operator_type as "ASSIGNMENT"
    End OperatorMapping)
    
    Collections.list_append(mappings, OperatorMapping with
        canon_form as "gets multiplied by",
        developer_form as "*=",
        operator_type as "ASSIGNMENT"
    End OperatorMapping)
    
    Collections.list_append(mappings, OperatorMapping with
        canon_form as "gets divided by",
        developer_form as "/=",
        operator_type as "ASSIGNMENT"
    End OperatorMapping)
    
    Note: Special operators
    Collections.list_append(mappings, OperatorMapping with
        canon_form as "joined with",
        developer_form as "++",
        operator_type as "STRING"
    End OperatorMapping)
    
    Collections.list_append(mappings, OperatorMapping with
        canon_form as "contains",
        developer_form as "in",
        operator_type as "MEMBERSHIP"
    End OperatorMapping)
    
    Return mappings
End Process

Note: Create lookup dictionaries for fast conversion
Process called "create_operator_lookup_tables" returns Collections.Dictionary:
    Let tables be Collections.create_dictionary()
    Let canon_to_dev be Collections.create_dictionary()
    Let dev_to_canon be Collections.create_dictionary()
    Let mappings be get_operator_mappings()
    
    For i from 0 to Collections.list_length(mappings) minus 1:
        Let mapping be Collections.list_get(mappings, i)
        Collections.dict_set(canon_to_dev, mapping.canon_form, mapping.developer_form)
        Collections.dict_set(dev_to_canon, mapping.developer_form, mapping.canon_form)
    End For
    
    Collections.dict_set(tables, "canon_to_dev", canon_to_dev)
    Collections.dict_set(tables, "dev_to_canon", dev_to_canon)
    
    Return tables
End Process

Note: Cache the lookup tables
Let operator_tables be create_operator_lookup_tables()

Process called "convert_operator" that takes operator as String, target_mode as String returns String:
    @Implementation
        Convert operators between Canon and Developer modes.
        Keywords remain unchanged.
    @End Implementation
    
    If Primitives.string_equals(target_mode, "developer"):
        Let canon_to_dev be Collections.dict_get(operator_tables, "canon_to_dev")
        If Collections.dict_contains(canon_to_dev, operator):
            Return Collections.dict_get(canon_to_dev, operator)
        End If
    Otherwise If Primitives.string_equals(target_mode, "canon"):
        Let dev_to_canon be Collections.dict_get(operator_tables, "dev_to_canon")
        If Collections.dict_contains(dev_to_canon, operator):
            Return Collections.dict_get(dev_to_canon, operator)
        End If
    End If
    
    Note: If not an operator, return unchanged
    Return operator
End Process

Process called "is_operator" that takes text as String returns Boolean:
    @Implementation
        Check if text is an operator in either Canon or Developer mode.
    @End Implementation
    
    Let canon_to_dev be Collections.dict_get(operator_tables, "canon_to_dev")
    Let dev_to_canon be Collections.dict_get(operator_tables, "dev_to_canon")
    
    Return Collections.dict_contains(canon_to_dev, text) Or
           Collections.dict_contains(dev_to_canon, text)
End Process

Note: =====================================================================
Note: UTILITY FUNCTIONS
Note: =====================================================================

Process called "get_keyword_count" returns Integer:
    Return Collections.set_size(keyword_set)
End Process

Process called "get_all_keywords_list" returns Collections.List:
    Return Collections.set_to_list(keyword_set)
End Process

Process called "is_contextual_keyword" that takes word as String returns Boolean:
    Note: These keywords only have meaning in specific contexts
    Return word is equal to "called" Or word is equal to "that" Or 
           word is equal to "takes" Or word is equal to "returns" Or
           word is equal to "as" Or word is equal to "from" Or
           word is equal to "to" Or word is equal to "by" Or
           word is equal to "in" Or word is equal to "of" Or
           word is equal to "with" Or word is equal to "be" Or
           word is equal to "is" Or word is equal to "are" Or
           word is equal to "has" Or word is equal to "have"
End Process