Note:
compiler/frontend/lexical/intentional_recovery/recovery_engine.runa
Intentional Recovery Engine - Core Coordinator

This module implements the revolutionary 3-stage intentional recovery system.
The system treats errors not as failures but as moments of ambiguity where
high-level intent needs to be reconciled with low-level code.

Stage 1: Traditional Syntactic Recovery
Stage 2: Semantic Context Analysis  
Stage 3: Generative Intervention (Future AI Integration)
:End Note

Import Module "compiler/internal/collections" as Collections
Import Module "compiler/internal/string_utils" as StringUtils
Import Module "compiler/frontend/diagnostics/errors" as Errors
Import Module "compiler/frontend/lexical/intentional_recovery/syntactic_recovery" as SyntacticRecovery
Import Module "compiler/frontend/lexical/intentional_recovery/semantic_analysis" as SemanticAnalysis
Import Module "compiler/frontend/lexical/intentional_recovery/error_context" as ErrorContext

Note: =====================================================================
Note: RECOVERY ENGINE DATA STRUCTURES
Note: =====================================================================

Type called "RecoveryEngine":
    error_contexts as Collections.List
    recovery_strategies as Collections.List
    confidence_threshold as Float
    max_recovery_attempts as Integer
    current_attempt as Integer
    symbol_table_ref as Optional[Any]
    partial_ast_ref as Optional[Any]
    annotation_context as Collections.Dictionary
End Type

Type called "RecoveryResult":
    success as Boolean
    confidence as Float
    stage_reached as Integer
    correction as Optional[String]
    explanation as Optional[String]
    alternatives as Collections.List
    error_context_package as Optional[ErrorContext.ErrorContextPackage]
End Type

Type called "RecoveryStrategy":
    name as String
    stage as Integer
    apply_function as Process
    confidence_calculator as Process
End Type

Note: =====================================================================
Note: ENGINE INITIALIZATION
Note: =====================================================================

Process called "create_recovery_engine" returns RecoveryEngine:
    @Reasoning
        Initialize the recovery engine with all three stages of recovery strategies.
        The engine will attempt recovery in stages, escalating only when necessary.
    @End Reasoning
    
    Let engine be RecoveryEngine with
        error_contexts as Collections.create_list(),
        recovery_strategies as initialize_recovery_strategies(),
        confidence_threshold as 0.75,
        max_recovery_attempts as 5,
        current_attempt as 0,
        symbol_table_ref as None,
        partial_ast_ref as None,
        annotation_context as Collections.create_dictionary()
    End RecoveryEngine
    
    Return engine
End Process

Process called "initialize_recovery_strategies" returns Collections.List:
    @Implementation
        Register all recovery strategies for the three stages.
        Stage 1: Traditional methods (typo correction, phrase-level recovery)
        Stage 2: Semantic context analysis (symbol table, AST, annotations)
        Stage 3: AI integration preparation (structured context packaging)
    @End Implementation
    
    Let strategies be Collections.create_list()
    
    Note: Stage 1 Strategies
    Collections.list_append(strategies, create_strategy("typo_correction", 1, 
        "attempt_typo_correction", "calculate_edit_distance_confidence"))
    Collections.list_append(strategies, create_strategy("phrase_recovery", 1,
        "attempt_phrase_recovery", "calculate_phrase_confidence"))
    Collections.list_append(strategies, create_strategy("panic_mode", 1,
        "attempt_panic_mode_recovery", "calculate_panic_confidence"))
    
    Note: Stage 2 Strategies  
    Collections.list_append(strategies, create_strategy("symbol_table_analysis", 2,
        "analyze_symbol_table_context", "calculate_symbol_confidence"))
    Collections.list_append(strategies, create_strategy("ast_context_analysis", 2,
        "analyze_ast_context", "calculate_ast_confidence"))
    Collections.list_append(strategies, create_strategy("annotation_intent_analysis", 2,
        "analyze_annotation_intent", "calculate_annotation_confidence"))
    
    Note: Stage 3 Preparation (Future AI Integration)
    Collections.list_append(strategies, create_strategy("context_packaging", 3,
        "package_error_context_for_ai", "calculate_package_completeness"))
    
    Return strategies
End Process

Note: =====================================================================
Note: MAIN RECOVERY PROCESS
Note: =====================================================================

Process called "attempt_recovery" that takes engine as RecoveryEngine, error as Errors.LexerError, context as Any returns RecoveryResult:
    @Reasoning
        This is the main entry point for intentional recovery.
        It attempts recovery in stages, starting with traditional methods
        and escalating to semantic analysis if needed.
    @End Reasoning
    
    Set engine.current_attempt to engine.current_attempt plus 1
    
    If engine.current_attempt is greater than engine.max_recovery_attempts:
        Return create_failure_result("Maximum recovery attempts exceeded")
    End If
    
    Note: Try Stage 1: Traditional Syntactic Recovery
    Let stage1_result be attempt_stage_recovery(engine, error, context, 1)
    If stage1_result.success and stage1_result.confidence is greater than engine.confidence_threshold:
        Return stage1_result
    End If
    
    Note: Escalate to Stage 2: Semantic Context Analysis
    Let stage2_result be attempt_stage_recovery(engine, error, context, 2)
    If stage2_result.success and stage2_result.confidence is greater than engine.confidence_threshold:
        Return stage2_result
    End If
    
    Note: Prepare for Stage 3: AI Integration (Future Enhancement)
    Let stage3_prep be prepare_for_ai_intervention(engine, error, context, stage2_result)
    
    Return stage3_prep
End Process

Process called "attempt_stage_recovery" that takes engine as RecoveryEngine, error as Errors.LexerError, context as Any, stage as Integer returns RecoveryResult:
    @Implementation
        Execute all recovery strategies for a given stage and return
        the best result based on confidence scoring.
    @End Implementation
    
    Let best_result be create_empty_result()
    Let stage_strategies be filter_strategies_by_stage(engine.recovery_strategies, stage)
    
    For Each strategy in stage_strategies:
        Let result be apply_recovery_strategy(engine, strategy, error, context)
        
        If result.confidence is greater than best_result.confidence:
            Set best_result to result
        End If
        
        Note: Early exit if high confidence
        If result.confidence is greater than 0.9:
            Return result
        End If
    End For
    
    Return best_result
End Process

Note: =====================================================================
Note: STAGE 1: TRADITIONAL RECOVERY METHODS
Note: =====================================================================

Process called "attempt_typo_correction" that takes engine as RecoveryEngine, error as Errors.LexerError, context as Any returns RecoveryResult:
    @Reasoning
        Use edit distance algorithms to detect and correct common typos.
        This is the most basic form of recovery.
    @End Reasoning
    
    Let error_token be extract_error_token(error)
    Let candidates be SyntacticRecovery.find_typo_candidates(error_token, context)
    
    If Collections.list_is_empty(candidates):
        Return create_failure_result("No typo candidates found")
    End If
    
    Let best_candidate be Collections.list_get(candidates, 0)
    Let confidence be calculate_edit_distance_confidence(error_token, best_candidate)
    
    Return RecoveryResult with
        success as True,
        confidence as confidence,
        stage_reached as 1,
        correction as best_candidate,
        explanation as string_concat("Did you mean '", best_candidate, "'?"),
        alternatives as candidates,
        error_context_package as None
    End RecoveryResult
End Process

Process called "attempt_phrase_recovery" that takes engine as RecoveryEngine, error as Errors.LexerError, context as Any returns RecoveryResult:
    @Implementation
        Attempt to recover by looking at phrase-level patterns
        and common statement structures.
    @End Implementation
    
    Let phrase_context be SyntacticRecovery.extract_phrase_context(error, context)
    Let recovery_point be SyntacticRecovery.find_recovery_point(phrase_context)
    
    If recovery_point is None:
        Return create_failure_result("No phrase recovery point found")
    End If
    
    Let correction be SyntacticRecovery.generate_phrase_correction(phrase_context, recovery_point)
    Let confidence be calculate_phrase_confidence(phrase_context, correction)
    
    Return RecoveryResult with
        success as True,
        confidence as confidence,
        stage_reached as 1,
        correction as correction,
        explanation as "Phrase-level recovery applied",
        alternatives as Collections.create_list(),
        error_context_package as None
    End RecoveryResult
End Process

Note: =====================================================================
Note: STAGE 2: SEMANTIC CONTEXT ANALYSIS
Note: =====================================================================

Process called "analyze_symbol_table_context" that takes engine as RecoveryEngine, error as Errors.LexerError, context as Any returns RecoveryResult:
    @Reasoning
        Use the symbol table to understand what variables and functions
        are in scope, enabling intelligent corrections based on context.
    @End Reasoning
    
    If engine.symbol_table_ref is None:
        Return create_failure_result("Symbol table not available")
    End If
    
    Let error_identifier be extract_error_identifier(error)
    Let scope_symbols be SemanticAnalysis.get_symbols_in_scope(engine.symbol_table_ref, error)
    Let similar_symbols be SemanticAnalysis.find_similar_symbols(error_identifier, scope_symbols)
    
    If Collections.list_is_empty(similar_symbols):
        Return create_failure_result("No similar symbols in scope")
    End If
    
    Let best_match be SemanticAnalysis.rank_symbol_matches(similar_symbols, error_identifier)
    Let confidence be calculate_symbol_confidence(error_identifier, best_match)
    
    Return RecoveryResult with
        success as True,
        confidence as confidence,
        stage_reached as 2,
        correction as best_match.name,
        explanation as generate_symbol_explanation(error_identifier, best_match),
        alternatives as similar_symbols,
        error_context_package as None
    End RecoveryResult
End Process

Process called "analyze_annotation_intent" that takes engine as RecoveryEngine, error as Errors.LexerError, context as Any returns RecoveryResult:
    @Reasoning
        This is Runa's superpower - using @Task and @Reasoning annotations
        to understand developer intent and provide intelligent corrections.
    @End Reasoning
    
    Let annotations be SemanticAnalysis.extract_relevant_annotations(context, error)
    
    If Collections.dict_is_empty(annotations):
        Return create_failure_result("No annotations found for context")
    End If
    
    Let task_intent be SemanticAnalysis.parse_task_annotation(annotations)
    Let reasoning_context be SemanticAnalysis.parse_reasoning_annotation(annotations)
    
    Let intent_mismatch be SemanticAnalysis.detect_intent_code_mismatch(
        task_intent, reasoning_context, error)
    
    If intent_mismatch is None:
        Return create_failure_result("No intent mismatch detected")
    End If
    
    Let correction be SemanticAnalysis.generate_intent_based_correction(
        intent_mismatch, error, context)
    
    Let confidence be calculate_annotation_confidence(intent_mismatch, correction)
    
    Return RecoveryResult with
        success as True,
        confidence as confidence,
        stage_reached as 2,
        correction as correction.code,
        explanation as generate_intent_explanation(intent_mismatch, correction),
        alternatives as correction.alternatives,
        error_context_package as None
    End RecoveryResult
End Process

Note: =====================================================================
Note: STAGE 3: AI INTEGRATION PREPARATION
Note: =====================================================================

Process called "prepare_for_ai_intervention" that takes engine as RecoveryEngine, error as Errors.LexerError, context as Any, previous_result as RecoveryResult returns RecoveryResult:
    @Reasoning
        Package the error context for potential AI intervention.
        This prepares a structured report that could be sent to
        an AI agent like Hermod for generative correction.
    @End Reasoning
    
    Let error_package be ErrorContext.create_error_context_package()
    
    Note: Add all relevant context
    ErrorContext.add_error_info(error_package, error)
    ErrorContext.add_symbol_table(error_package, engine.symbol_table_ref)
    ErrorContext.add_partial_ast(error_package, engine.partial_ast_ref)
    ErrorContext.add_annotations(error_package, engine.annotation_context)
    ErrorContext.add_previous_attempts(error_package, previous_result)
    
    Note: Add surrounding code context
    Let code_context be extract_surrounding_code(error, context, 5)
    ErrorContext.add_code_context(error_package, code_context)
    
    Note: Generate structured prompt for AI
    Let ai_prompt be generate_ai_prompt(error_package)
    ErrorContext.set_ai_prompt(error_package, ai_prompt)
    
    Return RecoveryResult with
        success as False,
        confidence as 0.0,
        stage_reached as 3,
        correction as None,
        explanation as "Error context prepared for AI intervention",
        alternatives as Collections.create_list(),
        error_context_package as error_package
    End RecoveryResult
End Process

Note: =====================================================================
Note: HELPER FUNCTIONS
Note: =====================================================================

Process called "calculate_edit_distance_confidence" that takes original as String, corrected as String returns Float:
    @Implementation
        Calculate confidence based on Levenshtein edit distance.
        Closer matches have higher confidence.
    @End Implementation
    
    Let distance be StringUtils.levenshtein_distance(original, corrected)
    Let max_length be max(string_length(original), string_length(corrected))
    
    If max_length equals 0:
        Return 0.0
    End If
    
    Let similarity be 1.0 minus (float_divide(float(distance), float(max_length)))
    
    Note: Apply confidence scaling
    If distance equals 1:
        Return similarity multiplied by 0.95
    Otherwise If distance equals 2:
        Return similarity multiplied by 0.85
    Otherwise If distance is greater than 2:
        Return similarity multiplied by 0.7
    Otherwise:
        Return similarity
    End If
End Process

Process called "generate_intent_explanation" that takes mismatch as Any, correction as Any returns String:
    @Implementation
        Generate a detailed explanation of why the correction was suggested
        based on the detected intent-code mismatch.
    @End Implementation
    
    Let explanation be string_concat(
        "Based on the @Task annotation stating '",
        mismatch.task_objective,
        "', the code appears to conflict with the stated intent. ")
    
    Set explanation to string_concat(explanation,
        "The implementation uses '", mismatch.actual_code,
        "' but the annotation suggests '", correction.suggested_code, "'.")
    
    Return explanation
End Process

Process called "generate_ai_prompt" that takes error_package as ErrorContext.ErrorContextPackage returns String:
    @Implementation
        Generate a structured prompt that could be sent to an AI agent
        for generative correction.
    @End Implementation
    
    Let prompt be "The following code has a syntax or semantic error. "
    Set prompt to string_concat(prompt, "Based on the context and stated intent, ")
    Set prompt to string_concat(prompt, "generate a corrected version of only the erroneous lines.\n\n")
    
    Set prompt to string_concat(prompt, "Error: ", error_package.error_message, "\n")
    Set prompt to string_concat(prompt, "Line: ", integer_to_string(error_package.error_line), "\n")
    
    If error_package.task_annotation is not None:
        Set prompt to string_concat(prompt, "Task Objective: ", error_package.task_annotation, "\n")
    End If
    
    If error_package.reasoning_annotation is not None:
        Set prompt to string_concat(prompt, "Developer Reasoning: ", error_package.reasoning_annotation, "\n")
    End If
    
    Set prompt to string_concat(prompt, "\nCode Context:\n", error_package.code_context)
    
    Return prompt
End Process

Process called "create_strategy" that takes name as String, stage as Integer, apply_func as String, confidence_func as String returns RecoveryStrategy:
    Return RecoveryStrategy with
        name as name,
        stage as stage,
        apply_function as apply_func,
        confidence_calculator as confidence_func
    End RecoveryStrategy
End Process

Process called "create_failure_result" that takes message as String returns RecoveryResult:
    Return RecoveryResult with
        success as False,
        confidence as 0.0,
        stage_reached as 0,
        correction as None,
        explanation as message,
        alternatives as Collections.create_list(),
        error_context_package as None
    End RecoveryResult
End Process

Process called "create_empty_result" returns RecoveryResult:
    Return RecoveryResult with
        success as False,
        confidence as 0.0,
        stage_reached as 0,
        correction as None,
        explanation as None,
        alternatives as Collections.create_list(),
        error_context_package as None
    End RecoveryResult
End Process