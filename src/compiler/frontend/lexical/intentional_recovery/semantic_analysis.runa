Note:
compiler/frontend/lexical/intentional_recovery/semantic_analysis.runa
Semantic Context Analysis - Stage 2 Detective Work

This module implements the "detective" stage of intentional recovery.
It analyzes symbol tables, partial AST, and AI annotations to understand
the developer's intent and provide intelligent corrections.
:End Note

Import Module "compiler/internal/collections" as Collections
Import Module "compiler/internal/string_utils" as StringUtils

Note: =====================================================================
Note: SEMANTIC ANALYSIS DATA STRUCTURES
Note: =====================================================================

Type called "Symbol":
    name as String
    type_name as String
    kind as String
    definition_line as Integer
    scope_level as Integer
    is_mutable as Boolean
    annotations as Collections.List
End Type

Type called "IntentMismatch":
    task_objective as String
    actual_code as String
    expected_pattern as String
    mismatch_type as String
    confidence as Float
End Type

Type called "IntentCorrection":
    code as String
    suggested_code as String
    explanation as String
    alternatives as Collections.List
    confidence as Float
End Type

Type called "AnnotationIntent":
    annotation_type as String
    content as String
    extracted_objectives as Collections.List
    extracted_constraints as Collections.List
    key_concepts as Collections.List
End Type

Note: =====================================================================
Note: SYMBOL TABLE ANALYSIS
Note: =====================================================================

Process called "get_symbols_in_scope" that takes symbol_table as Any, error as Any returns Collections.List:
    @Reasoning
        Extract all symbols that are visible at the error location.
        This includes local variables, function parameters, and global symbols.
    @End Reasoning
    
    Let symbols be Collections.create_list()
    Let error_line be error.line
    Let error_scope be determine_scope_at_line(symbol_table, error_line)
    
    Note: Collect symbols from current scope and parent scopes
    Let current_scope be error_scope
    While current_scope is not None:
        Let scope_symbols be extract_symbols_from_scope(symbol_table, current_scope)
        
        For Each symbol in scope_symbols:
            Note: Only include symbols defined before the error
            If symbol.definition_line is less than error_line:
                Collections.list_append(symbols, symbol)
            End If
        End For
        
        Set current_scope to get_parent_scope(symbol_table, current_scope)
    End While
    
    Return symbols
End Process

Process called "find_similar_symbols" that takes error_identifier as String, scope_symbols as Collections.List returns Collections.List:
    @Implementation
        Find symbols with names similar to the error identifier.
        Uses both edit distance and semantic similarity.
    @End Implementation
    
    Let similar be Collections.create_list()
    Let max_distance be calculate_similarity_threshold(string_length(error_identifier))
    
    For Each symbol in scope_symbols:
        Note: Check edit distance
        Let distance be StringUtils.levenshtein_distance(error_identifier, symbol.name)
        
        If distance is less than or equal to max_distance:
            Let similarity_info be Collections.create_dictionary()
            Collections.dict_set(similarity_info, "symbol", symbol)
            Collections.dict_set(similarity_info, "distance", distance)
            Collections.dict_set(similarity_info, "semantic_score", calculate_semantic_similarity(error_identifier, symbol))
            Collections.list_append(similar, similarity_info)
        End If
        
        Note: Also check for case-insensitive matches
        If string_equals(string_to_lower(error_identifier), string_to_lower(symbol.name)):
            If not already_in_list(similar, symbol):
                Let similarity_info be Collections.create_dictionary()
                Collections.dict_set(similarity_info, "symbol", symbol)
                Collections.dict_set(similarity_info, "distance", 0)
                Collections.dict_set(similarity_info, "semantic_score", 1.0)
                Collections.list_append(similar, similarity_info)
            End If
        End If
    End For
    
    Return similar
End Process

Process called "rank_symbol_matches" that takes similar_symbols as Collections.List, error_identifier as String returns Symbol:
    @Implementation
        Rank similar symbols by combining edit distance, semantic similarity,
        and usage context to find the best match.
    @End Implementation
    
    Let best_match be None
    Let best_score be 0.0
    
    For Each similarity_info in similar_symbols:
        Let symbol be Collections.dict_get(similarity_info, "symbol")
        Let distance be Collections.dict_get(similarity_info, "distance")
        Let semantic_score be Collections.dict_get(similarity_info, "semantic_score")
        
        Note: Calculate combined score
        Let distance_score be 1.0 minus (float_divide(float(distance), float(string_length(error_identifier))))
        Let combined_score be (distance_score multiplied by 0.6) plus (semantic_score multiplied by 0.4)
        
        Note: Boost score for exact case-insensitive matches
        If string_equals(string_to_lower(symbol.name), string_to_lower(error_identifier)):
            Set combined_score to combined_score plus 0.3
        End If
        
        Note: Boost score for recently used symbols
        If symbol.definition_line is greater than 0:
            Let recency_boost be 0.1 multiplied by (1.0 minus float_divide(float(abs(error.line minus symbol.definition_line)), 100.0))
            Set combined_score to combined_score plus recency_boost
        End If
        
        If combined_score is greater than best_score:
            Set best_score to combined_score
            Set best_match to symbol
        End If
    End For
    
    Return best_match
End Process

Note: =====================================================================
Note: AST CONTEXT ANALYSIS
Note: =====================================================================

Process called "analyze_ast_context" that takes engine as Any, error as Any, context as Any returns Any:
    @Reasoning
        Analyze the partial AST to understand the program structure
        around the error and suggest contextually appropriate corrections.
    @End Reasoning
    
    If engine.partial_ast_ref is None:
        Return create_ast_failure_result("Partial AST not available")
    End If
    
    Let ast_context be extract_ast_context_at_error(engine.partial_ast_ref, error)
    Let surrounding_nodes be get_surrounding_ast_nodes(ast_context, 3)
    
    Note: Analyze what the code was doing
    Let code_pattern be identify_code_pattern(surrounding_nodes)
    Let expected_next be predict_next_construct(code_pattern, ast_context)
    
    If expected_next is None:
        Return create_ast_failure_result("Cannot predict expected construct")
    End If
    
    Let correction be generate_ast_based_correction(expected_next, error, context)
    Let confidence be calculate_ast_confidence(code_pattern, correction)
    
    Return create_ast_success_result(correction, confidence)
End Process

Process called "identify_code_pattern" that takes ast_nodes as Collections.List returns String:
    @Implementation
        Identify the pattern of code being written based on AST nodes.
    @End Implementation
    
    If Collections.list_is_empty(ast_nodes):
        Return "unknown"
    End If
    
    Let last_node be Collections.list_get(ast_nodes, Collections.list_size(ast_nodes) minus 1)
    
    Note: Check for common patterns
    If node_is_type_definition(last_node):
        Return "type_definition"
    Otherwise If node_is_function_definition(last_node):
        Return "function_definition"
    Otherwise If node_is_loop(last_node):
        Return "loop_construct"
    Otherwise If node_is_conditional(last_node):
        Return "conditional_construct"
    Otherwise If node_is_list_operation(last_node):
        Return "list_manipulation"
    Otherwise:
        Return "general_statement"
    End If
End Process

Note: =====================================================================
Note: ANNOTATION INTENT ANALYSIS
Note: =====================================================================

Process called "extract_relevant_annotations" that takes context as Any, error as Any returns Collections.Dictionary:
    @Reasoning
        Extract annotations that are relevant to understanding the error.
        Look for @Task, @Reasoning, @Implementation annotations near the error.
    @End Reasoning
    
    Let annotations be Collections.create_dictionary()
    Let search_range be 20
    
    Note: Search for annotations before the error
    Let start_line be max(1, error.line minus search_range)
    Let end_line be error.line
    
    For line_num from start_line to end_line:
        Let line_content be get_line_content(context, line_num)
        
        If string_starts_with(string_trim(line_content), "@"):
            Let annotation be parse_annotation_block(context, line_num)
            If annotation is not None:
                Collections.dict_set(annotations, annotation.type, annotation.content)
            End If
        End If
    End For
    
    Return annotations
End Process

Process called "parse_task_annotation" that takes annotations as Collections.Dictionary returns AnnotationIntent:
    @Implementation
        Parse @Task annotation to extract objectives and constraints.
    @End Implementation
    
    If not Collections.dict_contains(annotations, "Task"):
        Return None
    End If
    
    Let task_content be Collections.dict_get(annotations, "Task")
    
    Let intent be AnnotationIntent with
        annotation_type as "Task",
        content as task_content,
        extracted_objectives as extract_objectives(task_content),
        extracted_constraints as extract_constraints(task_content),
        key_concepts as extract_key_concepts(task_content)
    End AnnotationIntent
    
    Return intent
End Process

Process called "parse_reasoning_annotation" that takes annotations as Collections.Dictionary returns AnnotationIntent:
    @Implementation
        Parse @Reasoning annotation to understand developer's thought process.
    @End Implementation
    
    If not Collections.dict_contains(annotations, "Reasoning"):
        Return None
    End If
    
    Let reasoning_content be Collections.dict_get(annotations, "Reasoning")
    
    Let intent be AnnotationIntent with
        annotation_type as "Reasoning",
        content as reasoning_content,
        extracted_objectives as extract_reasoning_goals(reasoning_content),
        extracted_constraints as extract_reasoning_constraints(reasoning_content),
        key_concepts as extract_reasoning_concepts(reasoning_content)
    End AnnotationIntent
    
    Return intent
End Process

Process called "detect_intent_code_mismatch" that takes task_intent as AnnotationIntent, reasoning_intent as AnnotationIntent, error as Any returns IntentMismatch:
    @Reasoning
        This is Runa's superpower - detecting when the code doesn't match
        the stated intent in annotations.
    @End Reasoning
    
    If task_intent is None and reasoning_intent is None:
        Return None
    End If
    
    Let mismatch be None
    
    Note: Check if error conflicts with task objectives
    If task_intent is not None:
        For Each objective in task_intent.extracted_objectives:
            Let conflict be check_objective_conflict(objective, error)
            If conflict is not None:
                Set mismatch to IntentMismatch with
                    task_objective as objective,
                    actual_code as error.token_text,
                    expected_pattern as conflict.expected_pattern,
                    mismatch_type as "task_objective_conflict",
                    confidence as conflict.confidence
                End IntentMismatch
                Break
            End If
        End For
    End If
    
    Note: Check if error violates stated constraints
    If mismatch is None and task_intent is not None:
        For Each constraint in task_intent.extracted_constraints:
            Let violation be check_constraint_violation(constraint, error)
            If violation is not None:
                Set mismatch to IntentMismatch with
                    task_objective as constraint,
                    actual_code as error.token_text,
                    expected_pattern as violation.expected_pattern,
                    mismatch_type as "constraint_violation",
                    confidence as violation.confidence
                End IntentMismatch
                Break
            End If
        End For
    End If
    
    Note: Check reasoning intent if no task mismatch found
    If mismatch is None and reasoning_intent is not None:
        Set mismatch to check_reasoning_mismatch(reasoning_intent, error)
    End If
    
    Return mismatch
End Process

Process called "generate_intent_based_correction" that takes mismatch as IntentMismatch, error as Any, context as Any returns IntentCorrection:
    @Implementation
        Generate a correction that aligns the code with the stated intent.
    @End Implementation
    
    Let correction be IntentCorrection with
        code as error.token_text,
        suggested_code as "",
        explanation as "",
        alternatives as Collections.create_list(),
        confidence as mismatch.confidence
    End IntentCorrection
    
    Match mismatch.mismatch_type:
        When "task_objective_conflict":
            Set correction.suggested_code to generate_objective_aligned_code(mismatch, context)
            Set correction.explanation to string_concat(
                "The code conflicts with the stated objective: '",
                mismatch.task_objective, "'. ")
            
        When "constraint_violation":
            Set correction.suggested_code to generate_constraint_compliant_code(mismatch, context)
            Set correction.explanation to string_concat(
                "The code violates the constraint: '",
                mismatch.task_objective, "'. ")
            
        When "reasoning_mismatch":
            Set correction.suggested_code to generate_reasoning_aligned_code(mismatch, context)
            Set correction.explanation to "The implementation doesn't match the stated reasoning. "
            
        Default:
            Set correction.suggested_code to mismatch.expected_pattern
            Set correction.explanation to "Generic intent mismatch detected. "
    End Match
    
    Note: Generate alternatives based on intent
    Let alternatives be generate_intent_alternatives(mismatch, context)
    Set correction.alternatives to alternatives
    
    Return correction
End Process

Note: =====================================================================
Note: HELPER FUNCTIONS
Note: =====================================================================

Process called "calculate_semantic_similarity" that takes identifier1 as String, symbol as Symbol returns Float:
    @Implementation
        Calculate semantic similarity between an identifier and a symbol.
        Consider naming patterns, type compatibility, and usage context.
    @End Implementation
    
    Let similarity be 0.0
    
    Note: Check for common prefixes/suffixes
    Let prefix_match be check_common_prefix(identifier1, symbol.name)
    Let suffix_match be check_common_suffix(identifier1, symbol.name)
    
    If prefix_match:
        Set similarity to similarity plus 0.3
    End If
    
    If suffix_match:
        Set similarity to similarity plus 0.3
    End If
    
    Note: Check for camelCase/snake_case variations
    If are_case_variations(identifier1, symbol.name):
        Set similarity to similarity plus 0.4
    End If
    
    Note: Check for abbreviation matches
    If is_abbreviation_of(identifier1, symbol.name) or is_abbreviation_of(symbol.name, identifier1):
        Set similarity to similarity plus 0.5
    End If
    
    Return min(similarity, 1.0)
End Process

Process called "extract_objectives" that takes content as String returns Collections.List:
    @Implementation
        Extract objectives from task annotation content.
        Look for patterns like "Objective:", "Goal:", "Purpose:", etc.
    @End Implementation
    
    Let objectives be Collections.create_list()
    Let lines be string_split(content, "\n")
    
    For Each line in lines:
        Let trimmed be string_trim(line)
        
        If string_contains_any(string_to_lower(trimmed), ["objective", "goal", "purpose", "task"]):
            Let objective be extract_objective_from_line(trimmed)
            If objective is not None:
                Collections.list_append(objectives, objective)
            End If
        End If
    End For
    
    Return objectives
End Process

Process called "check_objective_conflict" that takes objective as String, error as Any returns Any:
    @Implementation
        Check if the error conflicts with a stated objective.
    @End Implementation
    
    Note: Parse the objective for key actions
    Let key_actions be extract_key_actions(objective)
    
    For Each action in key_actions:
        If conflicts_with_action(error.token_text, action):
            Return create_conflict_info(action, determine_expected_for_action(action))
        End If
    End For
    
    Return None
End Process

Process called "generate_objective_aligned_code" that takes mismatch as IntentMismatch, context as Any returns String:
    @Implementation
        Generate code that aligns with the stated objective.
    @End Implementation
    
    Note: Extract key action from objective
    Let key_action be extract_primary_action(mismatch.task_objective)
    
    Match key_action:
        When "sort":
            Return generate_sort_code(mismatch, context)
        When "filter":
            Return generate_filter_code(mismatch, context)
        When "calculate":
            Return generate_calculation_code(mismatch, context)
        When "validate":
            Return generate_validation_code(mismatch, context)
        Default:
            Return mismatch.expected_pattern
    End Match
End Process

Process called "calculate_symbol_confidence" that takes error_identifier as String, best_match as Symbol returns Float:
    @Implementation
        Calculate confidence in a symbol-based correction.
    @End Implementation
    
    If best_match is None:
        Return 0.0
    End If
    
    Let distance be StringUtils.levenshtein_distance(error_identifier, best_match.name)
    Let max_length be max(string_length(error_identifier), string_length(best_match.name))
    
    Let base_confidence be 1.0 minus float_divide(float(distance), float(max_length))
    
    Note: Boost confidence for exact case-insensitive matches
    If string_equals(string_to_lower(error_identifier), string_to_lower(best_match.name)):
        Set base_confidence to min(base_confidence plus 0.2, 0.95)
    End If
    
    Note: Boost confidence if symbol is frequently used
    If best_match.kind equals "variable" or best_match.kind equals "function":
        Set base_confidence to min(base_confidence plus 0.1, 0.95)
    End If
    
    Return base_confidence
End Process

Process called "calculate_annotation_confidence" that takes mismatch as IntentMismatch, correction as IntentCorrection returns Float:
    @Implementation
        Calculate confidence in an annotation-based correction.
        Higher confidence when intent is clearly stated.
    @End Implementation
    
    Let base_confidence be mismatch.confidence
    
    Note: Boost confidence if correction directly addresses the mismatch
    If string_contains(correction.suggested_code, mismatch.expected_pattern):
        Set base_confidence to min(base_confidence plus 0.2, 0.95)
    End If
    
    Note: Very high confidence for exact pattern matches
    If string_equals(correction.suggested_code, mismatch.expected_pattern):
        Return 0.95
    End If
    
    Return base_confidence
End Process

Process called "generate_symbol_explanation" that takes error_identifier as String, best_match as Symbol returns String:
    @Implementation
        Generate an explanation for a symbol-based correction.
    @End Implementation
    
    Let explanation be string_concat("Did you mean '", best_match.name, "'?")
    
    Note: Add context about the symbol
    Set explanation to string_concat(explanation, " (", best_match.kind)
    
    If best_match.type_name is not None:
        Set explanation to string_concat(explanation, " of type ", best_match.type_name)
    End If
    
    Set explanation to string_concat(explanation, ", defined at line ", 
        integer_to_string(best_match.definition_line), ")")
    
    Return explanation
End Process

Process called "calculate_ast_confidence" that takes pattern as String, correction as Any returns Float:
    @Implementation
        Calculate confidence in an AST-based correction.
    @End Implementation
    
    Let base_confidence be 0.6
    
    Note: Higher confidence for well-known patterns
    Match pattern:
        When "type_definition":
            Set base_confidence to 0.8
        When "function_definition":
            Set base_confidence to 0.8
        When "loop_construct":
            Set base_confidence to 0.75
        When "conditional_construct":
            Set base_confidence to 0.75
        Default:
            Set base_confidence to 0.6
    End Match
    
    Return base_confidence
End Process

Process called "calculate_similarity_threshold" that takes length as Integer returns Integer:
    @Implementation
        Calculate the maximum edit distance for similarity matching.
    @End Implementation
    
    If length is less than or equal to 4:
        Return 1
    Otherwise If length is less than or equal to 8:
        Return 2
    Otherwise:
        Return 3
    End If
End Process