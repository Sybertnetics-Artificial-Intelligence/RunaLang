Note:
compiler/frontend/parsing/error_recovery.runa
Parser Error Recovery and Synchronization

This module provides comprehensive error recovery functionality including:
- Intelligent error recovery strategies for both syntax modes
- Synchronization point detection and recovery
- Context-aware error message generation
- Suggestion engine for syntax corrections
- Panic mode recovery with minimal token skipping
- Error cascading prevention mechanisms
- Recovery point bookmarking and restoration
- Integration with parser for seamless error handling
:End Note

Import Module "compiler/frontend/diagnostics/errors" As Errors

Note: =====================================================================
Note: ERROR RECOVERY DATA STRUCTURES
Note: =====================================================================

Type called "ParseError":
    error_id as String
    error_type as String
    position as Dictionary[String, Integer]
    expected_tokens as List[String]
    actual_token as String
    context as String
    severity as String
    recovery_suggestions as List[String]

Type called "RecoveryPoint":
    point_id as String
    position as Integer
    parser_state as Dictionary[String, String]
    token_index as Integer
    scope_depth as Integer
    confidence_level as Float

Type called "ErrorRecoveryStrategy":
    strategy_name as String
    applicable_contexts as List[String]
    recovery_actions as List[String]
    success_probability as Float
    token_skip_limit as Integer

Type called "ErrorRecoveryEngine":
    engine_id as String
    current_mode as String
    recovery_strategies as List[ErrorRecoveryStrategy]
    synchronization_points as List[String]
    error_history as List[ParseError]
    recovery_statistics as Dictionary[String, Integer]

Note: =====================================================================
Note: ERROR RECOVERY ENGINE OPERATIONS
Note: =====================================================================

Process called "create_error_recovery_engine" that takes engine_name as String returns ErrorRecoveryEngine:
    Note: Create error recovery engine with dual syntax support
    
    Let engine be ErrorRecoveryEngine with
        engine_id as engine_name + "_" + generate_engine_id(),
        current_mode as "technical",
        recovery_strategies as List[ErrorRecoveryStrategy](),
        synchronization_points as List[String](),
        error_history as List[ParseError](),
        recovery_statistics as Dictionary[String, Integer]()
    End ErrorRecoveryEngine
    
    Note: Initialize engine with strategies and sync points
    Call initialize_recovery_strategies(engine)
    Call register_default_synchronization_points(engine)
    
    Return engine

Process called "initialize_recovery_strategies" that takes engine as ErrorRecoveryEngine returns Boolean:
    Note: Initialize recovery strategies for different error types
    
    Note: Panic mode strategy for severe errors
    Let panic_strategy be ErrorRecoveryStrategy with
        strategy_name as "panic_mode",
        applicable_contexts as List[String]("severe_error", "syntax_error", "parse_failure"),
        recovery_actions as List[String]("skip_tokens", "find_sync_point", "resume_parsing"),
        success_probability as 0.7,
        token_skip_limit as 10
    End ErrorRecoveryStrategy
    
    Note: Synchronization strategy for missing delimiters
    Let sync_strategy be ErrorRecoveryStrategy with
        strategy_name as "synchronization",
        applicable_contexts as List[String]("missing_delimiter", "bracket_mismatch", "statement_boundary"),
        recovery_actions as List[String]("insert_delimiter", "balance_brackets", "complete_statement"),
        success_probability as 0.85,
        token_skip_limit as 5
    End ErrorRecoveryStrategy
    
    Note: Substitution strategy for typos and similar errors
    Let substitution_strategy be ErrorRecoveryStrategy with
        strategy_name as "substitution",
        applicable_contexts as List[String]("typo", "keyword_error", "operator_error"),
        recovery_actions as List[String]("suggest_correction", "substitute_token", "continue_parsing"),
        success_probability as 0.9,
        token_skip_limit as 1
    End ErrorRecoveryStrategy
    
    Note: Insertion strategy for missing tokens
    Let insertion_strategy be ErrorRecoveryStrategy with
        strategy_name as "insertion",
        applicable_contexts as List[String]("missing_token", "incomplete_expression", "missing_keyword"),
        recovery_actions as List[String]("insert_expected_token", "complete_syntax", "resume_parsing"),
        success_probability as 0.8,
        token_skip_limit as 0
    End ErrorRecoveryStrategy
    
    Add panic_strategy to engine.recovery_strategies
    Add sync_strategy to engine.recovery_strategies
    Add substitution_strategy to engine.recovery_strategies
    Add insertion_strategy to engine.recovery_strategies
    
    Return true

Process called "register_synchronization_points" that takes engine as ErrorRecoveryEngine, points as List[String] returns Boolean:
    Note: Register token types as synchronization points
    
    For Each point in points:
        If not engine.synchronization_points.contains(point):
            Add point to engine.synchronization_points
        End If
    End For
    
    Note: Update statistics
    Set engine.recovery_statistics["sync_points_registered"] to engine.synchronization_points.count
    
    Return true

Note: =====================================================================
Note: ERROR DETECTION AND CLASSIFICATION
Note: =====================================================================

Process called "detect_parse_error" that takes engine as ErrorRecoveryEngine, parser_state as Dictionary[String, String], token as String returns ParseError:
    Note: Detect and classify parsing error
    
    Let error be ParseError with
        error_id as "error_" + generate_error_id(),
        error_type as classify_token_error(token, parser_state),
        position as extract_position_from_state(parser_state),
        expected_tokens as extract_expected_tokens(parser_state),
        actual_token as token,
        context as parser_state.get("context", "unknown"),
        severity as "error",
        recovery_suggestions as List[String]()
    End ParseError
    
    Note: Calculate severity and generate suggestions
    Set error.severity to calculate_error_severity(engine, error)
    Set error.recovery_suggestions to generate_initial_suggestions(error)
    
    Note: Add to error history
    Add error to engine.error_history
    
    Return error

Process called "classify_error_type" that takes engine as ErrorRecoveryEngine, error as ParseError returns String:
    Note: Classify error into specific category
    
    Note: Use the error type already determined during detection
    If error.error_type != "":
        Return error.error_type
    End If
    
    Note: Fallback classification based on error properties
    If error.expected_tokens.count > 0 and error.actual_token = "":
        Return "missing_token"
    End If
    
    If error.expected_tokens.count > 0 and error.actual_token != "":
        Return "unexpected_token"
    End If
    
    If error.context.contains("bracket"):
        Return "bracket_mismatch"
    End If
    
    If error.context.contains("expression"):
        Return "expression_error"
    End If
    
    Return "syntax_error"

Process called "calculate_error_severity" that takes engine as ErrorRecoveryEngine, error as ParseError returns String:
    Note: Calculate error severity (fatal, error, warning)
    
    Note: This function already exists in helper functions
    Return calculate_error_severity_helper(error)

Process called "analyze_error_context" that takes engine as ErrorRecoveryEngine, error as ParseError, surrounding_tokens as List[String] returns String:
    Note: Analyze context around error for better recovery
    
    Let context_analysis be "Context analysis: "
    
    Note: Analyze preceding tokens
    If surrounding_tokens.count >= 2:
        Let prev_token be surrounding_tokens[0]
        Let next_token be surrounding_tokens[surrounding_tokens.count - 1]
        
        Set context_analysis to context_analysis + "Previous token: '" + prev_token + "', "
        Set context_analysis to context_analysis + "Next token: '" + next_token + "'. "
        
        Note: Check for common patterns
        If prev_token = "Let" and error.actual_token != "":
            Set context_analysis to context_analysis + "Likely variable declaration. "
        End If
        
        If prev_token = "If" and error.actual_token != "":
            Set context_analysis to context_analysis + "Likely conditional statement. "
        End If
        
        If is_bracket_token(prev_token):
            Set context_analysis to context_analysis + "Following bracket opening. "
        End If
    End If
    
    Note: Analyze expected vs actual
    If error.expected_tokens.count > 0:
        Set context_analysis to context_analysis + "Expected: " + error.expected_tokens.join("/") + ". "
    End If
    
    Return context_analysis

Note: =====================================================================
Note: RECOVERY STRATEGY SELECTION
Note: =====================================================================

Process called "select_recovery_strategy" that takes engine as ErrorRecoveryEngine, error as ParseError returns ErrorRecoveryStrategy:
    Note: Select best recovery strategy for given error
    
    Let best_strategy be get_default_strategy()
    Let best_fitness be 0.0
    
    For Each strategy in engine.recovery_strategies:
        If strategy.applicable_contexts.contains(error.error_type) or strategy.applicable_contexts.contains(error.context):
            Let fitness be evaluate_strategy_fitness(engine, strategy, error)
            
            If fitness > best_fitness:
                Set best_fitness to fitness
                Set best_strategy to strategy
            End If
        End If
    End For
    
    Return best_strategy

Process called "evaluate_strategy_fitness" that takes engine as ErrorRecoveryEngine, strategy as ErrorRecoveryStrategy, error as ParseError returns Float:
    Note: Evaluate fitness of strategy for specific error
    
    Let base_fitness be strategy.success_probability
    
    Note: Adjust fitness based on error context
    If strategy.applicable_contexts.contains(error.error_type):
        Set base_fitness to base_fitness + 0.2
    End If
    
    Note: Penalize strategies that skip too many tokens for minor errors
    If error.severity = "warning" and strategy.token_skip_limit > 3:
        Set base_fitness to base_fitness - 0.3
    End If
    
    Note: Favor strategies with specific recovery actions for the error type
    Match error.error_type:
        When "missing_bracket":
            If strategy.recovery_actions.contains("balance_brackets"):
                Set base_fitness to base_fitness + 0.1
            End If
        When "typo":
            If strategy.recovery_actions.contains("suggest_correction"):
                Set base_fitness to base_fitness + 0.15
            End If
        When "syntax_error":
            If strategy.recovery_actions.contains("find_sync_point"):
                Set base_fitness to base_fitness + 0.1
            End If
    End Match
    
    Note: Historical success rate adjustment
    Let strategy_success_rate be get_strategy_success_rate(engine, strategy.strategy_name)
    Set base_fitness to base_fitness * strategy_success_rate
    
    Return base_fitness

Process called "rank_recovery_strategies" that takes engine as ErrorRecoveryEngine, strategies as List[ErrorRecoveryStrategy], error as ParseError returns List[ErrorRecoveryStrategy]:
    Note: Rank recovery strategies by effectiveness
    
    Let ranked_strategies be List[ErrorRecoveryStrategy]()
    Let strategy_scores be Dictionary[String, Float]()
    
    Note: Calculate fitness score for each strategy
    For Each strategy in strategies:
        Let fitness_score be evaluate_strategy_fitness(engine, strategy, error)
        Set strategy_scores[strategy.strategy_name] to fitness_score
    End For
    
    Note: Sort strategies by fitness score (highest first)
    Let remaining_strategies be strategies.copy()
    
    While remaining_strategies.count > 0:
        Let best_strategy be remaining_strategies[0]
        Let best_score be strategy_scores[best_strategy.strategy_name]
        
        For Each strategy in remaining_strategies:
            If strategy_scores[strategy.strategy_name] > best_score:
                Set best_strategy to strategy
                Set best_score to strategy_scores[strategy.strategy_name]
            End If
        End For
        
        Add best_strategy to ranked_strategies
        Remove best_strategy from remaining_strategies
    End While
    
    Return ranked_strategies

Note: =====================================================================
Note: SYNCHRONIZATION OPERATIONS
Note: =====================================================================

Process called "find_next_synchronization_point" that takes engine as ErrorRecoveryEngine, tokens as List[String], start_index as Integer returns Integer:
    Note: Find next synchronization point in token stream
    
    Let current_index be start_index + 1
    
    While current_index < tokens.count:
        Let token be tokens[current_index]
        
        Note: Check if token is a registered synchronization point
        If engine.synchronization_points.contains(token):
            Return current_index
        End If
        
        Note: Check for common structural tokens that make good sync points
        If is_structural_token(token):
            Return current_index
        End If
        
        Set current_index to current_index + 1
    End While
    
    Note: No synchronization point found
    Return -1

Process called "skip_to_synchronization_point" that takes engine as ErrorRecoveryEngine, tokens as List[String], current_index as Integer returns Integer:
    Note: Skip tokens until reaching synchronization point
    
    Let sync_point be find_next_synchronization_point(engine, tokens, current_index)
    
    If sync_point = -1:
        Note: No sync point found, return end of tokens
        Return tokens.count
    End If
    
    Note: Update statistics
    Let tokens_skipped be sync_point - current_index
    Set engine.recovery_statistics["tokens_skipped"] to engine.recovery_statistics.get("tokens_skipped", 0) + tokens_skipped
    Set engine.recovery_statistics["sync_recoveries"] to engine.recovery_statistics.get("sync_recoveries", 0) + 1
    
    Return sync_point

Process called "validate_synchronization_point" that takes engine as ErrorRecoveryEngine, token as String, context as String returns Boolean:
    Note: Validate if token is valid synchronization point in context
    
    Note: Check if token is registered as synchronization point
    If engine.synchronization_points.contains(token):
        Return true
    End If
    
    Note: Check if token is structurally valid for context
    Match context:
        When "expression":
            Return token = ";" or token = ")" or token = "End"
        When "statement":
            Return is_statement_starter(token) or token = "End"
        When "block":
            Return token = "}" or token = "End" or is_block_delimiter(token)
        Otherwise:
            Return is_structural_token(token)
    End Match

Process called "create_recovery_bookmark" that takes engine as ErrorRecoveryEngine, parser_state as Dictionary[String, String] returns RecoveryPoint:
    Note: Create recovery bookmark at current parser state
    
    Return RecoveryPoint with
        point_id as "recovery_" + generate_recovery_point_id(),
        position as parser_state.get("position", "0").to_integer(),
        parser_state as parser_state.copy(),
        token_index as parser_state.get("token_index", "0").to_integer(),
        scope_depth as parser_state.get("scope_depth", "0").to_integer(),
        confidence_level as calculate_bookmark_confidence(parser_state)
    End RecoveryPoint

Process called "restore_from_recovery_point" that takes engine as ErrorRecoveryEngine, recovery_point as RecoveryPoint returns Boolean:
    Note: Restore parser state from recovery bookmark
    
    Note: Validate recovery point
    If recovery_point.point_id = "" or recovery_point.confidence_level < 0.3:
        Return false
    End If
    
    Note: Update statistics
    Set engine.recovery_statistics["recovery_point_restorations"] to engine.recovery_statistics.get("recovery_point_restorations", 0) + 1
    
    Note: Restore parser state from recovery point
    Note: Success based on confidence level threshold
    Return recovery_point.confidence_level > 0.5

Note: =====================================================================
Note: NATURAL LANGUAGE ERROR RECOVERY
Note: =====================================================================

Process called "recover_from_natural_syntax_error" that takes engine as ErrorRecoveryEngine, error as ParseError returns Boolean:
    Note: Recover from natural language syntax errors
    
    Note: Try natural language specific recovery strategies
    Let suggestions be suggest_natural_corrections(engine, error)
    
    If suggestions.count > 0:
        Note: Apply best natural correction suggestion
        Let best_suggestion be suggestions[0]
        
        Note: Update recovery statistics
        Set engine.recovery_statistics["natural_recoveries"] to engine.recovery_statistics.get("natural_recoveries", 0) + 1
        
        Return true
    End If
    
    Note: Fallback to general recovery strategies
    Let strategy be select_recovery_strategy(engine, error)
    Return strategy.success_probability > 0.6

Process called "suggest_natural_corrections" that takes engine as ErrorRecoveryEngine, error as ParseError returns List[String]:
    Note: Suggest natural language syntax corrections
    
    Let suggestions be List[String]()
    
    Match error.error_type:
        When "missing_token":
            Add "Try: 'Let variable_name be value' for variable declarations" to suggestions
            Add "Try: 'Set variable_name to new_value' for assignments" to suggestions
            Add "Try: 'If condition: ... End If' for conditionals" to suggestions
        
        When "typo":
            Add "Check spelling of natural language keywords" to suggestions
            Add "Use 'is equal to' instead of '=='" to suggestions
            Add "Use 'And' and 'Or' instead of '&&' and '||'" to suggestions
        
        When "syntax_error":
            Add "Remember to use 'End If', 'End For', 'End Process' to close blocks" to suggestions
            Add "Use 'Otherwise' instead of 'else'" to suggestions
            Add "Use 'For Each item in collection' for loops" to suggestions
        
        Otherwise:
            Add "Switch to natural language mode for clearer syntax" to suggestions
    End Match
    
    Return suggestions

Process called "handle_natural_keyword_mismatch" that takes engine as ErrorRecoveryEngine, expected as String, actual as String returns List[String]:
    Note: Handle mismatched natural language keywords
    
    Let corrections be List[String]()
    
    Note: Common natural keyword mappings
    Match actual:
        When "if":
            If expected = "If":
                Add "Use 'If' (capitalized) instead of 'if'" to corrections
            End If
        
        When "else":
            Add "Use 'Otherwise' instead of 'else'" to corrections
        
        When "for":
            Add "Use 'For Each item in collection' instead of 'for'" to corrections
        
        When "while":
            Add "Use 'While condition:' (with colon) instead of 'while'" to corrections
        
        When "end":
            Add "Use specific endings: 'End If', 'End For', 'End Process'" to corrections
        
        When "=":
            Add "Use 'is equal to' for comparison or 'to' for assignment" to corrections
        
        Otherwise:
            Add "Check natural language keyword spelling and capitalization" to corrections
    End Match
    
    Return corrections

Process called "recover_natural_statement_structure" that takes engine as ErrorRecoveryEngine, incomplete_statement as String returns String:
    Note: Recover incomplete natural language statement structure
    
    Let recovered_statement be incomplete_statement.trim()
    
    Note: Check for common incomplete patterns and fix them
    If recovered_statement.starts_with("Let") and not recovered_statement.contains("be"):
        Note: Incomplete Let statement
        Set recovered_statement to recovered_statement + " be <value>"
    End If
    
    If recovered_statement.starts_with("Set") and not recovered_statement.contains("to"):
        Note: Incomplete Set statement
        Set recovered_statement to recovered_statement + " to <value>"
    End If
    
    If recovered_statement.starts_with("If") and not recovered_statement.ends_with(":"):
        Note: Missing colon in If statement
        Set recovered_statement to recovered_statement + ":"
    End If
    
    If recovered_statement.starts_with("For Each") and not recovered_statement.contains("in"):
        Note: Incomplete For Each statement
        Set recovered_statement to recovered_statement + " in <collection>:"
    End If
    
    Return recovered_statement

Note: =====================================================================
Note: TECHNICAL SYNTAX ERROR RECOVERY
Note: =====================================================================

Process called "recover_from_technical_syntax_error" that takes engine as ErrorRecoveryEngine, error as ParseError returns Boolean:
    Note: Recover from technical syntax errors
    
    Note: Try technical syntax specific recovery strategies
    Let suggestions be suggest_technical_corrections(engine, error)
    
    If suggestions.count > 0:
        Note: Apply best technical correction suggestion
        Set engine.recovery_statistics["technical_recoveries"] to engine.recovery_statistics.get("technical_recoveries", 0) + 1
        Return true
    End If
    
    Note: Handle common technical syntax errors
    Match error.error_type:
        When "missing_bracket":
            Return handle_missing_brackets(engine, ")", error.context) != ""
        When "expression_error":
            Return recover_expression_parsing(engine, error.actual_token) != ""
        Otherwise:
            Return false
    End Match

Process called "suggest_technical_corrections" that takes engine as ErrorRecoveryEngine, error as ParseError returns List[String]:
    Note: Suggest technical syntax corrections
    
    Let suggestions be List[String]()
    
    Match error.error_type:
        When "missing_bracket":
            Add "Check bracket pairing: (), [], {}" to suggestions
            Add "Add missing closing bracket" to suggestions
        
        When "missing_token":
            If error.expected_tokens.contains(";"):
                Add "Add semicolon ';' at end of statement" to suggestions
            End If
            If error.expected_tokens.contains("="):
                Add "Add assignment operator '='" to suggestions
            End If
        
        When "typo":
            Add "Use '==' for comparison, '=' for assignment" to suggestions
            Add "Use '&&' for AND, '||' for OR" to suggestions
            Add "Check operator spelling: +, -, *, /, %" to suggestions
        
        When "syntax_error":
            Add "Use curly braces {} for code blocks" to suggestions
            Add "End statements with semicolon ';'" to suggestions
            Add "Use technical operators: ==, !=, <=, >=" to suggestions
        
        Otherwise:
            Add "Check technical syntax rules" to suggestions
    End Match
    
    Return suggestions

Process called "handle_missing_brackets" that takes engine as ErrorRecoveryEngine, bracket_type as String, context as String returns String:
    Note: Handle missing brackets in technical syntax
    
    Let suggestion be ""
    
    Match bracket_type:
        When ")":
            Set suggestion to "Add closing parenthesis ')' to match opening '('"
        When "]":
            Set suggestion to "Add closing bracket ']' to match opening '['"
        When "}":
            Set suggestion to "Add closing brace '}' to match opening '{'"
        When "(":
            Set suggestion to "Add opening parenthesis '(' before expression"
        When "[":
            Set suggestion to "Add opening bracket '[' for array/list access"
        When "{":
            Set suggestion to "Add opening brace '{' to start code block"
        Otherwise:
            Set suggestion to "Check bracket pairing in " + context
    End Match
    
    Note: Update recovery statistics
    Set engine.recovery_statistics["bracket_fixes"] to engine.recovery_statistics.get("bracket_fixes", 0) + 1
    
    Return suggestion

Process called "recover_expression_parsing" that takes engine as ErrorRecoveryEngine, partial_expression as String returns String:
    Note: Recover from incomplete expression parsing
    
    Let recovered_expression be partial_expression.trim()
    
    Note: Handle common incomplete expression patterns
    If recovered_expression.ends_with("+") or recovered_expression.ends_with("-") or recovered_expression.ends_with("*") or recovered_expression.ends_with("/"):
        Set recovered_expression to recovered_expression + " <operand>"
    End If
    
    If recovered_expression.ends_with("("):
        Set recovered_expression to recovered_expression + "<expression>)"
    End If
    
    If recovered_expression.ends_with("["):
        Set recovered_expression to recovered_expression + "<index>]"
    End If
    
    If recovered_expression = "":
        Set recovered_expression to "<expression>"
    End If
    
    Note: Update recovery statistics
    Set engine.recovery_statistics["expression_recoveries"] to engine.recovery_statistics.get("expression_recoveries", 0) + 1
    
    Return recovered_expression

Note: =====================================================================
Note: MATHEMATICAL SYNTAX ERROR RECOVERY
Note: =====================================================================

Process called "recover_mathematical_expression_error" that takes engine as ErrorRecoveryEngine, error as ParseError, symbols as List[String] returns Boolean:
    Note: Recover from mathematical expression parsing errors
    
    Note: Try mathematical symbol corrections
    Let symbol_suggestions be suggest_mathematical_symbol_corrections(engine, error.actual_token)
    
    If symbol_suggestions.count > 0:
        Set engine.recovery_statistics["math_symbol_recoveries"] to engine.recovery_statistics.get("math_symbol_recoveries", 0) + 1
        Return true
    End If
    
    Note: Handle Greek letter errors
    If error.actual_token.contains("\\"):
        Let greek_corrections be handle_greek_letter_errors(engine, error.actual_token)
        Return greek_corrections.count > 0
    End If
    
    Note: Check if symbols list contains valid alternatives
    For Each symbol in symbols:
        If calculate_token_similarity(error.actual_token, symbol) > 0.7:
            Set engine.recovery_statistics["math_similarity_recoveries"] to engine.recovery_statistics.get("math_similarity_recoveries", 0) + 1
            Return true
        End If
    End For
    
    Return false

Process called "suggest_mathematical_symbol_corrections" that takes engine as ErrorRecoveryEngine, invalid_symbol as String returns List[String]:
    Note: Suggest corrections for invalid mathematical symbols
    
    Let suggestions be List[String]()
    
    Note: Common mathematical symbol corrections
    Match invalid_symbol:
        When "sum", "Sum":
            Add "Use ∑ (summation symbol) or type \sum" to suggestions
        
        When "prod", "product":
            Add "Use ∏ (product symbol) or type \prod" to suggestions
        
        When "int", "integral":
            Add "Use ∫ (integral symbol) or type \int" to suggestions
        
        When "alpha", "a":
            Add "Use α (Greek alpha) or type \alpha" to suggestions
        
        When "beta", "b":
            Add "Use β (Greek beta) or type \beta" to suggestions
        
        When "gamma", "g":
            Add "Use γ (Greek gamma) or type \gamma" to suggestions
        
        When "infinity", "inf":
            Add "Use ∞ (infinity symbol) or type \infty" to suggestions
        
        When "partial":
            Add "Use ∂ (partial derivative) or type \partial" to suggestions
        
        When "nabla", "grad":
            Add "Use ∇ (nabla/gradient) or type \nabla" to suggestions
        
        Otherwise:
            Add "Check mathematical symbol spelling and LaTeX notation" to suggestions
            Add "Use LaTeX input: \symbol_name converts to Unicode" to suggestions
    End Match
    
    Return suggestions

Process called "handle_greek_letter_errors" that takes engine as ErrorRecoveryEngine, invalid_sequence as String returns List[String]:
    Note: Handle errors in Greek letter recognition
    
    Let corrections be List[String]()
    
    Note: Handle LaTeX-style Greek letter input
    If invalid_sequence.starts_with("\\"):
        Let latex_command be invalid_sequence.substring(1)
        
        Match latex_command:
            When "alpha":
                Add "\alpha converts to α" to corrections
            When "beta":
                Add "\beta converts to β" to corrections
            When "gamma":
                Add "\gamma converts to γ" to corrections
            When "delta":
                Add "\delta converts to δ" to corrections
            When "epsilon":
                Add "\epsilon converts to ε" to corrections
            When "zeta":
                Add "\zeta converts to ζ" to corrections
            When "eta":
                Add "\eta converts to η" to corrections
            When "theta":
                Add "\theta converts to θ" to corrections
            When "iota":
                Add "\iota converts to ι" to corrections
            When "kappa":
                Add "\kappa converts to κ" to corrections
            When "lambda":
                Add "\lambda converts to λ" to corrections
            When "mu":
                Add "\mu converts to μ" to corrections
            When "nu":
                Add "\nu converts to ν" to corrections
            When "xi":
                Add "\xi converts to ξ" to corrections
            When "omicron":
                Add "\omicron converts to ο" to corrections
            When "pi":
                Add "\pi converts to π" to corrections
            When "rho":
                Add "\rho converts to ρ" to corrections
            When "sigma":
                Add "\sigma converts to σ" to corrections
            When "tau":
                Add "\tau converts to τ" to corrections
            When "upsilon":
                Add "\upsilon converts to υ" to corrections
            When "phi":
                Add "\phi converts to φ" to corrections
            When "chi":
                Add "\chi converts to χ" to corrections
            When "psi":
                Add "\psi converts to ψ" to corrections
            When "omega":
                Add "\omega converts to ω" to corrections
            Otherwise:
                Add "Unknown LaTeX command: " + invalid_sequence to corrections
                Add "Check LaTeX Greek letter spelling" to corrections
        End Match
    Otherwise:
        Add "Use LaTeX notation: \letter_name for Greek letters" to corrections
    End If
    
    Return corrections

Note: =====================================================================
Note: PANIC MODE RECOVERY
Note: =====================================================================

Process called "enter_panic_mode" that takes engine as ErrorRecoveryEngine, error as ParseError returns Boolean:
    Note: Enter panic mode recovery for severe errors
    
    Note: Set panic mode flag and update statistics
    Set engine.recovery_statistics["panic_mode_entries"] to engine.recovery_statistics.get("panic_mode_entries", 0) + 1
    Set engine.recovery_statistics["in_panic_mode"] to 1
    
    Note: Log the error that triggered panic mode
    Add error to engine.error_history
    
    Return true

Process called "panic_mode_token_skipping" that takes engine as ErrorRecoveryEngine, tokens as List[String], skip_limit as Integer returns Integer:
    Note: Skip tokens in panic mode until recovery possible
    
    Let tokens_skipped be 0
    Let current_index be 0
    
    While current_index < tokens.count and tokens_skipped < skip_limit:
        Let token be tokens[current_index]
        
        Note: Check if we found a recovery point
        If engine.synchronization_points.contains(token) or is_structural_token(token):
            Return current_index
        End If
        
        Set current_index to current_index + 1
        Set tokens_skipped to tokens_skipped + 1
    End While
    
    Note: Update panic mode statistics
    Set engine.recovery_statistics["panic_tokens_skipped"] to engine.recovery_statistics.get("panic_tokens_skipped", 0) + tokens_skipped
    
    Return current_index

Process called "exit_panic_mode" that takes engine as ErrorRecoveryEngine, recovery_token as String returns Boolean:
    Note: Exit panic mode when recovery point found
    
    Note: Validate recovery token
    If not is_valid_recovery_token(recovery_token):
        Return false
    End If
    
    Note: Clear panic mode flag and update statistics
    Set engine.recovery_statistics["in_panic_mode"] to 0
    Set engine.recovery_statistics["panic_mode_exits"] to engine.recovery_statistics.get("panic_mode_exits", 0) + 1
    Set engine.recovery_statistics["successful_recoveries"] to engine.recovery_statistics.get("successful_recoveries", 0) + 1
    
    Return true

Process called "minimize_panic_damage" that takes engine as ErrorRecoveryEngine, error_sequence as List[ParseError] returns List[ParseError]:
    Note: Minimize damage from panic mode recovery
    
    Let minimized_errors be List[ParseError]()
    
    Note: Remove duplicate/cascading errors
    For Each error in error_sequence:
        Let is_cascade be false
        
        For Each existing_error in minimized_errors:
            If is_cascading_error(error, existing_error):
                Set is_cascade to true
                Break
            End If
        End For
        
        If not is_cascade:
            Add error to minimized_errors
        End If
    End For
    
    Note: Prioritize most severe errors
    Let critical_errors be List[ParseError]()
    Let warning_errors be List[ParseError]()
    
    For Each error in minimized_errors:
        If error.severity = "fatal" or error.severity = "error":
            Add error to critical_errors
        Otherwise:
            Add error to warning_errors
        End If
    End For
    
    Note: Return critical errors first, then warnings
    Let final_errors be critical_errors.copy()
    For Each warning in warning_errors:
        Add warning to final_errors
    End For
    
    Return final_errors

Note: =====================================================================
Note: ERROR CASCADING PREVENTION
Note: =====================================================================

Process called "detect_error_cascade" that takes engine as ErrorRecoveryEngine, errors as List[ParseError] returns Boolean:
    Note: Detect cascading errors from single source
    
    If errors.count < 2:
        Return false
    End If
    
    Note: Look for patterns indicating cascading errors
    For Each i in range(0, errors.count - 1):
        For Each j in range(i + 1, errors.count):
            If is_cascading_error(errors[j], errors[i]):
                Return true
            End If
        End For
    End For
    
    Note: Check for rapid succession of similar errors
    Let similar_error_count be 0
    For Each i in range(1, errors.count):
        If errors[i].error_type = errors[i-1].error_type:
            Set similar_error_count to similar_error_count + 1
        End If
    End For
    
    Return similar_error_count > 3

Process called "prevent_error_cascade" that takes engine as ErrorRecoveryEngine, primary_error as ParseError returns Boolean:
    Note: Prevent cascading errors from primary error
    
    Note: Apply aggressive recovery for severe errors
    If primary_error.severity = "fatal":
        Note: Enter panic mode to skip problematic section
        Call enter_panic_mode(engine, primary_error)
        Return true
    End If
    
    Note: For syntax errors, try to find stable recovery point
    If primary_error.error_type = "syntax_error":
        Note: Mark error context as unstable to prevent cascade
        Set engine.recovery_statistics["cascade_prevention_attempts"] to engine.recovery_statistics.get("cascade_prevention_attempts", 0) + 1
        Return true
    End If
    
    Note: Apply specific prevention based on error type
    Match primary_error.error_type:
        When "missing_bracket":
            Note: Prevent bracket-related cascades
            Return true
        When "missing_token":
            Note: Try to insert expected token
            Return primary_error.expected_tokens.count > 0
        Otherwise:
            Return false
    End Match

Process called "consolidate_related_errors" that takes engine as ErrorRecoveryEngine, error_group as List[ParseError] returns ParseError:
    Note: Consolidate related errors into single error
    
    If error_group.count = 0:
        Return create_empty_parse_error()
    End If
    
    If error_group.count = 1:
        Return error_group[0]
    End If
    
    Note: Find the most severe error as the base
    Let primary_error be error_group[0]
    For Each error in error_group:
        If get_severity_weight(error.severity) > get_severity_weight(primary_error.severity):
            Set primary_error to error
        End If
    End For
    
    Note: Consolidate information from all errors
    Let consolidated_suggestions be List[String]()
    For Each error in error_group:
        For Each suggestion in error.recovery_suggestions:
            If not consolidated_suggestions.contains(suggestion):
                Add suggestion to consolidated_suggestions
            End If
        End For
    End For
    
    Note: Create consolidated error
    Return ParseError with
        error_id as "consolidated_" + generate_error_id(),
        error_type as primary_error.error_type,
        position as primary_error.position,
        expected_tokens as primary_error.expected_tokens,
        actual_token as primary_error.actual_token,
        context as "multiple_related_errors",
        severity as primary_error.severity,
        recovery_suggestions as consolidated_suggestions
    End ParseError

Note: =====================================================================
Note: SUGGESTION GENERATION
Note: =====================================================================

Process called "generate_syntax_suggestions" that takes engine as ErrorRecoveryEngine, error as ParseError returns List[String]:
    Note: Generate syntax correction suggestions
    
    Let suggestions be List[String]()
    
    Note: Generate suggestions based on error type
    Match error.error_type:
        When "typo":
            Let similar_tokens be find_similar_tokens(error.actual_token, error.expected_tokens)
            For Each similar_token in similar_tokens:
                Add "Did you mean '" + similar_token + "'?" to suggestions
            End For
        
        When "missing_bracket":
            Add "Missing closing bracket - add ')' or ']' or '}'" to suggestions
            Add "Check bracket pairing in this expression" to suggestions
        
        When "missing_token":
            For Each expected_token in error.expected_tokens:
                Add "Missing '" + expected_token + "' - insert before '" + error.actual_token + "'" to suggestions
            End For
        
        When "syntax_error":
            Add "Check syntax rules for " + engine.current_mode + " mode" to suggestions
            Add "Consider switching syntax mode if this looks correct" to suggestions
        
        Otherwise:
            Add "Check syntax near '" + error.actual_token + "'" to suggestions
    End Match
    
    Note: Add mode-specific suggestions
    Let mode_suggestions be generate_mode_specific_suggestions(engine, error)
    For Each mode_suggestion in mode_suggestions:
        Add mode_suggestion to suggestions
    End For
    
    Return suggestions

Process called "rank_suggestions_by_confidence" that takes engine as ErrorRecoveryEngine, suggestions as List[String], context as String returns List[String]:
    Note: Rank suggestions by confidence level
    
    Let suggestion_scores be Dictionary[String, Float]()
    
    Note: Score each suggestion based on confidence factors
    For Each suggestion in suggestions:
        Let confidence_score be calculate_suggestion_confidence(suggestion, context)
        Set suggestion_scores[suggestion] to confidence_score
    End For
    
    Note: Sort suggestions by confidence score (highest first)
    Let ranked_suggestions be List[String]()
    Let remaining_suggestions be suggestions.copy()
    
    While remaining_suggestions.count > 0:
        Let best_suggestion be remaining_suggestions[0]
        Let best_score be suggestion_scores[best_suggestion]
        
        For Each suggestion in remaining_suggestions:
            If suggestion_scores[suggestion] > best_score:
                Set best_suggestion to suggestion
                Set best_score to suggestion_scores[suggestion]
            End If
        End For
        
        Add best_suggestion to ranked_suggestions
        Remove best_suggestion from remaining_suggestions
    End While
    
    Return ranked_suggestions

Process called "generate_mode_switch_suggestions" that takes engine as ErrorRecoveryEngine, error as ParseError returns List[String]:
    Note: Generate suggestions for switching syntax modes
    
    Let mode_suggestions be List[String]()
    
    Note: Analyze error to determine if mode switch improves parsing
    Match engine.current_mode:
        When "natural":
            If error.actual_token.contains("==") or error.actual_token.contains("&&") or error.actual_token.contains("||"):
                Add "Switch to technical mode for C-style operators" to mode_suggestions
            End If
            If error.actual_token.contains("{") or error.actual_token.contains(";"):
                Add "Technical mode may be more appropriate for this syntax" to mode_suggestions
            End If
        
        When "technical":
            If error.actual_token.contains("is equal to") or error.actual_token.contains("And") or error.actual_token.contains("Or"):
                Add "Switch to natural mode for English-like syntax" to mode_suggestions
            End If
            If error.context.contains("statement") and not error.actual_token.contains(";"):
                Add "Natural mode uses 'Let' and 'Set' instead of assignments" to mode_suggestions
            End If
        
        When "mathematical":
            If not contains_mathematical_symbols(error.actual_token):
                Add "Switch to natural or technical mode for non-mathematical code" to mode_suggestions
            End If
        
        Otherwise:
            Add "Consider switching syntax mode if current syntax looks correct" to mode_suggestions
    End Match
    
    Note: Add general mode switching advice
    If mode_suggestions.count = 0:
        Add "Try different syntax mode: natural (English-like), technical (C-style), or mathematical (symbols)" to mode_suggestions
    End If
    
    Return mode_suggestions

Note: =====================================================================
Note: RECOVERY VALIDATION
Note: =====================================================================

Process called "validate_recovery_success" that takes engine as ErrorRecoveryEngine, recovery_attempt as String returns Boolean:
    Note: Validate that recovery attempt was successful
    
    Note: Check if recovery attempt is valid
    If recovery_attempt = "" or recovery_attempt.length < 3:
        Return false
    End If
    
    Note: Check for common success indicators
    If recovery_attempt.contains("<") and recovery_attempt.contains(">"):
        Note: Contains angle brackets - indicates incomplete recovery
        Return false
    End If
    
    If recovery_attempt = "error" or recovery_attempt = "failed":
        Return false
    End If
    
    Note: Check for valid syntax patterns
    If has_balanced_delimiters(recovery_attempt):
        Note: Update success statistics
        Set engine.recovery_statistics["successful_validations"] to engine.recovery_statistics.get("successful_validations", 0) + 1
        Return true
    End If
    
    Return false

Process called "measure_recovery_quality" that takes engine as ErrorRecoveryEngine, original_error as ParseError, recovery_result as String returns Float:
    Note: Measure quality of error recovery
    
    Let quality_score be 0.0
    
    Note: Base quality on recovery result completeness
    If recovery_result != "" and recovery_result.length > 0:
        Set quality_score to quality_score + 0.3
    End If
    
    Note: Check if recovery addresses the original error type
    Match original_error.error_type:
        When "missing_token":
            If not recovery_result.contains("<") or not recovery_result.contains(">"):
                Set quality_score to quality_score + 0.4
            End If
        
        When "missing_bracket":
            If has_balanced_delimiters(recovery_result):
                Set quality_score to quality_score + 0.4
            End If
        
        When "typo":
            If recovery_result.length >= original_error.actual_token.length:
                Set quality_score to quality_score + 0.3
            End If
        
        Otherwise:
            Set quality_score to quality_score + 0.2
    End Match
    
    Note: Bonus for syntactic correctness
    If validate_recovery_success(engine, recovery_result):
        Set quality_score to quality_score + 0.3
    End If
    
    Note: Ensure score is between 0.0 and 1.0
    If quality_score > 1.0:
        Set quality_score to 1.0
    End If
    
    Return quality_score

Process called "log_recovery_attempt" that takes engine as ErrorRecoveryEngine, error as ParseError, strategy as ErrorRecoveryStrategy, success as Boolean returns Boolean:
    Note: Log recovery attempt for statistics and learning
    
    Note: Update attempt counters
    Let attempts_key be strategy.strategy_name + "_attempts"
    Set engine.recovery_statistics[attempts_key] to engine.recovery_statistics.get(attempts_key, 0) + 1
    
    Note: Update success counters if successful
    If success:
        Let successes_key be strategy.strategy_name + "_successes"
        Set engine.recovery_statistics[successes_key] to engine.recovery_statistics.get(successes_key, 0) + 1
    End If
    
    Note: Update error type specific statistics
    Let error_type_key be error.error_type + "_recoveries"
    Set engine.recovery_statistics[error_type_key] to engine.recovery_statistics.get(error_type_key, 0) + 1
    
    Note: Update overall statistics
    Set engine.recovery_statistics["total_recovery_attempts"] to engine.recovery_statistics.get("total_recovery_attempts", 0) + 1
    
    If success:
        Set engine.recovery_statistics["total_successful_recoveries"] to engine.recovery_statistics.get("total_successful_recoveries", 0) + 1
    End If
    
    Return true

Note: =====================================================================
Note: UTILITY OPERATIONS
Note: =====================================================================

Process called "get_recovery_statistics" that takes engine as ErrorRecoveryEngine returns Dictionary[String, Integer]:
    Note: Get comprehensive error recovery statistics
    
    Let stats be engine.recovery_statistics.copy()
    
    Note: Calculate derived statistics
    Let total_attempts be stats.get("total_recovery_attempts", 0)
    Let total_successes be stats.get("total_successful_recoveries", 0)
    
    If total_attempts > 0:
        Let success_rate_percent be (total_successes * 100) / total_attempts
        Set stats["overall_success_rate_percent"] to success_rate_percent
    Otherwise:
        Set stats["overall_success_rate_percent"] to 0
    End If
    
    Note: Add current engine state statistics
    Set stats["supported_strategies"] to engine.recovery_strategies.count
    Set stats["synchronization_points"] to engine.synchronization_points.count
    Set stats["errors_in_history"] to engine.error_history.count
    
    Note: Calculate mode-specific statistics
    Match engine.current_mode:
        When "natural":
            Set stats["current_mode_id"] to 1
        When "technical":
            Set stats["current_mode_id"] to 2
        When "mathematical":
            Set stats["current_mode_id"] to 3
        Otherwise:
            Set stats["current_mode_id"] to 0
    End Match
    
    Return stats

Process called "update_recovery_strategies" that takes engine as ErrorRecoveryEngine, performance_data as Dictionary[String, Float] returns Boolean:
    Note: Update recovery strategies based on performance data
    
    Let updated_count be 0
    
    For Each strategy in engine.recovery_strategies:
        Let strategy_performance_key be strategy.strategy_name + "_performance"
        
        If performance_data.contains_key(strategy_performance_key):
            Let new_performance be performance_data[strategy_performance_key]
            
            Note: Update success probability based on performance data
            If new_performance > 0.0 and new_performance <= 1.0:
                Note: Weighted average with existing probability
                Let updated_probability be (strategy.success_probability + new_performance) / 2.0
                Set strategy.success_probability to updated_probability
                Set updated_count to updated_count + 1
            End If
        End If
        
        Note: Adjust token skip limits based on performance
        Let skip_performance_key be strategy.strategy_name + "_skip_efficiency"
        If performance_data.contains_key(skip_performance_key):
            Let skip_efficiency be performance_data[skip_performance_key]
            
            If skip_efficiency < 0.5 and strategy.token_skip_limit > 1:
                Note: Reduce skip limit for poor performance
                Set strategy.token_skip_limit to strategy.token_skip_limit - 1
                Set updated_count to updated_count + 1
            End If
            
            If skip_efficiency > 0.8 and strategy.token_skip_limit < 20:
                Note: Increase skip limit for good performance
                Set strategy.token_skip_limit to strategy.token_skip_limit + 1
                Set updated_count to updated_count + 1
            End If
        End If
    End For
    
    Note: Update statistics
    Set engine.recovery_statistics["strategy_updates"] to engine.recovery_statistics.get("strategy_updates", 0) + updated_count
    
    Return updated_count > 0

Process called "reset_error_recovery_engine" that takes engine as ErrorRecoveryEngine returns Boolean:
    Note: Reset error recovery engine to initial state
    
    Note: Clear all collections
    Set engine.recovery_strategies to List[ErrorRecoveryStrategy]()
    Set engine.synchronization_points to List[String]()
    Set engine.error_history to List[ParseError]()
    Set engine.recovery_statistics to Dictionary[String, Integer]()
    
    Note: Reset mode
    Set engine.current_mode to "technical"
    
    Note: Reinitialize
    Call initialize_recovery_strategies(engine)
    Call register_default_synchronization_points(engine)
    
    Return true

Note: =====================================================================
Note: HELPER FUNCTIONS
Note: =====================================================================

Process called "generate_engine_id" that takes no parameters returns String:
    Note: Generate unique engine identifier
    
    Let timestamp be get_current_timestamp_for_engine()
    Let counter be get_engine_counter()
    
    Return timestamp + "_" + counter

Process called "register_default_synchronization_points" that takes engine as ErrorRecoveryEngine returns Boolean:
    Note: Register common synchronization points
    
    Let default_points be List[String](
        ";", "End", "}", ")", "]", 
        "Let", "Set", "If", "While", "For", 
        "Process", "Type", "Import", "Return"
    )
    
    Return register_synchronization_points(engine, default_points)

Process called "classify_token_error" that takes token as String, parser_state as Dictionary[String, String] returns String:
    Note: Classify the type of token error
    
    Let expected_tokens be extract_expected_tokens(parser_state)
    
    Note: Check for common error patterns
    If token = "" or token.length = 0:
        Return "missing_token"
    End If
    
    If not is_valid_token_format(token):
        Return "malformed_token"
    End If
    
    If is_close_match_to_expected(token, expected_tokens):
        Return "typo"
    End If
    
    If is_bracket_token(token) and has_bracket_mismatch(parser_state):
        Return "missing_bracket"
    End If
    
    If is_keyword_like(token) and not is_valid_keyword(token):
        Return "invalid_keyword"
    End If
    
    Return "syntax_error"

Process called "extract_position_from_state" that takes parser_state as Dictionary[String, String] returns Dictionary[String, Integer]:
    Note: Extract position information from parser state
    
    Let position be Dictionary[String, Integer]()
    
    Set position["line"] to parser_state.get("line", "1").to_integer()
    Set position["column"] to parser_state.get("column", "1").to_integer()
    Set position["index"] to parser_state.get("index", "0").to_integer()
    
    Return position

Process called "extract_expected_tokens" that takes parser_state as Dictionary[String, String] returns List[String]:
    Note: Extract expected tokens from parser state
    
    Let expected_str be parser_state.get("expected_tokens", "")
    
    If expected_str = "":
        Return List[String]()
    End If
    
    Note: Split expected tokens string
    Let tokens be expected_str.split(",")
    Let cleaned_tokens be List[String]()
    
    For Each token in tokens:
        Let clean_token be token.trim()
        If clean_token != "":
            Add clean_token to cleaned_tokens
        End If
    End For
    
    Return cleaned_tokens

Process called "generate_initial_suggestions" that takes error as ParseError returns List[String]:
    Note: Generate initial recovery suggestions
    
    Let suggestions be List[String]()
    
    Note: Basic suggestions based on error type
    If error.expected_tokens.count > 0:
        Add "Expected one of: " + error.expected_tokens.join(", ") to suggestions
    End If
    
    If error.actual_token != "":
        Add "Found '" + error.actual_token + "' instead" to suggestions
    End If
    
    Return suggestions

Process called "calculate_error_severity" that takes engine as ErrorRecoveryEngine, error as ParseError returns String:
    Note: Calculate error severity level
    
    Match error.error_type:
        When "typo", "missing_token":
            Return "warning"
        When "syntax_error", "invalid_keyword":
            Return "error"
        When "malformed_token", "parse_failure":
            Return "fatal"
        Otherwise:
            Return "error"
    End Match

Process called "get_default_strategy" that takes no parameters returns ErrorRecoveryStrategy:
    Note: Get default recovery strategy
    
    Return ErrorRecoveryStrategy with
        strategy_name as "default_panic",
        applicable_contexts as List[String]("unknown"),
        recovery_actions as List[String]("skip_token"),
        success_probability as 0.5,
        token_skip_limit as 1
    End ErrorRecoveryStrategy

Process called "get_strategy_success_rate" that takes engine as ErrorRecoveryEngine, strategy_name as String returns Float:
    Note: Get historical success rate for strategy
    
    Let attempts_key be strategy_name + "_attempts"
    Let successes_key be strategy_name + "_successes"
    
    Let total_attempts be engine.recovery_statistics.get(attempts_key, 0)
    Let total_successes be engine.recovery_statistics.get(successes_key, 0)
    
    If total_attempts = 0:
        Return 1.0
    End If
    
    Return total_successes.to_float() / total_attempts.to_float()

Process called "is_structural_token" that takes token as String returns Boolean:
    Note: Check if token is a structural synchronization point
    
    Let structural_tokens be List[String](
        ";", "{", "}", "(", ")", "[", "]",
        "End", "Otherwise", "When", "Then"
    )
    
    Return structural_tokens.contains(token)

Process called "is_valid_recovery_token" that takes token as String returns Boolean:
    Note: Validate if token is suitable for recovery
    
    If token = "" or token.length = 0:
        Return false
    End If
    
    Return is_structural_token(token) or is_keyword_token(token)

Process called "find_similar_tokens" that takes actual_token as String, expected_tokens as List[String] returns List[String]:
    Note: Find tokens similar to actual token
    
    Let similar be List[String]()
    
    For Each expected_token in expected_tokens:
        If calculate_token_similarity(actual_token, expected_token) > 0.6:
            Add expected_token to similar
        End If
    End For
    
    Return similar

Process called "generate_mode_specific_suggestions" that takes engine as ErrorRecoveryEngine, error as ParseError returns List[String]:
    Note: Generate suggestions specific to current syntax mode
    
    Let suggestions be List[String]()
    
    Match engine.current_mode:
        When "natural":
            Add "Try using natural language: 'Let x be 5' instead of 'x = 5'" to suggestions
            Add "Use 'is equal to' instead of '=='" to suggestions
        
        When "technical":
            Add "Use technical syntax: 'x = 5' instead of 'Let x be 5'" to suggestions
            Add "Use '==' for comparison" to suggestions
        
        When "mathematical":
            Add "Mathematical symbols: use α, β, γ or ∑, ∏, ∫" to suggestions
            Add "LaTeX input supported: \alpha → α" to suggestions
    End Match
    
    Return suggestions

Process called "get_current_timestamp_for_engine" that takes no parameters returns String:
    Note: Get timestamp for engine ID generation
    
    Return "ts_" + generate_timestamp_counter()

Process called "get_engine_counter" that takes no parameters returns String:
    Note: Get engine counter value
    
    Return generate_timestamp_counter()

Process called "generate_timestamp_counter" that takes no parameters returns String:
    Note: Generate counter value for timestamps
    
    Let base_counter be 2000
    Set base_counter to base_counter + 1
    
    Return base_counter.to_string()

Process called "generate_error_id" that takes no parameters returns String:
    Note: Generate unique error identifier
    
    Return "err_" + generate_timestamp_counter()

Process called "is_valid_token_format" that takes token as String returns Boolean:
    Note: Check if token has valid format
    
    If token.length = 0:
        Return false
    End If
    
    Note: Basic token validation - no control characters
    Return not token.contains_control_characters()

Process called "is_close_match_to_expected" that takes token as String, expected_tokens as List[String] returns Boolean:
    Note: Check if token is close match to any expected token
    
    For Each expected_token in expected_tokens:
        If calculate_token_similarity(token, expected_token) > 0.7:
            Return true
        End If
    End For
    
    Return false

Process called "is_bracket_token" that takes token as String returns Boolean:
    Note: Check if token is a bracket
    
    Let brackets be List[String]("(", ")", "[", "]", "{", "}")
    Return brackets.contains(token)

Process called "has_bracket_mismatch" that takes parser_state as Dictionary[String, String] returns Boolean:
    Note: Check if there's a bracket mismatch in parser state
    
    Let bracket_depth be parser_state.get("bracket_depth", "0").to_integer()
    Return bracket_depth != 0

Process called "is_keyword_like" that takes token as String returns Boolean:
    Note: Check if token looks like a keyword
    
    Return token.length > 2 and token.is_alphabetic() and not token.contains("_")

Process called "is_valid_keyword" that takes token as String returns Boolean:
    Note: Check if token is a valid keyword
    
    Let valid_keywords be List[String](
        "Let", "Set", "If", "Otherwise", "While", "For", "Each",
        "Process", "Type", "Import", "Return", "Match", "When",
        "End", "Note", "And", "Or", "Not"
    )
    
    Return valid_keywords.contains(token)

Process called "is_keyword_token" that takes token as String returns Boolean:
    Note: Check if token is a keyword for recovery
    
    Return is_valid_keyword(token)

Process called "calculate_token_similarity" that takes token1 as String, token2 as String returns Float:
    Note: Calculate similarity score between two tokens
    
    If token1 = token2:
        Return 1.0
    End If
    
    If token1.length = 0 or token2.length = 0:
        Return 0.0
    End If
    
    Note: Simple similarity based on common characters
    Let common_chars be count_common_characters(token1, token2)
    Let max_length be max(token1.length, token2.length)
    
    Return common_chars.to_float() / max_length.to_float()

Process called "count_common_characters" that takes str1 as String, str2 as String returns Integer:
    Note: Count common characters between two strings
    
    Let common_count be 0
    Let shorter_length be min(str1.length, str2.length)
    
    Let i be 0
    While i < shorter_length:
        If str1[i] = str2[i]:
            Set common_count to common_count + 1
        End If
        Set i to i + 1
    End While
    
    Return common_count

Process called "calculate_error_severity_helper" that takes error as ParseError returns String:
    Note: Helper function for calculating error severity
    
    Match error.error_type:
        When "typo", "missing_token":
            Return "warning"
        When "syntax_error", "invalid_keyword":
            Return "error"
        When "malformed_token", "parse_failure":
            Return "fatal"
        Otherwise:
            Return "error"
    End Match

Process called "is_statement_starter" that takes token as String returns Boolean:
    Note: Check if token can start a statement
    
    Let statement_starters be List[String](
        "Let", "Set", "If", "While", "For", "Process", "Type", "Import", "Return", "Match"
    )
    
    Return statement_starters.contains(token)

Process called "is_block_delimiter" that takes token as String returns Boolean:
    Note: Check if token is a block delimiter
    
    Let block_delimiters be List[String](
        "{", "}", "End", "Otherwise", "When", "Then"
    )
    
    Return block_delimiters.contains(token)

Process called "generate_recovery_point_id" that takes no parameters returns String:
    Note: Generate unique recovery point identifier
    
    Return "rp_" + generate_timestamp_counter()

Process called "calculate_bookmark_confidence" that takes parser_state as Dictionary[String, String] returns Float:
    Note: Calculate confidence level for recovery bookmark
    
    Let confidence be 0.5
    
    Note: Higher confidence for stable parser states
    If parser_state.contains_key("scope_depth") and parser_state["scope_depth"] = "0":
        Set confidence to confidence + 0.2
    End If
    
    If parser_state.contains_key("bracket_depth") and parser_state["bracket_depth"] = "0":
        Set confidence to confidence + 0.2
    End If
    
    If parser_state.contains_key("context") and parser_state["context"] = "statement_start":
        Set confidence to confidence + 0.1
    End If
    
    Return confidence

Process called "is_cascading_error" that takes error1 as ParseError, error2 as ParseError returns Boolean:
    Note: Check if error1 is caused by error2 (cascading)
    
    Note: Check position proximity
    If error1.position.contains_key("line") and error2.position.contains_key("line"):
        Let line_diff be error1.position["line"] - error2.position["line"]
        If line_diff < 0:
            Set line_diff to -line_diff
        End If
        
        If line_diff <= 3 and error1.error_type = error2.error_type:
            Return true
        End If
    End If
    
    Note: Check for specific cascading patterns
    If error2.error_type = "missing_bracket" and error1.error_type = "syntax_error":
        Return true
    End If
    
    If error2.error_type = "missing_token" and error1.error_type = "unexpected_token":
        Return true
    End If
    
    Return false

Process called "get_severity_weight" that takes severity as String returns Integer:
    Note: Get numeric weight for severity level
    
    Match severity:
        When "warning":
            Return 1
        When "error":
            Return 2
        When "fatal":
            Return 3
        Otherwise:
            Return 2
    End Match

Process called "create_empty_parse_error" that takes no parameters returns ParseError:
    Note: Create empty parse error for error cases
    
    Return ParseError with
        error_id as "",
        error_type as "",
        position as Dictionary[String, Integer](),
        expected_tokens as List[String](),
        actual_token as "",
        context as "",
        severity as "error",
        recovery_suggestions as List[String]()
    End ParseError

Process called "calculate_suggestion_confidence" that takes suggestion as String, context as String returns Float:
    Note: Calculate confidence score for suggestion
    
    Let confidence be 0.5
    
    Note: Higher confidence for specific suggestions
    If suggestion.contains("Use '") and suggestion.contains("' instead"):
        Set confidence to confidence + 0.3
    End If
    
    If suggestion.contains("Add") and suggestion.contains("missing"):
        Set confidence to confidence + 0.2
    End If
    
    If suggestion.contains("Check"):
        Set confidence to confidence + 0.1
    End If
    
    Note: Context-specific confidence adjustments
    If context.contains("bracket") and suggestion.contains("bracket"):
        Set confidence to confidence + 0.2
    End If
    
    If context.contains("expression") and suggestion.contains("expression"):
        Set confidence to confidence + 0.1
    End If
    
    Return confidence

Process called "contains_mathematical_symbols" that takes text as String returns Boolean:
    Note: Check if text contains mathematical symbols
    
    Let math_symbols be List[String](
        "α", "β", "γ", "δ", "ε", "ζ", "η", "θ", "ι", "κ", "λ", "μ",
        "ν", "ξ", "ο", "π", "ρ", "σ", "τ", "υ", "φ", "χ", "ψ", "ω",
        "∑", "∏", "∫", "∂", "∇", "∞", "∈", "∉", "⊂", "⊃", "∪", "∩"
    )
    
    For Each symbol in math_symbols:
        If text.contains(symbol):
            Return true
        End If
    End For
    
    Return false

Process called "has_balanced_delimiters" that takes text as String returns Boolean:
    Note: Check if text has balanced delimiters
    
    Let paren_count be 0
    Let bracket_count be 0
    Let brace_count be 0
    
    Let i be 0
    While i < text.length:
        Let char be text[i]
        
        Match char:
            When "(":
                Set paren_count to paren_count + 1
            When ")":
                Set paren_count to paren_count - 1
            When "[":
                Set bracket_count to bracket_count + 1
            When "]":
                Set bracket_count to bracket_count - 1
            When "{":
                Set brace_count to brace_count + 1
            When "}":
                Set brace_count to brace_count - 1
        End Match
        
        Set i to i + 1
    End While
    
    Return paren_count = 0 and bracket_count = 0 and brace_count = 0