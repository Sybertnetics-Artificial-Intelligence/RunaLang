Note:
compiler/frontend/semantic/semantic_analyzer.runa
Semantic Analysis Orchestrator

This module coordinates all semantic analysis phases including:
- Symbol table construction and management
- Scope analysis and variable lifetime tracking
- Type checking and inference
- Generic resolution and instantiation
- Trait checking and resolution
- Borrow checking and memory safety

@Reasoning
    The semantic analyzer orchestrates all semantic analysis phases in the correct
    order, managing dependencies between phases and aggregating results. It uses
    existing functions from each semantic module rather than creating duplicates.
@End Reasoning

@Implementation
    - Uses actual existing functions from semantic modules
    - Orchestrates analysis phases in dependency order
    - Aggregates errors and warnings from all phases
    - Provides unified semantic analysis interface
@End Implementation
:End Note

Import "symbol_table" as SymbolTable
Import "scope_analyzer" as ScopeAnalyzer
Import "type_checker" as TypeChecker
Import "generic_resolver" as GenericResolver
Import "trait_resolver" as TraitResolver
Import "borrow_checker" as BorrowChecker
Import "../parsing/ast" as AST
Import "../diagnostics/diagnostic_engine" as Diagnostics
Import "../diagnostics/errors" as Errors
Import "../primitives/core/string_primitive" as StringPrimitive

Note: =====================================================================
Note: SEMANTIC ANALYSIS DATA STRUCTURES
Note: =====================================================================

Type called "SemanticContext":
    symbol_table as SymbolTable.SymbolTable
    scope_analyzer as ScopeAnalyzer.ScopeAnalyzer
    type_checker as TypeChecker.TypeChecker
    generic_resolver as GenericResolver.GenericResolver
    trait_resolver as TraitResolver.TraitResolver
    borrow_checker as BorrowChecker.BorrowChecker
    diagnostic_engine as Diagnostics.DiagnosticEngine
    ast_builder as AST.ASTBuilder
    current_mode as String
End Type

Type called "SemanticResult":
    success as Boolean
    symbol_table as SymbolTable.SymbolTable
    errors as List[Errors.CompilerError]
    warnings as List[Errors.CompilerError]
    statistics as Dictionary[String, Integer]
End Type

Note: =====================================================================
Note: SEMANTIC ANALYZER INITIALIZATION
Note: =====================================================================

Process called "create_semantic_analyzer" that takes mode as String returns SemanticContext:
    @Implementation
    Creates and initializes a semantic analysis context with all required
    analyzers properly configured, using actual existing initialization functions.
    @End Implementation
    
    Note: Create symbol table
    Let symbol_table be SymbolTable.create_symbol_table("main_table")
    SymbolTable.initialize_builtin_symbols(symbol_table)
    
    Note: Create scope analyzer with symbol table reference
    Let scope_analyzer be ScopeAnalyzer.create_scope_analyzer(
        "main_analyzer",
        "main_table"
    )
    
    Note: Create type checker with symbol table
    Let type_checker be TypeChecker.create_type_checker(
        "main_checker",
        symbol_table
    )
    TypeChecker.initialize_builtin_types(type_checker)
    
    Note: Create generic resolver with dependencies
    Let generic_resolver be GenericResolver.create_generic_resolver(
        "main_generic_resolver",
        "main_table",
        "main_checker",
        "main_trait_resolver"
    )
    GenericResolver.initialize_builtin_generics(generic_resolver)
    
    Note: Create trait resolver with dependencies
    Let trait_resolver be TraitResolver.create_trait_resolver(
        "main_trait_resolver",
        "main_table",
        "main_checker"
    )
    TraitResolver.initialize_builtin_traits(trait_resolver)
    
    Note: Create borrow checker with dependencies
    Let borrow_checker be BorrowChecker.create_borrow_checker(
        "main_borrow_checker",
        "main_table",
        "main_analyzer"
    )
    
    Note: Create diagnostic engine
    Let diagnostic_engine be Diagnostics.create_diagnostic_engine("main_diagnostics")
    
    Note: Create AST builder for managing AST nodes
    Let ast_builder be AST.create_ast_builder("main_ast_builder", mode)
    
    Note: Create semantic context
    Let context be SemanticContext with
        symbol_table as symbol_table,
        scope_analyzer as scope_analyzer,
        type_checker as type_checker,
        generic_resolver as generic_resolver,
        trait_resolver as trait_resolver,
        borrow_checker as borrow_checker,
        diagnostic_engine as diagnostic_engine,
        ast_builder as ast_builder,
        current_mode as mode
    End SemanticContext
    
    Return context
End Process

Note: =====================================================================
Note: MAIN SEMANTIC ANALYSIS ENTRY POINT
Note: =====================================================================

Process called "analyze_program" that takes context as SemanticContext, ast_string as String returns SemanticResult:
    @Implementation
    Main entry point for semantic analysis. Orchestrates all analysis phases
    using the actual existing functions from each semantic module.
    @End Implementation
    
    Let errors be List[Errors.CompilerError]
    Let warnings be List[Errors.CompilerError]
    Let statistics be Dictionary[String, Integer]
    
    Note: Phase 1: Build symbol table - this happens during scope analysis
    
    Note: Phase 2: Scope Analysis
    Let scope_issues be ScopeAnalyzer.analyze_program_scopes(
        context.scope_analyzer,
        ast_string
    )
    For Each issue in scope_issues:
        Let error be Errors.create_semantic_error(issue)
        List.add(errors, error)
    End For
    
    Note: Analyze variable lifetimes
    ScopeAnalyzer.analyze_variable_lifetimes(context.scope_analyzer)
    
    Note: Check variable accessibility
    ScopeAnalyzer.analyze_variable_accessibility(context.scope_analyzer)
    
    Note: Detect variable captures
    ScopeAnalyzer.detect_variable_captures(context.scope_analyzer)
    
    Note: Find dead code
    Let dead_regions be ScopeAnalyzer.detect_dead_code(context.scope_analyzer)
    For Each region in dead_regions:
        Let warning_msg be "Dead code detected at line " + 
            StringPrimitive.integer_to_string(region["line"])
        Let warning be Errors.create_validation_error(warning_msg)
        List.add(warnings, warning)
    End For
    
    Note: Find unused variables
    Let unused be ScopeAnalyzer.detect_unused_variables(context.scope_analyzer)
    For Each var_name in unused:
        Let warning_msg be "Unused variable: " + var_name
        Let warning be Errors.create_validation_error(warning_msg)
        List.add(warnings, warning)
    End For
    
    Note: Phase 3: Type Checking - check statements and expressions
    Let type_errors be TypeChecker.check_statement_types(
        context.type_checker,
        ast_string
    )
    For Each error_msg in type_errors:
        Let error be Errors.create_type_error(error_msg)
        List.add(errors, error)
    End For
    
    Note: Phase 4: Generic Resolution
    Let generic_errors be GenericResolver.analyze_program_generics(
        context.generic_resolver,
        ast_string
    )
    For Each error_msg in generic_errors:
        Let error be Errors.create_type_error(error_msg)
        List.add(errors, error)
    End For
    
    Note: Phase 5: Trait Resolution
    Let trait_errors be TraitResolver.analyze_program_traits(
        context.trait_resolver,
        ast_string
    )
    For Each error_msg in trait_errors:
        Let error be Errors.create_type_error(error_msg)
        List.add(errors, error)
    End For
    
    Note: Check trait coherence
    Let coherence_errors be TraitResolver.check_trait_coherence(
        context.trait_resolver,
        "main"
    )
    For Each error_msg in coherence_errors:
        Let error be Errors.create_semantic_error(error_msg)
        List.add(errors, error)
    End For
    
    Note: Phase 6: Borrow Checking
    Let borrow_errors be BorrowChecker.analyze_program_ownership(
        context.borrow_checker,
        ast_string
    )
    For Each error_msg in borrow_errors:
        Let error be Errors.create_semantic_error(error_msg)
        List.add(errors, error)
    End For
    
    Note: Collect statistics
    Let symbol_stats be SymbolTable.get_symbol_table_statistics(context.symbol_table)
    For Each key in symbol_stats:
        Set statistics["symbols_" + key] to symbol_stats[key]
    End For
    
    Let scope_stats be ScopeAnalyzer.get_scope_analyzer_statistics(context.scope_analyzer)
    For Each key in scope_stats:
        Set statistics["scopes_" + key] to scope_stats[key]
    End For
    
    Note: Create final result
    Let success be List.length(errors) equals 0
    Let result be SemanticResult with
        success as success,
        symbol_table as context.symbol_table,
        errors as errors,
        warnings as warnings,
        statistics as statistics
    End SemanticResult
    
    Return result
End Process

Note: =====================================================================
Note: HELPER FUNCTIONS FOR SPECIFIC ANALYSIS TASKS
Note: =====================================================================

Process called "analyze_function" that takes context as SemanticContext, function_ast as String returns List[Errors.CompilerError]:
    @Implementation
    Analyzes a single function using the actual existing type checker functions.
    @End Implementation
    
    Let errors be List[Errors.CompilerError]
    
    Note: Check function signature
    Let signature_errors be TypeChecker.check_function_signature(
        context.type_checker,
        function_ast
    )
    For Each error_msg in signature_errors:
        Let error be Errors.create_type_error(error_msg)
        List.add(errors, error)
    End For
    
    Note: Infer return type
    Let inferred_type be TypeChecker.infer_function_return_type(
        context.type_checker,
        function_ast
    )
    
    Return errors
End Process

Process called "analyze_variable_declaration" that takes context as SemanticContext, declaration_ast as String returns List[Errors.CompilerError]:
    @Implementation
    Analyzes a variable declaration using actual existing type checker functions.
    @End Implementation
    
    Let errors be List[Errors.CompilerError]
    
    Note: Check variable declaration
    Let declaration_errors be TypeChecker.check_variable_declaration(
        context.type_checker,
        declaration_ast
    )
    For Each error_msg in declaration_errors:
        Let error be Errors.create_type_error(error_msg)
        List.add(errors, error)
    End For
    
    Return errors
End Process

Process called "analyze_expression" that takes context as SemanticContext, expression_ast as String returns TypeChecker.TypeInfo:
    @Implementation
    Analyzes an expression and returns its type using actual type checker functions.
    @End Implementation
    
    Note: Check expression type
    Let type_info be TypeChecker.check_expression_type(
        context.type_checker,
        expression_ast
    )
    
    Return type_info
End Process

Note: =====================================================================
Note: UTILITY FUNCTIONS
Note: =====================================================================

Process called "get_semantic_analyzer_version" returns String:
    @Implementation
    Returns the version of the semantic analyzer.
    @End Implementation
    
    Return "1.0.0"
End Process

Process called "reset_semantic_analyzer" that takes context as SemanticContext returns Boolean:
    @Implementation
    Resets the semantic analyzer to initial state using actual reset functions.
    @End Implementation
    
    Note: Reset all components
    SymbolTable.reset_symbol_table(context.symbol_table)
    ScopeAnalyzer.reset_scope_analyzer(context.scope_analyzer)
    TypeChecker.reset_type_checker(context.type_checker)
    GenericResolver.reset_generic_resolver(context.generic_resolver)
    TraitResolver.reset_trait_resolver(context.trait_resolver)
    BorrowChecker.reset_borrow_checker(context.borrow_checker)
    
    Note: Re-initialize builtins
    SymbolTable.initialize_builtin_symbols(context.symbol_table)
    TypeChecker.initialize_builtin_types(context.type_checker)
    GenericResolver.initialize_builtin_generics(context.generic_resolver)
    TraitResolver.initialize_builtin_traits(context.trait_resolver)
    
    Return true
End Process

Note: =====================================================================
Note: AST WALKING INFRASTRUCTURE SKELETONS
Note: =====================================================================

Process called "walk_ast_node" that takes context as SemanticContext, ast_node as AST.ASTNode returns List[Errors.CompilerError]:
    @Implementation
    Core AST walking function that dispatches to specific walkers based on node type.
    This is the main entry point for traversing any AST node during semantic analysis.
    @End Implementation
    
    @Reasoning
    AST walking is essential for semantic analysis as it allows us to traverse the
    syntax tree and perform analysis on each node. This dispatcher determines the
    node type and calls the appropriate specialized walker.
    @End Reasoning
    
    Let errors be List[Errors.CompilerError]
    
    Note: Get the node type from the ASTNode
    Let node_type be ast_node.node_type
    
    Note: Dispatch to appropriate walker based on node type
    Match node_type:
        When "Block":
            Let block_errors be walk_block(context, ast_node)
            For Each error in block_errors:
                List.add(errors, error)
            End For
        When "Expression":
            Let expr_errors be walk_expression(context, ast_node)
            For Each error in expr_errors:
                List.add(errors, error)
            End For
        When "Statement":
            Let stmt_errors be walk_statement(context, ast_node)
            For Each error in stmt_errors:
                List.add(errors, error)
            End For
        When "FunctionDefinition":
            Let func_errors be walk_function_definition(context, ast_node)
            For Each error in func_errors:
                List.add(errors, error)
            End For
        When "TypeDefinition":
            Let type_errors be walk_type_definition(context, ast_node)
            For Each error in type_errors:
                List.add(errors, error)
            End For
        When "TraitDefinition":
            Let trait_errors be walk_trait_definition(context, ast_node)
            For Each error in trait_errors:
                List.add(errors, error)
            End For
        When "Import":
            Let import_errors be collect_import(context, ast_node)
            For Each error in import_errors:
                List.add(errors, error)
            End For
        When "VariableDeclaration":
            Let var_errors be collect_variable_definition(context, ast_node)
            For Each error in var_errors:
                List.add(errors, error)
            End For
        When "Match":
            Let match_errors be analyze_match_expression(context, ast_node)
            For Each error in match_errors:
                List.add(errors, error)
            End For
        Otherwise:
            Note: For unknown node types, recursively walk children
            If ast_node.children is not null:
                For Each child_id in ast_node.children:
                    Let child_node be AST.get_node_by_id_direct(context.ast_builder, child_id)
                    If child_node.node_id not equals "":
                        Let child_errors be walk_ast_node(context, child_node)
                        For Each error in child_errors:
                            List.add(errors, error)
                        End For
                    End If
                End For
            End If
    End Match
    
    Return errors
End Process

Process called "walk_block" that takes context as SemanticContext, block_ast as AST.ASTNode returns List[Errors.CompilerError]:
    @Implementation
    Walks a block statement, processing all statements within the block scope.
    Manages scope entry and exit for the block.
    @End Implementation
    
    @Reasoning
    Blocks create new scopes and contain sequences of statements. This walker
    ensures proper scope management and processes each statement in order.
    @End Reasoning
    
    Let errors be List[Errors.CompilerError]
    
    Note: Get the block node ID
    Let block_id be block_ast.node_id
    
    Note: Enter new scope for this block
    Let scope_name be "block_" + block_id
    ScopeAnalyzer.enter_scope(context.scope_analyzer, scope_name, "block")
    
    Note: Process all statements in the block
    If block_ast.children is not null:
        For Each child_id in block_ast.children:
            Let child_node be AST.get_node_by_id_direct(context.ast_builder, child_id)
            If child_node.node_id not equals "":
                Note: Walk each child statement
                Let child_errors be walk_ast_node(context, child_node)
                For Each error in child_errors:
                    List.add(errors, error)
                End For
            End If
        End For
    End If
    
    Note: Check for unreachable code in this block
    Let unreachable_errors be check_unreachable_code(context, block_ast)
    For Each error in unreachable_errors:
        List.add(errors, error)
    End For
    
    Note: Exit the block scope
    ScopeAnalyzer.exit_scope(context.scope_analyzer)
    
    Return errors
End Process

Process called "walk_expression" that takes context as SemanticContext, expression_ast as AST.ASTNode returns List[Errors.CompilerError]:
    @Implementation
    Walks an expression node, handling all expression types including literals,
    identifiers, binary operations, function calls, and more complex expressions.
    @End Implementation
    
    @Reasoning
    Expressions are the building blocks of computation. This walker analyzes
    expressions for type correctness, symbol resolution, and semantic validity.
    @End Reasoning
    
    Let errors be List[Errors.CompilerError]
    
    Note: Get expression type from attributes
    Let expr_type be Dictionary.get(expression_ast.attributes, "expression_type")
    If expr_type equals null:
        Set expr_type to expression_ast.node_type
    End If
    
    Match expr_type:
        When "BinaryOperation":
            Note: Check binary operation - children should be left and right operands
            If expression_ast.children is not null:
                If List.length(expression_ast.children) >= 2:
                    Let left_id be List.get(expression_ast.children, 0)
                    Let right_id be List.get(expression_ast.children, 1)
                    
                    Note: Walk left operand
                    Let left_node be AST.get_node_by_id_direct(context.ast_builder, left_id)
                    If left_node.node_id not equals "":
                        Let left_errors be walk_expression(context, left_node)
                        For Each error in left_errors:
                            List.add(errors, error)
                        End For
                    End If
                    
                    Note: Walk right operand
                    Let right_node be AST.get_node_by_id_direct(context.ast_builder, right_id)
                    If right_node.node_id not equals "":
                        Let right_errors be walk_expression(context, right_node)
                        For Each error in right_errors:
                            List.add(errors, error)
                        End For
                    End If
                End If
            End If
            
            Note: Type check the binary operation
            Let type_info be TypeChecker.check_expression_type(
                context.type_checker,
                AST.serialize_ast(context.ast_builder, expression_ast, "runa")
            )
            
        When "UnaryOperation":
            Note: Check unary operation - first child is operand
            If expression_ast.children is not null:
                If List.length(expression_ast.children) >= 1:
                    Let operand_id be List.get(expression_ast.children, 0)
                    Let operand_node be AST.get_node_by_id_direct(context.ast_builder, operand_id)
                    If operand_node.node_id not equals "":
                        Let operand_errors be walk_expression(context, operand_node)
                        For Each error in operand_errors:
                            List.add(errors, error)
                        End For
                    End If
                End If
            End If
            
        When "FunctionCall":
            Note: Resolve and check function call
            Let func_symbol be resolve_function_call(context, expression_ast)
            If func_symbol.name equals "":
                Let func_name be Dictionary.get(expression_ast.attributes, "function_name")
                Let error_msg be "Unresolved function call: " + func_name
                Let error be Errors.create_semantic_error(error_msg)
                List.add(errors, error)
            End If
            
            Note: Walk argument expressions (children are arguments)
            If expression_ast.children is not null:
                For Each arg_id in expression_ast.children:
                    Let arg_node be AST.get_node_by_id_direct(context.ast_builder, arg_id)
                    If arg_node.node_id not equals "":
                        Let arg_errors be walk_expression(context, arg_node)
                        For Each error in arg_errors:
                            List.add(errors, error)
                        End For
                    End If
                End For
            End If
            
        When "Identifier":
            Note: Resolve identifier
            Let symbol be resolve_identifier(context, expression_ast)
            If symbol.name equals "":
                Let id_name be Dictionary.get(expression_ast.attributes, "name")
                Let current_scope be ScopeAnalyzer.get_current_scope(context.scope_analyzer)
                Let suggestion be suggest_similar_symbol(context, id_name, current_scope.scope_name)
                Let error_msg be "Undefined identifier: " + id_name
                If suggestion not equals "":
                    Set error_msg to error_msg + ". Did you mean '" + suggestion + "'?"
                End If
                Let error be Errors.create_semantic_error(error_msg)
                List.add(errors, error)
            Otherwise:
                Note: Track symbol usage
                Let line_num be Dictionary.get(expression_ast.position, "line")
                track_symbol_usage(context, symbol.name, 
                    StringPrimitive.integer_to_string(line_num))
            End If
            
        When "Literal":
            Note: Literals are always valid, just verify type annotation
            Let annotated be annotate_with_types(context, expression_ast)
            
        When "MemberAccess":
            Note: Check member access - first child is the object
            If expression_ast.children is not null:
                If List.length(expression_ast.children) >= 1:
                    Let object_id be List.get(expression_ast.children, 0)
                    Let object_node be AST.get_node_by_id_direct(context.ast_builder, object_id)
                    If object_node.node_id not equals "":
                        Let object_errors be walk_expression(context, object_node)
                        For Each error in object_errors:
                            List.add(errors, error)
                        End For
                    End If
                End If
            End If
            
        Otherwise:
            Note: For other expression types, walk children recursively
            If expression_ast.children is not null:
                For Each child_id in expression_ast.children:
                    Let child_node be AST.get_node_by_id_direct(context.ast_builder, child_id)
                    If child_node.node_id not equals "":
                        Let child_errors be walk_ast_node(context, child_node)
                        For Each error in child_errors:
                            List.add(errors, error)
                        End For
                    End If
                End For
            End If
    End Match
    
    Return errors
End Process

Process called "walk_statement" that takes context as SemanticContext, statement_ast as AST.ASTNode returns List[Errors.CompilerError]:
    @Implementation
    Walks a statement node, handling variable declarations, assignments,
    control flow statements, and other statement types.
    @End Implementation
    
    @Reasoning
    Statements represent actions and control flow. This walker ensures statements
    are semantically valid and updates the symbol table as needed.
    @End Reasoning
    
    Let errors be List[Errors.CompilerError]
    
    Note: Get statement type from attributes or node type
    Let stmt_type be Dictionary.get(statement_ast.attributes, "statement_type")
    If stmt_type equals null:
        Set stmt_type to statement_ast.node_type
    End If
    
    Match stmt_type:
        When "VariableDeclaration":
            Note: Collect and check variable declaration
            Let var_errors be collect_variable_definition(context, statement_ast)
            For Each error in var_errors:
                List.add(errors, error)
            End For
            
            Note: Check initializer expression if present (should be first child)
            If statement_ast.children is not null:
                If List.length(statement_ast.children) >= 1:
                    Let init_id be List.get(statement_ast.children, 0)
                    Let init_node be AST.get_node_by_id_direct(context.ast_builder, init_id)
                    If init_node.node_id not equals "":
                        Let init_errors be walk_expression(context, init_node)
                        For Each error in init_errors:
                            List.add(errors, error)
                        End For
                    End If
                End If
            End If
            
        When "Assignment":
            Note: Check assignment target and value (children: target, value)
            If statement_ast.children is not null:
                If List.length(statement_ast.children) >= 2:
                    Let target_id be List.get(statement_ast.children, 0)
                    Let value_id be List.get(statement_ast.children, 1)

                    Note: Walk target expression
                    Let target_node be AST.get_node_by_id_direct(context.ast_builder, target_id)
                    If target_node.node_id not equals "":
                        Let target_errors be walk_expression(context, target_node)
                        For Each error in target_errors:
                            List.add(errors, error)
                        End For
                    End If

                    Note: Walk value expression
                    Let value_node be AST.get_node_by_id_direct(context.ast_builder, value_id)
                    If value_node.node_id not equals "":
                        Let value_errors be walk_expression(context, value_node)
                        For Each error in value_errors:
                            List.add(errors, error)
                        End For
                    End If
                End If
            End If

            Note: Type check the assignment
            Let ast_string be AST.serialize_ast(context.ast_builder, statement_ast, "runa")
            Let type_results be TypeChecker.check_statement_types(
                context.type_checker,
                ast_string
            )
            If type_results not equals "valid":
                Let error be Errors.create_type_error(type_results)
                List.add(errors, error)
            End If
            
        When "Return":
            Note: Check return statement
            Let return_errors be check_return_statements(context, statement_ast)
            For Each error in return_errors:
                List.add(errors, error)
            End For

            Note: Check return value expression if present (first child)
            If statement_ast.children is not null:
                If List.length(statement_ast.children) >= 1:
                    Let value_id be List.get(statement_ast.children, 0)
                    Let value_node be AST.get_node_by_id_direct(context.ast_builder, value_id)
                    If value_node.node_id not equals "":
                        Let value_errors be walk_expression(context, value_node)
                        For Each error in value_errors:
                            List.add(errors, error)
                        End For
                    End If
                End If
            End If
            
        When "If":
            Note: Check if statement (children: condition, then_branch, [else_branch])
            If statement_ast.children is not null:
                Let child_count be List.length(statement_ast.children)

                Note: First child is condition
                If child_count >= 1:
                    Let condition_id be List.get(statement_ast.children, 0)
                    Let condition_node be AST.get_node_by_id_direct(context.ast_builder, condition_id)
                    If condition_node.node_id not equals "":
                        Let condition_errors be walk_expression(context, condition_node)
                        For Each error in condition_errors:
                            List.add(errors, error)
                        End For
                    End If
                End If

                Note: Second child is then branch
                If child_count >= 2:
                    Let then_id be List.get(statement_ast.children, 1)
                    Let then_node be AST.get_node_by_id_direct(context.ast_builder, then_id)
                    If then_node.node_id not equals "":
                        Let then_errors be walk_block(context, then_node)
                        For Each error in then_errors:
                            List.add(errors, error)
                        End For
                    End If
                End If

                Note: Optional third child is else branch
                If child_count >= 3:
                    Let else_id be List.get(statement_ast.children, 2)
                    Let else_node be AST.get_node_by_id_direct(context.ast_builder, else_id)
                    If else_node.node_id not equals "":
                        Let else_errors be walk_block(context, else_node)
                        For Each error in else_errors:
                            List.add(errors, error)
                        End For
                    End If
                End If
            End If
            
        When "While":
            Note: Check while loop (children: condition, body)
            If statement_ast.children is not null:
                Let child_count be List.length(statement_ast.children)

                Note: First child is condition
                If child_count >= 1:
                    Let condition_id be List.get(statement_ast.children, 0)
                    Let condition_node be AST.get_node_by_id_direct(context.ast_builder, condition_id)
                    If condition_node.node_id not equals "":
                        Let condition_errors be walk_expression(context, condition_node)
                        For Each error in condition_errors:
                            List.add(errors, error)
                        End For
                    End If
                End If

                Note: Second child is body
                If child_count >= 2:
                    Let body_id be List.get(statement_ast.children, 1)
                    Let body_node be AST.get_node_by_id_direct(context.ast_builder, body_id)
                    If body_node.node_id not equals "":
                        Let body_errors be walk_block(context, body_node)
                        For Each error in body_errors:
                            List.add(errors, error)
                        End For
                    End If
                End If
            End If
            
        When "For":
            Note: Check for loop (children: init, condition, update, body)
            If statement_ast.children is not null:
                Let child_count be List.length(statement_ast.children)

                Note: First child is initializer
                If child_count >= 1:
                    Let init_id be List.get(statement_ast.children, 0)
                    Let init_node be AST.get_node_by_id_direct(context.ast_builder, init_id)
                    If init_node.node_id not equals "":
                        Let init_errors be walk_statement(context, init_node)
                        For Each error in init_errors:
                            List.add(errors, error)
                        End For
                    End If
                End If

                Note: Second child is condition
                If child_count >= 2:
                    Let condition_id be List.get(statement_ast.children, 1)
                    Let condition_node be AST.get_node_by_id_direct(context.ast_builder, condition_id)
                    If condition_node.node_id not equals "":
                        Let condition_errors be walk_expression(context, condition_node)
                        For Each error in condition_errors:
                            List.add(errors, error)
                        End For
                    End If
                End If

                Note: Third child is update expression
                If child_count >= 3:
                    Let update_id be List.get(statement_ast.children, 2)
                    Let update_node be AST.get_node_by_id_direct(context.ast_builder, update_id)
                    If update_node.node_id not equals "":
                        Let update_errors be walk_expression(context, update_node)
                        For Each error in update_errors:
                            List.add(errors, error)
                        End For
                    End If
                End If

                Note: Fourth child is body
                If child_count >= 4:
                    Let body_id be List.get(statement_ast.children, 3)
                    Let body_node be AST.get_node_by_id_direct(context.ast_builder, body_id)
                    If body_node.node_id not equals "":
                        Let body_errors be walk_block(context, body_node)
                        For Each error in body_errors:
                            List.add(errors, error)
                        End For
                    End If
                End If
            End If
            
        When "Break":
            Note: Check break statement
            Let break_errors be check_break_continue(context, statement_ast)
            For Each error in break_errors:
                List.add(errors, error)
            End For
            
        When "Continue":
            Note: Check continue statement  
            Let continue_errors be check_break_continue(context, statement_ast)
            For Each error in continue_errors:
                List.add(errors, error)
            End For
            
        When "ExpressionStatement":
            Note: Walk the expression (first child)
            If statement_ast.children is not null:
                If List.length(statement_ast.children) >= 1:
                    Let expr_id be List.get(statement_ast.children, 0)
                    Let expr_node be AST.get_node_by_id_direct(context.ast_builder, expr_id)
                    If expr_node.node_id not equals "":
                        Let expr_errors be walk_expression(context, expr_node)
                        For Each error in expr_errors:
                            List.add(errors, error)
                        End For
                    End If
                End If
            End If
            
        Otherwise:
            Note: For other statement types, walk children
            If statement_ast.children is not null:
                For Each child_id in statement_ast.children:
                    Let child_node be AST.get_node_by_id_direct(context.ast_builder, child_id)
                    If child_node.node_id not equals "":
                        Let child_errors be walk_ast_node(context, child_node)
                        For Each error in child_errors:
                            List.add(errors, error)
                        End For
                    End If
                End For
            End If
    End Match
    
    Return errors
End Process

Note: =====================================================================
Note: SYMBOL COLLECTION SKELETONS
Note: =====================================================================

Process called "collect_function_definition" that takes context as SemanticContext, function_ast as AST.ASTNode returns List[Errors.CompilerError]:
    @Implementation
    Collects a function definition and adds it to the symbol table.
    Handles parameters, return type, and function body scope.
    @End Implementation

    @Reasoning
    Function definitions need to be collected in a first pass before resolution
    to handle forward references and mutual recursion properly.
    @End Reasoning

    Let errors be List[Errors.CompilerError]

    Note: Extract function name from attributes
    Let func_name be Dictionary.get(function_ast.attributes, "name")
    If func_name equals null:
        Let error be Errors.create_semantic_error("Function definition missing name")
        List.add(errors, error)
        Return errors
    End If

    Note: Extract return type
    Let return_type be Dictionary.get(function_ast.attributes, "return_type")
    If return_type equals null:
        Set return_type to "Void"
    End If

    Note: Create function symbol
    Let func_symbol be SymbolTable.Symbol with
        name as func_name,
        symbol_type as SymbolTable.SymbolType.Function,
        data_type as return_type,
        scope as ScopeAnalyzer.get_current_scope(context.scope_analyzer).scope_name,
        metadata as Dictionary[String, String]
    End SymbolTable.Symbol

    Note: Add metadata about the function
    Dictionary.set(func_symbol.metadata, "node_id", function_ast.node_id)
    Dictionary.set(func_symbol.metadata, "visibility", Dictionary.get(function_ast.attributes, "visibility"))
    Dictionary.set(func_symbol.metadata, "is_generic", Dictionary.get(function_ast.attributes, "is_generic"))

    Note: Register the function symbol
    Let add_result be SymbolTable.add_symbol(context.symbol_table, func_symbol)
    If not add_result:
        Let error be Errors.create_semantic_error("Duplicate function definition: " + func_name)
        List.add(errors, error)
    End If

    Note: Enter function scope
    Let func_scope be "function_" + func_name
    ScopeAnalyzer.enter_scope(context.scope_analyzer, func_scope, "function")

    Note: Process parameters (should be in children)
    If function_ast.children is not null:
        Let param_count be 0
        For Each child_id in function_ast.children:
            Let child_node be AST.get_node_by_id_direct(context.ast_builder, child_id)
            If child_node.node_type equals "Parameter":
                Note: Create parameter symbol
                Let param_name be Dictionary.get(child_node.attributes, "name")
                Let param_type be Dictionary.get(child_node.attributes, "type")

                Let param_symbol be SymbolTable.Symbol with
                    name as param_name,
                    symbol_type as SymbolTable.SymbolType.Variable,
                    data_type as param_type,
                    scope as func_scope,
                    metadata as Dictionary[String, String]
                End SymbolTable.Symbol

                Dictionary.set(param_symbol.metadata, "is_parameter", "true")
                Dictionary.set(param_symbol.metadata, "parameter_index", StringPrimitive.integer_to_string(param_count))

                Note: Add parameter to symbol table
                Let param_result be SymbolTable.add_symbol(context.symbol_table, param_symbol)
                If not param_result:
                    Let error be Errors.create_semantic_error("Duplicate parameter: " + param_name)
                    List.add(errors, error)
                End If

                Set param_count to param_count + 1
            End If
        End For

        Note: Store parameter count in function metadata
        Dictionary.set(func_symbol.metadata, "parameter_count", StringPrimitive.integer_to_string(param_count))
    End If

    Note: Exit function scope after processing parameters
    ScopeAnalyzer.exit_scope(context.scope_analyzer)

    Return errors
End Process

Process called "collect_type_definition" that takes context as SemanticContext, type_ast as AST.ASTNode returns List[Errors.CompilerError]:
    @Implementation
    Collects a type definition (struct, enum, or type alias) and adds it to the symbol table.
    Handles type parameters for generic types.
    @End Implementation

    @Reasoning
    Type definitions must be collected early to resolve type references in
    function signatures and variable declarations.
    @End Reasoning

    Let errors be List[Errors.CompilerError]

    Note: Extract type name from attributes
    Let type_name be Dictionary.get(type_ast.attributes, "name")
    If type_name equals null:
        Let error be Errors.create_semantic_error("Type definition missing name")
        List.add(errors, error)
        Return errors
    End If

    Note: Determine type kind
    Let type_kind be Dictionary.get(type_ast.attributes, "type_kind")
    If type_kind equals null:
        Set type_kind to "struct"
    End If

    Note: Create type symbol
    Let type_symbol be SymbolTable.Symbol with
        name as type_name,
        symbol_type as SymbolTable.SymbolType.Type,
        data_type as type_kind,
        scope as ScopeAnalyzer.get_current_scope(context.scope_analyzer).scope_name,
        metadata as Dictionary[String, String]
    End SymbolTable.Symbol

    Note: Add metadata about the type
    Dictionary.set(type_symbol.metadata, "node_id", type_ast.node_id)
    Dictionary.set(type_symbol.metadata, "visibility", Dictionary.get(type_ast.attributes, "visibility"))
    Dictionary.set(type_symbol.metadata, "is_generic", Dictionary.get(type_ast.attributes, "is_generic"))
    Dictionary.set(type_symbol.metadata, "type_kind", type_kind)

    Note: Process generic parameters if present
    Let generic_params be Dictionary.get(type_ast.attributes, "generic_params")
    If generic_params is not null:
        Dictionary.set(type_symbol.metadata, "generic_params", generic_params)
    End If

    Note: Register the type symbol
    Let add_result be SymbolTable.add_symbol(context.symbol_table, type_symbol)
    If not add_result:
        Let error be Errors.create_semantic_error("Duplicate type definition: " + type_name)
        List.add(errors, error)
    End If

    Note: Process type members/fields (should be in children)
    If type_ast.children is not null:
        Let field_count be 0
        For Each child_id in type_ast.children:
            Let child_node be AST.get_node_by_id_direct(context.ast_builder, child_id)
            If child_node.node_type equals "Field" or child_node.node_type equals "Member":
                Note: Create field symbol
                Let field_name be Dictionary.get(child_node.attributes, "name")
                Let field_type be Dictionary.get(child_node.attributes, "type")

                Let field_symbol be SymbolTable.Symbol with
                    name as type_name + "." + field_name,
                    symbol_type as SymbolTable.SymbolType.Variable,
                    data_type as field_type,
                    scope as ScopeAnalyzer.get_current_scope(context.scope_analyzer).scope_name,
                    metadata as Dictionary[String, String]
                End SymbolTable.Symbol

                Dictionary.set(field_symbol.metadata, "is_field", "true")
                Dictionary.set(field_symbol.metadata, "parent_type", type_name)
                Dictionary.set(field_symbol.metadata, "field_index", StringPrimitive.integer_to_string(field_count))
                Dictionary.set(field_symbol.metadata, "visibility", Dictionary.get(child_node.attributes, "visibility"))

                Note: Add field to symbol table
                Let field_result be SymbolTable.add_symbol(context.symbol_table, field_symbol)
                If not field_result:
                    Let error be Errors.create_semantic_error("Duplicate field: " + field_name + " in type " + type_name)
                    List.add(errors, error)
                End If

                Set field_count to field_count + 1
            Otherwise If child_node.node_type equals "Variant":
                Note: Handle enum variants
                Let variant_name be Dictionary.get(child_node.attributes, "name")
                Let variant_data be Dictionary.get(child_node.attributes, "data_type")

                Let variant_symbol be SymbolTable.Symbol with
                    name as type_name + "::" + variant_name,
                    symbol_type as SymbolTable.SymbolType.Variable,
                    data_type as variant_data,
                    scope as ScopeAnalyzer.get_current_scope(context.scope_analyzer).scope_name,
                    metadata as Dictionary[String, String]
                End SymbolTable.Symbol

                Dictionary.set(variant_symbol.metadata, "is_variant", "true")
                Dictionary.set(variant_symbol.metadata, "parent_enum", type_name)
                Dictionary.set(variant_symbol.metadata, "variant_index", StringPrimitive.integer_to_string(field_count))

                Note: Add variant to symbol table
                Let variant_result be SymbolTable.add_symbol(context.symbol_table, variant_symbol)
                If not variant_result:
                    Let error be Errors.create_semantic_error("Duplicate variant: " + variant_name + " in enum " + type_name)
                    List.add(errors, error)
                End If

                Set field_count to field_count + 1
            End If
        End For

        Note: Store field/variant count in type metadata
        Dictionary.set(type_symbol.metadata, "member_count", StringPrimitive.integer_to_string(field_count))
    End If

    Return errors
End Process

Process called "collect_variable_definition" that takes context as SemanticContext, variable_ast as AST.ASTNode returns List[Errors.CompilerError]:
    @Implementation
    Collects a variable definition and adds it to the symbol table in the current scope.
    Handles type annotations and initialization expressions.
    @End Implementation

    @Reasoning
    Variable definitions create new symbols that must be tracked for scope
    analysis and type checking.
    @End Reasoning

    Let errors be List[Errors.CompilerError]

    Note: Extract variable name from attributes
    Let var_name be Dictionary.get(variable_ast.attributes, "name")
    If var_name equals null:
        Let error be Errors.create_semantic_error("Variable definition missing name")
        List.add(errors, error)
        Return errors
    End If

    Note: Extract variable type
    Let var_type be Dictionary.get(variable_ast.attributes, "type")
    If var_type equals null:
        Note: Try to infer type from initializer if present
        If variable_ast.children is not null:
            If List.length(variable_ast.children) > 0:
                Let init_id be List.get(variable_ast.children, 0)
                Let init_node be AST.get_node_by_id_direct(context.ast_builder, init_id)
                If init_node.node_id not equals "":
                    Note: Use type checker to infer type from initializer
                    Let ast_string be AST.serialize_ast(context.ast_builder, init_node, "runa")
                    Let inferred_type be TypeChecker.check_expression_type(
                        context.type_checker,
                        ast_string
                    )
                    Set var_type to inferred_type
                End If
            End If
        End If

        Note: If still no type, report error
        If var_type equals null:
            Let error be Errors.create_semantic_error("Variable '" + var_name + "' missing type annotation and cannot infer type")
            List.add(errors, error)
            Set var_type to "Unknown"
        End If
    End If

    Note: Get current scope
    Let current_scope be ScopeAnalyzer.get_current_scope(context.scope_analyzer)

    Note: Create variable symbol
    Let var_symbol be SymbolTable.Symbol with
        name as var_name,
        symbol_type as SymbolTable.SymbolType.Variable,
        data_type as var_type,
        scope as current_scope.scope_name,
        metadata as Dictionary[String, String]
    End SymbolTable.Symbol

    Note: Add metadata about the variable
    Dictionary.set(var_symbol.metadata, "node_id", variable_ast.node_id)
    Dictionary.set(var_symbol.metadata, "is_mutable", Dictionary.get(variable_ast.attributes, "is_mutable"))
    Dictionary.set(var_symbol.metadata, "is_constant", Dictionary.get(variable_ast.attributes, "is_constant"))
    Dictionary.set(var_symbol.metadata, "has_initializer", StringPrimitive.boolean_to_string(
        variable_ast.children is not null and List.length(variable_ast.children) > 0
    ))

    Note: Register the variable symbol
    Let add_result be SymbolTable.add_symbol(context.symbol_table, var_symbol)
    If not add_result:
        Let error be Errors.create_semantic_error("Duplicate variable definition: " + var_name + " in scope " + current_scope.scope_name)
        List.add(errors, error)
    End If

    Note: Track variable in scope analyzer
    ScopeAnalyzer.add_variable_to_scope(context.scope_analyzer, var_name, var_type)

    Return errors
End Process

Process called "collect_import" that takes context as SemanticContext, import_ast as AST.ASTNode returns List[Errors.CompilerError]:
    @Implementation
    Collects an import statement and records it for later resolution.
    Handles aliased imports and selective imports.
    @End Implementation

    @Reasoning
    Imports must be collected and resolved before other symbols to ensure
    imported symbols are available for resolution.
    @End Reasoning

    Let errors be List[Errors.CompilerError]

    Note: Extract module path from attributes
    Let module_path be Dictionary.get(import_ast.attributes, "module_path")
    If module_path equals null:
        Let error be Errors.create_semantic_error("Import statement missing module path")
        List.add(errors, error)
        Return errors
    End If

    Note: Extract alias if present
    Let import_alias be Dictionary.get(import_ast.attributes, "alias")
    If import_alias equals null:
        Note: Use last part of module path as default alias
        Let path_parts be StringPrimitive.split(module_path, "/")
        Let part_count be List.length(path_parts)
        If part_count > 0:
            Set import_alias to List.get(path_parts, part_count - 1)
        Otherwise:
            Set import_alias to module_path
        End If
    End If

    Note: Create import symbol
    Let import_symbol be SymbolTable.Symbol with
        name as import_alias,
        symbol_type as SymbolTable.SymbolType.Module,
        data_type as "Module",
        scope as ScopeAnalyzer.get_current_scope(context.scope_analyzer).scope_name,
        metadata as Dictionary[String, String]
    End SymbolTable.Symbol

    Note: Add metadata about the import
    Dictionary.set(import_symbol.metadata, "node_id", import_ast.node_id)
    Dictionary.set(import_symbol.metadata, "module_path", module_path)
    Dictionary.set(import_symbol.metadata, "is_aliased", StringPrimitive.boolean_to_string(import_alias not equals module_path))

    Note: Check for selective imports (specific symbols)
    Let selective_imports be Dictionary.get(import_ast.attributes, "selective_imports")
    If selective_imports is not null:
        Dictionary.set(import_symbol.metadata, "selective_imports", selective_imports)
        Dictionary.set(import_symbol.metadata, "is_selective", "true")
    Otherwise:
        Dictionary.set(import_symbol.metadata, "is_selective", "false")
    End If

    Note: Register the import symbol
    Let add_result be SymbolTable.add_symbol(context.symbol_table, import_symbol)
    If not add_result:
        Let error be Errors.create_semantic_error("Duplicate import alias: " + import_alias)
        List.add(errors, error)
    End If

    Note: Track import for later resolution
    ScopeAnalyzer.add_import_to_scope(context.scope_analyzer, module_path, import_alias)

    Note: Mark import for deferred resolution
    Dictionary.set(import_symbol.metadata, "resolved", "false")

    Return errors
End Process

Note: =====================================================================
Note: SYMBOL RESOLUTION SKELETONS
Note: =====================================================================

Process called "resolve_identifier" that takes context as SemanticContext, identifier_ast as AST.ASTNode returns SymbolTable.Symbol:
    @Implementation
    Resolves an identifier to its symbol definition, searching through scopes
    from innermost to outermost.
    @End Implementation
    
    @Reasoning
    Identifier resolution is critical for connecting uses to definitions and
    ensuring variables are properly scoped.
    @End Reasoning
    
    Note: Extract identifier name from AST node
    Let identifier_name be Dictionary.get(identifier_ast.attributes, "name")
    If identifier_name equals null:
        Note: Return empty symbol for error case
        Return SymbolTable.Symbol with
            name as "",
            symbol_type as SymbolTable.SymbolType.Variable,
            data_type as "Unknown",
            scope as "",
            metadata as Dictionary[String, String]
        End SymbolTable.Symbol
    End If

    Note: Search for symbol starting from current scope
    Let current_scope be ScopeAnalyzer.get_current_scope(context.scope_analyzer)
    Let symbol be SymbolTable.lookup_symbol(
        context.symbol_table,
        identifier_name,
        current_scope.scope_name
    )

    Note: If found, return the symbol
    If symbol.name not equals "":
        Return symbol
    End If

    Note: Search in parent scopes
    Let scope_chain be ScopeAnalyzer.get_scope_chain(context.scope_analyzer)
    For Each scope_name in scope_chain:
        Let parent_symbol be SymbolTable.lookup_symbol(
            context.symbol_table,
            identifier_name,
            scope_name
        )
        If parent_symbol.name not equals "":
            Return parent_symbol
        End If
    End For

    Note: Check imported modules
    Let imports be ScopeAnalyzer.get_imports_in_scope(context.scope_analyzer)
    For Each import_alias in imports:
        Note: Check if identifier is prefixed with import alias
        If StringPrimitive.starts_with(identifier_name, import_alias + "."):
            Let imported_name be StringPrimitive.substring(
                identifier_name,
                StringPrimitive.length(import_alias) + 1,
                StringPrimitive.length(identifier_name)
            )
            Let imported_symbol be SymbolTable.lookup_symbol(
                context.symbol_table,
                imported_name,
                "module_" + import_alias
            )
            If imported_symbol.name not equals "":
                Return imported_symbol
            End If
        End If
    End For

    Note: Symbol not found, return empty symbol
    Return SymbolTable.Symbol with
        name as "",
        symbol_type as SymbolTable.SymbolType.Variable,
        data_type as "Unknown",
        scope as "",
        metadata as Dictionary[String, String]
    End SymbolTable.Symbol
End Process

Process called "resolve_type_reference" that takes context as SemanticContext, type_ref_ast as AST.ASTNode returns TypeChecker.TypeInfo:
    @Implementation
    Resolves a type reference to its actual type definition, handling generic
    type parameters and qualified names.
    @End Implementation
    
    @Reasoning
    Type references appear in variable declarations, function signatures, and
    type annotations. Proper resolution is essential for type checking.
    @End Reasoning
    
    Note: Extract type name from AST node
    Let type_name be Dictionary.get(type_ref_ast.attributes, "type_name")
    If type_name equals null:
        Note: Return unknown type for error case
        Return TypeChecker.TypeInfo with
            type_name as "Unknown",
            type_kind as TypeChecker.TypeKind.Unknown,
            is_nullable as false,
            is_mutable as false,
            generic_params as List[String],
            constraints as List[String]
        End TypeChecker.TypeInfo
    End If

    Note: Check if this is a built-in type
    Let builtin_type be TypeChecker.get_builtin_type(context.type_checker, type_name)
    If builtin_type.type_name not equals "":
        Return builtin_type
    End If

    Note: Look up type in symbol table
    Let current_scope be ScopeAnalyzer.get_current_scope(context.scope_analyzer)
    Let type_symbol be SymbolTable.lookup_symbol(
        context.symbol_table,
        type_name,
        current_scope.scope_name
    )

    Note: If not found in current scope, search parent scopes
    If type_symbol.name equals "":
        Let scope_chain be ScopeAnalyzer.get_scope_chain(context.scope_analyzer)
        For Each scope_name in scope_chain:
            Set type_symbol to SymbolTable.lookup_symbol(
                context.symbol_table,
                type_name,
                scope_name
            )
            If type_symbol.name not equals "":
                Break
            End If
        End For
    End If

    Note: If still not found, check imported types
    If type_symbol.name equals "":
        Let imports be ScopeAnalyzer.get_imports_in_scope(context.scope_analyzer)
        For Each import_alias in imports:
            Let qualified_name be import_alias + "." + type_name
            Set type_symbol to SymbolTable.lookup_symbol(
                context.symbol_table,
                qualified_name,
                "global"
            )
            If type_symbol.name not equals "":
                Break
            End If
        End For
    End If

    Note: If type not found, return unknown
    If type_symbol.name equals "":
        Return TypeChecker.TypeInfo with
            type_name as "Unknown",
            type_kind as TypeChecker.TypeKind.Unknown,
            is_nullable as false,
            is_mutable as false,
            generic_params as List[String],
            constraints as List[String]
        End TypeChecker.TypeInfo
    End If

    Note: Extract type information from symbol
    Let type_kind_str be Dictionary.get(type_symbol.metadata, "type_kind")
    Let type_kind be TypeChecker.TypeKind.UserDefined
    If type_kind_str equals "struct":
        Set type_kind to TypeChecker.TypeKind.Struct
    Otherwise If type_kind_str equals "enum":
        Set type_kind to TypeChecker.TypeKind.Enum
    Otherwise If type_kind_str equals "interface":
        Set type_kind to TypeChecker.TypeKind.Interface
    End If

    Note: Extract generic parameters if present
    Let generic_params be List[String]
    Let generic_params_str be Dictionary.get(type_symbol.metadata, "generic_params")
    If generic_params_str is not null:
        Set generic_params to StringPrimitive.split(generic_params_str, ",")
    End If

    Note: Check type attributes from AST
    Let is_nullable be Dictionary.get(type_ref_ast.attributes, "is_nullable") equals "true"
    Let is_mutable be Dictionary.get(type_ref_ast.attributes, "is_mutable") equals "true"

    Note: Extract constraints if present
    Let constraints be List[String]
    If type_ref_ast.children is not null:
        For Each child_id in type_ref_ast.children:
            Let child_node be AST.get_node_by_id_direct(context.ast_builder, child_id)
            If child_node.node_type equals "Constraint":
                Let constraint be Dictionary.get(child_node.attributes, "constraint")
                List.add(constraints, constraint)
            End If
        End For
    End If

    Return TypeChecker.TypeInfo with
        type_name as type_name,
        type_kind as type_kind,
        is_nullable as is_nullable,
        is_mutable as is_mutable,
        generic_params as generic_params,
        constraints as constraints
    End TypeChecker.TypeInfo
End Process

Process called "resolve_function_call" that takes context as SemanticContext, call_ast as AST.ASTNode returns SymbolTable.Symbol:
    @Implementation
    Resolves a function call to its definition, handling overloading and
    method resolution.
    @End Implementation
    
    @Reasoning
    Function call resolution must handle overloading, method dispatch, and
    generic instantiation to find the correct function.
    @End Reasoning
    
    Note: Extract function name from AST node
    Let func_name be Dictionary.get(call_ast.attributes, "function_name")
    If func_name equals null:
        Note: Try to extract from first child if it's an identifier
        If call_ast.children is not null:
            If List.length(call_ast.children) > 0:
                Let func_node_id be List.get(call_ast.children, 0)
                Let func_node be AST.get_node_by_id_direct(context.ast_builder, func_node_id)
                If func_node.node_type equals "Identifier":
                    Set func_name to Dictionary.get(func_node.attributes, "name")
                End If
            End If
        End If
    End If

    If func_name equals null:
        Note: Return empty symbol for error case
        Return SymbolTable.Symbol with
            name as "",
            symbol_type as SymbolTable.SymbolType.Function,
            data_type as "",
            scope as "",
            metadata as Dictionary[String, String]
        End SymbolTable.Symbol
    End If

    Note: Check if this is a method call (has receiver)
    Let is_method_call be Dictionary.get(call_ast.attributes, "is_method_call") equals "true"
    Let receiver_type be ""

    If is_method_call:
        Note: Get receiver type for method resolution
        If call_ast.children is not null:
            If List.length(call_ast.children) > 0:
                Let receiver_id be List.get(call_ast.children, 0)
                Let receiver_node be AST.get_node_by_id_direct(context.ast_builder, receiver_id)
                Let receiver_ast_str be AST.serialize_ast(context.ast_builder, receiver_node, "runa")
                Set receiver_type to TypeChecker.check_expression_type(
                    context.type_checker,
                    receiver_ast_str
                )
                Note: Adjust function name to include type
                Set func_name to receiver_type + "." + func_name
            End If
        End If
    End If

    Note: Look up function in symbol table
    Let current_scope be ScopeAnalyzer.get_current_scope(context.scope_analyzer)
    Let func_symbol be SymbolTable.lookup_symbol(
        context.symbol_table,
        func_name,
        current_scope.scope_name
    )

    Note: If not found in current scope, search parent scopes
    If func_symbol.name equals "":
        Let scope_chain be ScopeAnalyzer.get_scope_chain(context.scope_analyzer)
        For Each scope_name in scope_chain:
            Set func_symbol to SymbolTable.lookup_symbol(
                context.symbol_table,
                func_name,
                scope_name
            )
            If func_symbol.name not equals "":
                Break
            End If
        End For
    End If

    Note: Check imported functions
    If func_symbol.name equals "":
        Let imports be ScopeAnalyzer.get_imports_in_scope(context.scope_analyzer)
        For Each import_alias in imports:
            Note: Check both direct and qualified names
            Let qualified_name be import_alias + "." + func_name
            Set func_symbol to SymbolTable.lookup_symbol(
                context.symbol_table,
                qualified_name,
                "global"
            )
            If func_symbol.name not equals "":
                Break
            End If
        End For
    End If

    Note: Handle overloading - find best match based on arguments
    If func_symbol.name not equals "":
        Note: Count arguments
        Let arg_count be 0
        If call_ast.children is not null:
            Set arg_count to List.length(call_ast.children)
            If is_method_call and arg_count > 0:
                Set arg_count to arg_count - 1
            End If
        End If

        Note: Check if parameter count matches
        Let param_count_str be Dictionary.get(func_symbol.metadata, "parameter_count")
        If param_count_str is not null:
            Let param_count be StringPrimitive.string_to_integer(param_count_str)
            If param_count not equals arg_count:
                Note: Look for overloaded version
                Let overloaded_name be func_name + "_" + StringPrimitive.integer_to_string(arg_count)
                Let overloaded_symbol be SymbolTable.lookup_symbol(
                    context.symbol_table,
                    overloaded_name,
                    current_scope.scope_name
                )
                If overloaded_symbol.name not equals "":
                    Set func_symbol to overloaded_symbol
                End If
            End If
        End If
    End If

    Return func_symbol
End Process

Note: =====================================================================
Note: IMPORT RESOLUTION SKELETONS
Note: =====================================================================

Process called "resolve_imports" that takes context as SemanticContext, imports as List[String] returns List[Errors.CompilerError]:
    @Implementation
    Resolves all import statements, loading imported modules and adding their
    exported symbols to the symbol table.
    @End Implementation

    @Reasoning
    Import resolution must happen early in semantic analysis to make imported
    symbols available for the rest of the analysis.
    @End Reasoning

    Let errors be List[Errors.CompilerError]
    Let resolved_count be 0
    Let import_chain be List[String]

    Note: Process each import path
    For Each import_path in imports:
        Note: Check for circular dependencies first
        List.add(import_chain, import_path)
        Let is_circular be check_circular_imports(context, import_path)
        If is_circular:
            Let error be Errors.create_semantic_error("Circular import detected: " + import_path)
            List.add(errors, error)
            List.remove_last(import_chain)
            Continue
        End If

        Note: Look up the import symbol
        Let import_symbol be SymbolTable.lookup_symbol(
            context.symbol_table,
            import_path,
            "global"
        )

        If import_symbol.name equals "":
            Let error be Errors.create_semantic_error("Cannot resolve import: " + import_path)
            List.add(errors, error)
            List.remove_last(import_chain)
            Continue
        End If

        Note: Check if already resolved
        Let is_resolved be Dictionary.get(import_symbol.metadata, "resolved") equals "true"
        If is_resolved:
            Set resolved_count to resolved_count + 1
            List.remove_last(import_chain)
            Continue
        End If

        Note: Get the actual module path
        Let module_path be Dictionary.get(import_symbol.metadata, "module_path")
        If module_path equals null:
            Set module_path to import_path
        End If

        Note: Create scope for imported module
        Let module_scope be "module_" + import_path
        ScopeAnalyzer.enter_scope(context.scope_analyzer, module_scope, "module")

        Note: Load module exports
        Let exports be load_module_exports(context, module_path)

        Note: Check for selective imports
        Let is_selective be Dictionary.get(import_symbol.metadata, "is_selective") equals "true"
        If is_selective:
            Let selective_imports be Dictionary.get(import_symbol.metadata, "selective_imports")
            If selective_imports is not null:
                Let selected_names be StringPrimitive.split(selective_imports, ",")
                For Each export_symbol in exports:
                    Let export_name be export_symbol.name
                    Let is_selected be false
                    For Each selected_name in selected_names:
                        If export_name equals selected_name:
                            Set is_selected to true
                            Break
                        End If
                    End For
                    If is_selected:
                        Note: Add selected symbol to current scope
                        Let imported_symbol be SymbolTable.Symbol with
                            name as export_name,
                            symbol_type as export_symbol.symbol_type,
                            data_type as export_symbol.data_type,
                            scope as ScopeAnalyzer.get_current_scope(context.scope_analyzer).scope_name,
                            metadata as export_symbol.metadata
                        End SymbolTable.Symbol
                        SymbolTable.add_symbol(context.symbol_table, imported_symbol)
                    End If
                End For
            End If
        Otherwise:
            Note: Import all exports
            For Each export_symbol in exports:
                Note: Add prefixed symbol to current scope
                Let prefixed_name be import_path + "." + export_symbol.name
                Let imported_symbol be SymbolTable.Symbol with
                    name as prefixed_name,
                    symbol_type as export_symbol.symbol_type,
                    data_type as export_symbol.data_type,
                    scope as module_scope,
                    metadata as export_symbol.metadata
                End SymbolTable.Symbol
                SymbolTable.add_symbol(context.symbol_table, imported_symbol)
            End For
        End If

        Note: Mark import as resolved
        Dictionary.set(import_symbol.metadata, "resolved", "true")
        Set resolved_count to resolved_count + 1

        Note: Exit module scope
        ScopeAnalyzer.exit_scope(context.scope_analyzer)
        List.remove_last(import_chain)
    End For

    Return errors
End Process

Process called "check_circular_imports" that takes context as SemanticContext, module_path as String returns Boolean:
    @Implementation
    Checks for circular import dependencies by tracking the import chain.
    Returns true if a circular dependency is detected.
    @End Implementation

    @Reasoning
    Circular imports can cause infinite loops during compilation and must be
    detected and reported as errors.
    @End Reasoning

    Note: Get or create import tracking metadata
    Let import_tracker be Dictionary.get(context.symbol_table.metadata, "import_chain")
    If import_tracker equals null:
        Set import_tracker to List[String]
        Dictionary.set(context.symbol_table.metadata, "import_chain", import_tracker)
    End If

    Note: Check if module is already in the import chain
    For Each imported_module in import_tracker:
        If imported_module equals module_path:
            Note: Circular dependency detected
            Return true
        End If
    End For

    Note: Add current module to import chain
    List.add(import_tracker, module_path)

    Note: Check dependencies of this module
    Let module_symbol be SymbolTable.lookup_symbol(
        context.symbol_table,
        module_path,
        "global"
    )

    If module_symbol.name not equals "":
        Let dependencies be Dictionary.get(module_symbol.metadata, "dependencies")
        If dependencies is not null:
            Let dep_list be StringPrimitive.split(dependencies, ",")
            For Each dependency in dep_list:
                Let is_circular be check_circular_imports(context, dependency)
                If is_circular:
                    Note: Remove from chain before returning
                    List.remove_last(import_tracker)
                    Return true
                End If
            End For
        End If
    End If

    Note: Remove from import chain after checking
    List.remove_last(import_tracker)
    Return false
End Process

Process called "load_module_exports" that takes context as SemanticContext, module_path as String returns List[SymbolTable.Symbol]:
    @Implementation
    Loads the exported symbols from a module by reading from compiled module files
    or source files. Returns module's public symbols.
    @End Implementation

    @Reasoning
    Module exports need to be loaded to make imported symbols available in the
    importing module's scope.
    @End Reasoning

    Let exports be List[SymbolTable.Symbol]

    Note: Find all symbols in the module scope
    Let module_scope be "module_" + module_path
    Let all_symbols be SymbolTable.get_symbols_in_scope(
        context.symbol_table,
        module_scope
    )

    Note: Filter for exported symbols (public visibility)
    For Each symbol in all_symbols:
        Let visibility be Dictionary.get(symbol.metadata, "visibility")
        If visibility equals "public" or visibility equals null:
            Note: Default visibility is public if not specified
            List.add(exports, symbol)
        End If
    End For

    Return exports
End Process

Note: =====================================================================
Note: SEMANTIC VALIDATION SKELETONS
Note: =====================================================================

Process called "check_duplicate_definitions" that takes context as SemanticContext, scope as String returns List[Errors.CompilerError]:
    @Implementation
    Checks for duplicate symbol definitions within the same scope, including
    functions, types, and variables.
    @End Implementation

    @Reasoning
    Duplicate definitions are errors that must be caught during semantic analysis
    to prevent ambiguity and ensure program correctness.
    @End Reasoning

    Let errors be List[Errors.CompilerError]
    Let seen_symbols be Dictionary[String, String]

    Note: Get all symbols in the specified scope
    Let symbols_in_scope be SymbolTable.get_symbols_in_scope(
        context.symbol_table,
        scope
    )

    Note: Check each symbol for duplicates
    For Each symbol in symbols_in_scope:
        Let symbol_key be symbol.name

        Note: For functions, include parameter count in key to support overloading
        If symbol.symbol_type equals SymbolTable.SymbolType.Function:
            Let param_count be Dictionary.get(symbol.metadata, "parameter_count")
            If param_count is not null:
                Set symbol_key to symbol_key + "_" + param_count
            End If
        End If

        Note: Check if we've seen this symbol before
        Let previous_location be Dictionary.get(seen_symbols, symbol_key)
        If previous_location is not null:
            Note: Duplicate found
            Let error_msg be "Duplicate definition of '" + symbol.name + "' in scope '" + scope + "'"
            If previous_location not equals "":
                Set error_msg to error_msg + ". Previously defined at " + previous_location
            End If
            Let error be Errors.create_semantic_error(error_msg)
            List.add(errors, error)
        Otherwise:
            Note: Record this symbol
            Let location be Dictionary.get(symbol.metadata, "node_id")
            If location equals null:
                Set location to "unknown"
            End If
            Dictionary.set(seen_symbols, symbol_key, location)
        End If
    End For

    Note: Check for shadowing from parent scopes if needed
    Let check_shadowing be Dictionary.get(context.symbol_table.metadata, "check_shadowing") equals "true"
    If check_shadowing:
        Let parent_scope be ScopeAnalyzer.get_parent_scope(context.scope_analyzer, scope)
        If parent_scope.scope_name not equals "":
            For Each symbol in symbols_in_scope:
                Let parent_symbol be SymbolTable.lookup_symbol(
                    context.symbol_table,
                    symbol.name,
                    parent_scope.scope_name
                )
                If parent_symbol.name not equals "":
                    Let warning_msg be "Symbol '" + symbol.name + "' shadows definition from parent scope '" + parent_scope.scope_name + "'"
                    Let warning be Errors.create_semantic_warning(warning_msg)
                    List.add(errors, warning)
                End If
            End For
        End If
    End If

    Return errors
End Process

Process called "check_return_statements" that takes context as SemanticContext, function_ast as AST.ASTNode returns List[Errors.CompilerError]:
    @Implementation
    Validates return statements in a function, ensuring all paths return a value
    of the correct type and that void functions don't return values.
    @End Implementation
    
    @Reasoning
    Return statement validation ensures type safety and that all code paths
    in non-void functions return appropriate values.
    @End Reasoning
    
    Let errors be List[Errors.CompilerError]

    Note: Extract function return type
    Let return_type be Dictionary.get(function_ast.attributes, "return_type")
    If return_type equals null:
        Set return_type to "Void"
    End If

    Note: Track if all paths return
    Let all_paths_return be analyze_return_paths(context, function_ast)

    Note: Check if non-void function has all paths returning
    If return_type not equals "Void":
        If not all_paths_return:
            Let func_name be Dictionary.get(function_ast.attributes, "name")
            Let error_msg be "Function '" + func_name + "' must return a value of type '" + return_type + "' on all code paths"
            Let error be Errors.create_semantic_error(error_msg)
            List.add(errors, error)
        End If
    End If

    Note: Check each return statement in the function
    Let return_statements be find_return_statements(context, function_ast)
    For Each return_stmt in return_statements:
        Let return_value_id be ""
        If return_stmt.children is not null:
            If List.length(return_stmt.children) > 0:
                Set return_value_id to List.get(return_stmt.children, 0)
            End If
        End If

        If return_type equals "Void":
            Note: Void function shouldn't return a value
            If return_value_id not equals "":
                Let error_msg be "Void function cannot return a value"
                Let error be Errors.create_semantic_error(error_msg)
                List.add(errors, error)
            End If
        Otherwise:
            Note: Non-void function must return a value
            If return_value_id equals "":
                Let error_msg be "Function must return a value of type '" + return_type + "'"
                Let error be Errors.create_semantic_error(error_msg)
                List.add(errors, error)
            Otherwise:
                Note: Check return value type matches function return type
                Let return_value_node be AST.get_node_by_id_direct(context.ast_builder, return_value_id)
                If return_value_node.node_id not equals "":
                    Let value_ast_str be AST.serialize_ast(context.ast_builder, return_value_node, "runa")
                    Let value_type be TypeChecker.check_expression_type(
                        context.type_checker,
                        value_ast_str
                    )
                    If value_type not equals return_type:
                        Let error_msg be "Return type mismatch: expected '" + return_type + "' but got '" + value_type + "'"
                        Let error be Errors.create_type_error(error_msg)
                        List.add(errors, error)
                    End If
                End If
            End If
        End If
    End For

    Return errors
End Process

Process called "analyze_return_paths" that takes context as SemanticContext, function_ast as AST.ASTNode returns Boolean:
    @Implementation
    Analyzes if all code paths in a function return a value.
    @End Implementation

    @Reasoning
    Non-void functions must return on all paths to ensure type safety.
    @End Reasoning

    Note: Check function body
    If function_ast.children is null:
        Return false
    End If

    Note: Find the function body (usually last child)
    Let body_node_id be ""
    For Each child_id in function_ast.children:
        Let child_node be AST.get_node_by_id_direct(context.ast_builder, child_id)
        If child_node.node_type equals "Block" or child_node.node_type equals "FunctionBody":
            Set body_node_id to child_id
            Break
        End If
    End For

    If body_node_id equals "":
        Return false
    End If

    Let body_node be AST.get_node_by_id_direct(context.ast_builder, body_node_id)
    Return analyze_block_returns(context, body_node)
End Process

Process called "analyze_block_returns" that takes context as SemanticContext, block_node as AST.ASTNode returns Boolean:
    @Implementation
    Checks if a block always returns.
    @End Implementation

    If block_node.children is null:
        Return false
    End If

    Let has_return be false
    Let has_unconditional_return be false

    For Each stmt_id in block_node.children:
        Let stmt_node be AST.get_node_by_id_direct(context.ast_builder, stmt_id)

        If stmt_node.node_type equals "Return":
            Set has_unconditional_return to true
            Break
        Otherwise If stmt_node.node_type equals "If":
            Note: Check if both branches return
            Let if_returns be analyze_if_returns(context, stmt_node)
            If if_returns:
                Set has_unconditional_return to true
                Break
            End If
        Otherwise If stmt_node.node_type equals "Match":
            Note: Check if all match arms return and is exhaustive
            Let match_returns be analyze_match_returns(context, stmt_node)
            If match_returns:
                Set has_unconditional_return to true
                Break
            End If
        End If
    End For

    Return has_unconditional_return
End Process

Process called "analyze_if_returns" that takes context as SemanticContext, if_node as AST.ASTNode returns Boolean:
    @Implementation
    Checks if both branches of an if statement return.
    @End Implementation

    If if_node.children is null:
        Return false
    End If

    Let child_count be List.length(if_node.children)
    If child_count < 3:
        Note: No else branch
        Return false
    End If

    Note: Check then branch
    Let then_id be List.get(if_node.children, 1)
    Let then_node be AST.get_node_by_id_direct(context.ast_builder, then_id)
    Let then_returns be analyze_block_returns(context, then_node)

    Note: Check else branch
    Let else_id be List.get(if_node.children, 2)
    Let else_node be AST.get_node_by_id_direct(context.ast_builder, else_id)
    Let else_returns be analyze_block_returns(context, else_node)

    Return then_returns and else_returns
End Process

Process called "analyze_match_returns" that takes context as SemanticContext, match_node as AST.ASTNode returns Boolean:
    @Implementation
    Checks if all match arms return and the match is exhaustive.
    @End Implementation

    If match_node.children is null:
        Return false
    End If

    Let all_arms_return be true
    Let has_default be false

    For Each arm_id in match_node.children:
        Let arm_node be AST.get_node_by_id_direct(context.ast_builder, arm_id)
        If arm_node.node_type equals "MatchArm":
            Let pattern be Dictionary.get(arm_node.attributes, "pattern")
            If pattern equals "_" or pattern equals "default":
                Set has_default to true
            End If

            If arm_node.children is not null:
                If List.length(arm_node.children) > 0:
                    Let body_id be List.get(arm_node.children, List.length(arm_node.children) - 1)
                    Let body_node be AST.get_node_by_id_direct(context.ast_builder, body_id)
                    Let arm_returns be analyze_block_returns(context, body_node)
                    If not arm_returns:
                        Set all_arms_return to false
                    End If
                Otherwise:
                    Set all_arms_return to false
                End If
            Otherwise:
                Set all_arms_return to false
            End If
        End If
    End For

    Return all_arms_return and has_default
End Process

Process called "find_return_statements" that takes context as SemanticContext, node as AST.ASTNode returns List[AST.ASTNode]:
    @Implementation
    Finds all return statements in a function body.
    @End Implementation

    Let returns be List[AST.ASTNode]

    If node.node_type equals "Return":
        List.add(returns, node)
        Return returns
    End If

    If node.children is not null:
        For Each child_id in node.children:
            Let child_node be AST.get_node_by_id_direct(context.ast_builder, child_id)
            If child_node.node_id not equals "":
                Let child_returns be find_return_statements(context, child_node)
                For Each ret in child_returns:
                    List.add(returns, ret)
                End For
            End If
        End For
    End If

    Return returns
End Process

Process called "check_break_continue" that takes context as SemanticContext, statement_ast as AST.ASTNode returns List[Errors.CompilerError]:
    @Implementation
    Validates that break and continue statements only appear within loops
    and that labeled breaks/continues refer to valid labels.
    @End Implementation
    
    @Reasoning
    Break and continue statements must be properly scoped within loops to
    ensure control flow integrity.
    @End Reasoning

    Let errors be List[Errors.CompilerError]

    Note: Determine statement type
    Let stmt_type be statement_ast.node_type
    If stmt_type not equals "Break" and stmt_type not equals "Continue":
        Note: Not a break or continue statement
        Return errors
    End If

    Note: Check if we're inside a loop
    Let is_in_loop be is_within_loop_context(context)
    If not is_in_loop:
        Let error_msg be stmt_type + " statement not within a loop"
        Let error be Errors.create_semantic_error(error_msg)
        List.add(errors, error)
        Return errors
    End If

    Note: Check for labeled break/continue
    Let label be Dictionary.get(statement_ast.attributes, "label")
    If label is not null:
        Note: Verify label exists and is reachable
        Let label_scope be find_label_scope(context, label)
        If label_scope equals "":
            Let error_msg be "Undefined label: '" + label + "'"
            Let error be Errors.create_semantic_error(error_msg)
            List.add(errors, error)
        Otherwise:
            Note: Check if label is on a loop
            Let label_on_loop be is_label_on_loop(context, label)
            If not label_on_loop:
                Let error_msg be "Label '" + label + "' is not on a loop statement"
                Let error be Errors.create_semantic_error(error_msg)
                List.add(errors, error)
            End If
        End If
    End If

    Return errors
End Process

Process called "is_within_loop_context" that takes context as SemanticContext returns Boolean:
    @Implementation
    Checks if the current context is within a loop.
    @End Implementation

    Let scope_chain be ScopeAnalyzer.get_scope_chain(context.scope_analyzer)
    For Each scope_name in scope_chain:
        If StringPrimitive.contains(scope_name, "loop_") or
           StringPrimitive.contains(scope_name, "while_") or
           StringPrimitive.contains(scope_name, "for_"):
            Return true
        End If
    End For
    Return false
End Process

Process called "find_label_scope" that takes context as SemanticContext, label as String returns String:
    @Implementation
    Finds the scope where a label is defined.
    @End Implementation

    Let label_symbol be SymbolTable.lookup_symbol(
        context.symbol_table,
        "label_" + label,
        ScopeAnalyzer.get_current_scope(context.scope_analyzer).scope_name
    )

    If label_symbol.name not equals "":
        Return label_symbol.scope
    End If

    Note: Search parent scopes
    Let scope_chain be ScopeAnalyzer.get_scope_chain(context.scope_analyzer)
    For Each scope_name in scope_chain:
        Set label_symbol to SymbolTable.lookup_symbol(
            context.symbol_table,
            "label_" + label,
            scope_name
        )
        If label_symbol.name not equals "":
            Return label_symbol.scope
        End If
    End For

    Return ""
End Process

Process called "is_label_on_loop" that takes context as SemanticContext, label as String returns Boolean:
    @Implementation
    Checks if a label is attached to a loop statement.
    @End Implementation

    Let label_symbol be SymbolTable.lookup_symbol(
        context.symbol_table,
        "label_" + label,
        ScopeAnalyzer.get_current_scope(context.scope_analyzer).scope_name
    )

    If label_symbol.name equals "":
        Note: Search parent scopes
        Let scope_chain be ScopeAnalyzer.get_scope_chain(context.scope_analyzer)
        For Each scope_name in scope_chain:
            Set label_symbol to SymbolTable.lookup_symbol(
                context.symbol_table,
                "label_" + label,
                scope_name
            )
            If label_symbol.name not equals "":
                Break
            End If
        End For
    End If

    If label_symbol.name not equals "":
        Let attached_to be Dictionary.get(label_symbol.metadata, "attached_to")
        Return attached_to equals "loop" or attached_to equals "while" or attached_to equals "for"
    End If

    Return false
End Process

Process called "check_unreachable_code" that takes context as SemanticContext, block_ast as AST.ASTNode returns List[Errors.CompilerError]:
    @Implementation
    Detects unreachable code after return, break, continue, or throw statements
    and reports it as a warning or error.
    @End Implementation

    @Reasoning
    Unreachable code indicates potential logic errors and should be flagged
    to help developers identify dead code.
    @End Reasoning

    Let errors be List[Errors.CompilerError]

    If block_ast.node_type not equals "Block":
        Return errors
    End If

    Let statements be block_ast.children
    Let found_terminator be false
    Let terminator_index be -1

    Note: Find first terminating statement (return, break, continue, throw)
    Let index be 0
    For Each stmt in statements:
        If is_terminating_statement(stmt):
            Set found_terminator to true
            Set terminator_index to index
            Break
        End If
        Set index to index + 1
    End For

    Note: Check for unreachable code after terminator
    If found_terminator:
        Let remaining be List.size(statements) - terminator_index - 1
        If remaining > 0:
            Note: There are statements after the terminator
            Let first_unreachable be List.get(statements, terminator_index + 1)
            Let line_num be Dictionary.get(first_unreachable.attributes, "line")
            Let error_msg be "Unreachable code detected at line " + IntegerPrimitive.to_string(line_num)
            Let error be Errors.create_semantic_error(error_msg)
            List.add(errors, error)
        End If
    End If

    Note: Recursively check nested blocks
    For Each stmt in statements:
        If stmt.node_type equals "If":
            Let then_block be Dictionary.get(stmt.attributes, "then_block")
            If then_block.node_type equals "Block":
                Let nested_errors be check_unreachable_code(context, then_block)
                For Each err in nested_errors:
                    List.add(errors, err)
                End For
            End If

            Let else_block be Dictionary.get(stmt.attributes, "else_block")
            If else_block.node_type equals "Block":
                Let nested_errors be check_unreachable_code(context, else_block)
                For Each err in nested_errors:
                    List.add(errors, err)
                End For
            End If
        Otherwise If stmt.node_type equals "While" or stmt.node_type equals "For":
            Let body be Dictionary.get(stmt.attributes, "body")
            If body.node_type equals "Block":
                Let nested_errors be check_unreachable_code(context, body)
                For Each err in nested_errors:
                    List.add(errors, err)
                End For
            End If
        Otherwise If stmt.node_type equals "Match":
            Let cases be Dictionary.get(stmt.attributes, "cases")
            For Each case_node in cases:
                Let case_body be Dictionary.get(case_node.attributes, "body")
                If case_body.node_type equals "Block":
                    Let nested_errors be check_unreachable_code(context, case_body)
                    For Each err in nested_errors:
                        List.add(errors, err)
                    End For
                End If
            End For
        Otherwise If stmt.node_type equals "Try":
            Let try_block be Dictionary.get(stmt.attributes, "try_block")
            If try_block.node_type equals "Block":
                Let nested_errors be check_unreachable_code(context, try_block)
                For Each err in nested_errors:
                    List.add(errors, err)
                End For
            End If

            Let catch_blocks be Dictionary.get(stmt.attributes, "catch_blocks")
            For Each catch_block in catch_blocks:
                Let catch_body be Dictionary.get(catch_block.attributes, "body")
                If catch_body.node_type equals "Block":
                    Let nested_errors be check_unreachable_code(context, catch_body)
                    For Each err in nested_errors:
                        List.add(errors, err)
                    End For
                End If
            End For

            Let finally_block be Dictionary.get(stmt.attributes, "finally_block")
            If finally_block.node_type equals "Block":
                Let nested_errors be check_unreachable_code(context, finally_block)
                For Each err in nested_errors:
                    List.add(errors, err)
                End For
            End If
        End If
    End For

    Return errors
End Process

Process called "is_terminating_statement" that takes stmt as AST.ASTNode returns Boolean:
    @Implementation
    Checks if a statement is a terminating statement that prevents subsequent
    code from executing (return, break, continue, throw).
    @End Implementation

    Let stmt_type be stmt.node_type
    Return stmt_type equals "Return" or
           stmt_type equals "Break" or
           stmt_type equals "Continue" or
           stmt_type equals "Throw"
End Process

Note: =====================================================================
Note: AST ANNOTATION SKELETONS
Note: =====================================================================

Process called "annotate_with_types" that takes context as SemanticContext, ast_node as AST.ASTNode returns AST.ASTNode:
    @Implementation
    Annotates AST nodes with their resolved type information for use by
    later compilation phases.
    @End Implementation

    @Reasoning
    Type annotations on the AST are essential for code generation and
    optimization phases that need type information.
    @End Reasoning

    Note: Add type annotation based on node type
    Let node_type be ast_node.node_type

    Match node_type:
        When "Identifier":
            Let name be Dictionary.get(ast_node.attributes, "name")
            Let symbol be SymbolTable.lookup_symbol(
                context.symbol_table,
                name,
                ScopeAnalyzer.get_current_scope(context.scope_analyzer).scope_name
            )
            If symbol.name not equals "":
                Dictionary.set(ast_node.attributes, "resolved_type", symbol.value_type)
            End If

        When "Literal":
            Let literal_type be Dictionary.get(ast_node.attributes, "literal_type")
            Match literal_type:
                When "Integer":
                    Dictionary.set(ast_node.attributes, "resolved_type", "Integer")
                When "Float":
                    Dictionary.set(ast_node.attributes, "resolved_type", "Float")
                When "String":
                    Dictionary.set(ast_node.attributes, "resolved_type", "String")
                When "Boolean":
                    Dictionary.set(ast_node.attributes, "resolved_type", "Boolean")
                When "Null":
                    Dictionary.set(ast_node.attributes, "resolved_type", "Null")
            End Match

        When "BinaryOp":
            Note: Annotate operands first
            Let left be Dictionary.get(ast_node.attributes, "left")
            Let right be Dictionary.get(ast_node.attributes, "right")
            Set left to annotate_with_types(context, left)
            Set right to annotate_with_types(context, right)
            Dictionary.set(ast_node.attributes, "left", left)
            Dictionary.set(ast_node.attributes, "right", right)

            Note: Determine result type based on operator and operand types
            Let op be Dictionary.get(ast_node.attributes, "operator")
            Let left_type be Dictionary.get(left.attributes, "resolved_type")
            Let right_type be Dictionary.get(right.attributes, "resolved_type")
            Let result_type be infer_binary_op_type(op, left_type, right_type)
            Dictionary.set(ast_node.attributes, "resolved_type", result_type)

        When "UnaryOp":
            Let operand be Dictionary.get(ast_node.attributes, "operand")
            Set operand to annotate_with_types(context, operand)
            Dictionary.set(ast_node.attributes, "operand", operand)

            Let op be Dictionary.get(ast_node.attributes, "operator")
            Let operand_type be Dictionary.get(operand.attributes, "resolved_type")
            Let result_type be infer_unary_op_type(op, operand_type)
            Dictionary.set(ast_node.attributes, "resolved_type", result_type)

        When "FunctionCall":
            Let func_name be Dictionary.get(ast_node.attributes, "name")
            Let func_symbol be SymbolTable.lookup_symbol(
                context.symbol_table,
                func_name,
                ScopeAnalyzer.get_current_scope(context.scope_analyzer).scope_name
            )
            If func_symbol.name not equals "":
                Let return_type be Dictionary.get(func_symbol.metadata, "return_type")
                Dictionary.set(ast_node.attributes, "resolved_type", return_type)
            End If

            Note: Annotate arguments
            Let args be Dictionary.get(ast_node.attributes, "arguments")
            Let annotated_args be List[AST.ASTNode]
            For Each arg in args:
                Let annotated_arg be annotate_with_types(context, arg)
                List.add(annotated_args, annotated_arg)
            End For
            Dictionary.set(ast_node.attributes, "arguments", annotated_args)

        When "ArrayLiteral":
            Let elements be Dictionary.get(ast_node.attributes, "elements")
            Let annotated_elements be List[AST.ASTNode]
            Let element_type be ""

            For Each elem in elements:
                Let annotated_elem be annotate_with_types(context, elem)
                List.add(annotated_elements, annotated_elem)
                If element_type equals "":
                    Set element_type to Dictionary.get(annotated_elem.attributes, "resolved_type")
                End If
            End For
            Dictionary.set(ast_node.attributes, "elements", annotated_elements)
            Dictionary.set(ast_node.attributes, "resolved_type", "List[" + element_type + "]")

        When "MemberAccess":
            Let object be Dictionary.get(ast_node.attributes, "object")
            Set object to annotate_with_types(context, object)
            Dictionary.set(ast_node.attributes, "object", object)

            Let object_type be Dictionary.get(object.attributes, "resolved_type")
            Let member be Dictionary.get(ast_node.attributes, "member")
            Let member_type be resolve_member_type(context, object_type, member)
            Dictionary.set(ast_node.attributes, "resolved_type", member_type)
    End Match

    Note: Recursively annotate children
    Let index be 0
    For Each child in ast_node.children:
        Let annotated_child be annotate_with_types(context, child)
        List.set(ast_node.children, index, annotated_child)
        Set index to index + 1
    End For

    Return ast_node
End Process

Process called "infer_binary_op_type" that takes op as String, left_type as String, right_type as String returns String:
    @Implementation
    Infers the result type of a binary operation based on operator and operand types.
    @End Implementation

    Note: Arithmetic operators
    If op equals "+" or op equals "-" or op equals "*" or op equals "/" or op equals "%":
        If left_type equals "Float" or right_type equals "Float":
            Return "Float"
        Otherwise If left_type equals "Integer" and right_type equals "Integer":
            Return "Integer"
        Otherwise If left_type equals "String" and op equals "+":
            Return "String"
        End If
    End If

    Note: Comparison operators
    If op equals "<" or op equals ">" or op equals "<=" or op equals ">=" or op equals "==" or op equals "!=":
        Return "Boolean"
    End If

    Note: Logical operators
    If op equals "and" or op equals "or":
        Return "Boolean"
    End If

    Note: Bitwise operators
    If op equals "&" or op equals "|" or op equals "^" or op equals "<<" or op equals ">>":
        Return "Integer"
    End If

    Return "Unknown"
End Process

Process called "infer_unary_op_type" that takes op as String, operand_type as String returns String:
    @Implementation
    Infers the result type of a unary operation based on operator and operand type.
    @End Implementation

    If op equals "-" or op equals "+":
        Return operand_type
    End If

    If op equals "not":
        Return "Boolean"
    End If

    If op equals "~":
        Return "Integer"
    End If

    Return "Unknown"
End Process

Process called "resolve_member_type" that takes context as SemanticContext, object_type as String, member as String returns String:
    @Implementation
    Resolves the type of a member access expression.
    @End Implementation

    Note: Look up type definition
    Let type_symbol be SymbolTable.lookup_symbol(
        context.symbol_table,
        object_type,
        "global"
    )

    If type_symbol.name not equals "":
        Let fields be Dictionary.get(type_symbol.metadata, "fields")
        If fields not equals null:
            For Each field_info in fields:
                Let field_name be Dictionary.get(field_info, "name")
                If field_name equals member:
                    Return Dictionary.get(field_info, "type")
                End If
            End For
        End If

        Note: Check for methods
        Let methods be Dictionary.get(type_symbol.metadata, "methods")
        If methods not equals null:
            For Each method_info in methods:
                Let method_name be Dictionary.get(method_info, "name")
                If method_name equals member:
                    Return Dictionary.get(method_info, "return_type")
                End If
            End For
        End If
    End If

    Return "Unknown"
End Process

Process called "annotate_with_symbols" that takes context as SemanticContext, ast_node as AST.ASTNode returns AST.ASTNode:
    @Implementation
    Annotates AST nodes with resolved symbol information, linking uses to
    their definitions.
    @End Implementation
    
    @Reasoning
    Symbol annotations create a direct link from symbol uses to their definitions,
    simplifying later compilation phases.
    @End Reasoning

    Let node_type be ast_node.node_type

    Match node_type:
        When "Identifier":
            Let name be Dictionary.get(ast_node.attributes, "name")
            Let current_scope be ScopeAnalyzer.get_current_scope(context.scope_analyzer).scope_name
            Let symbol be SymbolTable.lookup_symbol(context.symbol_table, name, current_scope)

            If symbol.name not equals "":
                Note: Link to symbol definition
                Dictionary.set(ast_node.attributes, "symbol_id", symbol.id)
                Dictionary.set(ast_node.attributes, "symbol_scope", symbol.scope)
                Dictionary.set(ast_node.attributes, "symbol_type", SymbolTable.symbol_type_to_string(symbol.symbol_type))

                Note: Track symbol usage
                track_symbol_usage(context, symbol.id, ast_node)
            End If

        When "FunctionCall":
            Let func_name be Dictionary.get(ast_node.attributes, "name")
            Let current_scope be ScopeAnalyzer.get_current_scope(context.scope_analyzer).scope_name
            Let func_symbol be SymbolTable.lookup_symbol(context.symbol_table, func_name, current_scope)

            If func_symbol.name not equals "":
                Dictionary.set(ast_node.attributes, "symbol_id", func_symbol.id)
                Dictionary.set(ast_node.attributes, "symbol_scope", func_symbol.scope)
                Dictionary.set(ast_node.attributes, "is_function", "true")

                Note: Track function usage
                track_symbol_usage(context, func_symbol.id, ast_node)
            End If

            Note: Annotate arguments
            Let args be Dictionary.get(ast_node.attributes, "arguments")
            Let annotated_args be List[AST.ASTNode]
            For Each arg in args:
                Let annotated_arg be annotate_with_symbols(context, arg)
                List.add(annotated_args, annotated_arg)
            End For
            Dictionary.set(ast_node.attributes, "arguments", annotated_args)

        When "TypeReference":
            Let type_name be Dictionary.get(ast_node.attributes, "name")
            Let type_symbol be SymbolTable.lookup_symbol(context.symbol_table, type_name, "global")

            If type_symbol.name not equals "":
                Dictionary.set(ast_node.attributes, "symbol_id", type_symbol.id)
                Dictionary.set(ast_node.attributes, "symbol_scope", type_symbol.scope)
                Dictionary.set(ast_node.attributes, "is_type", "true")

                track_symbol_usage(context, type_symbol.id, ast_node)
            End If

        When "MemberAccess":
            Let object be Dictionary.get(ast_node.attributes, "object")
            Set object to annotate_with_symbols(context, object)
            Dictionary.set(ast_node.attributes, "object", object)

            Note: Member resolution depends on object's type
            Let object_type be Dictionary.get(object.attributes, "resolved_type")
            If object_type not equals "":
                Let member_name be Dictionary.get(ast_node.attributes, "member")
                Let member_symbol_name be object_type + "." + member_name
                Let member_symbol be SymbolTable.lookup_symbol(context.symbol_table, member_symbol_name, "global")

                If member_symbol.name not equals "":
                    Dictionary.set(ast_node.attributes, "member_symbol_id", member_symbol.id)
                    track_symbol_usage(context, member_symbol.id, ast_node)
                End If
            End If

        When "BinaryOp":
            Let left be Dictionary.get(ast_node.attributes, "left")
            Let right be Dictionary.get(ast_node.attributes, "right")
            Set left to annotate_with_symbols(context, left)
            Set right to annotate_with_symbols(context, right)
            Dictionary.set(ast_node.attributes, "left", left)
            Dictionary.set(ast_node.attributes, "right", right)

        When "UnaryOp":
            Let operand be Dictionary.get(ast_node.attributes, "operand")
            Set operand to annotate_with_symbols(context, operand)
            Dictionary.set(ast_node.attributes, "operand", operand)

        When "ArrayLiteral":
            Let elements be Dictionary.get(ast_node.attributes, "elements")
            Let annotated_elements be List[AST.ASTNode]
            For Each elem in elements:
                Let annotated_elem be annotate_with_symbols(context, elem)
                List.add(annotated_elements, annotated_elem)
            End For
            Dictionary.set(ast_node.attributes, "elements", annotated_elements)

        When "Assignment":
            Let target be Dictionary.get(ast_node.attributes, "target")
            Let value be Dictionary.get(ast_node.attributes, "value")
            Set target to annotate_with_symbols(context, target)
            Set value to annotate_with_symbols(context, value)
            Dictionary.set(ast_node.attributes, "target", target)
            Dictionary.set(ast_node.attributes, "value", value)
    End Match

    Note: Recursively annotate children
    Let index be 0
    For Each child in ast_node.children:
        Let annotated_child be annotate_with_symbols(context, child)
        List.set(ast_node.children, index, annotated_child)
        Set index to index + 1
    End For

    Return ast_node
End Process

Note: =====================================================================
Note: ERROR RECOVERY SKELETONS
Note: =====================================================================

Process called "recover_from_error" that takes context as SemanticContext, error as Errors.CompilerError, ast_node as AST.ASTNode returns AST.ASTNode:
    @Implementation
    Attempts to recover from a semantic error by creating placeholder symbols
    or types to allow analysis to continue.
    @End Implementation

    @Reasoning
    Error recovery allows the compiler to report multiple errors in a single
    compilation pass rather than stopping at the first error.
    @End Reasoning

    Let error_type be error.error_type
    Let node_type be ast_node.node_type

    Match error_type:
        When "UndefinedSymbol":
            Note: Create placeholder symbol to allow continued analysis
            Let symbol_name be Dictionary.get(ast_node.attributes, "name")
            If symbol_name not equals "":
                Let placeholder_symbol be SymbolTable.Symbol with
                    id as "error_" + symbol_name,
                    name as symbol_name,
                    symbol_type as SymbolTable.SymbolType.Variable,
                    scope as ScopeAnalyzer.get_current_scope(context.scope_analyzer).scope_name,
                    value_type as "Unknown",
                    metadata as Dictionary[String, String]

                Note: Mark as error recovery symbol
                Dictionary.set(placeholder_symbol.metadata, "is_error_recovery", "true")
                Dictionary.set(placeholder_symbol.metadata, "error_id", error.id)

                SymbolTable.register_symbol(context.symbol_table, placeholder_symbol)
                Dictionary.set(ast_node.attributes, "is_error_recovery", "true")
            End If

        When "TypeMismatch":
            Note: Annotate with expected type to continue analysis
            Let expected_type be Dictionary.get(error.metadata, "expected_type")
            If expected_type not equals "":
                Dictionary.set(ast_node.attributes, "resolved_type", expected_type)
                Dictionary.set(ast_node.attributes, "has_type_error", "true")
            End If

        When "UndefinedType":
            Note: Create placeholder type
            Let type_name be Dictionary.get(ast_node.attributes, "name")
            If type_name not equals "":
                Let placeholder_type be SymbolTable.Symbol with
                    id as "error_type_" + type_name,
                    name as type_name,
                    symbol_type as SymbolTable.SymbolType.Type,
                    scope as "global",
                    value_type as "Type",
                    metadata as Dictionary[String, String]

                Dictionary.set(placeholder_type.metadata, "is_error_recovery", "true")
                SymbolTable.register_symbol(context.symbol_table, placeholder_type)
            End If

        When "DuplicateDefinition":
            Note: Mark node as duplicate but continue
            Dictionary.set(ast_node.attributes, "is_duplicate", "true")
            Dictionary.set(ast_node.attributes, "original_symbol", Dictionary.get(error.metadata, "original_symbol"))

        When "InvalidAccess":
            Note: Mark access as invalid but continue parsing
            Dictionary.set(ast_node.attributes, "access_error", "true")
            Dictionary.set(ast_node.attributes, "error_reason", error.message)
    End Match

    Note: Mark node as having been through error recovery
    Dictionary.set(ast_node.attributes, "error_recovery_applied", "true")

    Return ast_node
End Process

Process called "create_error_scope" that takes context as SemanticContext, error_location as String returns String:
    @Implementation
    Creates an error recovery scope to isolate errors and prevent cascading
    error reports from a single root cause.
    @End Implementation

    @Reasoning
    Error scopes help contain the impact of errors and prevent spurious
    error messages that result from earlier errors.
    @End Reasoning

    Note: Generate unique error scope name
    Let counter_key be "error_scope_counter"
    If not Dictionary.has_key(context.metadata, counter_key):
        Dictionary.set(context.metadata, counter_key, 0)
    End If
    Let counter be Dictionary.get(context.metadata, counter_key)
    Dictionary.set(context.metadata, counter_key, counter + 1)
    Let scope_name be "error_scope_" + error_location + "_" + IntegerPrimitive.to_string(counter)

    Note: Create error recovery scope
    Let error_scope be ScopeAnalyzer.Scope with
        scope_name as scope_name,
        scope_type as ScopeAnalyzer.ScopeType.Block,
        parent_scope as ScopeAnalyzer.get_current_scope(context.scope_analyzer).scope_name,
        symbols as List[String],
        metadata as Dictionary[String, String]

    Note: Mark as error recovery scope
    Dictionary.set(error_scope.metadata, "is_error_recovery", "true")
    Dictionary.set(error_scope.metadata, "error_location", error_location)

    Note: Push error scope
    ScopeAnalyzer.push_scope(context.scope_analyzer, error_scope)

    Note: Track error scope in context
    If not Dictionary.has_key(context.metadata, "error_scopes"):
        Dictionary.set(context.metadata, "error_scopes", List[String])
    End If
    Let error_scopes be Dictionary.get(context.metadata, "error_scopes")
    List.add(error_scopes, scope_name)

    Return scope_name
End Process

Note: =====================================================================
Note: CROSS-REFERENCE TRACKING SKELETONS
Note: =====================================================================

Process called "track_symbol_usage" that takes context as SemanticContext, symbol_id as String, usage_node as AST.ASTNode returns Boolean:
    @Implementation
    Records a usage of a symbol for cross-reference tracking, used for
    features like "find all references" and unused symbol detection.
    @End Implementation
    
    @Reasoning
    Tracking symbol usage enables IDE features and helps identify unused code
    that can be removed.
    @End Reasoning

    Note: Initialize usage tracking if needed
    If not Dictionary.has_key(context.metadata, "symbol_usage"):
        Dictionary.set(context.metadata, "symbol_usage", Dictionary[String, List[AST.ASTNode]])
    End If

    Let usage_map be Dictionary.get(context.metadata, "symbol_usage")

    Note: Get or create usage list for this symbol
    If not Dictionary.has_key(usage_map, symbol_id):
        Dictionary.set(usage_map, symbol_id, List[AST.ASTNode])
    End If

    Let usage_list be Dictionary.get(usage_map, symbol_id)
    List.add(usage_list, usage_node)

    Note: Also track line information for IDE features
    Let line_num be Dictionary.get(usage_node.attributes, "line")
    Let col_num be Dictionary.get(usage_node.attributes, "column")
    Let file_path be Dictionary.get(usage_node.attributes, "file_path")

    Note: Store usage location metadata
    If not Dictionary.has_key(context.metadata, "symbol_locations"):
        Dictionary.set(context.metadata, "symbol_locations", Dictionary[String, List[String]])
    End If

    Let location_map be Dictionary.get(context.metadata, "symbol_locations")
    If not Dictionary.has_key(location_map, symbol_id):
        Dictionary.set(location_map, symbol_id, List[String])
    End If

    Let locations be Dictionary.get(location_map, symbol_id)
    Let location_str be file_path + ":" + IntegerPrimitive.to_string(line_num) + ":" + IntegerPrimitive.to_string(col_num)
    List.add(locations, location_str)

    Return true
End Process

Process called "find_unused_symbols" that takes context as SemanticContext returns List[String]:
    @Implementation
    Identifies symbols that are defined but never used, helping developers
    clean up dead code.
    @End Implementation

    @Reasoning
    Unused symbol detection helps maintain clean codebases and can identify
    potential bugs where a symbol was meant to be used.
    @End Reasoning

    Let unused_symbols be List[String]
    Let usage_map be Dictionary.get(context.metadata, "symbol_usage")

    Note: Get all defined symbols
    Let all_symbols be SymbolTable.get_all_symbols(context.symbol_table)

    For Each symbol in all_symbols:
        Note: Skip certain symbol types that don't need usage tracking
        If symbol.symbol_type equals SymbolTable.SymbolType.Module:
            Continue
        End If

        Note: Skip compiler-generated symbols
        Let is_generated be Dictionary.get(symbol.metadata, "compiler_generated")
        If is_generated equals "true":
            Continue
        End If

        Note: Skip error recovery symbols
        Let is_error_recovery be Dictionary.get(symbol.metadata, "is_error_recovery")
        If is_error_recovery equals "true":
            Continue
        End If

        Note: Check if symbol has any usages
        If usage_map not equals null:
            If not Dictionary.has_key(usage_map, symbol.id):
                Note: Symbol has no usages
                Let symbol_info be symbol.name + " (" + SymbolTable.symbol_type_to_string(symbol.symbol_type) + ") in scope " + symbol.scope
                List.add(unused_symbols, symbol_info)
            Otherwise:
                Let usage_list be Dictionary.get(usage_map, symbol.id)
                If List.size(usage_list) equals 0:
                    Let symbol_info be symbol.name + " (" + SymbolTable.symbol_type_to_string(symbol.symbol_type) + ") in scope " + symbol.scope
                    List.add(unused_symbols, symbol_info)
                End If
            End If
        Otherwise:
            Note: No usage tracking means symbol is unused
            Let symbol_info be symbol.name + " (" + SymbolTable.symbol_type_to_string(symbol.symbol_type) + ") in scope " + symbol.scope
            List.add(unused_symbols, symbol_info)
        End If
    End For

    Return unused_symbols
End Process

Note: =====================================================================
Note: MODULE-LEVEL ANALYSIS SKELETONS
Note: =====================================================================

Process called "analyze_module" that takes context as SemanticContext, module_ast as AST.ASTNode returns SemanticResult:
    @Implementation
    Analyzes an entire module or compilation unit, orchestrating all semantic
    analysis phases for the module's contents.
    @End Implementation
    
    @Reasoning
    Module-level analysis provides a clean entry point for analyzing individual
    compilation units, which is essential for incremental compilation and
    parallel analysis of multiple modules.
    @End Reasoning

    Let errors be List[Errors.CompilerError]
    Let warnings be List[Errors.CompilerError]
    Let statistics be Dictionary[String, Integer]

    Note: Initialize statistics
    Dictionary.set(statistics, "total_symbols", 0)
    Dictionary.set(statistics, "total_types", 0)
    Dictionary.set(statistics, "total_functions", 0)
    Dictionary.set(statistics, "total_variables", 0)
    Dictionary.set(statistics, "total_errors", 0)
    Dictionary.set(statistics, "total_warnings", 0)

    Note: Create module scope
    Let module_name be Dictionary.get(module_ast.attributes, "module_name")
    If module_name equals "":
        Set module_name to "main"
    End If

    Let module_scope be ScopeAnalyzer.Scope with
        scope_name as "module_" + module_name,
        scope_type as ScopeAnalyzer.ScopeType.Module,
        parent_scope as "global",
        symbols as List[String],
        metadata as Dictionary[String, String]

    Dictionary.set(module_scope.metadata, "module_name", module_name)
    ScopeAnalyzer.push_scope(context.scope_analyzer, module_scope)

    Note: Phase 1: Collect all top-level declarations
    For Each child in module_ast.children:
        Let child_type be child.node_type
        Match child_type:
            When "FunctionDefinition":
                Let func_errors be collect_function_definition(context, child)
                For Each err in func_errors:
                    List.add(errors, err)
                End For
                Dictionary.set(statistics, "total_functions", Dictionary.get(statistics, "total_functions") + 1)

            When "TypeDefinition":
                Let type_errors be collect_type_definition(context, child)
                For Each err in type_errors:
                    List.add(errors, err)
                End For
                Dictionary.set(statistics, "total_types", Dictionary.get(statistics, "total_types") + 1)

            When "VariableDefinition":
                Let var_errors be collect_variable_definition(context, child)
                For Each err in var_errors:
                    List.add(errors, err)
                End For
                Dictionary.set(statistics, "total_variables", Dictionary.get(statistics, "total_variables") + 1)

            When "Import":
                Let import_errors be collect_import(context, child)
                For Each err in import_errors:
                    List.add(errors, err)
                End For
        End Match
    End For

    Note: Phase 2: Resolve imports
    Let import_errors be resolve_imports(context)
    For Each err in import_errors:
        List.add(errors, err)
    End For

    Note: Phase 3: Check for circular dependencies
    Let circular_errors be check_circular_imports(context)
    For Each err in circular_errors:
        List.add(errors, err)
    End For

    Note: Phase 4: Walk and analyze the AST
    Let walk_errors be walk_ast_node(context, module_ast)
    For Each err in walk_errors:
        List.add(errors, err)
    End For

    Note: Phase 5: Check for duplicate definitions
    Let dup_errors be check_duplicate_definitions(context, module_scope.scope_name)
    For Each err in dup_errors:
        List.add(errors, err)
    End For

    Note: Phase 6: Check for unreachable code
    For Each child in module_ast.children:
        If child.node_type equals "FunctionDefinition":
            Let func_body be Dictionary.get(child.attributes, "body")
            If func_body.node_type equals "Block":
                Let unreachable_errors be check_unreachable_code(context, func_body)
                For Each err in unreachable_errors:
                    List.add(warnings, err)
                End For
            End If
        End If
    End For

    Note: Phase 7: Find unused symbols
    Let unused be find_unused_symbols(context)
    For Each unused_symbol in unused:
        Let warning_msg be "Unused symbol: " + unused_symbol
        Let warning be Errors.create_warning(warning_msg)
        List.add(warnings, warning)
    End For

    Note: Phase 8: Annotate AST with types and symbols
    Set module_ast to annotate_with_types(context, module_ast)
    Set module_ast to annotate_with_symbols(context, module_ast)

    Note: Pop module scope
    ScopeAnalyzer.pop_scope(context.scope_analyzer)

    Note: Update statistics
    Let all_symbols be SymbolTable.get_all_symbols(context.symbol_table)
    Dictionary.set(statistics, "total_symbols", List.size(all_symbols))
    Dictionary.set(statistics, "total_errors", List.size(errors))
    Dictionary.set(statistics, "total_warnings", List.size(warnings))

    Note: Determine success
    Let success be List.size(errors) equals 0

    Return SemanticResult with
        success as success,
        symbol_table as context.symbol_table,
        errors as errors,
        warnings as warnings,
        statistics as statistics
End Process

Process called "analyze_module_exports" that takes context as SemanticContext, module_ast as AST.ASTNode returns List[SymbolTable.Symbol]:
    @Implementation
    Determines which symbols a module exports for use by other modules.
    Handles explicit export declarations and visibility modifiers.
    @End Implementation
    
    @Reasoning
    Export analysis is crucial for module interfaces and encapsulation,
    ensuring only intended symbols are visible outside the module.
    @End Reasoning

    Let exported_symbols be List[SymbolTable.Symbol]
    Let module_name be Dictionary.get(module_ast.attributes, "module_name")
    If module_name equals "":
        Set module_name to "main"
    End If

    Let module_scope be "module_" + module_name

    Note: Iterate through module children to find exported symbols
    For Each child in module_ast.children:
        Let child_type be child.node_type

        Match child_type:
            When "Export":
                Note: Explicit export statement
                Let export_name be Dictionary.get(child.attributes, "name")
                Let symbol be SymbolTable.lookup_symbol(context.symbol_table, export_name, module_scope)
                If symbol.name not equals "":
                    List.add(exported_symbols, symbol)
                End If

            When "FunctionDefinition":
                Let visibility be Dictionary.get(child.attributes, "visibility")
                If visibility equals "public" or visibility equals "export":
                    Let func_name be Dictionary.get(child.attributes, "name")
                    Let func_symbol be SymbolTable.lookup_symbol(context.symbol_table, func_name, module_scope)
                    If func_symbol.name not equals "":
                        List.add(exported_symbols, func_symbol)
                    End If
                End If

            When "TypeDefinition":
                Let visibility be Dictionary.get(child.attributes, "visibility")
                If visibility equals "public" or visibility equals "export":
                    Let type_name be Dictionary.get(child.attributes, "name")
                    Let type_symbol be SymbolTable.lookup_symbol(context.symbol_table, type_name, module_scope)
                    If type_symbol.name not equals "":
                        List.add(exported_symbols, type_symbol)
                    End If
                End If

            When "VariableDefinition":
                Let visibility be Dictionary.get(child.attributes, "visibility")
                If visibility equals "public" or visibility equals "export":
                    Let var_name be Dictionary.get(child.attributes, "name")
                    Let var_symbol be SymbolTable.lookup_symbol(context.symbol_table, var_name, module_scope)
                    If var_symbol.name not equals "":
                        List.add(exported_symbols, var_symbol)
                    End If
                End If

            When "TraitDefinition":
                Let visibility be Dictionary.get(child.attributes, "visibility")
                If visibility equals "public" or visibility equals "export":
                    Let trait_name be Dictionary.get(child.attributes, "name")
                    Let trait_symbol be SymbolTable.lookup_symbol(context.symbol_table, trait_name, module_scope)
                    If trait_symbol.name not equals "":
                        List.add(exported_symbols, trait_symbol)
                    End If
                End If
        End Match
    End For

    Return exported_symbols
End Process

Note: =====================================================================
Note: TYPE-SPECIFIC WALKER SKELETONS
Note: =====================================================================

Process called "walk_type_definition" that takes context as SemanticContext, type_def_ast as AST.ASTNode returns List[Errors.CompilerError]:
    @Implementation
    Specialized walker for type definitions including structs, enums, and
    type aliases. Handles generic parameters and constraints.
    @End Implementation
    
    @Reasoning
    Type definitions require special handling for generic parameters,
    constraints, and recursive type checking that differs from general
    statement walking.
    @End Reasoning

    Let errors be List[Errors.CompilerError]
    Let type_name be Dictionary.get(type_def_ast.attributes, "name")
    Let type_kind be Dictionary.get(type_def_ast.attributes, "kind")

    Note: Create scope for type definition
    Let type_scope be ScopeAnalyzer.Scope with
        scope_name as "type_" + type_name,
        scope_type as ScopeAnalyzer.ScopeType.Type,
        parent_scope as ScopeAnalyzer.get_current_scope(context.scope_analyzer).scope_name,
        symbols as List[String],
        metadata as Dictionary[String, String]

    Dictionary.set(type_scope.metadata, "type_name", type_name)
    Dictionary.set(type_scope.metadata, "type_kind", type_kind)
    ScopeAnalyzer.push_scope(context.scope_analyzer, type_scope)

    Note: Handle generic parameters
    Let generic_params be Dictionary.get(type_def_ast.attributes, "generic_params")
    If generic_params not equals null:
        For Each param in generic_params:
            Let param_name be Dictionary.get(param.attributes, "name")
            Let param_constraint be Dictionary.get(param.attributes, "constraint")

            Note: Register generic parameter as type variable
            Let type_param_symbol be SymbolTable.Symbol with
                id as "generic_" + type_name + "_" + param_name,
                name as param_name,
                symbol_type as SymbolTable.SymbolType.Type,
                scope as type_scope.scope_name,
                value_type as "TypeParameter",
                metadata as Dictionary[String, String]

            Dictionary.set(type_param_symbol.metadata, "is_generic", "true")
            Dictionary.set(type_param_symbol.metadata, "constraint", param_constraint)
            SymbolTable.register_symbol(context.symbol_table, type_param_symbol)
        End For
    End If

    Match type_kind:
        When "struct":
            Note: Process struct fields
            Let fields be Dictionary.get(type_def_ast.attributes, "fields")
            If fields not equals null:
                For Each field in fields:
                    Let field_name be Dictionary.get(field.attributes, "name")
                    Let field_type be Dictionary.get(field.attributes, "type")

                    Note: Resolve field type
                    Let resolved_type be resolve_type_reference(context, field_type)
                    If resolved_type.name equals "":
                        Let error_msg be "Unknown type '" + field_type + "' for field '" + field_name + "'"
                        Let error be Errors.create_semantic_error(error_msg)
                        List.add(errors, error)
                    End If

                    Note: Register field in symbol table
                    Let field_symbol be SymbolTable.Symbol with
                        id as type_name + "." + field_name,
                        name as field_name,
                        symbol_type as SymbolTable.SymbolType.Variable,
                        scope as type_scope.scope_name,
                        value_type as field_type,
                        metadata as Dictionary[String, String]

                    Dictionary.set(field_symbol.metadata, "is_field", "true")
                    Dictionary.set(field_symbol.metadata, "parent_type", type_name)
                    SymbolTable.register_symbol(context.symbol_table, field_symbol)
                End For
            End If

        When "enum":
            Note: Process enum variants
            Let variants be Dictionary.get(type_def_ast.attributes, "variants")
            If variants not equals null:
                For Each variant in variants:
                    Let variant_name be Dictionary.get(variant.attributes, "name")
                    Let variant_data be Dictionary.get(variant.attributes, "data")

                    Note: Register variant
                    Let variant_symbol be SymbolTable.Symbol with
                        id as type_name + "::" + variant_name,
                        name as variant_name,
                        symbol_type as SymbolTable.SymbolType.Variable,
                        scope as type_scope.scope_name,
                        value_type as type_name,
                        metadata as Dictionary[String, String]

                    Dictionary.set(variant_symbol.metadata, "is_variant", "true")
                    Dictionary.set(variant_symbol.metadata, "parent_enum", type_name)
                    If variant_data not equals null:
                        Dictionary.set(variant_symbol.metadata, "variant_data", variant_data)
                    End If
                    SymbolTable.register_symbol(context.symbol_table, variant_symbol)
                End For
            End If

        When "alias":
            Note: Process type alias
            Let aliased_type be Dictionary.get(type_def_ast.attributes, "aliased_type")
            Let resolved_alias be resolve_type_reference(context, aliased_type)
            If resolved_alias.name equals "":
                Let error_msg be "Unknown type '" + aliased_type + "' for type alias '" + type_name + "'"
                Let error be Errors.create_semantic_error(error_msg)
                List.add(errors, error)
            End If
    End Match

    Note: Pop type scope
    ScopeAnalyzer.pop_scope(context.scope_analyzer)

    Return errors
End Process

Process called "walk_function_definition" that takes context as SemanticContext, function_def_ast as AST.ASTNode returns List[Errors.CompilerError]:
    @Implementation
    Specialized walker for function definitions. Handles parameters, return
    types, generic constraints, and the function body scope.
    @End Implementation
    
    @Reasoning
    Functions create their own scope with parameters and require special
    handling for return type checking and generic instantiation.
    @End Reasoning

    Let errors be List[Errors.CompilerError]
    Let func_name be Dictionary.get(function_def_ast.attributes, "name")
    Let return_type be Dictionary.get(function_def_ast.attributes, "return_type")

    Note: Create function scope
    Let func_scope be ScopeAnalyzer.Scope with
        scope_name as "function_" + func_name,
        scope_type as ScopeAnalyzer.ScopeType.Function,
        parent_scope as ScopeAnalyzer.get_current_scope(context.scope_analyzer).scope_name,
        symbols as List[String],
        metadata as Dictionary[String, String]

    Dictionary.set(func_scope.metadata, "function_name", func_name)
    Dictionary.set(func_scope.metadata, "return_type", return_type)
    ScopeAnalyzer.push_scope(context.scope_analyzer, func_scope)

    Note: Handle generic parameters
    Let generic_params be Dictionary.get(function_def_ast.attributes, "generic_params")
    If generic_params not equals null:
        For Each param in generic_params:
            Let param_name be Dictionary.get(param.attributes, "name")
            Let param_constraint be Dictionary.get(param.attributes, "constraint")

            Let type_param_symbol be SymbolTable.Symbol with
                id as "generic_" + func_name + "_" + param_name,
                name as param_name,
                symbol_type as SymbolTable.SymbolType.Type,
                scope as func_scope.scope_name,
                value_type as "TypeParameter",
                metadata as Dictionary[String, String]

            Dictionary.set(type_param_symbol.metadata, "is_generic", "true")
            Dictionary.set(type_param_symbol.metadata, "constraint", param_constraint)
            SymbolTable.register_symbol(context.symbol_table, type_param_symbol)
        End For
    End If

    Note: Process parameters
    Let parameters be Dictionary.get(function_def_ast.attributes, "parameters")
    If parameters not equals null:
        For Each param in parameters:
            Let param_name be Dictionary.get(param.attributes, "name")
            Let param_type be Dictionary.get(param.attributes, "type")
            Let is_mutable be Dictionary.get(param.attributes, "mutable")

            Note: Resolve parameter type
            Let resolved_type be resolve_type_reference(context, param_type)
            If resolved_type.name equals "":
                Let error_msg be "Unknown type '" + param_type + "' for parameter '" + param_name + "'"
                Let error be Errors.create_semantic_error(error_msg)
                List.add(errors, error)
            End If

            Note: Register parameter in symbol table
            Let param_symbol be SymbolTable.Symbol with
                id as func_name + "_param_" + param_name,
                name as param_name,
                symbol_type as SymbolTable.SymbolType.Variable,
                scope as func_scope.scope_name,
                value_type as param_type,
                metadata as Dictionary[String, String]

            Dictionary.set(param_symbol.metadata, "is_parameter", "true")
            Dictionary.set(param_symbol.metadata, "is_mutable", is_mutable)
            SymbolTable.register_symbol(context.symbol_table, param_symbol)
        End For
    End If

    Note: Resolve return type
    If return_type not equals "":
        Let resolved_return be resolve_type_reference(context, return_type)
        If resolved_return.name equals "":
            Let error_msg be "Unknown return type '" + return_type + "' for function '" + func_name + "'"
            Let error be Errors.create_semantic_error(error_msg)
            List.add(errors, error)
        End If
    End If

    Note: Walk function body
    Let func_body be Dictionary.get(function_def_ast.attributes, "body")
    If func_body not equals null:
        Let body_errors be walk_ast_node(context, func_body)
        For Each err in body_errors:
            List.add(errors, err)
        End For

        Note: Check return statements
        Let return_errors be check_return_statements(context, func_body)
        For Each err in return_errors:
            List.add(errors, err)
        End For

        Note: Check for unreachable code
        Let unreachable_errors be check_unreachable_code(context, func_body)
        For Each err in unreachable_errors:
            List.add(errors, err)
        End For
    End If

    Note: Pop function scope
    ScopeAnalyzer.pop_scope(context.scope_analyzer)

    Return errors
End Process

Process called "walk_trait_definition" that takes context as SemanticContext, trait_def_ast as AST.ASTNode returns List[Errors.CompilerError]:
    @Implementation
    Specialized walker for trait definitions. Handles associated types,
    required methods, and trait inheritance.
    @End Implementation
    
    @Reasoning
    Traits have unique semantics including associated types and default
    implementations that require specialized analysis beyond regular types.
    @End Reasoning

    Let errors be List[Errors.CompilerError]
    Let trait_name be Dictionary.get(trait_def_ast.attributes, "name")

    Note: Create trait scope
    Let trait_scope be ScopeAnalyzer.Scope with
        scope_name as "trait_" + trait_name,
        scope_type as ScopeAnalyzer.ScopeType.Type,
        parent_scope as ScopeAnalyzer.get_current_scope(context.scope_analyzer).scope_name,
        symbols as List[String],
        metadata as Dictionary[String, String]

    Dictionary.set(trait_scope.metadata, "trait_name", trait_name)
    ScopeAnalyzer.push_scope(context.scope_analyzer, trait_scope)

    Note: Handle trait inheritance
    Let super_traits be Dictionary.get(trait_def_ast.attributes, "super_traits")
    If super_traits not equals null:
        For Each super_trait in super_traits:
            Let super_name be Dictionary.get(super_trait.attributes, "name")
            Let super_symbol be SymbolTable.lookup_symbol(context.symbol_table, super_name, "global")
            If super_symbol.name equals "":
                Let error_msg be "Unknown super trait '" + super_name + "' for trait '" + trait_name + "'"
                Let error be Errors.create_semantic_error(error_msg)
                List.add(errors, error)
            End If
        End For
    End If

    Note: Handle associated types
    Let assoc_types be Dictionary.get(trait_def_ast.attributes, "associated_types")
    If assoc_types not equals null:
        For Each assoc_type in assoc_types:
            Let assoc_name be Dictionary.get(assoc_type.attributes, "name")
            Let assoc_bounds be Dictionary.get(assoc_type.attributes, "bounds")

            Let assoc_symbol be SymbolTable.Symbol with
                id as trait_name + "::" + assoc_name,
                name as assoc_name,
                symbol_type as SymbolTable.SymbolType.Type,
                scope as trait_scope.scope_name,
                value_type as "AssociatedType",
                metadata as Dictionary[String, String]

            Dictionary.set(assoc_symbol.metadata, "is_associated", "true")
            Dictionary.set(assoc_symbol.metadata, "parent_trait", trait_name)
            If assoc_bounds not equals null:
                Dictionary.set(assoc_symbol.metadata, "bounds", assoc_bounds)
            End If
            SymbolTable.register_symbol(context.symbol_table, assoc_symbol)
        End For
    End If

    Note: Process required methods
    Let methods be Dictionary.get(trait_def_ast.attributes, "methods")
    If methods not equals null:
        For Each method in methods:
            Let method_name be Dictionary.get(method.attributes, "name")
            Let method_params be Dictionary.get(method.attributes, "parameters")
            Let method_return be Dictionary.get(method.attributes, "return_type")
            Let has_default be Dictionary.get(method.attributes, "has_default")

            Note: Register method signature
            Let method_symbol be SymbolTable.Symbol with
                id as trait_name + "::" + method_name,
                name as method_name,
                symbol_type as SymbolTable.SymbolType.Function,
                scope as trait_scope.scope_name,
                value_type as method_return,
                metadata as Dictionary[String, String]

            Dictionary.set(method_symbol.metadata, "is_trait_method", "true")
            Dictionary.set(method_symbol.metadata, "parent_trait", trait_name)
            Dictionary.set(method_symbol.metadata, "has_default", has_default)
            SymbolTable.register_symbol(context.symbol_table, method_symbol)

            Note: Walk default implementation if present
            If has_default equals "true":
                Let default_impl be Dictionary.get(method.attributes, "default_impl")
                If default_impl not equals null:
                    Let impl_errors be walk_ast_node(context, default_impl)
                    For Each err in impl_errors:
                        List.add(errors, err)
                    End For
                End If
            End If
        End For
    End If

    Note: Pop trait scope
    ScopeAnalyzer.pop_scope(context.scope_analyzer)

    Return errors
End Process

Note: =====================================================================
Note: PATTERN MATCHING ANALYSIS SKELETONS
Note: =====================================================================

Process called "analyze_match_expression" that takes context as SemanticContext, match_ast as AST.ASTNode returns List[Errors.CompilerError]:
    @Implementation
    Analyzes match expressions for exhaustiveness, pattern validity, and
    type consistency across all branches.
    @End Implementation
    
    @Reasoning
    Pattern matching requires exhaustiveness checking to ensure all possible
    values are handled, preventing runtime errors from unmatched patterns.
    @End Reasoning

    Let errors be List[Errors.CompilerError]
    Let match_expr be Dictionary.get(match_ast.attributes, "expression")
    Let cases be Dictionary.get(match_ast.attributes, "cases")

    Note: Analyze matched expression to determine its type
    Let expr_type be ""
    If match_expr not equals null:
        Set match_expr to annotate_with_types(context, match_expr)
        Set expr_type to Dictionary.get(match_expr.attributes, "resolved_type")
    End If

    If expr_type equals "":
        Let error_msg be "Cannot determine type of matched expression"
        Let error be Errors.create_semantic_error(error_msg)
        List.add(errors, error)
        Return errors
    End If

    Note: Collect all patterns
    Let patterns be List[String]
    Let pattern_types be Dictionary[String, String]
    Let has_wildcard be false

    For Each case_node in cases:
        Let pattern be Dictionary.get(case_node.attributes, "pattern")
        Let pattern_str be Dictionary.get(pattern.attributes, "pattern_text")
        List.add(patterns, pattern_str)

        Note: Check for wildcard pattern
        If pattern_str equals "_" or pattern_str equals "otherwise":
            Set has_wildcard to true
        End If

        Note: Analyze pattern type
        Let pattern_type be analyze_pattern_type(context, pattern, expr_type)
        Dictionary.set(pattern_types, pattern_str, pattern_type)

        Note: Check pattern compatibility with matched type
        If not is_pattern_compatible(pattern_type, expr_type):
            Let error_msg be "Pattern '" + pattern_str + "' is incompatible with type '" + expr_type + "'"
            Let error be Errors.create_semantic_error(error_msg)
            List.add(errors, error)
        End If

        Note: Analyze case body
        Let case_body be Dictionary.get(case_node.attributes, "body")
        If case_body not equals null:
            Let body_errors be walk_ast_node(context, case_body)
            For Each err in body_errors:
                List.add(errors, err)
            End For
        End If

        Note: Handle guard conditions
        Let guard be Dictionary.get(case_node.attributes, "guard")
        If guard not equals null:
            Set guard to annotate_with_types(context, guard)
            Let guard_type be Dictionary.get(guard.attributes, "resolved_type")
            If guard_type not equals "Boolean":
                Let error_msg be "Guard condition must be of type Boolean, got '" + guard_type + "'"
                Let error be Errors.create_semantic_error(error_msg)
                List.add(errors, error)
            End If
        End If
    End For

    Note: Check exhaustiveness
    If not has_wildcard:
        Let is_exhaustive be check_pattern_coverage(context, patterns, expr_type)
        If not is_exhaustive:
            Let error_msg be "Non-exhaustive patterns in match expression for type '" + expr_type + "'"
            Let error be Errors.create_semantic_error(error_msg)
            List.add(errors, error)
        End If
    End If

    Return errors
End Process

Process called "check_pattern_coverage" that takes context as SemanticContext, patterns as List[String], match_type as String returns Boolean:
    @Implementation
    Verifies that a set of patterns covers all possible values of the
    matched type, including handling of wildcards and guards.
    @End Implementation
    
    @Reasoning
    Pattern coverage analysis ensures match expressions are exhaustive,
    which is critical for type safety and preventing runtime failures.
    @End Reasoning

    Note: Check if type is an enum
    Let type_symbol be SymbolTable.lookup_symbol(context.symbol_table, match_type, "global")
    If type_symbol.name equals "":
        Return false  Note: Unknown type cannot be verified as covered
    End If

    Let type_kind be Dictionary.get(type_symbol.metadata, "type_kind")

    Match type_kind:
        When "enum":
            Note: For enums, check all variants are covered
            Let all_variants be get_enum_variants(context, match_type)
            Let covered_variants be Dictionary[String, Boolean]

            For Each variant in all_variants:
                Dictionary.set(covered_variants, variant, false)
            End For

            For Each pattern in patterns:
                If pattern equals "_" or pattern equals "otherwise":
                    Return true  Note: Wildcard covers all cases
                End If

                Note: Check if pattern matches a variant
                For Each variant in all_variants:
                    If pattern equals match_type + "::" + variant or pattern equals variant:
                        Dictionary.set(covered_variants, variant, true)
                    End If
                End For
            End For

            Note: Check if all variants are covered
            For Each variant in all_variants:
                If not Dictionary.get(covered_variants, variant):
                    Return false
                End If
            End For
            Return true

        When "boolean":
            Note: For booleans, need true and false or wildcard
            Let has_true be false
            Let has_false be false

            For Each pattern in patterns:
                If pattern equals "_" or pattern equals "otherwise":
                    Return true
                End If
                If pattern equals "true":
                    Set has_true to true
                End If
                If pattern equals "false":
                    Set has_false to true
                End If
            End For

            Return has_true and has_false

        Otherwise:
            Note: For other types, wildcard is required
            For Each pattern in patterns:
                If pattern equals "_" or pattern equals "otherwise":
                    Return true
                End If
            End For

            Note: Check for numeric range coverage
            If match_type equals "Integer":
                Return check_numeric_range_coverage(patterns)
            End If

            Return false
    End Match
End Process

Process called "analyze_pattern_type" that takes context as SemanticContext, pattern as AST.ASTNode, expected_type as String returns String:
    @Implementation
    Analyzes a pattern and determines its type for pattern matching.
    @End Implementation

    Let pattern_kind be Dictionary.get(pattern.attributes, "kind")

    Match pattern_kind:
        When "wildcard":
            Return expected_type

        When "literal":
            Let literal_value be Dictionary.get(pattern.attributes, "value")
            Let literal_type be Dictionary.get(pattern.attributes, "type")
            Return literal_type

        When "constructor":
            Let constructor_name be Dictionary.get(pattern.attributes, "name")
            Let constructor_symbol be SymbolTable.lookup_symbol(context.symbol_table, constructor_name, "global")
            If constructor_symbol.name not equals "":
                Return constructor_symbol.value_type
            End If
            Return "Unknown"

        When "tuple":
            Let elements be Dictionary.get(pattern.attributes, "elements")
            Return "Tuple"

        When "struct":
            Let struct_name be Dictionary.get(pattern.attributes, "struct_name")
            Return struct_name

        Otherwise:
            Return expected_type
    End Match
End Process

Process called "is_pattern_compatible" that takes pattern_type as String, expected_type as String returns Boolean:
    @Implementation
    Checks if a pattern type is compatible with the expected type.
    @End Implementation

    If pattern_type equals expected_type:
        Return true
    End If

    If pattern_type equals "Unknown":
        Return false
    End If

    Note: Check for type compatibility
    If expected_type equals "Any":
        Return true
    End If

    Note: Check for numeric type compatibility
    If (pattern_type equals "Integer" or pattern_type equals "Float") and
       (expected_type equals "Integer" or expected_type equals "Float" or expected_type equals "Number"):
        Return true
    End If

    Return false
End Process

Process called "get_enum_variants" that takes context as SemanticContext, enum_type as String returns List[String]:
    @Implementation
    Gets all variants of an enum type.
    @End Implementation

    Let variants be List[String]
    Let type_symbol be SymbolTable.lookup_symbol(context.symbol_table, enum_type, "global")

    If type_symbol.name not equals "":
        Let all_symbols be SymbolTable.get_symbols_in_scope(context.symbol_table, "type_" + enum_type)
        For Each symbol in all_symbols:
            Let is_variant be Dictionary.get(symbol.metadata, "is_variant")
            If is_variant equals "true":
                List.add(variants, symbol.name)
            End If
        End For
    End If

    Return variants
End Process

Process called "check_numeric_range_coverage" that takes patterns as List[String] returns Boolean:
    @Implementation
    Checks for numeric range coverage in patterns by analyzing range patterns,
    guards, and literal values to determine exhaustiveness.
    @End Implementation

    For Each pattern in patterns:
        If pattern equals "_" or pattern equals "otherwise":
            Return true
        End If
    End For

    Note: Parse patterns to extract numeric ranges and conditions
    Let ranges be List[Dictionary[String, Integer]]
    Let has_unbounded_lower be false
    Let has_unbounded_upper be false

    For Each pattern in patterns:
        Note: Check for range patterns (e.g., "0..10", "5..=20")
        If StringPrimitive.contains(pattern, ".."):
            Let range_parts be StringPrimitive.split(pattern, "..")
            If List.size(range_parts) equals 2:
                Let lower_str be List.get(range_parts, 0)
                Let upper_str be List.get(range_parts, 1)

                Let range be Dictionary[String, Integer]
                If lower_str equals "":
                    Set has_unbounded_lower to true
                    Dictionary.set(range, "lower", -2147483648)  Note: Min integer
                Otherwise:
                    Dictionary.set(range, "lower", StringPrimitive.to_integer(lower_str))
                End If

                If upper_str equals "":
                    Set has_unbounded_upper to true
                    Dictionary.set(range, "upper", 2147483647)  Note: Max integer
                Otherwise:
                    Let inclusive be StringPrimitive.starts_with(upper_str, "=")
                    If inclusive:
                        Set upper_str to StringPrimitive.substring(upper_str, 1, StringPrimitive.length(upper_str))
                    End If
                    Dictionary.set(range, "upper", StringPrimitive.to_integer(upper_str))
                End If

                List.add(ranges, range)
            End If
        Otherwise:
            Note: Single value pattern
            Let value be StringPrimitive.to_integer(pattern)
            Let single_range be Dictionary[String, Integer]
            Dictionary.set(single_range, "lower", value)
            Dictionary.set(single_range, "upper", value)
            List.add(ranges, single_range)
        End If
    End For

    Note: Check if ranges cover entire integer space
    If has_unbounded_lower and has_unbounded_upper:
        Return true
    End If

    Note: Sort ranges and check for gaps
    Let sorted_ranges be sort_ranges_by_lower(ranges)
    If List.size(sorted_ranges) equals 0:
        Return false
    End If

    Note: Check coverage from minimum to maximum
    Let first_range be List.get(sorted_ranges, 0)
    If not has_unbounded_lower and Dictionary.get(first_range, "lower") > -2147483648:
        Return false  Note: Gap at the beginning
    End If

    Let last_range be List.get(sorted_ranges, List.size(sorted_ranges) - 1)
    If not has_unbounded_upper and Dictionary.get(last_range, "upper") < 2147483647:
        Return false  Note: Gap at the end
    End If

    Note: Check for gaps between consecutive ranges
    For i from 0 to List.size(sorted_ranges) - 2:
        Let current_range be List.get(sorted_ranges, i)
        Let next_range be List.get(sorted_ranges, i + 1)
        Let current_upper be Dictionary.get(current_range, "upper")
        Let next_lower be Dictionary.get(next_range, "lower")

        If current_upper + 1 < next_lower:
            Return false  Note: Gap between ranges
        End If
    End For

    Return true
End Process

Process called "sort_ranges_by_lower" that takes ranges as List[Dictionary[String, Integer]] returns List[Dictionary[String, Integer]]:
    @Implementation
    Sorts numeric ranges by their lower bound for gap analysis.
    @End Implementation

    Note: Bubble sort implementation for range sorting
    Let sorted be List[Dictionary[String, Integer]]
    For Each range in ranges:
        List.add(sorted, range)
    End For

    Let n be List.size(sorted)
    For i from 0 to n - 1:
        For j from 0 to n - i - 2:
            Let range1 be List.get(sorted, j)
            Let range2 be List.get(sorted, j + 1)
            Let lower1 be Dictionary.get(range1, "lower")
            Let lower2 be Dictionary.get(range2, "lower")

            If lower1 > lower2:
                List.set(sorted, j, range2)
                List.set(sorted, j + 1, range1)
            End If
        End For
    End For

    Return sorted
End Process

Note: =====================================================================
Note: CONSTANT EVALUATION SKELETONS
Note: =====================================================================

Process called "evaluate_constant_expression" that takes context as SemanticContext, const_expr_ast as AST.ASTNode returns String:
    @Implementation
    Evaluates compile-time constant expressions including arithmetic,
    string concatenation, and const function calls.
    @End Implementation
    
    @Reasoning
    Constant evaluation enables compile-time computation for array sizes,
    const generics, and optimization opportunities.
    @End Reasoning

    Let node_type be const_expr_ast.node_type

    Match node_type:
        When "Literal":
            Let value be Dictionary.get(const_expr_ast.attributes, "value")
            Return value

        When "BinaryOp":
            Let left be Dictionary.get(const_expr_ast.attributes, "left")
            Let right be Dictionary.get(const_expr_ast.attributes, "right")
            Let op be Dictionary.get(const_expr_ast.attributes, "operator")

            Let left_val be evaluate_constant_expression(context, left)
            Let right_val be evaluate_constant_expression(context, right)

            If left_val equals "" or right_val equals "":
                Return ""  Note: Cannot evaluate
            End If

            Return evaluate_binary_constant(op, left_val, right_val)

        When "UnaryOp":
            Let operand be Dictionary.get(const_expr_ast.attributes, "operand")
            Let op be Dictionary.get(const_expr_ast.attributes, "operator")

            Let operand_val be evaluate_constant_expression(context, operand)
            If operand_val equals "":
                Return ""
            End If

            Return evaluate_unary_constant(op, operand_val)

        When "Identifier":
            Let name be Dictionary.get(const_expr_ast.attributes, "name")
            Let symbol be SymbolTable.lookup_symbol(
                context.symbol_table,
                name,
                ScopeAnalyzer.get_current_scope(context.scope_analyzer).scope_name
            )

            If symbol.name not equals "":
                Let is_const be Dictionary.get(symbol.metadata, "is_const")
                If is_const equals "true":
                    Let const_value be Dictionary.get(symbol.metadata, "const_value")
                    Return const_value
                End If
            End If
            Return ""

        When "ArrayLength":
            Let array_type be Dictionary.get(const_expr_ast.attributes, "array_type")
            Let length be Dictionary.get(const_expr_ast.attributes, "length")
            Return length

        When "SizeOf":
            Let type_name be Dictionary.get(const_expr_ast.attributes, "type")
            Return get_type_size(context, type_name)

        Otherwise:
            Return ""
    End Match
End Process

Process called "check_constant_context" that takes context as SemanticContext, expression_ast as AST.ASTNode returns Boolean:
    @Implementation
    Verifies that an expression is valid in a constant context, containing
    only operations that can be evaluated at compile time.
    @End Implementation
    
    @Reasoning
    Constant contexts have restrictions on what operations are allowed,
    ensuring expressions can be evaluated during compilation.
    @End Reasoning

    Let node_type be expression_ast.node_type

    Match node_type:
        When "Literal":
            Return true

        When "BinaryOp":
            Let left be Dictionary.get(expression_ast.attributes, "left")
            Let right be Dictionary.get(expression_ast.attributes, "right")
            Return check_constant_context(context, left) and check_constant_context(context, right)

        When "UnaryOp":
            Let operand be Dictionary.get(expression_ast.attributes, "operand")
            Return check_constant_context(context, operand)

        When "Identifier":
            Let name be Dictionary.get(expression_ast.attributes, "name")
            Let symbol be SymbolTable.lookup_symbol(
                context.symbol_table,
                name,
                ScopeAnalyzer.get_current_scope(context.scope_analyzer).scope_name
            )
            If symbol.name not equals "":
                Let is_const be Dictionary.get(symbol.metadata, "is_const")
                Return is_const equals "true"
            End If
            Return false

        When "ArrayLength":
            Return true

        When "SizeOf":
            Return true

        When "FunctionCall":
            Let func_name be Dictionary.get(expression_ast.attributes, "name")
            Let func_symbol be SymbolTable.lookup_symbol(context.symbol_table, func_name, "global")
            If func_symbol.name not equals "":
                Let is_const_fn be Dictionary.get(func_symbol.metadata, "is_const_fn")
                If is_const_fn equals "true":
                    Let args be Dictionary.get(expression_ast.attributes, "arguments")
                    For Each arg in args:
                        If not check_constant_context(context, arg):
                            Return false
                        End If
                    End For
                    Return true
                End If
            End If
            Return false

        Otherwise:
            Return false
    End Match
End Process

Process called "evaluate_binary_constant" that takes op as String, left_val as String, right_val as String returns String:
    @Implementation
    Evaluates a binary operation on constant values.
    @End Implementation

    Note: Parse numeric values
    Let left_num be StringPrimitive.to_integer(left_val)
    Let right_num be StringPrimitive.to_integer(right_val)

    Match op:
        When "+":
            If StringPrimitive.contains(left_val, ".") or StringPrimitive.contains(right_val, "."):
                Let left_float be StringPrimitive.to_float(left_val)
                Let right_float be StringPrimitive.to_float(right_val)
                Return FloatPrimitive.to_string(left_float + right_float)
            End If
            Return IntegerPrimitive.to_string(left_num + right_num)

        When "-":
            If StringPrimitive.contains(left_val, ".") or StringPrimitive.contains(right_val, "."):
                Let left_float be StringPrimitive.to_float(left_val)
                Let right_float be StringPrimitive.to_float(right_val)
                Return FloatPrimitive.to_string(left_float - right_float)
            End If
            Return IntegerPrimitive.to_string(left_num - right_num)

        When "*":
            If StringPrimitive.contains(left_val, ".") or StringPrimitive.contains(right_val, "."):
                Let left_float be StringPrimitive.to_float(left_val)
                Let right_float be StringPrimitive.to_float(right_val)
                Return FloatPrimitive.to_string(left_float * right_float)
            End If
            Return IntegerPrimitive.to_string(left_num * right_num)

        When "/":
            If right_num equals 0:
                Return ""  Note: Division by zero
            End If
            If StringPrimitive.contains(left_val, ".") or StringPrimitive.contains(right_val, "."):
                Let left_float be StringPrimitive.to_float(left_val)
                Let right_float be StringPrimitive.to_float(right_val)
                Return FloatPrimitive.to_string(left_float / right_float)
            End If
            Return IntegerPrimitive.to_string(left_num / right_num)

        When "%":
            If right_num equals 0:
                Return ""
            End If
            Return IntegerPrimitive.to_string(left_num % right_num)

        When "&&":
            Let left_bool be left_val equals "true"
            Let right_bool be right_val equals "true"
            If left_bool and right_bool:
                Return "true"
            End If
            Return "false"

        When "||":
            Let left_bool be left_val equals "true"
            Let right_bool be right_val equals "true"
            If left_bool or right_bool:
                Return "true"
            End If
            Return "false"

        Otherwise:
            Return ""
    End Match
End Process

Process called "evaluate_unary_constant" that takes op as String, operand_val as String returns String:
    @Implementation
    Evaluates a unary operation on a constant value.
    @End Implementation

    Match op:
        When "-":
            If StringPrimitive.contains(operand_val, "."):
                Let float_val be StringPrimitive.to_float(operand_val)
                Return FloatPrimitive.to_string(-float_val)
            End If
            Let int_val be StringPrimitive.to_integer(operand_val)
            Return IntegerPrimitive.to_string(-int_val)

        When "+":
            Return operand_val

        When "!":
            If operand_val equals "true":
                Return "false"
            End If
            If operand_val equals "false":
                Return "true"
            End If
            Return ""

        When "~":
            Let int_val be StringPrimitive.to_integer(operand_val)
            Return IntegerPrimitive.to_string(~int_val)

        Otherwise:
            Return ""
    End Match
End Process

Process called "get_type_size" that takes context as SemanticContext, type_name as String returns String:
    @Implementation
    Gets the size in bytes of a type for compile-time sizeof operations.
    @End Implementation

    Match type_name:
        When "Integer":
            Return "8"
        When "Float":
            Return "8"
        When "Boolean":
            Return "1"
        When "Byte":
            Return "1"
        When "Short":
            Return "2"
        When "Long":
            Return "8"
        Otherwise:
            Let type_symbol be SymbolTable.lookup_symbol(context.symbol_table, type_name, "global")
            If type_symbol.name not equals "":
                Let size be Dictionary.get(type_symbol.metadata, "size")
                If size not equals "":
                    Return size
                End If
            End If
            Return "0"
    End Match
End Process

Note: =====================================================================
Note: VISIBILITY AND ACCESS CONTROL SKELETONS
Note: =====================================================================

Process called "check_visibility" that takes context as SemanticContext, symbol as SymbolTable.Symbol, access_location as String returns Boolean:
    @Implementation
    Ensures that private and protected symbols are only accessed from
    appropriate scopes according to visibility rules.
    @End Implementation
    
    @Reasoning
    Visibility checking enforces encapsulation and API boundaries, preventing
    unauthorized access to implementation details.
    @End Reasoning

    Let visibility be Dictionary.get(symbol.metadata, "visibility")
    If visibility equals "" or visibility equals "public":
        Return true  Note: Public symbols are always accessible
    End If

    Note: Get the scope where the symbol is defined
    Let symbol_scope be symbol.scope

    Note: Check if access is from the same scope or a child scope
    Let current_scope be access_location
    While current_scope not equals "":
        If current_scope equals symbol_scope:
            Return true  Note: Same scope access is allowed
        End If

        Note: Check for private visibility
        If visibility equals "private":
            Note: Private symbols only accessible in defining scope
            If current_scope equals symbol_scope:
                Return true
            End If
        End If

        Note: Check for protected visibility
        If visibility equals "protected":
            Note: Protected symbols accessible in same class/module hierarchy
            If is_in_same_hierarchy(context, current_scope, symbol_scope):
                Return true
            End If
        End If

        Note: Check for internal/package visibility
        If visibility equals "internal" or visibility equals "package":
            If is_in_same_module(context, current_scope, symbol_scope):
                Return true
            End If
        End If

        Note: Move to parent scope
        Let scope_info be ScopeAnalyzer.get_scope(context.scope_analyzer, current_scope)
        If scope_info.scope_name not equals "":
            Set current_scope to scope_info.parent_scope
        Otherwise:
            Break
        End If
    End While

    Return false
End Process

Process called "check_module_boundaries" that takes context as SemanticContext, from_module as String, to_module as String returns Boolean:
    @Implementation
    Verifies that module access rules are followed, ensuring modules only
    access exported symbols from their dependencies.
    @End Implementation
    
    @Reasoning
    Module boundaries enforce architectural constraints and prevent
    unintended coupling between modules.
    @End Reasoning

    If from_module equals to_module:
        Return true  Note: Same module access is always allowed
    End If

    Note: Check if from_module has declared dependency on to_module
    Let module_dependencies be Dictionary.get(context.metadata, "module_dependencies")
    If module_dependencies not equals null:
        Let from_deps be Dictionary.get(module_dependencies, from_module)
        If from_deps not equals null:
            For Each dep in from_deps:
                If dep equals to_module:
                    Return true
                End If
            End For
        End If
    End If

    Note: Check if to_module is a standard library module (always accessible)
    If StringPrimitive.starts_with(to_module, "std.") or to_module equals "std":
        Return true
    End If

    Note: Check if modules are in parent-child relationship
    If StringPrimitive.starts_with(from_module, to_module + "."):
        Return true  Note: Child can access parent
    End If

    If StringPrimitive.starts_with(to_module, from_module + "."):
        Note: Parent accessing child - verify symbol is exported
        Let exported_symbols be analyze_module_exports(context, find_module_ast(context, to_module))
        If List.size(exported_symbols) > 0:
            Return true
        End If
        Return false
    End If

    Return false
End Process

Process called "find_module_ast" that takes context as SemanticContext, module_name as String returns AST.ASTNode:
    @Implementation
    Finds the AST node for a module by name from the context's module cache.
    @End Implementation

    Let module_cache be Dictionary.get(context.metadata, "module_cache")
    If module_cache not equals null:
        Let module_ast be Dictionary.get(module_cache, module_name)
        If module_ast not equals null:
            Return module_ast
        End If
    End If

    Note: Create a placeholder module AST if not found
    Let placeholder_ast be AST.ASTNode with
        node_type as "Module",
        attributes as Dictionary[String, Any],
        children as List[AST.ASTNode]

    Dictionary.set(placeholder_ast.attributes, "module_name", module_name)
    Return placeholder_ast
End Process

Note: =====================================================================
Note: DIAGNOSTIC HELPER SKELETONS
Note: =====================================================================

Process called "suggest_similar_symbol" that takes context as SemanticContext, unknown_symbol as String, scope as String returns String:
    @Implementation
    Finds symbols with similar names to provide "did you mean?" suggestions
    for typos and misspellings in error messages.
    @End Implementation
    
    @Reasoning
    Similarity suggestions improve developer experience by helping identify
    and fix simple typos quickly.
    @End Reasoning

    Let best_match be ""
    Let best_distance be 999999
    Let max_distance be 3  Note: Maximum edit distance for suggestions

    Note: Get all symbols in scope and parent scopes
    Let all_symbols be SymbolTable.get_symbols_in_scope(context.symbol_table, scope)

    Note: Also check parent scopes
    Let current_scope be scope
    While current_scope not equals "":
        Let scope_symbols be SymbolTable.get_symbols_in_scope(context.symbol_table, current_scope)
        For Each symbol in scope_symbols:
            List.add(all_symbols, symbol)
        End For

        Let scope_info be ScopeAnalyzer.get_scope(context.scope_analyzer, current_scope)
        If scope_info.scope_name not equals "":
            Set current_scope to scope_info.parent_scope
        Otherwise:
            Break
        End If
    End While

    For Each symbol in all_symbols:
        Let distance be calculate_edit_distance(unknown_symbol, symbol.name)
        If distance < best_distance and distance <= max_distance:
            Set best_distance to distance
            Set best_match to symbol.name
        End If
    End For

    If best_match not equals "":
        Return best_match
    End If

    Return ""
End Process

Process called "get_symbol_location" that takes context as SemanticContext, symbol as SymbolTable.Symbol returns Dictionary[String, Integer]:
    @Implementation
    Retrieves the source location (file, line, column) for a symbol definition
    to provide accurate error and diagnostic locations.
    @End Implementation
    
    @Reasoning
    Accurate source locations are essential for meaningful error messages
    and IDE features like go-to-definition.
    @End Reasoning

    Let location be Dictionary[String, Integer]

    Note: Try to get location from symbol metadata
    Let line be Dictionary.get(symbol.metadata, "definition_line")
    Let column be Dictionary.get(symbol.metadata, "definition_column")
    Let file_id be Dictionary.get(symbol.metadata, "file_id")

    If line not equals "":
        Dictionary.set(location, "line", StringPrimitive.to_integer(line))
    Otherwise:
        Dictionary.set(location, "line", 0)
    End If

    If column not equals "":
        Dictionary.set(location, "column", StringPrimitive.to_integer(column))
    Otherwise:
        Dictionary.set(location, "column", 0)
    End If

    If file_id not equals "":
        Dictionary.set(location, "file_id", StringPrimitive.to_integer(file_id))
    Otherwise:
        Dictionary.set(location, "file_id", 0)
    End If

    Note: Try to find location from usage tracking
    Let location_map be Dictionary.get(context.metadata, "symbol_locations")
    If location_map not equals null:
        Let locations be Dictionary.get(location_map, symbol.id)
        If locations not equals null and List.size(locations) > 0:
            Let first_location be List.get(locations, 0)
            Note: Parse location string format "file:line:column"
            Let parts be StringPrimitive.split(first_location, ":")
            If List.size(parts) >= 2:
                Dictionary.set(location, "line", StringPrimitive.to_integer(List.get(parts, 1)))
                If List.size(parts) >= 3:
                    Dictionary.set(location, "column", StringPrimitive.to_integer(List.get(parts, 2)))
                End If
            End If
        End If
    End If

    Return location
End Process

Process called "is_in_same_hierarchy" that takes context as SemanticContext, scope1 as String, scope2 as String returns Boolean:
    @Implementation
    Checks if two scopes are in the same class/type hierarchy for protected access.
    @End Implementation

    Note: Extract type names from scopes
    Let type1 be extract_type_from_scope(scope1)
    Let type2 be extract_type_from_scope(scope2)

    If type1 equals type2:
        Return true
    End If

    Note: Check inheritance relationship
    Let type1_symbol be SymbolTable.lookup_symbol(context.symbol_table, type1, "global")
    Let type2_symbol be SymbolTable.lookup_symbol(context.symbol_table, type2, "global")

    If type1_symbol.name not equals "":
        Let base_type be Dictionary.get(type1_symbol.metadata, "base_type")
        If base_type equals type2:
            Return true
        End If
    End If

    If type2_symbol.name not equals "":
        Let base_type be Dictionary.get(type2_symbol.metadata, "base_type")
        If base_type equals type1:
            Return true
        End If
    End If

    Return false
End Process

Process called "is_in_same_module" that takes context as SemanticContext, scope1 as String, scope2 as String returns Boolean:
    @Implementation
    Checks if two scopes are in the same module for internal/package visibility.
    @End Implementation

    Let module1 be extract_module_from_scope(scope1)
    Let module2 be extract_module_from_scope(scope2)

    Return module1 equals module2
End Process

Process called "extract_type_from_scope" that takes scope as String returns String:
    @Implementation
    Extracts the type name from a scope string like "type_MyClass".
    @End Implementation

    If StringPrimitive.starts_with(scope, "type_"):
        Return StringPrimitive.substring(scope, 5, StringPrimitive.length(scope))
    End If

    If StringPrimitive.contains(scope, "::"):
        Let parts be StringPrimitive.split(scope, "::")
        Return List.get(parts, 0)
    End If

    Return scope
End Process

Process called "extract_module_from_scope" that takes scope as String returns String:
    @Implementation
    Extracts the module name from a scope string.
    @End Implementation

    If StringPrimitive.starts_with(scope, "module_"):
        Return StringPrimitive.substring(scope, 7, StringPrimitive.length(scope))
    End If

    Note: Find the module scope in the hierarchy
    If StringPrimitive.contains(scope, "module_"):
        Let parts be StringPrimitive.split(scope, "_")
        For Each part in parts:
            If part equals "module":
                Let idx be List.index_of(parts, part)
                If idx < List.size(parts) - 1:
                    Return List.get(parts, idx + 1)
                End If
            End If
        End For
    End If

    Return "global"
End Process

Process called "calculate_edit_distance" that takes str1 as String, str2 as String returns Integer:
    @Implementation
    Calculates the Levenshtein edit distance between two strings.
    @End Implementation

    Let len1 be StringPrimitive.length(str1)
    Let len2 be StringPrimitive.length(str2)

    Note: Create distance matrix
    Let matrix be List[List[Integer]]

    Note: Initialize first row and column
    For i from 0 to len1:
        Let row be List[Integer]
        For j from 0 to len2:
            If i equals 0:
                List.add(row, j)
            Otherwise If j equals 0:
                List.add(row, i)
            Otherwise:
                List.add(row, 0)
            End If
        End For
        List.add(matrix, row)
    End For

    Note: Fill in the matrix
    For i from 1 to len1:
        For j from 1 to len2:
            Let char1 be StringPrimitive.char_at(str1, i - 1)
            Let char2 be StringPrimitive.char_at(str2, j - 1)

            Let cost be 0
            If char1 not equals char2:
                Set cost to 1
            End If

            Let deletion be List.get(List.get(matrix, i - 1), j) + 1
            Let insertion be List.get(List.get(matrix, i), j - 1) + 1
            Let substitution be List.get(List.get(matrix, i - 1), j - 1) + cost

            Let min_cost be deletion
            If insertion < min_cost:
                Set min_cost to insertion
            End If
            If substitution < min_cost:
                Set min_cost to substitution
            End If

            List.set(List.get(matrix, i), j, min_cost)
        End For
    End For

    Return List.get(List.get(matrix, len1), len2)
End Process