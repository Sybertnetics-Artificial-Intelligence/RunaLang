Note: Test program for v0.1 lexer
Note: This tests the lexer's tokenization capabilities

Note: Import the lexer function from v0.1
Note: Since v0.1 isn't compiled yet, we'll test the lexer logic directly

Let test_source be "Let x be 42\nDisplay x"

Note: Test character classification
Let char_A be 65
Let char_z be 122
Let char_0 be 48
Let char_9 be 57
Let char_space be 32

Display "Testing character classification:"
Display char_A
Display char_z
Display char_0
Display char_9
Display char_space

Note: Simple test of tokenization concept
Display "Input source:"
Display test_source

Note: Demonstrate what tokens should look like
Let expected_tokens be "Let|Let|1|1\nIdentifier|x|1|5\nBe|be|1|7\nInteger|42|1|10\nDisplay|Display|2|1\nIdentifier|x|2|9"
Display "Expected tokens (conceptual):"
Display expected_tokens