Note: Main compiler driver for Stage 0.2 partial self-hosting
Note: Orchestrates the entire compilation pipeline

Import module "parser_frontend" as Parser
Import module "type_system" as Types
Import module "semantic_analyzer" as Semantic
Import module "ir_generator" as IR
Import module "code_generator" as CodeGen
Import module "diagnostic_system" as Diag
Import module "compiler_bridge" as Bridge
Import module "core_libs" as Core

Note: =====================================================================
Note: COMPILATION CONFIGURATION STRUCTURES
Note: =====================================================================

Type called "CompilerOptions":
    input_files as List[String]         Note: Source files to compile
    output_file as String                Note: Output executable/library name
    output_type as String                Note: executable, library, object
    optimization_level as Integer        Note: 0-3 optimization level
    debug_info as Boolean                Note: Include debug information
    warnings_as_errors as Boolean        Note: Treat warnings as errors
    verbose as Boolean                   Note: Verbose output
    target_triple as Optional[String]    Note: Cross-compilation target
    library_paths as List[String]        Note: Library search paths
    include_paths as List[String]        Note: Include file paths
    defines as Dictionary[String, String] Note: Preprocessor definitions
    link_libraries as List[String]       Note: Libraries to link
    emit_ir as Boolean                   Note: Output IR for debugging
    emit_asm as Boolean                  Note: Output assembly
    no_link as Boolean                   Note: Skip linking phase
End Type

Type called "CompilationUnit":
    source_file as String                Note: Source file path
    source_content as String             Note: File contents
    ast as Optional[Parser.ASTNode]      Note: Parsed AST
    symbol_table as Optional[Semantic.SymbolTable] Note: Symbol information
    ir_module as Optional[IR.IRModule]   Note: Generated IR
    object_code as Optional[Core.ByteArray] Note: Generated object code
    diagnostics as List[Diag.Diagnostic] Note: Unit-specific diagnostics
    dependencies as List[String]         Note: Files this unit depends on
End Type

Type called "CompilationState":
    units as List[CompilationUnit]       Note: All compilation units
    options as CompilerOptions           Note: Compiler configuration
    diagnostic_context as Diag.DiagnosticContext Note: Global diagnostics
    global_symbols as Dictionary[String, String] Note: Cross-unit symbols
    link_objects as List[String]         Note: Object files to link
    start_time as Integer                Note: Compilation start timestamp
    phase_timings as Dictionary[String, Integer] Note: Time per phase
End Type

Type called "CompilationResult":
    success as Boolean                   Note: Overall success status
    output_path as Optional[String]      Note: Generated output file
    diagnostics as List[Diag.Diagnostic] Note: All diagnostics
    statistics as Dictionary[String, Integer] Note: Compilation statistics
    total_time as Integer                Note: Total compilation time
End Type

Note: =====================================================================
Note: MAIN DRIVER OPERATIONS
Note: =====================================================================

External Process called "rust_print_string" that takes text as String
External Process called "rust_get_timestamp" returns Integer

Process called "compile" that takes args as Core.Array returns CompilationResult:
    Note: Main entry point for compilation
    
    Let start_time be rust_get_timestamp()
    
    Note: Parse command-line arguments
    Let options be parse_command_line(args)
    
    Note: Initialize compilation state
    Let state be initialize_compilation(options)
    
    Note: Run the compilation pipeline
    Let result be run_compilation_pipeline(state)
    
    Note: Calculate total time
    Let end_time be rust_get_timestamp()
    Set result.total_time to end_time minus start_time
    
    Return result
End Process

Process called "parse_command_line" that takes args as Core.Array returns CompilerOptions:
    Note: Parse command-line arguments
    
    Let options be CompilerOptions with
        input_files as Core.create_list(),
        output_file as "a.out",
        output_type as "executable",
        optimization_level as 0,
        debug_info as false,
        warnings_as_errors as false,
        verbose as false,
        target_triple as Core.create_optional_none(),
        library_paths as Core.create_list(),
        include_paths as Core.create_list(),
        defines as Core.create_dictionary(),
        link_libraries as Core.create_list(),
        emit_ir as false,
        emit_asm as false,
        no_link as false
    
    Let i be 0
    While i is less than Core.list_length(args):
        Let arg be Core.list_get(args, i)
        
        If arg is equal to "-o":
            Set i to i plus 1
            If i is less than Core.list_length(args):
                Set options.output_file to Core.list_get(args, i)
            End If
        Otherwise If arg is equal to "-O0":
            Set options.optimization_level to 0
        Otherwise If arg is equal to "-O1":
            Set options.optimization_level to 1
        Otherwise If arg is equal to "-O2":
            Set options.optimization_level to 2
        Otherwise If arg is equal to "-O3":
            Set options.optimization_level to 3
        Otherwise If arg is equal to "-g":
            Set options.debug_info to true
        Otherwise If arg is equal to "-v":
            Set options.verbose to true
        Otherwise If arg is equal to "--emit-ir":
            Set options.emit_ir to true
        Otherwise If arg is equal to "--emit-asm":
            Set options.emit_asm to true
        Otherwise If arg is equal to "-c":
            Set options.no_link to true
            Set options.output_type to "object"
        Otherwise:
            Note: Assume it's an input file
            If Core.string_ends_with(arg, ".runa"):
                Core.list_append(options.input_files, arg)
            End If
        End If
        
        Set i to i plus 1
    End While
    
    Return options
End Process

Process called "initialize_compilation" that takes options as CompilerOptions returns CompilationState:
    Note: Set up compilation state
    
    Let state be CompilationState with
        units as Core.create_list(),
        options as options,
        diagnostic_context as Diag.create_diagnostic_context(),
        global_symbols as Core.create_dictionary(),
        link_objects as Core.create_list(),
        start_time as rust_get_timestamp(),
        phase_timings as Core.create_dictionary()
    
    Note: Load each source file
    For Each input_file in options.input_files:
        Let unit be load_source_file(input_file)
        Core.list_append(state.units, unit)
    End For
    
    Return state
End Process

Process called "run_compilation_pipeline" that takes state as CompilationState returns CompilationResult:
    Note: Execute all compilation phases
    
    Let success be true
    Let all_diagnostics be Core.create_list()
    
    Note: Phase 1: Parsing
    If state.options.verbose:
        rust_print_string("Phase 1: Parsing...\n")
    End If
    
    Let parse_success be run_parsing_phase(state)
    If parse_success is equal to false:
        Set success to false
    End If
    
    If success:
        Note: Phase 2: Semantic Analysis
        If state.options.verbose:
            rust_print_string("Phase 2: Semantic Analysis...\n")
        End If
        
        Let semantic_success be run_semantic_phase(state)
        If semantic_success is equal to false:
            Set success to false
        End If
    End If
    
    If success:
        Note: Phase 3: Type Checking
        If state.options.verbose:
            rust_print_string("Phase 3: Type Checking...\n")
        End If
        
        Let type_success be run_type_checking_phase(state)
        If type_success is equal to false:
            Set success to false
        End If
    End If
    
    If success:
        Note: Phase 4: IR Generation
        If state.options.verbose:
            rust_print_string("Phase 4: IR Generation...\n")
        End If
        
        Let ir_success be run_ir_generation_phase(state)
        If ir_success is equal to false:
            Set success to false
        End If
    End If
    
    If success:
        Note: Phase 5: Code Generation
        If state.options.verbose:
            rust_print_string("Phase 5: Code Generation...\n")
        End If
        
        Let codegen_success be run_codegen_phase(state)
        If codegen_success is equal to false:
            Set success to false
        End If
    End If
    
    If success and state.options.no_link is equal to false:
        Note: Phase 6: Linking
        If state.options.verbose:
            rust_print_string("Phase 6: Linking...\n")
        End If
        
        Let link_success be run_linking_phase(state)
        If link_success is equal to false:
            Set success to false
        End If
    End If
    
    Note: Collect all diagnostics
    For Each unit in state.units:
        For Each diag in unit.diagnostics:
            Core.list_append(all_diagnostics, diag)
        End For
    End For
    
    Let output_path be Core.create_optional_none()
    If success:
        Set output_path to Core.create_optional_some(state.options.output_file)
    End If
    
    Return CompilationResult with
        success as success,
        output_path as output_path,
        diagnostics as all_diagnostics,
        statistics as Core.create_dictionary(),
        total_time as 0

Note: =====================================================================
Note: COMPILATION PHASES
Note: =====================================================================

Process called "run_parsing_phase" that takes state as CompilationState returns Boolean:
    Note: Parse all source files to AST
    
    Let all_success be true
    
    For Each unit in state.units:
        Let parse_result be Parser.parse_program(unit.source_content)
        
        If parse_result.success:
            Set unit.ast to Core.create_optional_some(parse_result.ast)
        Otherwise:
            Set all_success to false
            For Each error in parse_result.errors:
                Core.list_append(unit.diagnostics, error)
            End For
        End If
    End For
    
    Return all_success
End Process

Process called "run_semantic_phase" that takes state as CompilationState returns Boolean:
    Note: Perform semantic analysis on all units
    
    Let all_success be true
    
    For Each unit in state.units:
        If Core.optional_has_value(unit.ast):
            Let ast be Core.optional_get_value(unit.ast)
            Let symbol_table be Semantic.create_symbol_table()
            
            Let semantic_result be Semantic.analyze_program(ast, symbol_table)
            
            If semantic_result.success:
                Set unit.symbol_table to Core.create_optional_some(symbol_table)
            Otherwise:
                Set all_success to false
                For Each error in semantic_result.errors:
                    Core.list_append(unit.diagnostics, error)
                End For
            End If
        End If
    End For
    
    Return all_success
End Process

Process called "run_type_checking_phase" that takes state as CompilationState returns Boolean:
    Note: Type check all compilation units
    
    Let all_success be true
    
    For Each unit in state.units:
        If Core.optional_has_value(unit.ast) and Core.optional_has_value(unit.symbol_table):
            Let ast be Core.optional_get_value(unit.ast)
            Let symbol_table be Core.optional_get_value(unit.symbol_table)
            
            Let type_result be Types.check_program(ast, symbol_table)
            
            If type_result.success is equal to false:
                Set all_success to false
                For Each error in type_result.errors:
                    Core.list_append(unit.diagnostics, error)
                End For
            End If
        End If
    End For
    
    Return all_success
End Process

Process called "run_ir_generation_phase" that takes state as CompilationState returns Boolean:
    Note: Generate IR for all units
    
    Let all_success be true
    
    For Each unit in state.units:
        If Core.optional_has_value(unit.ast) and Core.optional_has_value(unit.symbol_table):
            Let ast be Core.optional_get_value(unit.ast)
            Let symbol_table be Core.optional_get_value(unit.symbol_table)
            
            Let ir_module be IR.build_ir_module(ast, symbol_table)
            
            If ir_module is equal to -1:
                Set all_success to false
                Core.list_append(unit.diagnostics, 
                    Diag.create_error("IR generation failed", unit.source_file, 0, 0))
            Otherwise:
                Set unit.ir_module to Core.create_optional_some(ir_module)
                
                Note: Apply optimizations if requested
                If state.options.optimization_level is greater than 0:
                    IR.fold_constants(ir_module)
                    If state.options.optimization_level is greater than 1:
                        IR.eliminate_dead_code(ir_module)
                    End If
                End If
            End If
        End If
    End For
    
    Return all_success
End Process

Process called "run_codegen_phase" that takes state as CompilationState returns Boolean:
    Note: Generate machine code for all units
    
    Let all_success be true
    
    Note: Create codegen context
    Let target be CodeGen.get_native_target()
    Let codegen_ctx be CodeGen.create_codegen_context(
        target,
        CodeGen.CodegenOptions with
            optimization_level as state.options.optimization_level,
            debug_info as state.options.debug_info,
            output_type as "object",
            pic as false,
            link_time_optimization as false,
            target_features as Core.create_list(),
            code_model as "small"
    )
    
    For Each unit in state.units:
        If Core.optional_has_value(unit.ir_module):
            Let ir_module be Core.optional_get_value(unit.ir_module)
            
            Note: Generate code
            Let codegen_result be CodeGen.generate_code(ir_module, codegen_ctx)
            
            If codegen_result.success:
                Set unit.object_code to Core.create_optional_some(codegen_result.output)
                
                Note: Write object file if requested
                If state.options.no_link:
                    Let obj_filename be Core.string_replace(unit.source_file, ".runa", ".o")
                    write_output_file(obj_filename, codegen_result.output)
                    Core.list_append(state.link_objects, obj_filename)
                End If
            Otherwise:
                Set all_success to false
                For Each error in codegen_result.errors:
                    Core.list_append(unit.diagnostics, 
                        Diag.create_error(error, unit.source_file, 0, 0))
                End For
            End If
        End If
    End For
    
    Return all_success
End Process

Process called "run_linking_phase" that takes state as CompilationState returns Boolean:
    Note: Link object files into final output
    Note: For Stage 0.2, linking is not implemented
    
    rust_print_string("Note: Linking not available in Stage 0.2\n")
    rust_print_string("Object files generated, manual linking required\n")
    
    Return true
End Process

Note: =====================================================================
Note: FILE I/O OPERATIONS
Note: =====================================================================

Process called "load_source_file" that takes path as String returns CompilationUnit:
    Note: Load and prepare source file
    
    Let content be Core.read_file(path)
    
    Return CompilationUnit with
        source_file as path,
        source_content as content,
        ast as Core.create_optional_none(),
        symbol_table as Core.create_optional_none(),
        ir_module as Core.create_optional_none(),
        object_code as Core.create_optional_none(),
        diagnostics as Core.create_list(),
        dependencies as Core.create_list()
End Process

Process called "write_output_file" that takes path as String, data as Core.ByteArray returns Boolean:
    Note: Write compilation output to file
    
    Core.write_file_bytes(path, data)
    
    Note: Make executable if needed
    If Core.string_ends_with(path, ".out") or path is equal to "a.out":
        Core.make_executable(path)
    End If
    
    Return true
End Process

Process called "find_import" that takes module_name as String, search_paths as Core.Array returns Core.Optional:
    Note: Locate imported module file
    
    Note: Try each search path
    For Each search_path in search_paths:
        Let full_path be Core.concat_strings(search_path, "/", module_name, ".runa")
        If Core.file_exists(full_path):
            Return Core.create_optional_some(full_path)
        End If
    End For
    
    Note: Try current directory
    Let local_path be Core.concat_strings(module_name, ".runa")
    If Core.file_exists(local_path):
        Return Core.create_optional_some(local_path)
    End If
    
    Return Core.create_optional_none()
End Process

Note: =====================================================================
Note: PARALLEL COMPILATION OPERATIONS
Note: =====================================================================

Process called "partition_units" that takes units as List[CompilationUnit] returns List[List[CompilationUnit]]:
    Note: Partition units for parallel compilation
    Note: Respects dependencies
    Note: Balances work across partitions
    
    Let partitions be Core.create_list()
    Let num_cores be Core.get_cpu_count()
    Let partition_size be Core.divide(Core.list_length(units), num_cores)
    
    If partition_size is equal to 0:
        Set partition_size to 1
    End If
    
    Note: Build dependency graph
    Let dependency_graph be Core.create_dictionary()
    For Each unit in units:
        Core.dictionary_set(dependency_graph, unit.source_file, unit.dependencies)
    End For
    
    Note: Sort units by dependency depth
    Let sorted_units be topological_sort(units, dependency_graph)
    
    Note: Create partitions
    Let current_partition be Core.create_list()
    For Each unit in sorted_units:
        Core.list_append(current_partition, unit)
        
        If Core.list_length(current_partition) is greater than or equal to partition_size:
            Core.list_append(partitions, current_partition)
            Set current_partition to Core.create_list()
        End If
    End For
    
    Note: Add remaining units
    If Core.list_length(current_partition) is greater than 0:
        Core.list_append(partitions, current_partition)
    End If
    
    Return partitions
End Process

Process called "compile_partition" that takes partition as List[CompilationUnit], state as CompilationState returns List[CompilationUnit]:
    Note: Compile a partition of units
    Note: Can run in parallel with others
    Note: Updates units with results
    
    Let compiled_units be Core.create_list()
    
    For Each unit in partition:
        Note: Parse
        Let parse_result be Parser.parse_program(unit.source_content)
        If parse_result.success:
            Set unit.ast to Core.create_optional_some(parse_result.ast)
            
            Note: Semantic analysis
            Let symbol_table be Semantic.create_symbol_table()
            Let semantic_result be Semantic.analyze_program(parse_result.ast, symbol_table)
            
            If semantic_result.success:
                Set unit.symbol_table to Core.create_optional_some(symbol_table)
                
                Note: Type checking
                Let type_result be Types.check_program(parse_result.ast, symbol_table)
                
                If type_result.success:
                    Note: IR generation
                    Let ir_module be IR.build_ir_module(parse_result.ast, symbol_table)
                    If ir_module is not equal to -1:
                        Set unit.ir_module to Core.create_optional_some(ir_module)
                        
                        Note: Code generation
                        Let codegen_ctx be create_codegen_context(state)
                        Let codegen_result be CodeGen.generate_code(ir_module, codegen_ctx)
                        
                        If codegen_result.success:
                            Set unit.object_code to Core.create_optional_some(codegen_result.output)
                        Otherwise:
                            For Each error in codegen_result.errors:
                                Core.list_append(unit.diagnostics, error)
                            End For
                        End If
                    End If
                Otherwise:
                    For Each error in type_result.errors:
                        Core.list_append(unit.diagnostics, error)
                    End For
                End If
            Otherwise:
                For Each error in semantic_result.errors:
                    Core.list_append(unit.diagnostics, error)
                End For
            End If
        Otherwise:
            For Each error in parse_result.errors:
                Core.list_append(unit.diagnostics, error)
            End For
        End If
        
        Core.list_append(compiled_units, unit)
    End For
    
    Return compiled_units
End Process

Process called "merge_compilation_results" that takes partitions as List[List[CompilationUnit]], state as CompilationState returns Boolean:
    Note: Merge results from parallel compilation
    Note: Resolves cross-partition symbols
    Note: Combines diagnostics
    
    Let all_success be true
    Let merged_units be Core.create_list()
    Let global_diagnostics be Core.create_list()
    
    Note: Collect all units and diagnostics
    For Each partition in partitions:
        For Each unit in partition:
            Core.list_append(merged_units, unit)
            
            Note: Check for errors
            If Core.list_length(unit.diagnostics) is greater than 0:
                Set all_success to false
                For Each diagnostic in unit.diagnostics:
                    Core.list_append(global_diagnostics, diagnostic)
                End For
            End If
        End For
    End For
    
    Note: Update state with merged results
    Set state.compilation_units to merged_units
    
    Note: Cross-partition symbol resolution
    Let global_symbol_table be Semantic.create_symbol_table()
    For Each unit in merged_units:
        If Core.optional_has_value(unit.symbol_table):
            Let unit_symbols be Core.optional_unwrap(unit.symbol_table)
            Semantic.merge_symbol_tables(global_symbol_table, unit_symbols)
        End If
    End For
    
    Note: Validate cross-references
    For Each unit in merged_units:
        If Core.optional_has_value(unit.ast):
            Let ast be Core.optional_unwrap(unit.ast)
            Let validation_result be Semantic.validate_cross_references(ast, global_symbol_table)
            If validation_result.success is equal to false:
                Set all_success to false
                For Each error in validation_result.errors:
                    Core.list_append(global_diagnostics, error)
                End For
            End If
        End If
    End For
    
    Note: Store merged diagnostics
    For Each diagnostic in global_diagnostics:
        Diag.add_diagnostic(state.diagnostics, diagnostic)
    End For
    
    Return all_success
End Process

Note: =====================================================================
Note: INCREMENTAL COMPILATION OPERATIONS
Note: =====================================================================

Process called "check_needs_recompilation" that takes unit as CompilationUnit, cache_path as String returns Boolean:
    Note: Check if unit needs recompilation
    Note: Compares timestamps and dependencies
    Note: Validates cached artifacts
    
    Note: Build cache file path
    Let cache_file be Core.concat_strings(cache_path, "/", 
        Core.string_replace(unit.source_file, "/", "_"), ".cache")
    
    Note: Check if cache exists
    If Core.file_exists(cache_file) is equal to false:
        Return true  Note: Need recompilation - no cache
    End If
    
    Note: Get source file modification time
    Let source_mtime be Core.get_file_modification_time(unit.source_file)
    Let cache_mtime be Core.get_file_modification_time(cache_file)
    
    Note: Check if source is newer than cache
    If source_mtime is greater than cache_mtime:
        Return true  Note: Need recompilation - source changed
    End If
    
    Note: Check dependencies
    For Each dep_file in unit.dependencies:
        Let dep_mtime be Core.get_file_modification_time(dep_file)
        If dep_mtime is greater than cache_mtime:
            Return true  Note: Need recompilation - dependency changed
        End If
    End For
    
    Note: Validate cache content
    Let cache_content be Core.read_file(cache_file)
    If Core.string_length(cache_content) is equal to 0:
        Return true  Note: Need recompilation - empty cache
    End If
    
    Note: Check cache version
    Let cache_version be extract_cache_version(cache_content)
    If cache_version is not equal to CACHE_VERSION:
        Return true  Note: Need recompilation - cache version mismatch
    End If
    
    Return false  Note: Can use cached version
End Process

Process called "load_compilation_cache" that takes cache_path as String returns Dictionary[String, CompilationUnit]:
    Note: Load cached compilation results
    Note: Validates cache integrity
    Note: Returns usable cached units
    
    Let cache_dict be Core.create_dictionary()
    
    Note: Check if cache directory exists
    If Core.file_exists(cache_path) is equal to false:
        Return cache_dict  Note: Empty cache if no directory
    End If
    
    Note: Look for cache files
    Let cache_files be Core.list_files_in_directory(cache_path)
    For Each cache_file in cache_files:
        If Core.string_ends_with(cache_file, ".cache"):
            Let cache_content be Core.read_file(Core.concat_strings(cache_path, "/", cache_file))
            If Core.string_length(cache_content) is greater than 0:
                Let cache_data be parse_cache_file(cache_content)
                If cache_data is not equal to Core.create_optional_none():
                    Let unit be Core.optional_unwrap(cache_data)
                    Core.dictionary_set(cache_dict, unit.source_file, unit)
                End If
            End If
        End If
    End For
    
    Return cache_dict
End Process

Process called "save_compilation_cache" that takes units as List[CompilationUnit], cache_path as String returns Boolean:
    Note: Save compilation results to cache
    Note: Stores intermediate artifacts
    Note: Enables incremental compilation
    
    Note: Ensure cache directory exists
    Core.create_directory_if_not_exists(cache_path)
    
    Let all_saved be true
    
    For Each unit in units:
        Note: Only cache successfully compiled units
        If Core.list_length(unit.diagnostics) is equal to 0:
            Let cache_filename be Core.concat_strings(
                Core.string_replace(unit.source_file, "/", "_"), ".cache")
            Let cache_filepath be Core.concat_strings(cache_path, "/", cache_filename)
            
            Note: Create cache content with metadata
            Let cache_content be Core.concat_strings(
                "CACHE_VERSION=", CACHE_VERSION, "\n",
                "SOURCE_FILE=", unit.source_file, "\n",
                "TIMESTAMP=", Core.integer_to_string(Core.get_current_timestamp()), "\n",
                "HAS_AST=", Core.boolean_to_string(Core.optional_has_value(unit.ast)), "\n",
                "HAS_SYMBOLS=", Core.boolean_to_string(Core.optional_has_value(unit.symbol_table)), "\n",
                "HAS_IR=", Core.boolean_to_string(Core.optional_has_value(unit.ir_module)), "\n",
                "HAS_OBJECT=", Core.boolean_to_string(Core.optional_has_value(unit.object_code)), "\n",
                "DEPENDENCIES="
            )
            
            Note: Add dependencies list
            For Each dep in unit.dependencies:
                Set cache_content to Core.concat_strings(cache_content, dep, ";")
            End For
            Set cache_content to Core.concat_strings(cache_content, "\n")
            
            Note: Write cache file
            If Core.write_file(cache_filepath, cache_content) is equal to false:
                Set all_saved to false
            End If
        End If
    End For
    
    Return all_saved
End Process

Note: =====================================================================
Note: DIAGNOSTIC AND REPORTING OPERATIONS
Note: =====================================================================

Process called "report_compilation_summary" that takes result as CompilationResult returns String:
    Note: Generate compilation summary report
    Note: Shows statistics and timings
    Note: Indicates success or failure
    
    Let report be ""
    
    Note: Header
    Set report to Core.concat_strings(report, "=== COMPILATION SUMMARY ===\n")
    
    Note: Overall result
    If result.success:
        Set report to Core.concat_strings(report, "Status: SUCCESS\n")
    Otherwise:
        Set report to Core.concat_strings(report, "Status: FAILED\n")
    End If
    
    Note: File statistics
    Set report to Core.concat_strings(report, "Files Processed: ", 
        Core.integer_to_string(Core.list_length(result.compiled_files)), "\n")
    
    Note: Diagnostic count
    Let error_count be 0
    Let warning_count be 0
    
    For Each diagnostic in result.diagnostics:
        If diagnostic.level is equal to "error":
            Set error_count to error_count plus 1
        Otherwise If diagnostic.level is equal to "warning":
            Set warning_count to warning_count plus 1
        End If
    End For
    
    Set report to Core.concat_strings(report, "Errors: ", 
        Core.integer_to_string(error_count), "\n")
    Set report to Core.concat_strings(report, "Warnings: ", 
        Core.integer_to_string(warning_count), "\n")
    
    Note: Timing information
    If result.timing_info is not equal to Core.create_optional_none():
        Let timings be Core.optional_unwrap(result.timing_info)
        Set report to Core.concat_strings(report, "Total Time: ", 
            Core.integer_to_string(timings.total_time), "ms\n")
        Set report to Core.concat_strings(report, "Parse Time: ", 
            Core.integer_to_string(timings.parse_time), "ms\n")
        Set report to Core.concat_strings(report, "Analysis Time: ", 
            Core.integer_to_string(timings.analysis_time), "ms\n")
        Set report to Core.concat_strings(report, "Codegen Time: ", 
            Core.integer_to_string(timings.codegen_time), "ms\n")
    End If
    
    Note: Output files
    If Core.list_length(result.output_files) is greater than 0:
        Set report to Core.concat_strings(report, "Output Files:\n")
        For Each output_file in result.output_files:
            Set report to Core.concat_strings(report, "  - ", output_file, "\n")
        End For
    End If
    
    Set report to Core.concat_strings(report, "=========================\n")
    
    Return report
End Process

Process called "emit_intermediate_output" that takes state as CompilationState, phase as String returns Boolean:
    Note: Output intermediate compilation artifacts
    Note: For debugging and analysis
    Note: Controlled by compiler options
    
    Note: Check if intermediate output is enabled
    If state.options.emit_intermediate is equal to false:
        Return true  Note: Not enabled, nothing to do
    End If
    
    Let output_dir be Core.concat_strings(state.output_directory, "/intermediate")
    Core.create_directory_if_not_exists(output_dir)
    
    Let all_success be true
    
    For Each unit in state.compilation_units:
        Let base_name be Core.get_file_basename(unit.source_file)
        
        Note: Emit phase-specific output
        Match phase:
            When "parse":
                If Core.optional_has_value(unit.ast):
                    Let ast_file be Core.concat_strings(output_dir, "/", base_name, ".ast")
                    Let ast_content be serialize_ast_to_text(Core.optional_unwrap(unit.ast))
                    If Core.write_file(ast_file, ast_content) is equal to false:
                        Set all_success to false
                    End If
                End If
            
            When "semantic":
                If Core.optional_has_value(unit.symbol_table):
                    Let symbols_file be Core.concat_strings(output_dir, "/", base_name, ".symbols")
                    Let symbols_content be serialize_symbol_table(Core.optional_unwrap(unit.symbol_table))
                    If Core.write_file(symbols_file, symbols_content) is equal to false:
                        Set all_success to false
                    End If
                End If
            
            When "ir":
                If Core.optional_has_value(unit.ir_module):
                    Let ir_file be Core.concat_strings(output_dir, "/", base_name, ".ir")
                    Let ir_content be serialize_ir_module(Core.optional_unwrap(unit.ir_module))
                    If Core.write_file(ir_file, ir_content) is equal to false:
                        Set all_success to false
                    End If
                End If
            
            When "codegen":
                If Core.optional_has_value(unit.object_code):
                    Let obj_file be Core.concat_strings(output_dir, "/", base_name, ".o")
                    If Core.write_file_bytes(obj_file, Core.optional_unwrap(unit.object_code)) is equal to false:
                        Set all_success to false
                    End If
                End If
        End Match
        
        Note: Always emit diagnostics for this phase
        If Core.list_length(unit.diagnostics) is greater than 0:
            Let diag_file be Core.concat_strings(output_dir, "/", base_name, ".", phase, ".diagnostics")
            Let diag_content be ""
            For Each diagnostic in unit.diagnostics:
                Set diag_content to Core.concat_strings(diag_content, 
                    diagnostic.level, ": ", diagnostic.message, "\n")
            End For
            If Core.write_file(diag_file, diag_content) is equal to false:
                Set all_success to false
            End If
        End If
    End For
    
    Return all_success
End Process

Process called "profile_compilation_phase" that takes phase_name as String, start_time as Integer, end_time as Integer, state as CompilationState returns Boolean:
    Note: Record phase timing information
    Note: Updates compilation statistics
    Note: For performance analysis
    
    Let duration be end_time minus start_time
    
    Note: Create performance entry
    Let perf_entry be PerformanceEntry with
        phase as phase_name,
        duration_ms as duration,
        timestamp as start_time,
        memory_usage as 0  Note: Memory tracking not implemented yet
    
    Note: Add to performance log
    Core.list_append(state.performance_log, perf_entry)
    
    Note: Update phase statistics
    If Core.dictionary_has_key(state.phase_timings, phase_name):
        Let existing_time be Core.dictionary_get(state.phase_timings, phase_name)
        Core.dictionary_set(state.phase_timings, phase_name, existing_time plus duration)
    Otherwise:
        Core.dictionary_set(state.phase_timings, phase_name, duration)
    End If
    
    Note: Track total compilation time
    Set state.total_compilation_time to state.total_compilation_time plus duration
    
    Note: Log performance data if enabled
    If state.options.performance_logging:
        rust_print_string(Core.concat_strings(
            "[PERF] ", phase_name, ": ", 
            Core.integer_to_string(duration), "ms\n"))
    End If
    
    Return true
End Process

Note: =====================================================================
Note: HELPER FUNCTIONS
Note: =====================================================================

Process called "topological_sort" that takes units as List[CompilationUnit], dependency_graph as Dictionary[String, Core.Array] returns List[CompilationUnit]:
    Note: Sort compilation units by dependency order
    Note: Units with fewer dependencies come first
    
    Let sorted_units be Core.create_list()
    Let remaining_units be Core.create_list()
    
    Note: Copy all units to remaining list
    For Each unit in units:
        Core.list_append(remaining_units, unit)
    End For
    
    Note: Simple dependency-aware sorting
    While Core.list_length(remaining_units) is greater than 0:
        Let progress_made be false
        Let units_to_remove be Core.create_list()
        
        For Each unit in remaining_units:
            Let dependencies_satisfied be true
            
            Note: Check if all dependencies are already sorted
            For Each dep_file in unit.dependencies:
                Let dep_found be false
                For Each sorted_unit in sorted_units:
                    If sorted_unit.source_file is equal to dep_file:
                        Set dep_found to true
                    End If
                End For
                If dep_found is equal to false:
                    Set dependencies_satisfied to false
                End If
            End For
            
            If dependencies_satisfied:
                Core.list_append(sorted_units, unit)
                Core.list_append(units_to_remove, unit)
                Set progress_made to true
            End If
        End For
        
        Note: Remove processed units
        For Each unit_to_remove in units_to_remove:
            Core.list_remove(remaining_units, unit_to_remove)
        End For
        
        Note: Detect circular dependencies
        If progress_made is equal to false:
            Note: Add remaining units in original order to avoid infinite loop
            For Each unit in remaining_units:
                Core.list_append(sorted_units, unit)
            End For
            Return sorted_units
        End If
    End While
    
    Return sorted_units
End Process

Process called "extract_cache_version" that takes cache_content as String returns String:
    Note: Extract version from cache file content
    
    Let lines be Core.string_split(cache_content, "\n")
    For Each line in lines:
        If Core.string_starts_with(line, "CACHE_VERSION="):
            Return Core.string_substring(line, 14, Core.string_length(line) minus 14)
        End If
    End For
    
    Return "unknown"
End Process

Process called "parse_cache_file" that takes cache_content as String returns Core.Optional:
    Note: Parse cache file and reconstruct compilation unit
    
    Let lines be Core.string_split(cache_content, "\n")
    Let unit_data be Core.create_dictionary()
    
    Note: Parse key-value pairs
    For Each line in lines:
        If Core.string_contains(line, "="):
            Let parts be Core.string_split(line, "=")
            If Core.list_length(parts) is equal to 2:
                Let key be Core.list_get(parts, 0)
                Let value be Core.list_get(parts, 1)
                Core.dictionary_set(unit_data, key, value)
            End If
        End If
    End For
    
    Note: Reconstruct compilation unit
    If Core.dictionary_has_key(unit_data, "SOURCE_FILE"):
        Let source_file be Core.dictionary_get(unit_data, "SOURCE_FILE")
        Let unit be CompilationUnit with
            source_file as source_file,
            source_content as "",  Note: Will be loaded when needed
            ast as Core.create_optional_none(),
            symbol_table as Core.create_optional_none(),
            ir_module as Core.create_optional_none(),
            object_code as Core.create_optional_none(),
            diagnostics as Core.create_list(),
            dependencies as Core.create_list()
        
        Note: Parse dependencies
        If Core.dictionary_has_key(unit_data, "DEPENDENCIES"):
            Let deps_str be Core.dictionary_get(unit_data, "DEPENDENCIES")
            If Core.string_length(deps_str) is greater than 0:
                Let deps be Core.string_split(deps_str, ";")
                For Each dep in deps:
                    If Core.string_length(dep) is greater than 0:
                        Core.list_append(unit.dependencies, dep)
                    End If
                End For
            End If
        End If
        
        Return Core.create_optional_some(unit)
    End If
    
    Return Core.create_optional_none()
End Process

Process called "serialize_ast_to_text" that takes ast as Integer returns String:
    Note: Convert AST to readable text format for debugging
    Return Core.concat_strings("AST[", Core.integer_to_string(ast), "]")
End Process

Process called "serialize_symbol_table" that takes symbol_table as Integer returns String:
    Note: Convert symbol table to readable text format
    Return Core.concat_strings("SymbolTable[", Core.integer_to_string(symbol_table), "]")
End Process

Process called "serialize_ir_module" that takes ir_module as Integer returns String:
    Note: Convert IR module to readable text format
    Return Core.concat_strings("IRModule[", Core.integer_to_string(ir_module), "]")
End Process

Note: Constants
Let CACHE_VERSION be "1.0"