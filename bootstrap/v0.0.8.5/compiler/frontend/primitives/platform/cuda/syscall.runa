Note:
Copyright 2025 Sybertnetics Artificial Intelligence Solutions

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
:End Note

Note:
CUDA Device API Implementation

This file implements CUDA device API calls for GPU kernel execution.

Platform-specific details:
- Platform: CUDA (NVIDIA GPU)
- Architecture: PTX (Parallel Thread Execution)
- API Convention: CUDA Runtime/Driver API
- Execution Model: Kernel launch with thread blocks and grids

CUDA uses device APIs rather than traditional OS syscalls:
1. Device management (cudaGetDevice, cudaSetDevice, cudaGetDeviceProperties)
2. Memory management (cudaMalloc, cudaFree, cudaMemcpy)
3. Kernel execution (cudaLaunchKernel, cudaDeviceSynchronize)
4. Stream management (cudaStreamCreate, cudaStreamDestroy, cudaStreamSynchronize)
5. Event management (cudaEventCreate, cudaEventDestroy, cudaEventRecord)
6. Texture and surface operations
7. Unified memory operations

This implementation provides low-level bindings to CUDA device APIs.
:End Note

Note: ============================================================================
Note: CUDA API RETURN CODES
Note: ============================================================================

Process called "CUDA_SUCCESS" returns Integer:
    Note: Operation completed successfully
    Return 0
End Process

Process called "CUDA_ERROR_INVALID_VALUE" returns Integer:
    Note: Invalid argument passed to API
    Return 1
End Process

Process called "CUDA_ERROR_OUT_OF_MEMORY" returns Integer:
    Note: Out of device memory
    Return 2
End Process

Process called "CUDA_ERROR_NOT_INITIALIZED" returns Integer:
    Note: CUDA driver not initialized
    Return 3
End Process

Process called "CUDA_ERROR_DEINITIALIZED" returns Integer:
    Note: CUDA driver being shut down
    Return 4
End Process

Process called "CUDA_ERROR_NO_DEVICE" returns Integer:
    Note: No CUDA-capable device found
    Return 100
End Process

Process called "CUDA_ERROR_INVALID_DEVICE" returns Integer:
    Note: Invalid device ordinal
    Return 101
End Process

Process called "CUDA_ERROR_INVALID_CONTEXT" returns Integer:
    Note: Invalid CUDA context
    Return 201
End Process

Process called "CUDA_ERROR_LAUNCH_FAILED" returns Integer:
    Note: Kernel launch failed
    Return 719
End Process

Process called "CUDA_ERROR_ILLEGAL_ADDRESS" returns Integer:
    Note: Illegal memory access
    Return 700
End Process

Note: ============================================================================
Note: CUDA MEMORY FLAGS AND CONSTANTS
Note: ============================================================================

Process called "cudaMemcpyHostToDevice" returns Integer:
    Note: Copy from host to device
    Return 1
End Process

Process called "cudaMemcpyDeviceToHost" returns Integer:
    Note: Copy from device to host
    Return 2
End Process

Process called "cudaMemcpyDeviceToDevice" returns Integer:
    Note: Copy from device to device
    Return 3
End Process

Process called "cudaMemcpyHostToHost" returns Integer:
    Note: Copy from host to host
    Return 0
End Process

Process called "cudaMemcpyDefault" returns Integer:
    Note: Direction inferred from pointer values (requires unified memory)
    Return 4
End Process

Process called "cudaHostAllocDefault" returns Integer:
    Note: Default pinned memory allocation
    Return 0
End Process

Process called "cudaHostAllocPortable" returns Integer:
    Note: Pinned memory usable by all CUDA contexts
    Return 1
End Process

Process called "cudaHostAllocMapped" returns Integer:
    Note: Map allocation into device address space
    Return 2
End Process

Process called "cudaHostAllocWriteCombined" returns Integer:
    Note: Write-combined memory
    Return 4
End Process

Note: ============================================================================
Note: CUDA DEVICE MANAGEMENT
Note: ============================================================================

Process called "cuda_get_device" takes device_ptr as Integer returns Integer:
    Note: Get current device ordinal
    Note: device_ptr: Pointer to integer to receive device ordinal
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        // This is a host-side API call
        call.uni cudaGetDevice, (device_ptr)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_set_device" takes device as Integer returns Integer:
    Note: Set current device
    Note: device: Device ordinal to set as current
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaSetDevice, (device)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_get_device_count" takes count_ptr as Integer returns Integer:
    Note: Get number of CUDA-capable devices
    Note: count_ptr: Pointer to integer to receive device count
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaGetDeviceCount, (count_ptr)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_device_synchronize" returns Integer:
    Note: Block until device has completed all preceding tasks
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: synchronization barrier
        call.uni cudaDeviceSynchronize, ()
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_device_reset" returns Integer:
    Note: Reset device and destroy all contexts
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaDeviceReset, ()
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Note: ============================================================================
Note: CUDA MEMORY MANAGEMENT
Note: ============================================================================

Process called "cuda_malloc" takes dev_ptr_ptr as Integer, size as Integer returns Integer:
    Note: Allocate device memory
    Note: dev_ptr_ptr: Pointer to receive device pointer
    Note: size: Size in bytes to allocate
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaMalloc, (dev_ptr_ptr, size)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_free" takes dev_ptr as Integer returns Integer:
    Note: Free device memory
    Note: dev_ptr: Device pointer to free
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaFree, (dev_ptr)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_memcpy" takes dst as Integer, src as Integer, count as Integer, kind as Integer returns Integer:
    Note: Copy memory between host and device
    Note: dst: Destination pointer
    Note: src: Source pointer
    Note: count: Size in bytes
    Note: kind: Direction (cudaMemcpyHostToDevice, etc.)
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaMemcpy, (dst, src, count, kind)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_memcpy_async" takes dst as Integer, src as Integer, count as Integer, kind as Integer, stream as Integer returns Integer:
    Note: Asynchronously copy memory
    Note: stream: CUDA stream for async operation
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaMemcpyAsync, (dst, src, count, kind, stream)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_memset" takes dev_ptr as Integer, value as Integer, count as Integer returns Integer:
    Note: Set device memory to value
    Note: dev_ptr: Device pointer
    Note: value: Value to set (interpreted as unsigned char)
    Note: count: Size in bytes
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaMemset, (dev_ptr, value, count)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_malloc_host" takes ptr_ptr as Integer, size as Integer returns Integer:
    Note: Allocate pinned host memory
    Note: ptr_ptr: Pointer to receive host pointer
    Note: size: Size in bytes
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaMallocHost, (ptr_ptr, size)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_free_host" takes ptr as Integer returns Integer:
    Note: Free pinned host memory
    Note: ptr: Host pointer to free
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaFreeHost, (ptr)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_malloc_managed" takes dev_ptr_ptr as Integer, size as Integer, flags as Integer returns Integer:
    Note: Allocate unified memory
    Note: dev_ptr_ptr: Pointer to receive unified memory pointer
    Note: size: Size in bytes
    Note: flags: Allocation flags
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaMallocManaged, (dev_ptr_ptr, size, flags)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Note: ============================================================================
Note: CUDA STREAM MANAGEMENT
Note: ============================================================================

Process called "cuda_stream_create" takes stream_ptr as Integer returns Integer:
    Note: Create CUDA stream
    Note: stream_ptr: Pointer to receive stream handle
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaStreamCreate, (stream_ptr)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_stream_destroy" takes stream as Integer returns Integer:
    Note: Destroy CUDA stream
    Note: stream: Stream handle to destroy
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaStreamDestroy, (stream)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_stream_synchronize" takes stream as Integer returns Integer:
    Note: Wait for stream to complete
    Note: stream: Stream handle
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaStreamSynchronize, (stream)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_stream_query" takes stream as Integer returns Integer:
    Note: Query stream completion status (non-blocking)
    Note: stream: Stream handle
    Note: Returns: cudaSuccess if complete, cudaErrorNotReady if still running
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaStreamQuery, (stream)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Note: ============================================================================
Note: CUDA EVENT MANAGEMENT
Note: ============================================================================

Process called "cuda_event_create" takes event_ptr as Integer returns Integer:
    Note: Create CUDA event
    Note: event_ptr: Pointer to receive event handle
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaEventCreate, (event_ptr)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_event_destroy" takes event as Integer returns Integer:
    Note: Destroy CUDA event
    Note: event: Event handle to destroy
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaEventDestroy, (event)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_event_record" takes event as Integer, stream as Integer returns Integer:
    Note: Record event in stream
    Note: event: Event handle
    Note: stream: Stream handle (0 for default stream)
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaEventRecord, (event, stream)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_event_synchronize" takes event as Integer returns Integer:
    Note: Wait for event completion
    Note: event: Event handle
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaEventSynchronize, (event)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_event_elapsed_time" takes ms_ptr as Integer, start_event as Integer, end_event as Integer returns Integer:
    Note: Get elapsed time between events
    Note: ms_ptr: Pointer to receive time in milliseconds
    Note: start_event: Start event handle
    Note: end_event: End event handle
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaEventElapsedTime, (ms_ptr, start_event, end_event)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Note: ============================================================================
Note: CUDA KERNEL LAUNCH
Note: ============================================================================

Process called "cuda_launch_kernel" takes func as Integer, grid_dim_x as Integer, grid_dim_y as Integer, grid_dim_z as Integer, block_dim_x as Integer, block_dim_y as Integer, block_dim_z as Integer, shared_mem as Integer, stream as Integer, kernel_params as Integer returns Integer:
    Note: Launch CUDA kernel
    Note: func: Kernel function pointer
    Note: grid_dim_x/y/z: Grid dimensions
    Note: block_dim_x/y/z: Block dimensions
    Note: shared_mem: Shared memory size in bytes
    Note: stream: Stream handle (0 for default stream)
    Note: kernel_params: Pointer to array of kernel parameters
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaLaunchKernel, (func, grid_dim_x, grid_dim_y, grid_dim_z, block_dim_x, block_dim_y, block_dim_z, shared_mem, stream, kernel_params)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_configure_call" takes grid_dim_x as Integer, grid_dim_y as Integer, grid_dim_z as Integer, block_dim_x as Integer, block_dim_y as Integer, block_dim_z as Integer, shared_mem as Integer, stream as Integer returns Integer:
    Note: Configure parameters for kernel launch
    Note: Used for <<<grid, block, shared_mem, stream>>> syntax
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaConfigureCall, (grid_dim_x, grid_dim_y, grid_dim_z, block_dim_x, block_dim_y, block_dim_z, shared_mem, stream)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Note: ============================================================================
Note: CUDA DEVICE PROPERTIES
Note: ============================================================================

Process called "cuda_get_device_properties" takes prop_ptr as Integer, device as Integer returns Integer:
    Note: Get device properties
    Note: prop_ptr: Pointer to cudaDeviceProp structure
    Note: device: Device ordinal
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaGetDeviceProperties, (prop_ptr, device)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_device_get_attribute" takes value_ptr as Integer, attr as Integer, device as Integer returns Integer:
    Note: Get specific device attribute
    Note: value_ptr: Pointer to receive attribute value
    Note: attr: Attribute to query
    Note: device: Device ordinal
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaDeviceGetAttribute, (value_ptr, attr, device)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Note: ============================================================================
Note: CUDA OCCUPANCY CALCULATION
Note: ============================================================================

Process called "cuda_occupancy_max_active_blocks_per_multiprocessor" takes num_blocks_ptr as Integer, func as Integer, block_size as Integer, dynamic_smem_size as Integer returns Integer:
    Note: Calculate maximum active blocks per SM
    Note: num_blocks_ptr: Pointer to receive result
    Note: func: Kernel function pointer
    Note: block_size: Block size (threads per block)
    Note: dynamic_smem_size: Dynamic shared memory size
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaOccupancyMaxActiveBlocksPerMultiprocessor, (num_blocks_ptr, func, block_size, dynamic_smem_size)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Note: ============================================================================
Note: CUDA ERROR HANDLING
Note: ============================================================================

Process called "cuda_get_last_error" returns Integer:
    Note: Get last error code
    Note: Returns: Last error code (clears error state)
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaGetLastError, ()
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_peek_at_last_error" returns Integer:
    Note: Get last error code without clearing
    Note: Returns: Last error code (does not clear error state)
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaPeekAtLastError, ()
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_get_error_string" takes error as Integer returns Integer:
    Note: Get error message string
    Note: error: Error code
    Note: Returns: Pointer to error message string
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaGetErrorString, (error)
        st.param.u64 result, %r0
    End Assembly
    Return result
End Process

Note: ============================================================================
Note: CUDA PEER DEVICE ACCESS
Note: ============================================================================

Process called "cuda_device_enable_peer_access" takes peer_device as Integer, flags as Integer returns Integer:
    Note: Enable peer access between devices
    Note: peer_device: Device to enable access to
    Note: flags: Reserved (must be 0)
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaDeviceEnablePeerAccess, (peer_device, flags)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_device_disable_peer_access" takes peer_device as Integer returns Integer:
    Note: Disable peer access
    Note: peer_device: Device to disable access to
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaDeviceDisablePeerAccess, (peer_device)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Note: ============================================================================
Note: CUDA TEXTURE AND SURFACE OPERATIONS
Note: ============================================================================

Process called "cuda_create_texture_object" takes tex_obj_ptr as Integer, res_desc_ptr as Integer, tex_desc_ptr as Integer, res_view_desc_ptr as Integer returns Integer:
    Note: Create texture object
    Note: tex_obj_ptr: Pointer to receive texture object
    Note: res_desc_ptr: Resource descriptor
    Note: tex_desc_ptr: Texture descriptor
    Note: res_view_desc_ptr: Resource view descriptor (can be NULL)
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaCreateTextureObject, (tex_obj_ptr, res_desc_ptr, tex_desc_ptr, res_view_desc_ptr)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_destroy_texture_object" takes tex_obj as Integer returns Integer:
    Note: Destroy texture object
    Note: tex_obj: Texture object to destroy
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaDestroyTextureObject, (tex_obj)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Note: ============================================================================
Note: CUDA UNIFIED MEMORY
Note: ============================================================================

Process called "cuda_mem_advise" takes dev_ptr as Integer, count as Integer, advice as Integer, device as Integer returns Integer:
    Note: Advise about memory usage
    Note: dev_ptr: Pointer to unified memory
    Note: count: Size in bytes
    Note: advice: Memory advice hint
    Note: device: Device ordinal
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaMemAdvise, (dev_ptr, count, advice, device)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_mem_prefetch_async" takes dev_ptr as Integer, count as Integer, dst_device as Integer, stream as Integer returns Integer:
    Note: Prefetch unified memory to device
    Note: dev_ptr: Pointer to unified memory
    Note: count: Size in bytes
    Note: dst_device: Destination device
    Note: stream: Stream for async operation
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaMemPrefetchAsync, (dev_ptr, count, dst_device, stream)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Note: ============================================================================
Note: CUDA GRAPH OPERATIONS
Note: ============================================================================

Process called "cuda_graph_create" takes graph_ptr as Integer, flags as Integer returns Integer:
    Note: Create CUDA graph
    Note: graph_ptr: Pointer to receive graph handle
    Note: flags: Graph creation flags
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaGraphCreate, (graph_ptr, flags)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_graph_destroy" takes graph as Integer returns Integer:
    Note: Destroy CUDA graph
    Note: graph: Graph handle to destroy
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaGraphDestroy, (graph)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_graph_instantiate" takes graph_exec_ptr as Integer, graph as Integer, flags as Integer returns Integer:
    Note: Instantiate graph for execution
    Note: graph_exec_ptr: Pointer to receive executable graph
    Note: graph: Graph handle
    Note: flags: Instantiation flags
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaGraphInstantiate, (graph_exec_ptr, graph, flags)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_graph_launch" takes graph_exec as Integer, stream as Integer returns Integer:
    Note: Launch executable graph in stream
    Note: graph_exec: Executable graph handle
    Note: stream: Stream for execution
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaGraphLaunch, (graph_exec, stream)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Note: ============================================================================
Note: CUDA PROFILER CONTROL
Note: ============================================================================

Process called "cuda_profiler_start" returns Integer:
    Note: Enable profiler data collection
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaProfilerStart, ()
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_profiler_stop" returns Integer:
    Note: Disable profiler data collection
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaProfilerStop, ()
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Note: ============================================================================
Note: CUDA CONTEXT MANAGEMENT
Note: ============================================================================

Process called "cuda_device_get_cache_config" takes config_ptr as Integer returns Integer:
    Note: Get current cache config preference
    Note: config_ptr: Pointer to receive cache config
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaDeviceGetCacheConfig, (config_ptr)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_device_set_cache_config" takes config as Integer returns Integer:
    Note: Set cache config preference
    Note: config: Cache config value
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaDeviceSetCacheConfig, (config)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_device_get_shared_mem_config" takes config_ptr as Integer returns Integer:
    Note: Get shared memory bank size config
    Note: config_ptr: Pointer to receive config
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaDeviceGetSharedMemConfig, (config_ptr)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_device_set_shared_mem_config" takes config as Integer returns Integer:
    Note: Set shared memory bank size config
    Note: config: Config value (4-byte or 8-byte banks)
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaDeviceSetSharedMemConfig, (config)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_device_get_limit" takes limit_ptr as Integer, limit_type as Integer returns Integer:
    Note: Get device resource limit
    Note: limit_ptr: Pointer to receive limit value
    Note: limit_type: Type of limit to query
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaDeviceGetLimit, (limit_ptr, limit_type)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_device_set_limit" takes limit_type as Integer, value as Integer returns Integer:
    Note: Set device resource limit
    Note: limit_type: Type of limit to set
    Note: value: Limit value
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaDeviceSetLimit, (limit_type, value)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Note: ============================================================================
Note: CUDA MEMORY MANAGEMENT (EXTENDED)
Note: ============================================================================

Process called "cuda_memcpy_2d" takes dst as Integer, dpitch as Integer, src as Integer, spitch as Integer, width as Integer, height as Integer, kind as Integer returns Integer:
    Note: Copy 2D memory region
    Note: dst: Destination pointer
    Note: dpitch: Destination pitch
    Note: src: Source pointer
    Note: spitch: Source pitch
    Note: width: Width in bytes
    Note: height: Height in rows
    Note: kind: Copy direction
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaMemcpy2D, (dst, dpitch, src, spitch, width, height, kind)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_memcpy_2d_async" takes dst as Integer, dpitch as Integer, src as Integer, spitch as Integer, width as Integer, height as Integer, kind as Integer, stream as Integer returns Integer:
    Note: Async copy 2D memory region
    Note: stream: Stream for async operation
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaMemcpy2DAsync, (dst, dpitch, src, spitch, width, height, kind, stream)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_memcpy_3d" takes p as Integer returns Integer:
    Note: Copy 3D memory region
    Note: p: Pointer to cudaMemcpy3DParms structure
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaMemcpy3D, (p)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_memcpy_3d_async" takes p as Integer, stream as Integer returns Integer:
    Note: Async copy 3D memory region
    Note: p: Pointer to cudaMemcpy3DParms structure
    Note: stream: Stream for async operation
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaMemcpy3DAsync, (p, stream)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_memcpy_peer" takes dst as Integer, dst_device as Integer, src as Integer, src_device as Integer, count as Integer returns Integer:
    Note: Copy memory between devices
    Note: dst: Destination pointer
    Note: dst_device: Destination device
    Note: src: Source pointer
    Note: src_device: Source device
    Note: count: Size in bytes
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaMemcpyPeer, (dst, dst_device, src, src_device, count)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_memcpy_peer_async" takes dst as Integer, dst_device as Integer, src as Integer, src_device as Integer, count as Integer, stream as Integer returns Integer:
    Note: Async copy memory between devices
    Note: stream: Stream for async operation
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaMemcpyPeerAsync, (dst, dst_device, src, src_device, count, stream)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_memset_async" takes dev_ptr as Integer, value as Integer, count as Integer, stream as Integer returns Integer:
    Note: Async set device memory
    Note: dev_ptr: Device pointer
    Note: value: Value to set
    Note: count: Size in bytes
    Note: stream: Stream for async operation
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaMemsetAsync, (dev_ptr, value, count, stream)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_memset_2d" takes dev_ptr as Integer, pitch as Integer, value as Integer, width as Integer, height as Integer returns Integer:
    Note: Set 2D device memory
    Note: dev_ptr: Device pointer
    Note: pitch: Pitch in bytes
    Note: value: Value to set
    Note: width: Width in bytes
    Note: height: Height in rows
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaMemset2D, (dev_ptr, pitch, value, width, height)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_memset_2d_async" takes dev_ptr as Integer, pitch as Integer, value as Integer, width as Integer, height as Integer, stream as Integer returns Integer:
    Note: Async set 2D device memory
    Note: stream: Stream for async operation
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaMemset2DAsync, (dev_ptr, pitch, value, width, height, stream)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_memset_3d" takes pitchedDevPtr as Integer, value as Integer, extent as Integer returns Integer:
    Note: Set 3D device memory
    Note: pitchedDevPtr: Pitched device pointer structure
    Note: value: Value to set
    Note: extent: Extent structure defining dimensions
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaMemset3D, (pitchedDevPtr, value, extent)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_memset_3d_async" takes pitchedDevPtr as Integer, value as Integer, extent as Integer, stream as Integer returns Integer:
    Note: Async set 3D device memory
    Note: stream: Stream for async operation
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaMemset3DAsync, (pitchedDevPtr, value, extent, stream)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_malloc_pitch" takes dev_ptr_ptr as Integer, pitch_ptr as Integer, width as Integer, height as Integer returns Integer:
    Note: Allocate pitched device memory
    Note: dev_ptr_ptr: Pointer to receive device pointer
    Note: pitch_ptr: Pointer to receive pitch value
    Note: width: Width in bytes
    Note: height: Height in rows
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaMallocPitch, (dev_ptr_ptr, pitch_ptr, width, height)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_malloc_3d" takes pitchedDevPtr as Integer, extent as Integer returns Integer:
    Note: Allocate 3D device memory
    Note: pitchedDevPtr: Pitched device pointer structure
    Note: extent: Extent structure defining dimensions
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaMalloc3D, (pitchedDevPtr, extent)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_malloc_array" takes array_ptr as Integer, desc as Integer, width as Integer, height as Integer, flags as Integer returns Integer:
    Note: Allocate CUDA array
    Note: array_ptr: Pointer to receive array handle
    Note: desc: Channel format descriptor
    Note: width: Array width
    Note: height: Array height
    Note: flags: Allocation flags
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaMallocArray, (array_ptr, desc, width, height, flags)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_free_array" takes array as Integer returns Integer:
    Note: Free CUDA array
    Note: array: Array handle to free
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaFreeArray, (array)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_malloc_mipmapped_array" takes mipmapped_array_ptr as Integer, desc as Integer, extent as Integer, num_levels as Integer, flags as Integer returns Integer:
    Note: Allocate mipmapped CUDA array
    Note: mipmapped_array_ptr: Pointer to receive mipmapped array
    Note: desc: Channel format descriptor
    Note: extent: Array extent
    Note: num_levels: Number of mipmap levels
    Note: flags: Allocation flags
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaMallocMipmappedArray, (mipmapped_array_ptr, desc, extent, num_levels, flags)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_free_mipmapped_array" takes mipmapped_array as Integer returns Integer:
    Note: Free mipmapped CUDA array
    Note: mipmapped_array: Mipmapped array to free
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaFreeMipmappedArray, (mipmapped_array)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Note: ============================================================================
Note: CUDA HOST MEMORY ALLOCATION (EXTENDED)
Note: ============================================================================

Process called "cuda_host_alloc" takes ptr_ptr as Integer, size as Integer, flags as Integer returns Integer:
    Note: Allocate page-locked host memory with flags
    Note: ptr_ptr: Pointer to receive host pointer
    Note: size: Size in bytes
    Note: flags: Allocation flags
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaHostAlloc, (ptr_ptr, size, flags)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_host_get_device_pointer" takes dev_ptr_ptr as Integer, host_ptr as Integer, flags as Integer returns Integer:
    Note: Get device pointer for mapped host memory
    Note: dev_ptr_ptr: Pointer to receive device pointer
    Note: host_ptr: Host pointer
    Note: flags: Reserved (must be 0)
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaHostGetDevicePointer, (dev_ptr_ptr, host_ptr, flags)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_host_get_flags" takes flags_ptr as Integer, host_ptr as Integer returns Integer:
    Note: Get flags for host memory allocation
    Note: flags_ptr: Pointer to receive flags
    Note: host_ptr: Host pointer
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaHostGetFlags, (flags_ptr, host_ptr)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_host_register" takes ptr as Integer, size as Integer, flags as Integer returns Integer:
    Note: Register existing host memory for CUDA use
    Note: ptr: Host pointer to register
    Note: size: Size in bytes
    Note: flags: Registration flags
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaHostRegister, (ptr, size, flags)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_host_unregister" takes ptr as Integer returns Integer:
    Note: Unregister host memory
    Note: ptr: Host pointer to unregister
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaHostUnregister, (ptr)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Note: ============================================================================
Note: CUDA MEMORY POOLS (CUDA 11.2+)
Note: ============================================================================

Process called "cuda_malloc_async" takes dev_ptr_ptr as Integer, size as Integer, stream as Integer returns Integer:
    Note: Allocate device memory from stream-ordered pool
    Note: dev_ptr_ptr: Pointer to receive device pointer
    Note: size: Size in bytes
    Note: stream: Stream for memory ordering
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaMallocAsync, (dev_ptr_ptr, size, stream)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_free_async" takes dev_ptr as Integer, stream as Integer returns Integer:
    Note: Free device memory to stream-ordered pool
    Note: dev_ptr: Device pointer to free
    Note: stream: Stream for memory ordering
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaFreeAsync, (dev_ptr, stream)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_mem_pool_create" takes pool_ptr as Integer, pool_props as Integer returns Integer:
    Note: Create memory pool
    Note: pool_ptr: Pointer to receive pool handle
    Note: pool_props: Pool properties structure
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaMemPoolCreate, (pool_ptr, pool_props)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_mem_pool_destroy" takes pool as Integer returns Integer:
    Note: Destroy memory pool
    Note: pool: Pool handle to destroy
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaMemPoolDestroy, (pool)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_mem_pool_get_attribute" takes pool as Integer, attr as Integer, value_ptr as Integer returns Integer:
    Note: Get memory pool attribute
    Note: pool: Pool handle
    Note: attr: Attribute to query
    Note: value_ptr: Pointer to receive value
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaMemPoolGetAttribute, (pool, attr, value_ptr)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_mem_pool_set_attribute" takes pool as Integer, attr as Integer, value_ptr as Integer returns Integer:
    Note: Set memory pool attribute
    Note: pool: Pool handle
    Note: attr: Attribute to set
    Note: value_ptr: Pointer to value
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaMemPoolSetAttribute, (pool, attr, value_ptr)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Note: ============================================================================
Note: CUDA STREAM MANAGEMENT (EXTENDED)
Note: ============================================================================

Process called "cuda_stream_create_with_flags" takes stream_ptr as Integer, flags as Integer returns Integer:
    Note: Create stream with flags
    Note: stream_ptr: Pointer to receive stream handle
    Note: flags: Stream flags
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaStreamCreateWithFlags, (stream_ptr, flags)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_stream_create_with_priority" takes stream_ptr as Integer, flags as Integer, priority as Integer returns Integer:
    Note: Create stream with priority
    Note: stream_ptr: Pointer to receive stream handle
    Note: flags: Stream flags
    Note: priority: Stream priority
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaStreamCreateWithPriority, (stream_ptr, flags, priority)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_stream_get_priority" takes stream as Integer, priority_ptr as Integer returns Integer:
    Note: Get stream priority
    Note: stream: Stream handle
    Note: priority_ptr: Pointer to receive priority
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaStreamGetPriority, (stream, priority_ptr)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_stream_get_flags" takes stream as Integer, flags_ptr as Integer returns Integer:
    Note: Get stream flags
    Note: stream: Stream handle
    Note: flags_ptr: Pointer to receive flags
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaStreamGetFlags, (stream, flags_ptr)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_stream_wait_event" takes stream as Integer, event as Integer, flags as Integer returns Integer:
    Note: Make stream wait for event
    Note: stream: Stream handle
    Note: event: Event to wait for
    Note: flags: Reserved (must be 0)
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaStreamWaitEvent, (stream, event, flags)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_stream_add_callback" takes stream as Integer, callback as Integer, user_data as Integer, flags as Integer returns Integer:
    Note: Add callback to stream
    Note: stream: Stream handle
    Note: callback: Callback function pointer
    Note: user_data: User data passed to callback
    Note: flags: Reserved (must be 0)
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaStreamAddCallback, (stream, callback, user_data, flags)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_stream_attach_mem_async" takes stream as Integer, dev_ptr as Integer, length as Integer, flags as Integer returns Integer:
    Note: Attach memory to stream
    Note: stream: Stream handle
    Note: dev_ptr: Device pointer
    Note: length: Size in bytes
    Note: flags: Attachment flags
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaStreamAttachMemAsync, (stream, dev_ptr, length, flags)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_stream_begin_capture" takes stream as Integer, mode as Integer returns Integer:
    Note: Begin stream capture
    Note: stream: Stream to capture
    Note: mode: Capture mode
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaStreamBeginCapture, (stream, mode)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_stream_end_capture" takes stream as Integer, graph_ptr as Integer returns Integer:
    Note: End stream capture
    Note: stream: Stream being captured
    Note: graph_ptr: Pointer to receive captured graph
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaStreamEndCapture, (stream, graph_ptr)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_stream_is_capturing" takes stream as Integer, status_ptr as Integer returns Integer:
    Note: Query if stream is capturing
    Note: stream: Stream handle
    Note: status_ptr: Pointer to receive capture status
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaStreamIsCapturing, (stream, status_ptr)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Note: ============================================================================
Note: CUDA EVENT MANAGEMENT (EXTENDED)
Note: ============================================================================

Process called "cuda_event_create_with_flags" takes event_ptr as Integer, flags as Integer returns Integer:
    Note: Create event with flags
    Note: event_ptr: Pointer to receive event handle
    Note: flags: Event flags
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaEventCreateWithFlags, (event_ptr, flags)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_event_query" takes event as Integer returns Integer:
    Note: Query event status
    Note: event: Event handle
    Note: Returns: cudaSuccess if complete, cudaErrorNotReady otherwise
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaEventQuery, (event)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_event_record_with_flags" takes event as Integer, stream as Integer, flags as Integer returns Integer:
    Note: Record event with flags
    Note: event: Event handle
    Note: stream: Stream handle
    Note: flags: Record flags
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaEventRecordWithFlags, (event, stream, flags)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Note: ============================================================================
Note: CUDA FUNCTION ATTRIBUTES
Note: ============================================================================

Process called "cuda_func_get_attributes" takes attr_ptr as Integer, func as Integer returns Integer:
    Note: Get function attributes
    Note: attr_ptr: Pointer to cudaFuncAttributes structure
    Note: func: Function pointer
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaFuncGetAttributes, (attr_ptr, func)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_func_set_cache_config" takes func as Integer, config as Integer returns Integer:
    Note: Set function cache config
    Note: func: Function pointer
    Note: config: Cache config value
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaFuncSetCacheConfig, (func, config)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_func_set_shared_mem_config" takes func as Integer, config as Integer returns Integer:
    Note: Set function shared memory config
    Note: func: Function pointer
    Note: config: Shared memory config
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaFuncSetSharedMemConfig, (func, config)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_func_set_attribute" takes func as Integer, attr as Integer, value as Integer returns Integer:
    Note: Set function attribute
    Note: func: Function pointer
    Note: attr: Attribute to set
    Note: value: Attribute value
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaFuncSetAttribute, (func, attr, value)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Note: ============================================================================
Note: CUDA LAUNCH CONFIGURATION
Note: ============================================================================

Process called "cuda_launch_cooperative_kernel" takes func as Integer, grid_dim_x as Integer, grid_dim_y as Integer, grid_dim_z as Integer, block_dim_x as Integer, block_dim_y as Integer, block_dim_z as Integer, shared_mem as Integer, stream as Integer, kernel_params as Integer returns Integer:
    Note: Launch cooperative kernel
    Note: Requires all blocks to run concurrently
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaLaunchCooperativeKernel, (func, grid_dim_x, grid_dim_y, grid_dim_z, block_dim_x, block_dim_y, block_dim_z, shared_mem, stream, kernel_params)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_launch_cooperative_kernel_multi_device" takes launch_params_list as Integer, num_devices as Integer, flags as Integer returns Integer:
    Note: Launch cooperative kernel on multiple devices
    Note: launch_params_list: Array of launch parameters
    Note: num_devices: Number of devices
    Note: flags: Launch flags
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaLaunchCooperativeKernelMultiDevice, (launch_params_list, num_devices, flags)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_launch_host_func" takes stream as Integer, func as Integer, user_data as Integer returns Integer:
    Note: Launch host function in stream
    Note: stream: Stream handle
    Note: func: Host function pointer
    Note: user_data: User data passed to function
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaLaunchHostFunc, (stream, func, user_data)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Note: ============================================================================
Note: CUDA IPC (INTER-PROCESS COMMUNICATION)
Note: ============================================================================

Process called "cuda_ipc_get_mem_handle" takes handle_ptr as Integer, dev_ptr as Integer returns Integer:
    Note: Get IPC memory handle
    Note: handle_ptr: Pointer to receive IPC handle
    Note: dev_ptr: Device pointer
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaIpcGetMemHandle, (handle_ptr, dev_ptr)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_ipc_open_mem_handle" takes dev_ptr_ptr as Integer, handle as Integer, flags as Integer returns Integer:
    Note: Open IPC memory handle
    Note: dev_ptr_ptr: Pointer to receive device pointer
    Note: handle: IPC handle
    Note: flags: Open flags
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaIpcOpenMemHandle, (dev_ptr_ptr, handle, flags)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_ipc_close_mem_handle" takes dev_ptr as Integer returns Integer:
    Note: Close IPC memory handle
    Note: dev_ptr: Device pointer from IPC
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaIpcCloseMemHandle, (dev_ptr)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_ipc_get_event_handle" takes handle_ptr as Integer, event as Integer returns Integer:
    Note: Get IPC event handle
    Note: handle_ptr: Pointer to receive IPC event handle
    Note: event: Event handle
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaIpcGetEventHandle, (handle_ptr, event)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_ipc_open_event_handle" takes event_ptr as Integer, handle as Integer returns Integer:
    Note: Open IPC event handle
    Note: event_ptr: Pointer to receive event handle
    Note: handle: IPC event handle
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaIpcOpenEventHandle, (event_ptr, handle)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Note: ============================================================================
Note: CUDA UNIFIED VIRTUAL ADDRESSING
Note: ============================================================================

Process called "cuda_pointer_get_attributes" takes attributes_ptr as Integer, ptr as Integer returns Integer:
    Note: Get pointer attributes
    Note: attributes_ptr: Pointer to cudaPointerAttributes structure
    Note: ptr: Pointer to query
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaPointerGetAttributes, (attributes_ptr, ptr)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_device_can_access_peer" takes can_access_ptr as Integer, device as Integer, peer_device as Integer returns Integer:
    Note: Check if device can access peer
    Note: can_access_ptr: Pointer to receive result (1 or 0)
    Note: device: Device ordinal
    Note: peer_device: Peer device ordinal
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaDeviceCanAccessPeer, (can_access_ptr, device, peer_device)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Note: ============================================================================
Note: CUDA RUNTIME VERSION
Note: ============================================================================

Process called "cuda_runtime_get_version" takes version_ptr as Integer returns Integer:
    Note: Get CUDA runtime version
    Note: version_ptr: Pointer to receive version number
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaRuntimeGetVersion, (version_ptr)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_driver_get_version" takes version_ptr as Integer returns Integer:
    Note: Get CUDA driver version
    Note: version_ptr: Pointer to receive version number
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaDriverGetVersion, (version_ptr)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Note: ============================================================================
Note: CUDA TEXTURE/SURFACE (EXTENDED)
Note: ============================================================================

Process called "cuda_create_surface_object" takes surf_obj_ptr as Integer, res_desc_ptr as Integer returns Integer:
    Note: Create surface object
    Note: surf_obj_ptr: Pointer to receive surface object
    Note: res_desc_ptr: Resource descriptor
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaCreateSurfaceObject, (surf_obj_ptr, res_desc_ptr)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_destroy_surface_object" takes surf_obj as Integer returns Integer:
    Note: Destroy surface object
    Note: surf_obj: Surface object to destroy
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaDestroySurfaceObject, (surf_obj)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_get_texture_object_resource_desc" takes res_desc_ptr as Integer, tex_obj as Integer returns Integer:
    Note: Get texture resource descriptor
    Note: res_desc_ptr: Pointer to receive resource descriptor
    Note: tex_obj: Texture object
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaGetTextureObjectResourceDesc, (res_desc_ptr, tex_obj)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_get_texture_object_texture_desc" takes tex_desc_ptr as Integer, tex_obj as Integer returns Integer:
    Note: Get texture descriptor
    Note: tex_desc_ptr: Pointer to receive texture descriptor
    Note: tex_obj: Texture object
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaGetTextureObjectTextureDesc, (tex_desc_ptr, tex_obj)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Note: ============================================================================
Note: CUDA GRAPH (EXTENDED)
Note: ============================================================================

Process called "cuda_graph_add_empty_node" takes node_ptr as Integer, graph as Integer, dependencies as Integer, num_dependencies as Integer returns Integer:
    Note: Add empty node to graph
    Note: node_ptr: Pointer to receive node handle
    Note: graph: Graph handle
    Note: dependencies: Array of dependency nodes
    Note: num_dependencies: Number of dependencies
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaGraphAddEmptyNode, (node_ptr, graph, dependencies, num_dependencies)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_graph_add_kernel_node" takes node_ptr as Integer, graph as Integer, dependencies as Integer, num_dependencies as Integer, node_params as Integer returns Integer:
    Note: Add kernel node to graph
    Note: node_ptr: Pointer to receive node handle
    Note: graph: Graph handle
    Note: dependencies: Array of dependency nodes
    Note: num_dependencies: Number of dependencies
    Note: node_params: Kernel node parameters
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaGraphAddKernelNode, (node_ptr, graph, dependencies, num_dependencies, node_params)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_graph_add_memcpy_node" takes node_ptr as Integer, graph as Integer, dependencies as Integer, num_dependencies as Integer, copy_params as Integer returns Integer:
    Note: Add memcpy node to graph
    Note: node_ptr: Pointer to receive node handle
    Note: graph: Graph handle
    Note: dependencies: Array of dependency nodes
    Note: num_dependencies: Number of dependencies
    Note: copy_params: Memcpy parameters
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaGraphAddMemcpyNode, (node_ptr, graph, dependencies, num_dependencies, copy_params)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_graph_add_memset_node" takes node_ptr as Integer, graph as Integer, dependencies as Integer, num_dependencies as Integer, memset_params as Integer returns Integer:
    Note: Add memset node to graph
    Note: node_ptr: Pointer to receive node handle
    Note: graph: Graph handle
    Note: dependencies: Array of dependency nodes
    Note: num_dependencies: Number of dependencies
    Note: memset_params: Memset parameters
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaGraphAddMemsetNode, (node_ptr, graph, dependencies, num_dependencies, memset_params)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_graph_add_host_node" takes node_ptr as Integer, graph as Integer, dependencies as Integer, num_dependencies as Integer, node_params as Integer returns Integer:
    Note: Add host node to graph
    Note: node_ptr: Pointer to receive node handle
    Note: graph: Graph handle
    Note: dependencies: Array of dependency nodes
    Note: num_dependencies: Number of dependencies
    Note: node_params: Host node parameters
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaGraphAddHostNode, (node_ptr, graph, dependencies, num_dependencies, node_params)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_graph_add_child_graph_node" takes node_ptr as Integer, graph as Integer, dependencies as Integer, num_dependencies as Integer, child_graph as Integer returns Integer:
    Note: Add child graph node
    Note: node_ptr: Pointer to receive node handle
    Note: graph: Parent graph handle
    Note: dependencies: Array of dependency nodes
    Note: num_dependencies: Number of dependencies
    Note: child_graph: Child graph handle
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaGraphAddChildGraphNode, (node_ptr, graph, dependencies, num_dependencies, child_graph)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_graph_clone" takes cloned_graph_ptr as Integer, original_graph as Integer returns Integer:
    Note: Clone graph
    Note: cloned_graph_ptr: Pointer to receive cloned graph
    Note: original_graph: Original graph to clone
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaGraphClone, (cloned_graph_ptr, original_graph)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_graph_exec_destroy" takes graph_exec as Integer returns Integer:
    Note: Destroy executable graph
    Note: graph_exec: Executable graph to destroy
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaGraphExecDestroy, (graph_exec)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_graph_exec_update" takes graph_exec as Integer, graph as Integer, result_info_ptr as Integer returns Integer:
    Note: Update executable graph
    Note: graph_exec: Executable graph to update
    Note: graph: Graph with updated topology
    Note: result_info_ptr: Pointer to receive result info
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaGraphExecUpdate, (graph_exec, graph, result_info_ptr)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Note: ============================================================================
Note: CUDA EXTERNAL RESOURCES
Note: ============================================================================

Process called "cuda_import_external_memory" takes ext_mem_ptr as Integer, mem_handle_desc as Integer returns Integer:
    Note: Import external memory
    Note: ext_mem_ptr: Pointer to receive external memory handle
    Note: mem_handle_desc: Memory handle descriptor
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaImportExternalMemory, (ext_mem_ptr, mem_handle_desc)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_external_memory_get_mapped_buffer" takes dev_ptr_ptr as Integer, ext_mem as Integer, buffer_desc as Integer returns Integer:
    Note: Get mapped buffer from external memory
    Note: dev_ptr_ptr: Pointer to receive device pointer
    Note: ext_mem: External memory handle
    Note: buffer_desc: Buffer descriptor
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaExternalMemoryGetMappedBuffer, (dev_ptr_ptr, ext_mem, buffer_desc)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_destroy_external_memory" takes ext_mem as Integer returns Integer:
    Note: Destroy external memory
    Note: ext_mem: External memory handle
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaDestroyExternalMemory, (ext_mem)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_import_external_semaphore" takes ext_sem_ptr as Integer, sem_handle_desc as Integer returns Integer:
    Note: Import external semaphore
    Note: ext_sem_ptr: Pointer to receive external semaphore
    Note: sem_handle_desc: Semaphore handle descriptor
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaImportExternalSemaphore, (ext_sem_ptr, sem_handle_desc)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_signal_external_semaphores_async" takes ext_sem_array as Integer, params_array as Integer, num_ext_sems as Integer, stream as Integer returns Integer:
    Note: Signal external semaphores
    Note: ext_sem_array: Array of external semaphores
    Note: params_array: Array of signal parameters
    Note: num_ext_sems: Number of semaphores
    Note: stream: Stream for async operation
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaSignalExternalSemaphoresAsync, (ext_sem_array, params_array, num_ext_sems, stream)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_wait_external_semaphores_async" takes ext_sem_array as Integer, params_array as Integer, num_ext_sems as Integer, stream as Integer returns Integer:
    Note: Wait on external semaphores
    Note: ext_sem_array: Array of external semaphores
    Note: params_array: Array of wait parameters
    Note: num_ext_sems: Number of semaphores
    Note: stream: Stream for async operation
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaWaitExternalSemaphoresAsync, (ext_sem_array, params_array, num_ext_sems, stream)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process

Process called "cuda_destroy_external_semaphore" takes ext_sem as Integer returns Integer:
    Note: Destroy external semaphore
    Note: ext_sem: External semaphore handle
    Note: Returns: cudaSuccess or error code
    Let result be 0
    Inline Assembly:
        // PTX: call CUDA runtime API
        call.uni cudaDestroyExternalSemaphore, (ext_sem)
        st.param.u32 result, %r0
    End Assembly
    Return result
End Process
