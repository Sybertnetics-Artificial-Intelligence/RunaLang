Note: 
Copyright 2025 Sybertnetics Artificial Intelligence Solutions

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
:End Note

Note:
This file defines and manages Runa language keywords and reserved words.

This file performs the following tasks:
- Define all Runa language keywords (Let, Set, If, Otherwise, etc.)
- Provide keyword recognition and tokenization
- Handle keyword context and scope validation
- Manage reserved word conflicts and validation
- Support multi-word keywords and natural language operators

This file is essential because of the following reasons:
- Keywords are the foundation of Runa's natural language syntax
- Proper keyword handling ensures correct language parsing
- Keyword validation prevents naming conflicts and syntax errors
- Multi-word keyword support enables natural language expressions

This file consists of the following functions/features/operation types:
- Keyword definition and lookup tables
- Keyword recognition and tokenization functions
- Context-sensitive keyword validation
- Reserved word conflict detection and resolution
- Multi-word keyword phrase matching

Dependencies:
- Imports collections/hashtable.runa for keyword lookup table
- Imports core/string_core.runa for string comparison
- Imports memory/layout.runa for Token allocation
:End Note

Import "compiler/frontend/primitives/collections/hashtable.runa" as HashTable
Import "compiler/frontend/primitives/core/string_core.runa" as StringCore
Import "compiler/frontend/primitives/memory/layout.runa" as Layout

Note: ============================================================================
Note: Token Type Constants for Keywords
Note: ============================================================================

Note: These constants define the token types for Runa keywords
Note: Grouped by category for organization

Note: Variable and Constant Keywords
Define constant TOKEN_LET as 300         Note: Let (variable declaration)
Define constant TOKEN_SET as 301         Note: Set (variable assignment)
Define constant TOKEN_DEFINE as 302      Note: Define (constant declaration)

Note: Control Flow Keywords
Define constant TOKEN_IF as 310          Note: If
Define constant TOKEN_OTHERWISE as 311   Note: Otherwise (else)
Define constant TOKEN_UNLESS as 312      Note: Unless (negated if)
Define constant TOKEN_WHEN as 313        Note: When (case)
Define constant TOKEN_MATCH as 314       Note: Match (pattern matching)
Define constant TOKEN_FOR as 315         Note: For (loop)
Define constant TOKEN_WHILE as 316       Note: While (loop)
Define constant TOKEN_LOOP as 317        Note: Loop (infinite loop)
Define constant TOKEN_BREAK as 318       Note: Break
Define constant TOKEN_CONTINUE as 319    Note: Continue

Note: Function and Type Keywords
Define constant TOKEN_PROCESS as 320     Note: Process (function definition)
Define constant TOKEN_TYPE as 321        Note: Type (type definition)
Define constant TOKEN_PROTOCOL as 322    Note: Protocol (interface definition)
Define constant TOKEN_RETURN as 323      Note: Return
Define constant TOKEN_YIELD as 324       Note: Yield (generator)

Note: Import and Module Keywords
Define constant TOKEN_IMPORT as 330      Note: Import
Define constant TOKEN_FROM as 331        Note: From (import source)
Define constant TOKEN_AS as 332          Note: As (alias)
Define constant TOKEN_EXPORT as 333      Note: Export (module export)

Note: Exception Handling Keywords
Define constant TOKEN_TRY as 340         Note: Try
Define constant TOKEN_CATCH as 341       Note: Catch
Define constant TOKEN_FINALLY as 342     Note: Finally
Define constant TOKEN_THROW as 343       Note: Throw

Note: Visibility and Modifier Keywords
Define constant TOKEN_PUBLIC as 350      Note: Public
Define constant TOKEN_PRIVATE as 351     Note: Private
Define constant TOKEN_STATIC as 352      Note: Static
Define constant TOKEN_ASYNC as 353       Note: Async
Define constant TOKEN_EXTERNAL as 354    Note: External

Note: Concurrency Keywords
Define constant TOKEN_AWAIT as 360       Note: Await
Define constant TOKEN_SEND as 361        Note: Send (message passing)
Define constant TOKEN_RECEIVE as 362     Note: Receive (message passing)
Define constant TOKEN_SPAWN as 363       Note: Spawn (create process)

Note: Other Keywords
Define constant TOKEN_NEW as 370         Note: New (object creation)
Define constant TOKEN_DELETE as 371      Note: Delete (memory deallocation)
Define constant TOKEN_WITH as 372        Note: With (context manager)
Define constant TOKEN_ASSERT as 373      Note: Assert (assertion)
Define constant TOKEN_ALERT as 374       Note: Alert (warning)
Define constant TOKEN_DISPLAY as 375     Note: Display (output)

Note: Natural Language Operator Keywords
Define constant TOKEN_AND as 380         Note: And (logical and)
Define constant TOKEN_OR as 381          Note: Or (logical or)
Define constant TOKEN_NOT as 382         Note: Not (logical not)
Define constant TOKEN_IS as 383          Note: Is (equality/type check)
Define constant TOKEN_IN as 384          Note: In (containment)
Define constant TOKEN_OF as 385          Note: Of (possession)
Define constant TOKEN_TO as 386          Note: To (direction/target)
Define constant TOKEN_BY as 387          Note: By (agent/increment)
Define constant TOKEN_WITH as 388        Note: With (accompaniment)
Define constant TOKEN_BE as 389          Note: Be (state)

Note: Arithmetic Word Keywords (Canon Mode)
Define constant TOKEN_PLUS as 390        Note: Plus (addition)
Define constant TOKEN_MINUS as 391       Note: Minus (subtraction)
Define constant TOKEN_TIMES as 392       Note: Times (multiplication)
Define constant TOKEN_MULTIPLIED as 393  Note: Multiplied (multiplication phrase start)
Define constant TOKEN_DIVIDED as 394     Note: Divided (division phrase start)
Define constant TOKEN_MODULO as 395      Note: Modulo (remainder)
Define constant TOKEN_POWER as 396       Note: Power (exponentiation)

Note: Comparison Word Keywords (Canon Mode)
Define constant TOKEN_EQUAL as 400       Note: Equal (equality keyword)
Define constant TOKEN_GREATER as 401     Note: Greater (comparison)
Define constant TOKEN_LESS as 402        Note: Less (comparison)
Define constant TOKEN_THAN as 403        Note: Than (comparison complement)
Define constant TOKEN_CONTAINS as 404    Note: Contains (collection membership)

Note: Boolean Literals (treated as keywords)
Define constant TOKEN_TRUE as 410        Note: True
Define constant TOKEN_FALSE as 411       Note: False

Note: Null Literals (treated as keywords)
Define constant TOKEN_NULL as 420        Note: Null
Define constant TOKEN_NONE as 421        Note: None
Define constant TOKEN_NIL as 422         Note: Nil

Note: End Keyword (for block termination)
Define constant TOKEN_END as 430         Note: End (block terminator)

Note: ============================================================================
Note: Keyword Lookup Table Structure
Note: ============================================================================

Type called "KeywordTable":
    keyword_map as Integer        Note: HashTable mapping keyword string -> token type
    multi_word_keywords as Integer Note: Array of multi-word keyword patterns
    keyword_count as Integer      Note: Total number of keywords registered
    case_sensitive as Integer     Note: Boolean: 1 if keywords are case-sensitive (they are)

Type called "MultiWordKeyword":
    words as Integer             Note: Array of pointers to word strings
    word_count as Integer        Note: Number of words in this keyword phrase
    token_type as Integer        Note: Token type for this multi-word keyword
    min_words as Integer         Note: Minimum words required (for partial matching)

Note: ============================================================================
Note: Keyword Table Initialization
Note: ============================================================================

Process called "create_keyword_table" returns Integer:
    Note: Create and initialize the keyword lookup table
    Note: 
    Note: Creates a KeywordTable and populates it with all Runa keywords
    Note: Includes single-word keywords (Let, Set, If) and multi-word phrases
    Note: (is equal to, is greater than, multiplied by, etc.)
    Note: 
    Note: Returns:
    Note:   Pointer to initialized KeywordTable structure
    Note:   Returns 0 on allocation failure
    Note: 
    Note: The table includes:
    Note: - 100+ single-word keywords
    Note: - 20+ multi-word keyword phrases
    Note: - Case-sensitive matching (Runa is case-sensitive)
    Note: 
    Note: Multi-word keywords examples:
    Note:   "is equal to" -> TOKEN_IS + TOKEN_EQUAL + TOKEN_TO (parsed as equality op)
    Note:   "is greater than" -> TOKEN_IS + TOKEN_GREATER + TOKEN_THAN
    Note:   "multiplied by" -> TOKEN_MULTIPLIED + TOKEN_BY
    Note:   "divided by" -> TOKEN_DIVIDED + TOKEN_BY
    Note: 
    Note: TODO: Implement using:
    Note: - Layout.allocate for KeywordTable structure
    Note: - HashTable.create for keyword_map
    Note: - register_keyword (defined below) for each keyword
    Note: - register_multi_word_keyword for phrase patterns
    
    Return 0  Note: Placeholder
End Process

Process called "register_keyword" takes table as Integer, keyword as Integer, token_type as Integer returns Integer:
    Note: Register a single-word keyword in the lookup table
    Note: 
    Note: Adds a keyword string to the hash table with its token type
    Note: 
    Note: Parameters:
    Note:   table - Pointer to KeywordTable
    Note:   keyword - Pointer to keyword string (e.g., "Let", "Set", "If")
    Note:   token_type - Token type constant for this keyword
    Note: 
    Note: Returns:
    Note:   1 on success, 0 on failure (duplicate keyword or allocation error)
    Note: 
    Note: TODO: Implement using:
    Note: - HashTable.set to add keyword -> token_type mapping
    Note: - Increment keyword_count on success
    
    Return 0  Note: Placeholder
End Process

Process called "register_multi_word_keyword" takes table as Integer, words as Integer, word_count as Integer, token_type as Integer returns Integer:
    Note: Register a multi-word keyword phrase
    Note: 
    Note: Adds a multi-word keyword pattern for phrases like:
    Note:   "is equal to" (3 words)
    Note:   "is greater than" (3 words)
    Note:   "multiplied by" (2 words)
    Note: 
    Note: Parameters:
    Note:   table - Pointer to KeywordTable
    Note:   words - Array of pointers to word strings
    Note:   word_count - Number of words in the phrase
    Note:   token_type - Combined token type or primary token
    Note: 
    Note: Returns:
    Note:   1 on success, 0 on failure
    Note: 
    Note: TODO: Implement using:
    Note: - Layout.allocate for MultiWordKeyword structure
    Note: - Add to multi_word_keywords array in table
    Note: - Store word array and metadata
    
    Return 0  Note: Placeholder
End Process

Note: ============================================================================
Note: Keyword Recognition
Note: ============================================================================

Process called "lookup_keyword" takes table as Integer, identifier as Integer returns Integer:
    Note: Look up an identifier in the keyword table
    Note: 
    Note: Checks if the given identifier is a reserved keyword
    Note: 
    Note: Parameters:
    Note:   table - Pointer to KeywordTable
    Note:   identifier - Pointer to identifier string to check
    Note: 
    Note: Returns:
    Note:   Token type constant if identifier is a keyword (TOKEN_LET, TOKEN_IF, etc.)
    Note:   Returns 0 if identifier is not a keyword (treat as regular identifier)
    Note: 
    Note: Case sensitivity: Runa keywords are case-sensitive
    Note:   "Let" is a keyword, "let" is not, "LET" is not
    Note: 
    Note: TODO: Implement using:
    Note: - HashTable.get to check keyword_map
    Note: - Return token type if found, 0 otherwise
    
    Return 0  Note: Placeholder
End Process

Process called "try_match_multi_word_keyword" takes table as Integer, lexer as Integer, first_word as Integer returns Integer:
    Note: Attempt to match a multi-word keyword starting with first_word
    Note: 
    Note: Looks ahead to see if the next tokens form a multi-word keyword phrase
    Note: Examples:
    Note:   "is" followed by "equal" and "to" -> complete phrase
    Note:   "multiplied" followed by "by" -> complete phrase
    Note: 
    Note: Parameters:
    Note:   table - Pointer to KeywordTable
    Note:   lexer - Pointer to lexer state (for lookahead)
    Note:   first_word - First word of potential multi-word keyword
    Note: 
    Note: Returns:
    Note:   Pointer to MultiWordKeyword structure if match found
    Note:   Returns 0 if no multi-word keyword matches
    Note: 
    Note: Algorithm:
    Note: 1. Iterate through multi_word_keywords array
    Note: 2. For each pattern, check if first_word matches first word
    Note: 3. If match, peek ahead in lexer to check remaining words
    Note: 4. Return MultiWordKeyword if all words match
    Note: 5. Return 0 if no complete phrase matches
    Note: 
    Note: Note: This function uses lookahead but doesn't consume tokens
    Note: 
    Note: TODO: Implement using:
    Note: - Loop through table.multi_word_keywords array
    Note: - StringCore.string_equals for word matching
    Note: - Lexer peek operations to check subsequent words
    
    Return 0  Note: Placeholder
End Process

Process called "tokenize_keyword" takes lexer as Integer, keyword_string as Integer, token_type as Integer, start_line as Integer, start_column as Integer returns Integer:
    Note: Create a token for a recognized keyword
    Note: 
    Note: Parameters:
    Note:   lexer - Pointer to lexer state
    Note:   keyword_string - The keyword string (e.g., "Let", "If")
    Note:   token_type - Token type constant for this keyword
    Note:   start_line - Line number where keyword starts
    Note:   start_column - Column number where keyword starts
    Note: 
    Note: Returns:
    Note:   Pointer to Token structure with:
    Note:     - token_type = keyword token type constant
    Note:     - value = pointer to keyword string
    Note:     - line/column = keyword position
    Note:     - length = length of keyword string
    Note: 
    Note: TODO: Implement using:
    Note: - Layout.allocate for Token structure
    Note: - StringCore.string_length for keyword length
    Note: - Populate all Token fields
    
    Return 0  Note: Placeholder
End Process

Note: ============================================================================
Note: Context-Sensitive Keyword Validation
Note: ============================================================================

Process called "validate_keyword_context" takes token_type as Integer, context as Integer returns Integer:
    Note: Validate that keyword is used in appropriate context
    Note: 
    Note: Some keywords are only valid in specific contexts:
    Note:   - "Otherwise" only valid after "If" block
    Note:   - "Catch" only valid after "Try" block
    Note:   - "Finally" only valid after "Try" or "Catch"
    Note:   - "Break" and "Continue" only valid inside loops
    Note:   - "Return" only valid inside Process definitions
    Note: 
    Note: Parameters:
    Note:   token_type - Keyword token type to validate
    Note:   context - Current parsing context (from parser state)
    Note: 
    Note: Returns:
    Note:   1 if keyword is valid in this context, 0 if invalid
    Note: 
    Note: Context flags (bit flags in context parameter):
    Note:   bit 0: Inside Process definition
    Note:   bit 1: Inside loop (For, While, Loop)
    Note:   bit 2: After If statement
    Note:   bit 3: Inside Try block
    Note:   bit 4: After Catch block
    Note: 
    Note: TODO: Implement context validation logic for each keyword
    Note: - Check context flags based on token_type
    Note: - Return 0 for invalid contexts with appropriate error
    
    Return 1  Note: Placeholder - assume valid
End Process

Process called "is_reserved_word" takes table as Integer, identifier as Integer returns Integer:
    Note: Check if identifier is a reserved word (keyword)
    Note: 
    Note: Used to prevent variables from being named with keyword names
    Note: 
    Note: Parameters:
    Note:   table - Pointer to KeywordTable
    Note:   identifier - Identifier string to check
    Note: 
    Note: Returns:
    Note:   1 if identifier is a reserved keyword, 0 if available for use
    Note: 
    Note: This is equivalent to lookup_keyword but returns boolean
    Note: instead of token type
    Note: 
    Note: TODO: Call lookup_keyword and check if result is non-zero
    
    Return 0  Note: Placeholder
End Process

Process called "suggest_keyword_correction" takes identifier as Integer, table as Integer returns Integer:
    Note: Suggest keyword correction for misspelled keywords
    Note: 
    Note: If user types "lst" instead of "Let", suggest correct keyword
    Note: Uses Levenshtein distance or similar algorithm for fuzzy matching
    Note: 
    Note: Parameters:
    Note:   identifier - The potentially misspelled identifier
    Note:   table - Keyword table to search
    Note: 
    Note: Returns:
    Note:   Pointer to suggested keyword string if close match found
    Note:   Returns 0 if no reasonable suggestion available
    Note: 
    Note: Example suggestions:
    Note:   "lets" -> "Let"
    Note:   "Retrun" -> "Return"
    Note:   "Otherwize" -> "Otherwise"
    Note: 
    Note: TODO: Implement fuzzy string matching algorithm
    Note: - Calculate edit distance to each keyword
    Note: - Return closest match if distance <= 2
    
    Return 0  Note: Placeholder
End Process

Note: ============================================================================
Note: Keyword Utility Functions
Note: ============================================================================

Process called "is_control_flow_keyword" takes token_type as Integer returns Integer:
    Note: Check if token type is a control flow keyword
    Note: 
    Note: Parameters:
    Note:   token_type - Token type constant to check
    Note: 
    Note: Returns:
    Note:   1 if token is control flow (If, Otherwise, While, For, Match, etc.)
    Note:   0 otherwise
    Note: 
    Note: TODO: Check if token_type is in range 310-319 or matches control flow keywords
    
    Return 0  Note: Placeholder
End Process

Process called "is_visibility_keyword" takes token_type as Integer returns Integer:
    Note: Check if token type is a visibility modifier
    Note: 
    Note: Parameters:
    Note:   token_type - Token type constant to check
    Note: 
    Note: Returns:
    Note:   1 if token is visibility modifier (Public, Private, Static)
    Note:   0 otherwise
    Note: 
    Note: TODO: Check if token_type is in range 350-354
    
    Return 0  Note: Placeholder
End Process

Process called "keyword_token_type_to_string" takes token_type as Integer returns Integer:
    Note: Convert keyword token type to readable string
    Note: 
    Note: Parameters:
    Note:   token_type - Keyword token type constant
    Note: 
    Note: Returns:
    Note:   Pointer to keyword string ("Let", "Set", "If", etc.)
    Note:   Returns "UNKNOWN" for unrecognized token type
    Note: 
    Note: Used for error messages and debugging
    Note: 
    Note: TODO: Implement lookup table or switch logic
    Note: - Map each TOKEN_* constant back to its string representation
    
    Return 0  Note: Placeholder
End Process

Process called "get_keyword_count" takes table as Integer returns Integer:
    Note: Get total number of keywords in the table
    Note: 
    Note: Parameters:
    Note:   table - Pointer to KeywordTable
    Note: 
    Note: Returns:
    Note:   Total count of registered keywords
    Note: 
    Note: TODO: Return table.keyword_count field
    
    Return 0  Note: Placeholder
End Process
