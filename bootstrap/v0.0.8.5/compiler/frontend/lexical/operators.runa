Note: 
Copyright 2025 Sybertnetics Artificial Intelligence Solutions

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
:End Note

Note:
This file handles general operators beyond mathematical symbols in Runa.

This file performs the following tasks:
- Recognize assignment operators (=, +=, -=, *=, /=, %=)
- Process ternary conditional operator (? :) for v0.0.8.5
- Handle member access operators (., ->)
- Process range operators (.., ..=)
- Handle special operators (typeof, sizeof, addressof)

This file is essential because of the following reasons:
- Assignment operators are fundamental to variable manipulation
- Ternary operator enables concise conditional expressions (v0.0.8.5 feature)
- Member access operators are critical for structure and object access
- Range operators enable slice and iteration syntax
- Special operators provide meta-programming capabilities

This file consists of the following functions/features/operation types:
- Assignment and compound assignment operator recognition
- Ternary operator parsing and validation
- Member access operator processing
- Range operator handling with inclusive/exclusive variants
- Special operator recognition and context validation

Dependencies:
- Imports math_symbols.runa for arithmetic operator context
- Imports keywords.runa for keyword operator disambiguation
- Imports memory/layout.runa for Token allocation
:End Note

Import "compiler/frontend/lexical/math_symbols.runa" as MathSymbols
Import "compiler/frontend/lexical/keywords.runa" as Keywords
Import "compiler/frontend/primitives/memory/layout.runa" as Layout

Note: ============================================================================
Note: Token Type Constants for General Operators
Note: ============================================================================

Note: Assignment Operators
Define constant TOKEN_ASSIGN as 600          Note: = (simple assignment)
Define constant TOKEN_PLUS_ASSIGN as 601     Note: += (add and assign)
Define constant TOKEN_MINUS_ASSIGN as 602    Note: -= (subtract and assign)
Define constant TOKEN_MUL_ASSIGN as 603      Note: *= (multiply and assign)
Define constant TOKEN_DIV_ASSIGN as 604      Note: /= (divide and assign)
Define constant TOKEN_MOD_ASSIGN as 605      Note: %= (modulo and assign)
Define constant TOKEN_AND_ASSIGN as 606      Note: &= (bitwise and assign)
Define constant TOKEN_OR_ASSIGN as 607       Note: |= (bitwise or assign)
Define constant TOKEN_XOR_ASSIGN as 608      Note: ^= (bitwise xor assign)
Define constant TOKEN_SHL_ASSIGN as 609      Note: <<= (shift left and assign)
Define constant TOKEN_SHR_ASSIGN as 610      Note: >>= (shift right and assign)

Note: Ternary Operator (v0.0.8.5)
Define constant TOKEN_QUESTION as 620        Note: ? (ternary condition)
Define constant TOKEN_COLON_TERNARY as 621   Note: : (ternary separator)

Note: Member Access Operators
Define constant TOKEN_DOT as 630             Note: . (member access)
Define constant TOKEN_ARROW as 631           Note: -> (pointer member access)

Note: Range Operators
Define constant TOKEN_RANGE as 640           Note: .. (exclusive range: 0..10)
Define constant TOKEN_RANGE_INCLUSIVE as 641 Note: ..= (inclusive range: 0..=10)

Note: Special Operators
Define constant TOKEN_TYPEOF as 650          Note: typeof (type query)
Define constant TOKEN_SIZEOF as 651          Note: sizeof (size query)
Define constant TOKEN_ADDRESSOF as 652       Note: addressof (address query)

Note: Optional/Null Handling Operators (v0.0.8.5)
Define constant TOKEN_QUESTION_MARK as 660   Note: ? (optional chaining: obj?.field)
Define constant TOKEN_NULLISH_COALESCE as 661 Note: ?? (nullish coalescing: a ?? b)

Note: ============================================================================
Note: Assignment Operator Recognition
Note: ============================================================================

Process called "tokenize_assignment_operator" takes lexer as Integer, first_char as Integer, start_line as Integer, start_column as Integer returns Integer:
    Note: Tokenize assignment or compound assignment operator
    Note: 
    Note: Handles:
    Note:   = (simple assignment)
    Note:   +=, -=, *=, /=, %= (compound arithmetic assignments)
    Note:   &=, |=, ^= (compound bitwise assignments)
    Note:   <<=, >>= (compound shift assignments)
    Note: 
    Note: Must distinguish:
    Note:   = vs == (assignment vs equality)
    Note:   + vs += (addition vs add-assign)
    Note:   < vs <= vs <<= (less than vs less-equal vs shift-left-assign)
    Note: 
    Note: Parameters:
    Note:   lexer - Pointer to lexer state structure
    Note:   first_char - First character (typically =, +, -, *, /, %, &, |, ^, <, >)
    Note:   start_line - Line number where operator starts
    Note:   start_column - Column number where operator starts
    Note: 
    Note: Returns:
    Note:   Pointer to Token structure with:
    Note:     - token_type = TOKEN_ASSIGN or TOKEN_*_ASSIGN variant
    Note:     - value = Operator string ("=", "+=", etc.)
    Note:     - line/column = operator position
    Note:     - length = 1-3 characters
    Note:   Returns 0 if not an assignment operator
    Note: 
    Note: Algorithm:
    Note: 1. Check if first_char could start assignment operator
    Note: 2. Peek next character to check for = (making it compound)
    Note: 3. For <<= and >>=, peek two characters ahead
    Note: 4. Determine specific assignment operator type
    Note: 5. Create and return Token
    Note: 
    Note: TODO: Implement using:
    Note: - Lexer peek operations for lookahead
    Note: - recognize_compound_assignment (defined below)
    Note: - Layout.allocate for Token structure
    
    Return 0  Note: Placeholder
End Process

Process called "recognize_compound_assignment" takes operator_char as Integer, equals_char as Integer returns Integer:
    Note: Recognize compound assignment operator from operator + equals
    Note: 
    Note: Parameters:
    Note:   operator_char - The operator character before = (ASCII code)
    Note:   equals_char - The = character (should be 61)
    Note: 
    Note: Returns:
    Note:   Token type for compound assignment, or 0 if not valid compound
    Note: 
    Note: Mappings:
    Note:   + followed by = (43, 61) -> TOKEN_PLUS_ASSIGN (601)
    Note:   - followed by = (45, 61) -> TOKEN_MINUS_ASSIGN (602)
    Note:   * followed by = (42, 61) -> TOKEN_MUL_ASSIGN (603)
    Note:   / followed by = (47, 61) -> TOKEN_DIV_ASSIGN (604)
    Note:   % followed by = (37, 61) -> TOKEN_MOD_ASSIGN (605)
    Note:   & followed by = (38, 61) -> TOKEN_AND_ASSIGN (606)
    Note:   | followed by = (124, 61) -> TOKEN_OR_ASSIGN (607)
    Note:   ^ followed by = (94, 61) -> TOKEN_XOR_ASSIGN (608)
    Note: 
    Note: TODO: Implement character code matching logic
    
    Return 0  Note: Placeholder
End Process

Process called "is_assignment_operator" takes token_type as Integer returns Integer:
    Note: Check if token type is any assignment operator
    Note: 
    Note: Parameters:
    Note:   token_type - Token type constant to check
    Note: 
    Note: Returns:
    Note:   1 if token is assignment operator (TOKEN_ASSIGN or TOKEN_*_ASSIGN)
    Note:   0 otherwise
    Note: 
    Note: TODO: Check if token_type is in range 600-610
    
    Return 0  Note: Placeholder
End Process

Note: ============================================================================
Note: Ternary Operator Recognition (v0.0.8.5)
Note: ============================================================================

Process called "tokenize_ternary_operator" takes lexer as Integer, operator_char as Integer, start_line as Integer, start_column as Integer returns Integer:
    Note: Tokenize ternary conditional operator (? or :)
    Note: 
    Note: Ternary operator syntax: condition ? true_value : false_value
    Note: 
    Note: Must distinguish:
    Note:   ? from optional chaining ?. (TOKEN_QUESTION_MARK vs TOKEN_QUESTION)
    Note:   : from type annotation colon (handled in context)
    Note: 
    Note: Parameters:
    Note:   lexer - Pointer to lexer state structure
    Note:   operator_char - Either ? (63) or : (58)
    Note:   start_line - Line number where operator appears
    Note:   start_column - Column number where operator appears
    Note: 
    Note: Returns:
    Note:   Pointer to Token structure with:
    Note:     - token_type = TOKEN_QUESTION (620) or TOKEN_COLON_TERNARY (621)
    Note:     - value = "?" or ":"
    Note:     - line/column = operator position
    Note:     - length = 1
    Note: 
    Note: Context handling:
    Note:   - Parser must track ternary nesting depth
    Note:   - Colon can mean ternary separator OR block start OR type annotation
    Note:   - Question mark can mean ternary OR optional chaining
    Note: 
    Note: TODO: Implement using:
    Note: - Context from lexer to distinguish ternary : from block :
    Note: - Layout.allocate for Token structure
    
    Return 0  Note: Placeholder
End Process

Process called "validate_ternary_syntax" takes question_token as Integer, colon_token as Integer, context as Integer returns Integer:
    Note: Validate that ternary operator is properly formed
    Note: 
    Note: Checks:
    Note:   - ? token has corresponding : token
    Note:   - Nesting is properly balanced
    Note:   - Expressions exist in all three positions (condition, true, false)
    Note: 
    Note: Parameters:
    Note:   question_token - The ? token
    Note:   colon_token - The corresponding : token
    Note:   context - Parsing context for validation
    Note: 
    Note: Returns:
    Note:   1 if ternary is properly formed, 0 if syntax error
    Note: 
    Note: TODO: Implement ternary validation rules
    Note: - Check token positions and expressions
    Note: - Validate nesting depth
    
    Return 1  Note: Placeholder
End Process

Note: ============================================================================
Note: Member Access Operator Recognition
Note: ============================================================================

Process called "tokenize_member_access" takes lexer as Integer, operator_char as Integer, start_line as Integer, start_column as Integer returns Integer:
    Note: Tokenize member access operator (. or ->)
    Note: 
    Note: Handles:
    Note:   . (dot) - Direct member access: object.field
    Note:   -> (arrow) - Pointer member access: pointer->field
    Note: 
    Note: Must distinguish:
    Note:   . from .. or ..= (range operators)
    Note:   - from -> (minus vs arrow)
    Note: 
    Note: Parameters:
    Note:   lexer - Pointer to lexer state structure
    Note:   operator_char - Either . (46) or - (45)
    Note:   start_line - Line number where operator appears
    Note:   start_column - Column number where operator appears
    Note: 
    Note: Returns:
    Note:   Pointer to Token structure with:
    Note:     - token_type = TOKEN_DOT (630) or TOKEN_ARROW (631)
    Note:     - value = "." or "->"
    Note:     - line/column = operator position
    Note:     - length = 1 or 2
    Note:   Returns 0 if not a member access operator
    Note: 
    Note: Algorithm:
    Note: 1. If operator_char is . (46):
    Note:    - Peek next char to check for .. or ..=
    Note:    - If single ., return TOKEN_DOT
    Note: 2. If operator_char is - (45):
    Note:    - Peek next char to check for >
    Note:    - If ->, return TOKEN_ARROW
    Note:    - Otherwise, not a member access operator
    Note: 3. Create and return Token
    Note: 
    Note: TODO: Implement using:
    Note: - Lexer peek operations for lookahead
    Note: - Layout.allocate for Token structure
    
    Return 0  Note: Placeholder
End Process

Note: ============================================================================
Note: Range Operator Recognition
Note: ============================================================================

Process called "tokenize_range_operator" takes lexer as Integer, start_line as Integer, start_column as Integer returns Integer:
    Note: Tokenize range operator (.. or ..=)
    Note: 
    Note: Range operators:
    Note:   .. (exclusive): 0..10 means [0, 1, 2, ..., 9] (excludes 10)
    Note:   ..= (inclusive): 0..=10 means [0, 1, 2, ..., 10] (includes 10)
    Note: 
    Note: Used for:
    Note:   - Array slicing: array[0..5]
    Note:   - Loop ranges: For i in 0..10:
    Note:   - Pattern matching ranges: When 1..=5:
    Note: 
    Note: Parameters:
    Note:   lexer - Pointer to lexer state structure (positioned at first .)
    Note:   start_line - Line number where range starts
    Note:   start_column - Column number where range starts
    Note: 
    Note: Returns:
    Note:   Pointer to Token structure with:
    Note:     - token_type = TOKEN_RANGE (640) or TOKEN_RANGE_INCLUSIVE (641)
    Note:     - value = ".." or "..="
    Note:     - line/column = range position
    Note:     - length = 2 or 3
    Note:   Returns 0 if not a range operator (single . is member access)
    Note: 
    Note: Algorithm:
    Note: 1. Confirm current char is . (46)
    Note: 2. Peek next char - must be . (46) for range
    Note: 3. Peek third char - if = (61), inclusive range; otherwise exclusive
    Note: 4. Create and return Token
    Note: 
    Note: TODO: Implement using:
    Note: - Lexer peek operations for lookahead
    Note: - Layout.allocate for Token structure
    
    Return 0  Note: Placeholder
End Process

Process called "is_range_operator" takes token_type as Integer returns Integer:
    Note: Check if token type is a range operator
    Note: 
    Note: Parameters:
    Note:   token_type - Token type constant to check
    Note: 
    Note: Returns:
    Note:   1 if token is range operator (TOKEN_RANGE or TOKEN_RANGE_INCLUSIVE)
    Note:   0 otherwise
    Note: 
    Note: TODO: Check if token_type is 640 or 641
    
    Return 0  Note: Placeholder
End Process

Note: ============================================================================
Note: Special Operator Recognition
Note: ============================================================================

Process called "tokenize_special_operator" takes lexer as Integer, keyword as Integer, start_line as Integer, start_column as Integer returns Integer:
    Note: Tokenize special meta-programming operators
    Note: 
    Note: Special operators (keyword-like):
    Note:   typeof - Get type of expression: typeof(variable)
    Note:   sizeof - Get size of type or expression: sizeof(Integer)
    Note:   addressof - Get memory address: addressof(variable)
    Note: 
    Note: These look like keywords but behave as operators
    Note: 
    Note: Parameters:
    Note:   lexer - Pointer to lexer state structure
    Note:   keyword - The keyword string ("typeof", "sizeof", "addressof")
    Note:   start_line - Line number where operator appears
    Note:   start_column - Column number where operator appears
    Note: 
    Note: Returns:
    Note:   Pointer to Token structure with:
    Note:     - token_type = TOKEN_TYPEOF, TOKEN_SIZEOF, or TOKEN_ADDRESSOF
    Note:     - value = Keyword string
    Note:     - line/column = operator position
    Note:     - length = Keyword length
    Note:   Returns 0 if not a special operator
    Note: 
    Note: TODO: Implement using:
    Note: - String comparison to identify operator keyword
    Note: - Layout.allocate for Token structure
    
    Return 0  Note: Placeholder
End Process

Process called "is_special_operator" takes token_type as Integer returns Integer:
    Note: Check if token type is a special operator
    Note: 
    Note: Parameters:
    Note:   token_type - Token type constant to check
    Note: 
    Note: Returns:
    Note:   1 if token is special operator (typeof, sizeof, addressof)
    Note:   0 otherwise
    Note: 
    Note: TODO: Check if token_type is in range 650-652
    
    Return 0  Note: Placeholder
End Process

Note: ============================================================================
Note: Optional and Nullish Operators (v0.0.8.5)
Note: ============================================================================

Process called "tokenize_optional_operator" takes lexer as Integer, question_char as Integer, start_line as Integer, start_column as Integer returns Integer:
    Note: Tokenize optional chaining or nullish coalescing operator
    Note: 
    Note: Optional operators (v0.0.8.5 advanced features):
    Note:   ?. - Optional chaining: object?.field (returns null if object is null)
    Note:   ?? - Nullish coalescing: value ?? default (use default if value is null)
    Note: 
    Note: Must distinguish:
    Note:   ? (ternary) vs ?. (optional chaining)
    Note:   ?? (nullish coalesce) vs ? (ternary)
    Note: 
    Note: Parameters:
    Note:   lexer - Pointer to lexer state structure
    Note:   question_char - The ? character (63)
    Note:   start_line - Line number where operator appears
    Note:   start_column - Column number where operator appears
    Note: 
    Note: Returns:
    Note:   Pointer to Token structure with:
    Note:     - token_type = TOKEN_QUESTION_MARK (660) or TOKEN_NULLISH_COALESCE (661)
    Note:     - value = "?." or "??"
    Note:     - line/column = operator position
    Note:     - length = 2
    Note:   Returns 0 if single ? (ternary, handled elsewhere)
    Note: 
    Note: Algorithm:
    Note: 1. Confirm current char is ? (63)
    Note: 2. Peek next char:
    Note:    - If . (46), return TOKEN_QUESTION_MARK (?.)
    Note:    - If ? (63), return TOKEN_NULLISH_COALESCE (??)
    Note:    - Otherwise, single ? (not optional operator)
    Note: 3. Create and return Token if multi-char operator
    Note: 
    Note: TODO: Implement using:
    Note: - Lexer peek operations for lookahead
    Note: - Layout.allocate for Token structure
    
    Return 0  Note: Placeholder
End Process

Note: ============================================================================
Note: Operator Utility Functions
Note: ============================================================================

Process called "get_operator_arity" takes token_type as Integer returns Integer:
    Note: Get the arity (number of operands) for an operator
    Note: 
    Note: Parameters:
    Note:   token_type - Operator token type constant
    Note: 
    Note: Returns:
    Note:   Arity: 1 (unary), 2 (binary), or 3 (ternary)
    Note:   Returns 0 for non-operator or unknown type
    Note: 
    Note: Examples:
    Note:   Assignment operators (=, +=, etc.) = 2 (binary)
    Note:   Ternary (? :) = 3 (ternary)
    Note:   Member access (., ->) = 2 (binary: object.member)
    Note:   Range operators (.., ..=) = 2 (binary: start..end)
    Note:   Special operators (typeof, sizeof) = 1 (unary)
    Note: 
    Note: TODO: Return appropriate arity based on operator type
    
    Return 0  Note: Placeholder
End Process

Process called "operator_type_to_string" takes token_type as Integer returns Integer:
    Note: Convert operator token type to readable string
    Note: 
    Note: Parameters:
    Note:   token_type - Operator token type constant
    Note: 
    Note: Returns:
    Note:   Pointer to operator string ("=", "+=", ".", "->", "..", etc.)
    Note:   Returns "UNKNOWN" for unrecognized type
    Note: 
    Note: Used for error messages and debugging
    Note: 
    Note: TODO: Implement lookup table for all operator types
    
    Return 0  Note: Placeholder
End Process

Process called "create_operator_token" takes token_type as Integer, operator_string as Integer, line as Integer, column as Integer, length as Integer returns Integer:
    Note: Create a token for a recognized operator
    Note: 
    Note: Parameters:
    Note:   token_type - Operator token type constant
    Note:   operator_string - Operator string representation
    Note:   line - Line number where operator appears
    Note:   column - Column number where operator appears
    Note:   length - Length of operator in characters
    Note: 
    Note: Returns:
    Note:   Pointer to Token structure with populated fields
    Note:   Returns 0 on allocation failure
    Note: 
    Note: TODO: Implement using Layout.allocate for Token structure
    
    Return 0  Note: Placeholder
End Process
