Note:
Copyright 2025 Sybertnetics Artificial Intelligence Solutions

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
:End Note

Note:
This file implements Developer syntax to Canonical syntax transformation.

This file performs the following tasks:
- Transform Developer syntax tokens to Canonical token sequences
- Convert symbolic operators (&, |, ^, ~, <<, >>) to natural language keywords
- Transform collection literals ([...], {...}) to natural language forms
- Convert assignment syntax (=) to canonical "Set" statements
- Handle mixed syntax in the same file (line-by-line transformation)

This file is essential because of the following reasons:
- Enables triple syntax support (Canonical, Developer, Viewer)
- Allows developers to use familiar symbolic syntax
- Parser only needs to handle one canonical form
- Simplifies AST generation and semantic analysis
- Supports mixed syntax files for gradual migration

This file consists of the following functions/features/operation types:
- Token pattern recognition for Developer syntax constructs
- Canonical token sequence emission
- Operator transformation (bitwise, logical, arithmetic)
- Collection literal transformation (lists, dictionaries)
- Assignment statement transformation
- Lookahead for disambiguation

Dependencies:
- Imports compiler/frontend/lexical/literals.runa for Token structure
- Imports compiler/frontend/lexical/keywords.runa for Canonical keyword tokens
- Imports compiler/frontend/lexical/math_symbols.runa for Developer operator tokens
- Imports compiler/frontend/lexical/delimiters.runa for bracket/delimiter tokens
- Imports compiler/frontend/primitives/collections/list.runa for token list management
- Imports compiler/frontend/primitives/core/string_core.runa for string operations
- Imports compiler/frontend/primitives/memory/layout.runa for memory allocation
:End Note

Import "compiler/frontend/lexical/literals.runa" as Literals
Import "compiler/frontend/lexical/keywords.runa" as Keywords
Import "compiler/frontend/lexical/math_symbols.runa" as MathSymbols
Import "compiler/frontend/lexical/delimiters.runa" as Delimiters
Import "compiler/frontend/primitives/collections/list.runa" as List
Import "compiler/frontend/primitives/core/string_core.runa" as StringCore
Import "compiler/frontend/primitives/memory/layout.runa" as Layout
Import "compiler/frontend/primitives/core/memory_core.runa" as MemoryCore

Note: ============================================================================
Note: Token Type Constants (from imported modules)
Note: ============================================================================

Note: Delimiter tokens (from delimiters.runa)
Constant TOKEN_LEFT_BRACKET as Integer is 204    Note: [
Constant TOKEN_RIGHT_BRACKET as Integer is 205   Note: ]
Constant TOKEN_LEFT_BRACE as Integer is 202      Note: {
Constant TOKEN_RIGHT_BRACE as Integer is 203     Note: }
Constant TOKEN_LEFT_PAREN as Integer is 200      Note: (
Constant TOKEN_RIGHT_PAREN as Integer is 201     Note: )
Constant TOKEN_COMMA as Integer is 211           Note: ,
Constant TOKEN_COLON as Integer is 210           Note: :

Note: Developer operator tokens (from math_symbols.runa)
Constant TOKEN_BITWISE_AND as Integer is 530     Note: &
Constant TOKEN_BITWISE_OR as Integer is 531      Note: |
Constant TOKEN_BITWISE_XOR as Integer is 532     Note: ^
Constant TOKEN_BITWISE_NOT as Integer is 533     Note: ~
Constant TOKEN_SHIFT_LEFT as Integer is 534      Note: <<
Constant TOKEN_SHIFT_RIGHT as Integer is 535     Note: >>

Note: Assignment and comparison (from operators.runa)
Constant TOKEN_ASSIGN as Integer is 601          Note: = (assignment)
Constant TOKEN_EQUAL_EQUAL as Integer is 510     Note: == (equality)

Note: Canonical keyword tokens (from keywords.runa)
Constant TOKEN_SET as Integer is 301             Note: Set
Constant TOKEN_TO as Integer is 386              Note: To
Constant TOKEN_BITWISE as Integer is 500         Note: bitwise
Constant TOKEN_AND as Integer is 380             Note: and
Constant TOKEN_OR as Integer is 381              Note: or
Constant TOKEN_XOR as Integer is 501             Note: xor
Constant TOKEN_NOT as Integer is 382             Note: not
Constant TOKEN_SHIFTED as Integer is 502         Note: shifted
Constant TOKEN_LEFT as Integer is 503            Note: left
Constant TOKEN_RIGHT as Integer is 504           Note: right
Constant TOKEN_BY as Integer is 387              Note: by

Note: Other tokens
Constant TOKEN_IDENTIFIER as Integer is 200      Note: Identifier
Constant TOKEN_A as Integer is 800               Note: "a" (article)
Constant TOKEN_AN as Integer is 801              Note: "an" (article)
Constant TOKEN_LIST as Integer is 802            Note: "list"
Constant TOKEN_DICTIONARY as Integer is 803      Note: "dictionary"
Constant TOKEN_CONTAINING as Integer is 804      Note: "containing"
Constant TOKEN_EMPTY as Integer is 805           Note: "empty"
Constant TOKEN_AT as Integer is 806              Note: "at"
Constant TOKEN_PROC as Integer is 440            Note: "proc"
Constant TOKEN_FROM as Integer is 331            Note: "from"
Constant TOKEN_WITH as Integer is 372            Note: "with"
Constant TOKEN_GETS as Integer is 490            Note: "gets"
Constant TOKEN_INCREASED as Integer is 491       Note: "increased"
Constant TOKEN_DECREASED as Integer is 492       Note: "decreased"
Constant TOKEN_MULTIPLIED as Integer is 393      Note: "multiplied"
Constant TOKEN_DIVIDED as Integer is 394         Note: "divided"
Constant TOKEN_IF as Integer is 310              Note: "if"
Constant TOKEN_THEN as Integer is 807            Note: "then"
Constant TOKEN_OTHERWISE as Integer is 311       Note: "otherwise"
Constant TOKEN_DOT as Integer is 213             Note: .
Constant TOKEN_QUESTION as Integer is 808        Note: ?
Constant TOKEN_AS as Integer is 332              Note: "as"

Note: Compound assignment operators
Constant TOKEN_PLUS_ASSIGN as Integer is 602     Note: +=
Constant TOKEN_MINUS_ASSIGN as Integer is 603    Note: -=
Constant TOKEN_MULTIPLY_ASSIGN as Integer is 604 Note: *=
Constant TOKEN_DIVIDE_ASSIGN as Integer is 605   Note: /=
Constant TOKEN_AND_ASSIGN as Integer is 606      Note: &=
Constant TOKEN_OR_ASSIGN as Integer is 607       Note: |=
Constant TOKEN_XOR_ASSIGN as Integer is 608      Note: ^=
Constant TOKEN_SHL_ASSIGN as Integer is 609      Note: <<=
Constant TOKEN_SHR_ASSIGN as Integer is 610      Note: >>=

Note: ============================================================================
Note: Transformation Context Structure
Note: ============================================================================

Type called "TransformContext":
    source_code as Integer      Note: Pointer to source code string
    source_length as Integer    Note: Length of source code
    current_position as Integer Note: Current position in source
    line as Integer            Note: Current line number
    column as Integer          Note: Current column number
    lookahead_buffer as Integer Note: List of lookahead tokens
    output_tokens as Integer    Note: List of output Canonical tokens
    transformation_count as Integer Note: Number of transformations performed

Note: ============================================================================
Note: Token Creation Helpers
Note: ============================================================================

Process called "create_token" takes token_type as Integer, value as Integer, line as Integer, column as Integer, length as Integer returns Integer:
    Note:
    Create a Token structure with specified fields.

    Parameters:
      token_type - Token type constant (TOKEN_SET, TOKEN_BITWISE, etc.)
      value - Pointer to string value or 0 for keywords
      line - Line number (1-indexed)
      column - Column number (1-indexed)
      length - Length of token in source

    Returns:
      Pointer to allocated Token structure or 0 on failure
    :End Note

    Note: Token structure: 6 fields Ã— 8 bytes = 48 bytes
    Let token_size be 48
    Let token be proc allocate from Layout with token_size

    If token is equal to 0:
        Return 0
    End If

    Note: Populate Token fields: token_type, value, line, column, length, literal_metadata
    Let dummy1 be proc memory_set_int64 from Layout with token, 0, token_type
    Let dummy2 be proc memory_set_int64 from Layout with token, 8, value
    Let dummy3 be proc memory_set_int64 from Layout with token, 16, line
    Let dummy4 be proc memory_set_int64 from Layout with token, 24, column
    Let dummy5 be proc memory_set_int64 from Layout with token, 32, length
    Let dummy6 be proc memory_set_int64 from Layout with token, 40, 0

    Return token
End Process

Process called "create_keyword_token" takes keyword_type as Integer, keyword_string as Integer, line as Integer, column as Integer returns Integer:
    Note:
    Create a Token for a Canonical keyword.

    Parameters:
      keyword_type - TOKEN_SET, TOKEN_BITWISE, etc.
      keyword_string - Pointer to keyword string ("Set", "bitwise", etc.)
      line - Line number
      column - Column number

    Returns:
      Pointer to Token or 0 on failure
    :End Note

    Note: Get keyword string length
    Let keyword_length be proc strlen from StringCore with keyword_string

    Note: Create token with keyword type and string value
    Let token be proc create_token with keyword_type, keyword_string, line, column, keyword_length

    Return token
End Process

Process called "create_identifier_token" takes identifier_string as Integer, line as Integer, column as Integer returns Integer:
    Note:
    Create a Token for an identifier (e.g., "a", "list", "containing").

    Parameters:
      identifier_string - Pointer to identifier string
      line - Line number
      column - Column number

    Returns:
      Pointer to Token or 0 on failure
    :End Note

    Note: Get identifier length
    Let id_length be proc strlen from StringCore with identifier_string

    Note: Create token with TOKEN_IDENTIFIER type
    Let token be proc create_token with TOKEN_IDENTIFIER, identifier_string, line, column, id_length

    Return token
End Process

Note: ============================================================================
Note: Bitwise Operator Transformation
Note: ============================================================================

Process called "transform_bitwise_and" takes developer_token as Integer, output_list as Integer returns Integer:
    Note:
    Transform & operator to "bitwise and" Canonical form.

    Developer: a & b
    Canonical: a bitwise and b

    Emits two tokens: TOKEN_BITWISE, TOKEN_AND

    Parameters:
      developer_token - Original & token
      output_list - List to append Canonical tokens to

    Returns:
      1 on success, 0 on failure
    :End Note

    Note: Extract line and column from developer token
    Let line be proc memory_get_int64 from Layout with developer_token, 16
    Let column be proc memory_get_int64 from Layout with developer_token, 24

    Note: Create "bitwise" string
    Let bitwise_str be proc string_create from StringCore with "bitwise"

    Note: Create "and" string
    Let and_str be proc string_create from StringCore with "and"

    Note: Create TOKEN_BITWISE token
    Let bitwise_token be proc create_keyword_token with TOKEN_BITWISE, bitwise_str, line, column

    If bitwise_token is equal to 0:
        Return 0
    End If

    Note: Create TOKEN_AND token
    Let and_token be proc create_keyword_token with TOKEN_AND, and_str, line, column plus 8

    If and_token is equal to 0:
        Return 0
    End If

    Note: Append tokens to output list
    Let dummy1 be proc append from List with output_list, bitwise_token
    Let dummy2 be proc append from List with output_list, and_token

    Return 1
End Process

Process called "transform_bitwise_or" takes developer_token as Integer, output_list as Integer returns Integer:
    Note:
    Transform | operator to "bitwise or" Canonical form.

    Developer: a | b
    Canonical: a bitwise or b

    Emits two tokens: TOKEN_BITWISE, TOKEN_OR

    Parameters:
      developer_token - Original | token
      output_list - List to append Canonical tokens to

    Returns:
      1 on success, 0 on failure
    :End Note

    Note: Extract line and column from developer token
    Let line be proc memory_get_int64 from Layout with developer_token, 16
    Let column be proc memory_get_int64 from Layout with developer_token, 24

    Note: Create "bitwise" string
    Let bitwise_str be proc string_create from StringCore with "bitwise"

    Note: Create "or" string
    Let or_str be proc string_create from StringCore with "or"

    Note: Create TOKEN_BITWISE token
    Let bitwise_token be proc create_keyword_token with TOKEN_BITWISE, bitwise_str, line, column

    If bitwise_token is equal to 0:
        Return 0
    End If

    Note: Create TOKEN_OR token
    Let or_token be proc create_keyword_token with TOKEN_OR, or_str, line, column plus 8

    If or_token is equal to 0:
        Return 0
    End If

    Note: Append tokens to output list
    Let dummy1 be proc append from List with output_list, bitwise_token
    Let dummy2 be proc append from List with output_list, or_token

    Return 1
End Process

Process called "transform_bitwise_xor" takes developer_token as Integer, output_list as Integer returns Integer:
    Note:
    Transform ^ operator to "bitwise xor" Canonical form.

    Developer: a ^ b
    Canonical: a bitwise xor b

    Emits two tokens: TOKEN_BITWISE, TOKEN_XOR

    Parameters:
      developer_token - Original ^ token
      output_list - List to append Canonical tokens to

    Returns:
      1 on success, 0 on failure
    :End Note

    Note: Extract line and column from developer token
    Let line be proc memory_get_int64 from Layout with developer_token, 16
    Let column be proc memory_get_int64 from Layout with developer_token, 24

    Note: Create "bitwise" string
    Let bitwise_str be proc string_create from StringCore with "bitwise"

    Note: Create "xor" string
    Let xor_str be proc string_create from StringCore with "xor"

    Note: Create TOKEN_BITWISE token
    Let bitwise_token be proc create_keyword_token with TOKEN_BITWISE, bitwise_str, line, column

    If bitwise_token is equal to 0:
        Return 0
    End If

    Note: Create TOKEN_XOR token
    Let xor_token be proc create_keyword_token with TOKEN_XOR, xor_str, line, column plus 8

    If xor_token is equal to 0:
        Return 0
    End If

    Note: Append tokens to output list
    Let dummy1 be proc append from List with output_list, bitwise_token
    Let dummy2 be proc append from List with output_list, xor_token

    Return 1
End Process

Process called "transform_bitwise_not" takes developer_token as Integer, output_list as Integer returns Integer:
    Note:
    Transform ~ operator to "bitwise not" Canonical form.

    Developer: ~a
    Canonical: bitwise not a

    Emits two tokens: TOKEN_BITWISE, TOKEN_NOT

    Parameters:
      developer_token - Original ~ token
      output_list - List to append Canonical tokens to

    Returns:
      1 on success, 0 on failure
    :End Note

    Note: Extract line and column from developer token
    Let line be proc memory_get_int64 from Layout with developer_token, 16
    Let column be proc memory_get_int64 from Layout with developer_token, 24

    Note: Create "bitwise" string
    Let bitwise_str be proc string_create from StringCore with "bitwise"

    Note: Create "not" string
    Let not_str be proc string_create from StringCore with "not"

    Note: Create TOKEN_BITWISE token
    Let bitwise_token be proc create_keyword_token with TOKEN_BITWISE, bitwise_str, line, column

    If bitwise_token is equal to 0:
        Return 0
    End If

    Note: Create TOKEN_NOT token
    Let not_token be proc create_keyword_token with TOKEN_NOT, not_str, line, column plus 8

    If not_token is equal to 0:
        Return 0
    End If

    Note: Append tokens to output list
    Let dummy1 be proc append from List with output_list, bitwise_token
    Let dummy2 be proc append from List with output_list, not_token

    Return 1
End Process

Process called "transform_shift_left" takes developer_token as Integer, output_list as Integer returns Integer:
    Note:
    Transform << operator to "shifted left by" Canonical form.

    Developer: a << 2
    Canonical: a shifted left by 2

    Emits three tokens: TOKEN_SHIFTED, TOKEN_LEFT, TOKEN_BY

    Parameters:
      developer_token - Original << token
      output_list - List to append Canonical tokens to

    Returns:
      1 on success, 0 on failure
    :End Note

    Note: Extract line and column from developer token
    Let line be proc memory_get_int64 from Layout with developer_token, 16
    Let column be proc memory_get_int64 from Layout with developer_token, 24

    Note: Create keyword strings
    Let shifted_str be proc string_create from StringCore with "shifted"
    Let left_str be proc string_create from StringCore with "left"
    Let by_str be proc string_create from StringCore with "by"

    Note: Create tokens
    Let shifted_token be proc create_keyword_token with TOKEN_SHIFTED, shifted_str, line, column

    If shifted_token is equal to 0:
        Return 0
    End If

    Let left_token be proc create_keyword_token with TOKEN_LEFT, left_str, line, column plus 8

    If left_token is equal to 0:
        Return 0
    End If

    Let by_token be proc create_keyword_token with TOKEN_BY, by_str, line, column plus 13

    If by_token is equal to 0:
        Return 0
    End If

    Note: Append tokens to output list
    Let dummy1 be proc append from List with output_list, shifted_token
    Let dummy2 be proc append from List with output_list, left_token
    Let dummy3 be proc append from List with output_list, by_token

    Return 1
End Process

Process called "transform_shift_right" takes developer_token as Integer, output_list as Integer returns Integer:
    Note:
    Transform >> operator to "shifted right by" Canonical form.

    Developer: a >> 2
    Canonical: a shifted right by 2

    Emits three tokens: TOKEN_SHIFTED, TOKEN_RIGHT, TOKEN_BY

    Parameters:
      developer_token - Original >> token
      output_list - List to append Canonical tokens to

    Returns:
      1 on success, 0 on failure
    :End Note

    Note: Extract line and column from developer token
    Let line be proc memory_get_int64 from Layout with developer_token, 16
    Let column be proc memory_get_int64 from Layout with developer_token, 24

    Note: Create keyword strings
    Let shifted_str be proc string_create from StringCore with "shifted"
    Let right_str be proc string_create from StringCore with "right"
    Let by_str be proc string_create from StringCore with "by"

    Note: Create tokens
    Let shifted_token be proc create_keyword_token with TOKEN_SHIFTED, shifted_str, line, column

    If shifted_token is equal to 0:
        Return 0
    End If

    Let right_token be proc create_keyword_token with TOKEN_RIGHT, right_str, line, column plus 8

    If right_token is equal to 0:
        Return 0
    End If

    Let by_token be proc create_keyword_token with TOKEN_BY, by_str, line, column plus 14

    If by_token is equal to 0:
        Return 0
    End If

    Note: Append tokens to output list
    Let dummy1 be proc append from List with output_list, shifted_token
    Let dummy2 be proc append from List with output_list, right_token
    Let dummy3 be proc append from List with output_list, by_token

    Return 1
End Process

Note: ============================================================================
Note: Assignment Transformation
Note: ============================================================================

Process called "transform_assignment" takes equal_token as Integer, identifier_token as Integer, output_list as Integer returns Integer:
    Note:
    Transform = assignment to "Set...to" Canonical form.

    Developer: x = 5
    Canonical: Set x to 5

    This function assumes it receives:
    - identifier_token: the variable being assigned (x)
    - equal_token: the = operator
    - The value expression follows in the token stream

    Emits tokens: TOKEN_SET, identifier, TOKEN_TO, ...

    Parameters:
      equal_token - The = token
      identifier_token - The variable identifier token
      output_list - List to append Canonical tokens to

    Returns:
      1 on success, 0 on failure
    :End Note

    Note: Extract line and column from equal token
    Let line be proc memory_get_int64 from Layout with equal_token, 16
    Let column be proc memory_get_int64 from Layout with equal_token, 24

    Note: Create "Set" keyword token
    Let set_str be proc string_create from StringCore with "Set"
    Let set_token be proc create_keyword_token with TOKEN_SET, set_str, line, column

    If set_token is equal to 0:
        Return 0
    End If

    Note: Create "to" keyword token
    Let to_str be proc string_create from StringCore with "to"
    Let to_token be proc create_keyword_token with TOKEN_TO, to_str, line, column plus 4

    If to_token is equal to 0:
        Return 0
    End If

    Note: Emit: SET identifier TO
    Let dummy1 be proc append from List with output_list, set_token
    Let dummy2 be proc append from List with output_list, identifier_token
    Let dummy3 be proc append from List with output_list, to_token

    Return 1
End Process

Note: ============================================================================
Note: Collection Literal Transformation
Note: ============================================================================

Process called "transform_list_literal" takes left_bracket_token as Integer, element_tokens as Integer, right_bracket_token as Integer, output_list as Integer returns Integer:
    Note:
    Transform [...] list literal to "a list containing..." Canonical form.

    Developer: [1, 2, 3]
    Canonical: a list containing 1, 2, 3

    Parameters:
      left_bracket_token - The [ token
      element_tokens - List of element tokens (expressions and commas)
      right_bracket_token - The ] token
      output_list - List to append Canonical tokens to

    Returns:
      1 on success, 0 on failure
    :End Note

    Note: Extract line and column from left bracket
    Let line be proc memory_get_int64 from Layout with left_bracket_token, 16
    Let column be proc memory_get_int64 from Layout with left_bracket_token, 24

    Note: Create "a" identifier token
    Let a_str be proc string_create from StringCore with "a"
    Let a_token be proc create_identifier_token with a_str, line, column

    If a_token is equal to 0:
        Return 0
    End If

    Note: Create "list" identifier token
    Let list_str be proc string_create from StringCore with "list"
    Let list_token be proc create_identifier_token with list_str, line, column plus 2

    If list_token is equal to 0:
        Return 0
    End If

    Note: Create "containing" identifier token
    Let containing_str be proc string_create from StringCore with "containing"
    Let containing_token be proc create_identifier_token with containing_str, line, column plus 7

    If containing_token is equal to 0:
        Return 0
    End If

    Note: Emit: a list containing [elements...]
    Let dummy1 be proc append from List with output_list, a_token
    Let dummy2 be proc append from List with output_list, list_token
    Let dummy3 be proc append from List with output_list, containing_token

    Note: Append all element tokens (preserving commas for separation)
    Let element_count be proc size from List with element_tokens
    Let i be 0

    While i is less than element_count:
        Let element be proc get from List with element_tokens, i
        Let dummy4 be proc append from List with output_list, element
        Set i to i plus 1
    End While

    Return 1
End Process

Process called "transform_dict_literal" takes left_brace_token as Integer, pair_tokens as Integer, right_brace_token as Integer, output_list as Integer returns Integer:
    Note:
    Transform {...} dictionary literal to "a dictionary containing..." Canonical form.

    Developer: {"key": "value", "age": 30}
    Canonical: a dictionary containing "key" as "value", "age" as 30

    Note: ":" in Developer syntax becomes "as" in Canonical

    Parameters:
      left_brace_token - The { token
      pair_tokens - List of key-value pair tokens (keys, colons, values, commas)
      right_brace_token - The } token
      output_list - List to append Canonical tokens to

    Returns:
      1 on success, 0 on failure
    :End Note

    Note: Extract line and column from left brace
    Let line be proc memory_get_int64 from Layout with left_brace_token, 16
    Let column be proc memory_get_int64 from Layout with left_brace_token, 24

    Note: Create "a" identifier token
    Let a_str be proc string_create from StringCore with "a"
    Let a_token be proc create_identifier_token with a_str, line, column

    If a_token is equal to 0:
        Return 0
    End If

    Note: Create "dictionary" identifier token
    Let dict_str be proc string_create from StringCore with "dictionary"
    Let dict_token be proc create_identifier_token with dict_str, line, column plus 2

    If dict_token is equal to 0:
        Return 0
    End If

    Note: Create "containing" identifier token
    Let containing_str be proc string_create from StringCore with "containing"
    Let containing_token be proc create_identifier_token with containing_str, line, column plus 13

    If containing_token is equal to 0:
        Return 0
    End If

    Note: Emit: a dictionary containing
    Let dummy1 be proc append from List with output_list, a_token
    Let dummy2 be proc append from List with output_list, dict_token
    Let dummy3 be proc append from List with output_list, containing_token

    Note: Transform pair_tokens: replace colons (:) with "as" keyword
    Let pair_count be proc size from List with pair_tokens
    Let i be 0

    While i is less than pair_count:
        Let pair_token be proc get from List with pair_tokens, i
        Let token_type be proc memory_get_int64 from Layout with pair_token, 0

        Note: Check if this is a colon token
        If token_type is equal to TOKEN_COLON:
            Note: Replace colon with "as" keyword
            Let as_str be proc string_create from StringCore with "as"
            Let pair_line be proc memory_get_int64 from Layout with pair_token, 16
            Let pair_column be proc memory_get_int64 from Layout with pair_token, 24
            Let as_token be proc create_keyword_token with TOKEN_AS, as_str, pair_line, pair_column

            If as_token is equal to 0:
                Return 0
            End If

            Let dummy4 be proc append from List with output_list, as_token
        Otherwise:
            Note: Keep other tokens as-is (keys, values, commas)
            Let dummy5 be proc append from List with output_list, pair_token
        End If

        Set i to i plus 1
    End While

    Return 1
End Process

Note: ============================================================================
Note: Main Transformation Dispatcher
Note: ============================================================================

Process called "transform_developer_token" takes developer_token as Integer, output_list as Integer returns Integer:
    Note:
    Main dispatcher for transforming Developer syntax tokens to Canonical.

    Examines the token type and dispatches to appropriate transformation function.

    Developer tokens that need transformation:
    - TOKEN_BITWISE_AND (&) â†’ "bitwise and"
    - TOKEN_BITWISE_OR (|) â†’ "bitwise or"
    - TOKEN_BITWISE_XOR (^) â†’ "bitwise xor"
    - TOKEN_BITWISE_NOT (~) â†’ "bitwise not"
    - TOKEN_SHIFT_LEFT (<<) â†’ "shifted left by"
    - TOKEN_SHIFT_RIGHT (>>) â†’ "shifted right by"
    - TOKEN_ASSIGN (=) â†’ "Set...to" (requires context)
    - TOKEN_LEFT_BRACKET ([) â†’ "a list containing..." (requires lookahead)
    - TOKEN_LEFT_BRACE ({) â†’ "a dictionary containing..." (requires lookahead)

    Parameters:
      developer_token - Token to potentially transform
      output_list - List to append transformed Canonical tokens to

    Returns:
      1 if token was transformed, 0 if token should pass through as-is
    :End Note

    Note: Get token type
    Let token_type be proc memory_get_int64 from Layout with developer_token, 0

    Note: Dispatch based on token type
    If token_type is equal to TOKEN_BITWISE_AND:
        Let result be proc transform_bitwise_and with developer_token, output_list
        Return result
    End If

    If token_type is equal to TOKEN_BITWISE_OR:
        Let result be proc transform_bitwise_or with developer_token, output_list
        Return result
    End If

    If token_type is equal to TOKEN_BITWISE_XOR:
        Let result be proc transform_bitwise_xor with developer_token, output_list
        Return result
    End If

    If token_type is equal to TOKEN_BITWISE_NOT:
        Let result be proc transform_bitwise_not with developer_token, output_list
        Return result
    End If

    If token_type is equal to TOKEN_SHIFT_LEFT:
        Let result be proc transform_shift_left with developer_token, output_list
        Return result
    End If

    If token_type is equal to TOKEN_SHIFT_RIGHT:
        Let result be proc transform_shift_right with developer_token, output_list
        Return result
    End If

    Note: For other tokens (=, [, {, etc.), return 0 to indicate no transformation
    Note: These require context/lookahead and should be handled by the lexer
    Return 0
End Process

Process called "is_developer_operator" takes token_type as Integer returns Integer:
    Note:
    Check if a token type is a Developer syntax operator that needs transformation.

    Parameters:
      token_type - Token type constant

    Returns:
      1 if token is a Developer operator, 0 otherwise
    :End Note

    If token_type is equal to TOKEN_BITWISE_AND:
        Return 1
    End If

    If token_type is equal to TOKEN_BITWISE_OR:
        Return 1
    End If

    If token_type is equal to TOKEN_BITWISE_XOR:
        Return 1
    End If

    If token_type is equal to TOKEN_BITWISE_NOT:
        Return 1
    End If

    If token_type is equal to TOKEN_SHIFT_LEFT:
        Return 1
    End If

    If token_type is equal to TOKEN_SHIFT_RIGHT:
        Return 1
    End If

    If token_type is equal to TOKEN_ASSIGN:
        Return 1
    End If

    If token_type is equal to TOKEN_LEFT_BRACKET:
        Return 1
    End If

    If token_type is equal to TOKEN_LEFT_BRACE:
        Return 1
    End If

    If token_type is equal to TOKEN_LEFT_PAREN:
        Return 1
    End If

    If token_type is equal to TOKEN_PLUS_ASSIGN:
        Return 1
    End If

    If token_type is equal to TOKEN_MINUS_ASSIGN:
        Return 1
    End If

    If token_type is equal to TOKEN_MULTIPLY_ASSIGN:
        Return 1
    End If

    If token_type is equal to TOKEN_DIVIDE_ASSIGN:
        Return 1
    End If

    If token_type is equal to TOKEN_AND_ASSIGN:
        Return 1
    End If

    If token_type is equal to TOKEN_OR_ASSIGN:
        Return 1
    End If

    If token_type is equal to TOKEN_XOR_ASSIGN:
        Return 1
    End If

    If token_type is equal to TOKEN_SHL_ASSIGN:
        Return 1
    End If

    If token_type is equal to TOKEN_SHR_ASSIGN:
        Return 1
    End If

    If token_type is equal to TOKEN_QUESTION:
        Return 1
    End If

    Return 0
End Process

Note: ============================================================================
Note: Structural Transformation Functions (Lists, Dicts, Calls, etc.)
Note: ============================================================================

Note: These functions require more sophisticated handling than simple operators
Note: They need to collect multiple tokens and build complex structures

Process called "collect_tokens_until" takes token_stream as Integer, start_index as Integer, end_delimiter_type as Integer returns Integer:
    Note:
    Collect all tokens from start_index until we hit the matching end delimiter.

    Handles nested delimiters correctly (e.g., nested lists, nested function calls).

    Parameters:
      token_stream - List of tokens
      start_index - Index to start collecting from
      end_delimiter_type - TOKEN_RIGHT_BRACKET, TOKEN_RIGHT_BRACE, or TOKEN_RIGHT_PAREN

    Returns:
      List of collected tokens (excluding the end delimiter)
      Returns 0 on error (unmatched delimiters)
    :End Note

    Note: Create result list
    Let collected be proc create from List

    If collected is equal to 0:
        Return 0
    End If

    Note: Track nesting depth
    Let depth be 1
    Let current_index be start_index
    Let stream_size be proc size from List with token_stream

    Note: Determine the matching opening delimiter
    Let opening_delimiter_type be 0
    If end_delimiter_type is equal to TOKEN_RIGHT_BRACKET:
        Set opening_delimiter_type to TOKEN_LEFT_BRACKET
    End If
    If end_delimiter_type is equal to TOKEN_RIGHT_BRACE:
        Set opening_delimiter_type to TOKEN_LEFT_BRACE
    End If
    If end_delimiter_type is equal to TOKEN_RIGHT_PAREN:
        Set opening_delimiter_type to TOKEN_LEFT_PAREN
    End If

    Note: Collect tokens until depth returns to 0
    While current_index is less than stream_size:
        Let token be proc get from List with token_stream, current_index
        Let token_type be proc memory_get_int64 from Layout with token, 0

        Note: Check if this increases or decreases nesting depth
        If token_type is equal to opening_delimiter_type:
            Set depth to depth plus 1
        End If

        If token_type is equal to end_delimiter_type:
            Set depth to depth minus 1
            If depth is equal to 0:
                Note: Found matching closing delimiter
                Return collected
            End If
        End If

        Note: Add token to collected list
        Let dummy1 be proc append from List with collected, token
        Set current_index to current_index plus 1
    End While

    Note: If we get here, delimiters were unmatched
    Return 0
End Process

Process called "transform_list_literal_complete" takes left_bracket_token as Integer, token_stream as Integer, bracket_index as Integer, output_list as Integer returns Integer:
    Note:
    Transform complete list literal from Developer to Canonical form.

    Developer: [1, 2, 3]
    Canonical: a list containing 1, 2, 3

    Developer: []
    Canonical: an empty list

    Parameters:
      left_bracket_token - The [ token
      token_stream - Full token stream for lookahead
      bracket_index - Index of [ in token_stream
      output_list - List to append Canonical tokens to

    Returns:
      Number of tokens consumed from token_stream (including closing ])
      Returns 0 on error
    :End Note

    Note: Extract line and column from left bracket
    Let line be proc memory_get_int64 from Layout with left_bracket_token, 16
    Let column be proc memory_get_int64 from Layout with left_bracket_token, 24

    Note: Collect all tokens until matching ]
    Let elements be proc collect_tokens_until with token_stream, bracket_index plus 1, TOKEN_RIGHT_BRACKET

    If elements is equal to 0:
        Note: Unmatched brackets
        Return 0
    End If

    Note: Check if list is empty
    Let element_count be proc size from List with elements

    If element_count is equal to 0:
        Note: Empty list: [] â†’ an empty list
        Let an_str be proc string_create from StringCore with "an"
        Let empty_str be proc string_create from StringCore with "empty"
        Let list_str be proc string_create from StringCore with "list"

        Let an_token be proc create_identifier_token with an_str, line, column
        Let empty_token be proc create_identifier_token with empty_str, line, column plus 3
        Let list_token be proc create_identifier_token with list_str, line, column plus 9

        Let dummy1 be proc append from List with output_list, an_token
        Let dummy2 be proc append from List with output_list, empty_token
        Let dummy3 be proc append from List with output_list, list_token

        Note: Return tokens consumed: [ + ]
        Return 2
    End If

    Note: Non-empty list: [elements...] â†’ a list containing elements...
    Let a_str be proc string_create from StringCore with "a"
    Let list_str be proc string_create from StringCore with "list"
    Let containing_str be proc string_create from StringCore with "containing"

    Let a_token be proc create_identifier_token with a_str, line, column
    Let list_token be proc create_identifier_token with list_str, line, column plus 2
    Let containing_token be proc create_identifier_token with containing_str, line, column plus 7

    Let dummy4 be proc append from List with output_list, a_token
    Let dummy5 be proc append from List with output_list, list_token
    Let dummy6 be proc append from List with output_list, containing_token

    Note: Append all element tokens (they stay as-is, but may need recursive transformation)
    Let i be 0
    While i is less than element_count:
        Let element_token be proc get from List with elements, i
        Let dummy7 be proc append from List with output_list, element_token
        Set i to i plus 1
    End While

    Note: Return tokens consumed: [ + elements + ]
    Return element_count plus 2
End Process

Process called "transform_dict_literal_complete" takes left_brace_token as Integer, token_stream as Integer, brace_index as Integer, output_list as Integer returns Integer:
    Note:
    Transform complete dictionary literal from Developer to Canonical form.

    Developer: {"key": "value", "age": 30}
    Canonical: a dictionary containing "key" as "value", "age" as 30

    Developer: {}
    Canonical: an empty dictionary

    Transforms : to "as" keyword.

    Parameters:
      left_brace_token - The { token
      token_stream - Full token stream for lookahead
      brace_index - Index of { in token_stream
      output_list - List to append Canonical tokens to

    Returns:
      Number of tokens consumed from token_stream (including closing })
      Returns 0 on error
    :End Note

    Note: Extract line and column from left brace
    Let line be proc memory_get_int64 from Layout with left_brace_token, 16
    Let column be proc memory_get_int64 from Layout with left_brace_token, 24

    Note: Collect all tokens until matching }
    Let pairs be proc collect_tokens_until with token_stream, brace_index plus 1, TOKEN_RIGHT_BRACE

    If pairs is equal to 0:
        Note: Unmatched braces
        Return 0
    End If

    Note: Check if dictionary is empty
    Let pair_count be proc size from List with pairs

    If pair_count is equal to 0:
        Note: Empty dictionary: {} â†’ an empty dictionary
        Let an_str be proc string_create from StringCore with "an"
        Let empty_str be proc string_create from StringCore with "empty"
        Let dict_str be proc string_create from StringCore with "dictionary"

        Let an_token be proc create_identifier_token with an_str, line, column
        Let empty_token be proc create_identifier_token with empty_str, line, column plus 3
        Let dict_token be proc create_identifier_token with dict_str, line, column plus 9

        Let dummy1 be proc append from List with output_list, an_token
        Let dummy2 be proc append from List with output_list, empty_token
        Let dummy3 be proc append from List with output_list, dict_token

        Note: Return tokens consumed: { + }
        Return 2
    End If

    Note: Non-empty dictionary: {pairs...} â†’ a dictionary containing pairs...
    Let a_str be proc string_create from StringCore with "a"
    Let dict_str be proc string_create from StringCore with "dictionary"
    Let containing_str be proc string_create from StringCore with "containing"

    Let a_token be proc create_identifier_token with a_str, line, column
    Let dict_token be proc create_identifier_token with dict_str, line, column plus 2
    Let containing_token be proc create_identifier_token with containing_str, line, column plus 13

    Let dummy4 be proc append from List with output_list, a_token
    Let dummy5 be proc append from List with output_list, dict_token
    Let dummy6 be proc append from List with output_list, containing_token

    Note: Transform pairs: replace : with "as"
    Let i be 0
    While i is less than pair_count:
        Let pair_token be proc get from List with pairs, i
        Let token_type be proc memory_get_int64 from Layout with pair_token, 0

        If token_type is equal to TOKEN_COLON:
            Note: Replace : with "as" keyword
            Let as_str be proc string_create from StringCore with "as"
            Let token_line be proc memory_get_int64 from Layout with pair_token, 16
            Let token_column be proc memory_get_int64 from Layout with pair_token, 24
            Let as_token be proc create_keyword_token with TOKEN_AS, as_str, token_line, token_column

            Let dummy7 be proc append from List with output_list, as_token
        Otherwise:
            Note: Keep other tokens as-is
            Let dummy8 be proc append from List with output_list, pair_token
        End If

        Set i to i plus 1
    End While

    Note: Return tokens consumed: { + pairs + }
    Return pair_count plus 2
End Process

Process called "transform_array_indexing" takes identifier_token as Integer, left_bracket_token as Integer, token_stream as Integer, bracket_index as Integer, output_list as Integer returns Integer:
    Note:
    Transform array/list indexing from Developer to Canonical form.

    Developer: arr[0]
    Canonical: arr at 0

    Developer: matrix[i][j]
    Canonical: (matrix at i) at j

    Parameters:
      identifier_token - The identifier being indexed (arr, matrix, etc.)
      left_bracket_token - The [ token
      token_stream - Full token stream for lookahead
      bracket_index - Index of [ in token_stream
      output_list - List to append Canonical tokens to

    Returns:
      Number of tokens consumed from token_stream (including closing ])
      Returns 0 on error
    :End Note

    Note: Extract line and column
    Let line be proc memory_get_int64 from Layout with left_bracket_token, 16
    Let column be proc memory_get_int64 from Layout with left_bracket_token, 24

    Note: Collect index expression tokens
    Let index_tokens be proc collect_tokens_until with token_stream, bracket_index plus 1, TOKEN_RIGHT_BRACKET

    If index_tokens is equal to 0:
        Note: Unmatched brackets
        Return 0
    End If

    Note: Emit: identifier at index_expression
    Let dummy1 be proc append from List with output_list, identifier_token

    Note: Create "at" keyword token
    Let at_str be proc string_create from StringCore with "at"
    Let at_token be proc create_identifier_token with at_str, line, column

    Let dummy2 be proc append from List with output_list, at_token

    Note: Append index expression tokens
    Let index_count be proc size from List with index_tokens
    Let i be 0
    While i is less than index_count:
        Let index_token be proc get from List with index_tokens, i
        Let dummy3 be proc append from List with output_list, index_token
        Set i to i plus 1
    End While

    Note: Return tokens consumed: [ + index + ]
    Return index_count plus 2
End Process

Process called "transform_assignment_statement" takes identifier_token as Integer, equal_token as Integer, token_stream as Integer, equal_index as Integer, output_list as Integer returns Integer:
    Note:
    Transform assignment statement from Developer to Canonical form.

    Developer: x = 5
    Canonical: Set x to 5

    Parameters:
      identifier_token - The variable being assigned
      equal_token - The = token
      token_stream - Full token stream (for future use)
      equal_index - Index of = in token_stream
      output_list - List to append Canonical tokens to

    Returns:
      1 on success (we don't consume extra tokens, just transform in place)
      0 on error
    :End Note

    Note: Extract line and column from equal token
    Let line be proc memory_get_int64 from Layout with equal_token, 16
    Let column be proc memory_get_int64 from Layout with equal_token, 24

    Note: Create "Set" keyword token
    Let set_str be proc string_create from StringCore with "Set"
    Let set_token be proc create_keyword_token with TOKEN_SET, set_str, line, column

    Note: Create "to" keyword token
    Let to_str be proc string_create from StringCore with "to"
    Let to_token be proc create_keyword_token with TOKEN_TO, to_str, line, column plus 4

    Note: Emit: Set identifier to ...
    Let dummy1 be proc append from List with output_list, set_token
    Let dummy2 be proc append from List with output_list, identifier_token
    Let dummy3 be proc append from List with output_list, to_token

    Note: The value expression follows in the token stream
    Return 1
End Process

Process called "transform_compound_assignment" takes identifier_token as Integer, compound_op_token as Integer, output_list as Integer returns Integer:
    Note:
    Transform compound assignment from Developer to Canonical form.

    Developer: x += 5 â†’ Canonical: x gets increased by 5
    Developer: x -= 3 â†’ Canonical: x gets decreased by 3
    Developer: x *= 2 â†’ Canonical: x gets multiplied by 2
    Developer: x /= 4 â†’ Canonical: x gets divided by 4
    Developer: x &= mask â†’ Canonical: x gets bitwise and mask

    Parameters:
      identifier_token - The variable being modified
      compound_op_token - The compound operator (+=, -=, *=, etc.)
      output_list - List to append Canonical tokens to

    Returns:
      1 on success
      0 on error
    :End Note

    Note: Extract line, column, and operator type
    Let line be proc memory_get_int64 from Layout with compound_op_token, 16
    Let column be proc memory_get_int64 from Layout with compound_op_token, 24
    Let op_type be proc memory_get_int64 from Layout with compound_op_token, 0

    Note: Create common keyword tokens
    Let gets_str be proc string_create from StringCore with "gets"
    Let by_str be proc string_create from StringCore with "by"

    Let gets_token be proc create_keyword_token with TOKEN_GETS, gets_str, line, column
    Let by_token be proc create_keyword_token with TOKEN_BY, by_str, line, column plus 10

    Note: Emit: identifier gets ...
    Let dummy1 be proc append from List with output_list, identifier_token
    Let dummy2 be proc append from List with output_list, gets_token

    Note: Determine operation keyword based on compound operator type
    If op_type is equal to TOKEN_PLUS_ASSIGN:
        Let increased_str be proc string_create from StringCore with "increased"
        Let increased_token be proc create_keyword_token with TOKEN_INCREASED, increased_str, line, column plus 5
        Let dummy3 be proc append from List with output_list, increased_token
        Let dummy4 be proc append from List with output_list, by_token
        Return 1
    End If

    If op_type is equal to TOKEN_MINUS_ASSIGN:
        Let decreased_str be proc string_create from StringCore with "decreased"
        Let decreased_token be proc create_keyword_token with TOKEN_DECREASED, decreased_str, line, column plus 5
        Let dummy5 be proc append from List with output_list, decreased_token
        Let dummy6 be proc append from List with output_list, by_token
        Return 1
    End If

    If op_type is equal to TOKEN_MULTIPLY_ASSIGN:
        Let multiplied_str be proc string_create from StringCore with "multiplied"
        Let multiplied_token be proc create_keyword_token with TOKEN_MULTIPLIED, multiplied_str, line, column plus 5
        Let dummy7 be proc append from List with output_list, multiplied_token
        Let dummy8 be proc append from List with output_list, by_token
        Return 1
    End If

    If op_type is equal to TOKEN_DIVIDE_ASSIGN:
        Let divided_str be proc string_create from StringCore with "divided"
        Let divided_token be proc create_keyword_token with TOKEN_DIVIDED, divided_str, line, column plus 5
        Let dummy9 be proc append from List with output_list, divided_token
        Let dummy10 be proc append from List with output_list, by_token
        Return 1
    End If

    If op_type is equal to TOKEN_AND_ASSIGN:
        Note: x &= y â†’ x gets bitwise and y (by is not needed here)
        Let bitwise_str be proc string_create from StringCore with "bitwise"
        Let and_str be proc string_create from StringCore with "and"
        Let bitwise_token be proc create_keyword_token with TOKEN_BITWISE, bitwise_str, line, column plus 5
        Let and_token be proc create_keyword_token with TOKEN_AND, and_str, line, column plus 13
        Let dummy11 be proc append from List with output_list, bitwise_token
        Let dummy12 be proc append from List with output_list, and_token
        Return 1
    End If

    If op_type is equal to TOKEN_OR_ASSIGN:
        Let bitwise_str be proc string_create from StringCore with "bitwise"
        Let or_str be proc string_create from StringCore with "or"
        Let bitwise_token be proc create_keyword_token with TOKEN_BITWISE, bitwise_str, line, column plus 5
        Let or_token be proc create_keyword_token with TOKEN_OR, or_str, line, column plus 13
        Let dummy13 be proc append from List with output_list, bitwise_token
        Let dummy14 be proc append from List with output_list, or_token
        Return 1
    End If

    If op_type is equal to TOKEN_XOR_ASSIGN:
        Let bitwise_str be proc string_create from StringCore with "bitwise"
        Let xor_str be proc string_create from StringCore with "xor"
        Let bitwise_token be proc create_keyword_token with TOKEN_BITWISE, bitwise_str, line, column plus 5
        Let xor_token be proc create_keyword_token with TOKEN_XOR, xor_str, line, column plus 13
        Let dummy15 be proc append from List with output_list, bitwise_token
        Let dummy16 be proc append from List with output_list, xor_token
        Return 1
    End If

    If op_type is equal to TOKEN_SHL_ASSIGN:
        Let shifted_str be proc string_create from StringCore with "shifted"
        Let left_str be proc string_create from StringCore with "left"
        Let shifted_token be proc create_keyword_token with TOKEN_SHIFTED, shifted_str, line, column plus 5
        Let left_token be proc create_keyword_token with TOKEN_LEFT, left_str, line, column plus 13
        Let dummy17 be proc append from List with output_list, shifted_token
        Let dummy18 be proc append from List with output_list, left_token
        Let dummy19 be proc append from List with output_list, by_token
        Return 1
    End If

    If op_type is equal to TOKEN_SHR_ASSIGN:
        Let shifted_str be proc string_create from StringCore with "shifted"
        Let right_str be proc string_create from StringCore with "right"
        Let shifted_token be proc create_keyword_token with TOKEN_SHIFTED, shifted_str, line, column plus 5
        Let right_token be proc create_keyword_token with TOKEN_RIGHT, right_str, line, column plus 13
        Let dummy20 be proc append from List with output_list, shifted_token
        Let dummy21 be proc append from List with output_list, right_token
        Let dummy22 be proc append from List with output_list, by_token
        Return 1
    End If

    Note: Unknown compound operator
    Return 0
End Process

Process called "transform_function_call" takes identifier_token as Integer, left_paren_token as Integer, token_stream as Integer, paren_index as Integer, output_list as Integer returns Integer:
    Note:
    Transform function call from Developer to Canonical form.

    Developer: func(arg1, arg2)
    Canonical: proc func with arg1, arg2

    Developer: func()
    Canonical: proc func

    Parameters:
      identifier_token - The function name
      left_paren_token - The ( token
      token_stream - Full token stream for lookahead
      paren_index - Index of ( in token_stream
      output_list - List to append Canonical tokens to

    Returns:
      Number of tokens consumed from token_stream (including closing ))
      Returns 0 on error
    :End Note

    Note: Extract line and column
    Let line be proc memory_get_int64 from Layout with left_paren_token, 16
    Let column be proc memory_get_int64 from Layout with left_paren_token, 24

    Note: Collect argument tokens
    Let args be proc collect_tokens_until with token_stream, paren_index plus 1, TOKEN_RIGHT_PAREN

    If args is equal to 0:
        Note: Unmatched parentheses
        Return 0
    End If

    Note: Create "proc" keyword token
    Let proc_str be proc string_create from StringCore with "proc"
    Let proc_token be proc create_keyword_token with TOKEN_PROC, proc_str, line, column

    Note: Emit: proc function_name
    Let dummy1 be proc append from List with output_list, proc_token
    Let dummy2 be proc append from List with output_list, identifier_token

    Note: Check if there are arguments
    Let arg_count be proc size from List with args

    If arg_count is greater than 0:
        Note: Emit: with arguments
        Let with_str be proc string_create from StringCore with "with"
        Let with_token be proc create_keyword_token with TOKEN_WITH, with_str, line, column plus 5

        Let dummy3 be proc append from List with output_list, with_token

        Note: Append all argument tokens
        Let i be 0
        While i is less than arg_count:
            Let arg_token be proc get from List with args, i
            Let dummy4 be proc append from List with output_list, arg_token
            Set i to i plus 1
        End While
    End If

    Note: Return tokens consumed: ( + args + )
    Return arg_count plus 2
End Process

Process called "transform_method_call" takes object_token as Integer, dot_token as Integer, method_token as Integer, left_paren_token as Integer, token_stream as Integer, paren_index as Integer, output_list as Integer returns Integer:
    Note:
    Transform method call from Developer to Canonical form.

    Developer: obj.method(arg1, arg2)
    Canonical: proc method from obj with arg1, arg2

    Developer: obj.method()
    Canonical: proc method from obj

    Parameters:
      object_token - The object identifier
      dot_token - The . token
      method_token - The method identifier
      left_paren_token - The ( token
      token_stream - Full token stream for lookahead
      paren_index - Index of ( in token_stream
      output_list - List to append Canonical tokens to

    Returns:
      Number of tokens consumed from token_stream (including closing ))
      Returns 0 on error
    :End Note

    Note: Extract line and column
    Let line be proc memory_get_int64 from Layout with left_paren_token, 16
    Let column be proc memory_get_int64 from Layout with left_paren_token, 24

    Note: Collect argument tokens
    Let args be proc collect_tokens_until with token_stream, paren_index plus 1, TOKEN_RIGHT_PAREN

    If args is equal to 0:
        Note: Unmatched parentheses
        Return 0
    End If

    Note: Create keyword tokens
    Let proc_str be proc string_create from StringCore with "proc"
    Let from_str be proc string_create from StringCore with "from"

    Let proc_token be proc create_keyword_token with TOKEN_PROC, proc_str, line, column
    Let from_token be proc create_keyword_token with TOKEN_FROM, from_str, line, column plus 5

    Note: Emit: proc method from object
    Let dummy1 be proc append from List with output_list, proc_token
    Let dummy2 be proc append from List with output_list, method_token
    Let dummy3 be proc append from List with output_list, from_token
    Let dummy4 be proc append from List with output_list, object_token

    Note: Check if there are arguments
    Let arg_count be proc size from List with args

    If arg_count is greater than 0:
        Note: Emit: with arguments
        Let with_str be proc string_create from StringCore with "with"
        Let with_token be proc create_keyword_token with TOKEN_WITH, with_str, line, column plus 10

        Let dummy5 be proc append from List with output_list, with_token

        Note: Append all argument tokens
        Let i be 0
        While i is less than arg_count:
            Let arg_token be proc get from List with args, i
            Let dummy6 be proc append from List with output_list, arg_token
            Set i to i plus 1
        End While
    End If

    Note: Return tokens consumed: . + method + ( + args + )
    Return arg_count plus 4
End Process

Process called "transform_ternary_operator" takes condition_tokens as Integer, question_token as Integer, true_value_tokens as Integer, colon_token as Integer, false_value_tokens as Integer, output_list as Integer returns Integer:
    Note:
    Transform ternary operator from Developer to Canonical form.

    Developer: condition ? value1 : value2
    Canonical: if condition then value1 otherwise value2

    Parameters:
      condition_tokens - List of tokens representing the condition expression
      question_token - The ? token
      true_value_tokens - List of tokens for the true case value
      colon_token - The : token
      false_value_tokens - List of tokens for the false case value
      output_list - List to append Canonical tokens to

    Returns:
      1 on success
      0 on error
    :End Note

    Note: Extract line and column from question token
    Let line be proc memory_get_int64 from Layout with question_token, 16
    Let column be proc memory_get_int64 from Layout with question_token, 24

    Note: Create keyword tokens
    Let if_str be proc string_create from StringCore with "if"
    Let then_str be proc string_create from StringCore with "then"
    Let otherwise_str be proc string_create from StringCore with "otherwise"

    Let if_token be proc create_keyword_token with TOKEN_IF, if_str, line, column
    Let then_token be proc create_keyword_token with TOKEN_THEN, then_str, line, column plus 3
    Let otherwise_token be proc create_keyword_token with TOKEN_OTHERWISE, otherwise_str, line, column plus 8

    Note: Emit: if condition
    Let dummy1 be proc append from List with output_list, if_token

    Note: Append condition tokens
    Let cond_count be proc size from List with condition_tokens
    Let i be 0
    While i is less than cond_count:
        Let cond_token be proc get from List with condition_tokens, i
        Let dummy2 be proc append from List with output_list, cond_token
        Set i to i plus 1
    End While

    Note: Emit: then true_value
    Let dummy3 be proc append from List with output_list, then_token

    Let true_count be proc size from List with true_value_tokens
    Set i to 0
    While i is less than true_count:
        Let true_token be proc get from List with true_value_tokens, i
        Let dummy4 be proc append from List with output_list, true_token
        Set i to i plus 1
    End While

    Note: Emit: otherwise false_value
    Let dummy5 be proc append from List with output_list, otherwise_token

    Let false_count be proc size from List with false_value_tokens
    Set i to 0
    While i is less than false_count:
        Let false_token be proc get from List with false_value_tokens, i
        Let dummy6 be proc append from List with output_list, false_token
        Set i to i plus 1
    End While

    Return 1
End Process

Note: ============================================================================
Note: Main Token Stream Transformation
Note: ============================================================================

Process called "transform_token_stream" takes input_stream as Integer returns Integer:
    Note:
    Main entry point for transforming a complete token stream from Developer to Canonical.

    This function processes the entire token stream and detects/transforms:
    - List literals: [...]
    - Dictionary literals: {...}
    - Array indexing: arr[i]
    - Assignment: x = value
    - Compound assignments: x += value
    - Function calls: func(args)
    - Method calls: obj.method(args)
    - Ternary operators: condition ? true_val : false_val
    - Bitwise operators: &, |, ^, ~, <<, >>

    Parameters:
      input_stream - List of input tokens (may be mixed Developer/Canonical)

    Returns:
      New List of output tokens (all Canonical form)
      Returns 0 on error

    Side Effects:
      - Creates new token list
      - Does NOT modify input_stream
    :End Note

    Note: Create output token list
    Let output_stream be proc create from List

    If output_stream is equal to 0:
        Return 0
    End If

    Note: Get input stream size
    Let stream_size be proc size from List with input_stream

    Note: Iterate through input stream
    Let i be 0

    While i is less than stream_size:
        Let current_token be proc get from List with input_stream, i
        Let token_type be proc memory_get_int64 from Layout with current_token, 0

        Note: Check for structural patterns requiring lookahead

        Note: Pattern 1: List literal or array indexing
        Note: [ can be either:
        Note:   - List literal if at start of expression: [1, 2, 3]
        Note:   - Array indexing if after identifier: arr[0]
        If token_type is equal to TOKEN_LEFT_BRACKET:
            Note: Check previous token to disambiguate
            Let is_indexing be 0

            If i is greater than 0:
                Let prev_token be proc get from List with input_stream, i minus 1
                Let prev_type be proc memory_get_int64 from Layout with prev_token, 0

                Note: If previous token is identifier or closing delimiter, this is indexing
                If prev_type is equal to TOKEN_IDENTIFIER:
                    Set is_indexing to 1
                End If
                If prev_type is equal to TOKEN_RIGHT_BRACKET:
                    Set is_indexing to 1
                End If
                If prev_type is equal to TOKEN_RIGHT_PAREN:
                    Set is_indexing to 1
                End If
            End If

            If is_indexing is equal to 1:
                Note: Array indexing: identifier[index]
                Let prev_token be proc get from List with input_stream, i minus 1
                Let consumed be proc transform_array_indexing with prev_token, current_token, input_stream, i, output_stream

                If consumed is greater than 0:
                    Note: Skip consumed tokens (we already processed them)
                    Set i to i plus consumed
                    Continue
                End If
            Otherwise:
                Note: List literal: [elements]
                Let consumed be proc transform_list_literal_complete with current_token, input_stream, i, output_stream

                If consumed is greater than 0:
                    Set i to i plus consumed
                    Continue
                End If
            End If
        End If

        Note: Pattern 2: Dictionary literal
        If token_type is equal to TOKEN_LEFT_BRACE:
            Let consumed be proc transform_dict_literal_complete with current_token, input_stream, i, output_stream

            If consumed is greater than 0:
                Set i to i plus consumed
                Continue
            End If
        End If

        Note: Pattern 3: Assignment or equality
        Note: = can be either:
        Note:   - Assignment if after identifier and not preceded by =: x = 5
        Note:   - Part of == comparison: x == 5
        If token_type is equal to TOKEN_ASSIGN:
            Note: Check if this is assignment (not ==)
            Let is_assignment be 0

            If i is greater than 0:
                Let prev_token be proc get from List with input_stream, i minus 1
                Let prev_type be proc memory_get_int64 from Layout with prev_token, 0

                If prev_type is equal to TOKEN_IDENTIFIER:
                    Set is_assignment to 1
                End If
            End If

            If is_assignment is equal to 1:
                Let prev_token be proc get from List with input_stream, i minus 1
                Let result be proc transform_assignment_statement with prev_token, current_token, input_stream, i, output_stream

                If result is equal to 1:
                    Note: Skip = token (already processed)
                    Set i to i plus 1
                    Continue
                End If
            End If
        End If

        Note: Pattern 4: Compound assignments
        If token_type is equal to TOKEN_PLUS_ASSIGN:
            If i is greater than 0:
                Let prev_token be proc get from List with input_stream, i minus 1
                Let result be proc transform_compound_assignment with prev_token, current_token, output_stream

                If result is equal to 1:
                    Set i to i plus 1
                    Continue
                End If
            End If
        End If

        If token_type is equal to TOKEN_MINUS_ASSIGN:
            If i is greater than 0:
                Let prev_token be proc get from List with input_stream, i minus 1
                Let result be proc transform_compound_assignment with prev_token, current_token, output_stream

                If result is equal to 1:
                    Set i to i plus 1
                    Continue
                End If
            End If
        End If

        If token_type is equal to TOKEN_MULTIPLY_ASSIGN:
            If i is greater than 0:
                Let prev_token be proc get from List with input_stream, i minus 1
                Let result be proc transform_compound_assignment with prev_token, current_token, output_stream

                If result is equal to 1:
                    Set i to i plus 1
                    Continue
                End If
            End If
        End If

        If token_type is equal to TOKEN_DIVIDE_ASSIGN:
            If i is greater than 0:
                Let prev_token be proc get from List with input_stream, i minus 1
                Let result be proc transform_compound_assignment with prev_token, current_token, output_stream

                If result is equal to 1:
                    Set i to i plus 1
                    Continue
                End If
            End If
        End If

        Note: Pattern 5: Method call or function call
        Note: identifier.method(args) or identifier(args)
        If token_type is equal to TOKEN_DOT:
            Note: Method call: obj.method(args)
            If i is greater than 0:
                If i plus 2 is less than stream_size:
                    Let obj_token be proc get from List with input_stream, i minus 1
                    Let method_token be proc get from List with input_stream, i plus 1
                    Let method_type be proc memory_get_int64 from Layout with method_token, 0

                    If method_type is equal to TOKEN_IDENTIFIER:
                        Note: Check if next token after method is (
                        If i plus 2 is less than stream_size:
                            Let paren_token be proc get from List with input_stream, i plus 2
                            Let paren_type be proc memory_get_int64 from Layout with paren_token, 0

                            If paren_type is equal to TOKEN_LEFT_PAREN:
                                Let consumed be proc transform_method_call with obj_token, current_token, method_token, paren_token, input_stream, i plus 2, output_stream

                                If consumed is greater than 0:
                                    Note: Skip obj + . + method + ( + args + )
                                    Set i to i plus consumed
                                    Continue
                                End If
                            End If
                        End If
                    End If
                End If
            End If
        End If

        If token_type is equal to TOKEN_LEFT_PAREN:
            Note: Function call: func(args) or grouping: (expr)
            Note: Disambiguate based on previous token
            Let is_function_call be 0

            If i is greater than 0:
                Let prev_token be proc get from List with input_stream, i minus 1
                Let prev_type be proc memory_get_int64 from Layout with prev_token, 0

                If prev_type is equal to TOKEN_IDENTIFIER:
                    Set is_function_call to 1
                End If
            End If

            If is_function_call is equal to 1:
                Let func_token be proc get from List with input_stream, i minus 1
                Let consumed be proc transform_function_call with func_token, current_token, input_stream, i, output_stream

                If consumed is greater than 0:
                    Set i to i plus consumed
                    Continue
                End If
            End If
        End If

        Note: Pattern 6: Bitwise operators (already implemented)
        If token_type is equal to TOKEN_BITWISE_AND:
            Let result be proc transform_bitwise_and with current_token, output_stream
            If result is equal to 1:
                Set i to i plus 1
                Continue
            End If
        End If

        If token_type is equal to TOKEN_BITWISE_OR:
            Let result be proc transform_bitwise_or with current_token, output_stream
            If result is equal to 1:
                Set i to i plus 1
                Continue
            End If
        End If

        If token_type is equal to TOKEN_BITWISE_XOR:
            Let result be proc transform_bitwise_xor with current_token, output_stream
            If result is equal to 1:
                Set i to i plus 1
                Continue
            End If
        End If

        If token_type is equal to TOKEN_BITWISE_NOT:
            Let result be proc transform_bitwise_not with current_token, output_stream
            If result is equal to 1:
                Set i to i plus 1
                Continue
            End If
        End If

        If token_type is equal to TOKEN_SHIFT_LEFT:
            Let result be proc transform_shift_left with current_token, output_stream
            If result is equal to 1:
                Set i to i plus 1
                Continue
            End If
        End If

        If token_type is equal to TOKEN_SHIFT_RIGHT:
            Let result be proc transform_shift_right with current_token, output_stream
            If result is equal to 1:
                Set i to i plus 1
                Continue
            End If
        End If

        Note: No transformation needed - keep token as-is
        Let dummy1 be proc append from List with output_stream, current_token
        Set i to i plus 1
    End While

    Return output_stream
End Process
