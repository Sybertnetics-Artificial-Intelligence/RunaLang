Note:
Copyright 2025 Sybertnetics Artificial Intelligence Solutions

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
:End Note

Note:
This file handles literal value recognition and tokenization in Runa.

This file performs the following tasks:
- Recognize and tokenize string literals (single and double quoted, raw, formatted)
- Process numeric literals (integers, floats, hex, octal, binary, scientific notation)
- Handle boolean literals (true, false)
- Process null literals (null, none, nil)
- Support string interpolation for formatted strings - v0.0.8.5 feature

This file is essential because of the following reasons:
- Literals are fundamental data types in Runa programs
- Proper literal handling ensures correct value representation and type safety
- Literal tokenization is required for accurate semantic analysis and code generation
- String interpolation is a core v0.0.8.5 feature requirement

This file consists of the following functions/features/operation types:
- String literal parsing with escape sequence handling
- Numeric literal recognition with multiple base support
- Boolean and null literal processing
- Formatted string (interpolation) tokenization
- Literal value validation and type inference

Dependencies:
- Imports core/string_core.runa for string manipulation
- Imports constants/literal.runa for literal constant definitions
- Imports memory/layout.runa for Token structure allocation
:End Note

Import "compiler/frontend/primitives/core/string_core.runa" as StringCore
Import "compiler/frontend/primitives/constants/literal.runa" as LiteralConstants
Import "compiler/frontend/primitives/memory/layout.runa" as Layout

Note: ============================================================================
Note: Token Type Constants for Literals
Note: ============================================================================

Note: These constants define the token types for different literal values
Note: Used in Token.token_type field to identify literal kind

Note: String literal types
Define constant TOKEN_STRING_LITERAL as 100
Define constant TOKEN_RAW_STRING_LITERAL as 101
Define constant TOKEN_FORMATTED_STRING_LITERAL as 102

Note: Numeric literal types
Define constant TOKEN_INTEGER_LITERAL as 110
Define constant TOKEN_FLOAT_LITERAL as 111
Define constant TOKEN_HEX_LITERAL as 112
Define constant TOKEN_BINARY_LITERAL as 113
Define constant TOKEN_OCTAL_LITERAL as 114

Note: Boolean literal types
Define constant TOKEN_BOOLEAN_TRUE as 120
Define constant TOKEN_BOOLEAN_FALSE as 121

Note: Null literal types
Define constant TOKEN_NULL as 130
Define constant TOKEN_NONE as 131
Define constant TOKEN_NIL as 132

Note: Character literal type
Define constant TOKEN_CHARACTER_LITERAL as 140

Note: ============================================================================
Note: Token Structure for Literal Values
Note: ============================================================================

Type called "Token":
    token_type as Integer      Note: Type identifier (TOKEN_STRING_LITERAL, TOKEN_INTEGER_LITERAL, etc.)
    value as Integer           Note: Pointer to token value string or numeric representation
    line as Integer            Note: Line number where token starts (1-indexed)
    column as Integer          Note: Column number where token starts (1-indexed)
    length as Integer          Note: Total length of token in source code
    literal_metadata as Integer Note: Pointer to additional literal-specific metadata

Note: Literal metadata structure for additional information
Type called "LiteralMetadata":
    base as Integer            Note: Numeric base (2, 8, 10, 16) for integer literals
    has_underscores as Integer Note: Boolean: 1 if literal contains underscore separators
    quote_style as Integer     Note: Quote character used (34 for ", 39 for ')
    is_raw as Integer          Note: Boolean: 1 if raw string (r"...")
    is_formatted as Integer    Note: Boolean: 1 if formatted string (f"...")
    escape_count as Integer    Note: Number of escape sequences in string

Note: ============================================================================
Note: String Literal Tokenization
Note: ============================================================================

Process called "tokenize_string_literal" takes lexer as Integer, start_pos as Integer, start_line as Integer, start_column as Integer returns Integer:
    Note: Tokenize a string literal starting at start_pos
    Note: 
    Note: Handles:
    Note: - Normal strings: "text" or 'text'
    Note: - Raw strings: r"text\n" (backslashes not escaped)
    Note: - Formatted strings: f"value is {expr}" (v0.0.8.5 feature)
    Note: - Multi-line strings with triple quotes: """text"""
    Note: 
    Note: Escape sequences supported: \n, \t, \r, \\, \", \', \u{XXXX}
    Note: 
    Note: Parameters:
    Note:   lexer - Pointer to lexer state structure
    Note:   start_pos - Starting position in source code
    Note:   start_line - Starting line number
    Note:   start_column - Starting column number
    Note: 
    Note: Returns:
    Note:   Pointer to Token structure with:
    Note:     - token_type = TOKEN_STRING_LITERAL (100), TOKEN_RAW_STRING_LITERAL (101), or TOKEN_FORMATTED_STRING_LITERAL (102)
    Note:     - value = pointer to string content (without quotes, escape sequences processed)
    Note:     - line/column = starting position
    Note:     - length = total characters including quotes
    Note:     - literal_metadata = LiteralMetadata with string properties
    Note:   Returns 0 on error (unterminated string, invalid escape sequence)
    Note: 
    Note: Algorithm:
    Note: 1. Detect string prefix (r, f, or none)
    Note: 2. Detect opening quote (" or ') or triple-quote (""" or ''')
    Note: 3. Scan characters until matching closing quote
    Note: 4. Process escape sequences if not raw string
    Note: 5. For formatted strings, identify interpolation points {expr}
    Note: 6. Handle unterminated string error (report with line/column)
    Note: 7. Allocate and populate Token and LiteralMetadata structures
    Note: 8. Return populated Token
    Note: 
    Note: TODO: Implement using:
    Note: - Layout.allocate for Token and LiteralMetadata structures
    Note: - StringCore.string_copy for value extraction
    Note: - process_escape_sequences (defined below) for \n, \t, etc.
    Note: - detect_interpolation_points for formatted strings
    Note: - Report error via lexer error handler if unterminated
    
    Return 0  Note: Placeholder - implement full tokenization logic
End Process

Process called "process_escape_sequences" takes raw_string as Integer, string_length as Integer returns Integer:
    Note: Process escape sequences in a string literal
    Note: 
    Note: Converts escape sequences to their actual byte values:
    Note:   \n  -> newline (0x0A)
    Note:   \t  -> tab (0x09)
    Note:   \r  -> carriage return (0x0D)
    Note:   \\  -> backslash (0x5C)
    Note:   \"  -> double quote (0x22)
    Note:   \'  -> single quote (0x27)
    Note:   \u{XXXX} -> Unicode character (up to 6 hex digits)
    Note: 
    Note: Parameters:
    Note:   raw_string - Pointer to string with escape sequences
    Note:   string_length - Length of raw string
    Note: 
    Note: Returns:
    Note:   Pointer to new allocated string with escape sequences resolved
    Note:   Returns 0 on invalid escape sequence
    Note: 
    Note: TODO: Implement escape sequence conversion logic
    
    Return 0  Note: Placeholder
End Process

Process called "detect_interpolation_points" takes format_string as Integer, string_length as Integer returns Integer:
    Note: Detect interpolation points in formatted string (f"text {expr}")
    Note: 
    Note: Identifies all {expr} interpolation points for later parsing
    Note: Handles nested braces: f"value {dict["key"]}" 
    Note: 
    Note: Parameters:
    Note:   format_string - Pointer to formatted string content
    Note:   string_length - Length of format string
    Note: 
    Note: Returns:
    Note:   Pointer to array of InterpolationPoint structures
    Note:   InterpolationPoint contains:
    Note:     - start_offset: Position where { starts
    Note:     - end_offset: Position where } ends
    Note:     - expression: Extracted expression string
    Note:   Array terminated with null entry (start_offset = -1)
    Note: 
    Note: TODO: Implement interpolation point detection with brace nesting tracking
    
    Return 0  Note: Placeholder
End Process

Note: ============================================================================
Note: Numeric Literal Tokenization
Note: ============================================================================

Process called "tokenize_numeric_literal" takes lexer as Integer, start_pos as Integer, start_line as Integer, start_column as Integer returns Integer:
    Note: Tokenize a numeric literal (integer or float)
    Note: 
    Note: Supports:
    Note: - Decimal integers: 42, 1_000_000 (underscores allowed)
    Note: - Hexadecimal: 0xFF, 0x1A_2B
    Note: - Binary: 0b1010, 0b1111_0000
    Note: - Octal: 0o755, 0o12_34
    Note: - Floating point: 3.14, 2.5_99
    Note: - Scientific notation: 1.5e10, 2.3e-5
    Note: 
    Note: Parameters:
    Note:   lexer - Pointer to lexer state structure
    Note:   start_pos - Starting position in source code
    Note:   start_line - Starting line number
    Note:   start_column - Starting column number
    Note: 
    Note: Returns:
    Note:   Pointer to Token structure with:
    Note:     - token_type = TOKEN_INTEGER_LITERAL (110), TOKEN_FLOAT_LITERAL (111),
    Note:                    TOKEN_HEX_LITERAL (112), TOKEN_BINARY_LITERAL (113),
    Note:                    or TOKEN_OCTAL_LITERAL (114)
    Note:     - value = pointer to string representation of number
    Note:     - line/column = starting position
    Note:     - length = total characters including prefix (0x, 0b, 0o) and underscores
    Note:     - literal_metadata = LiteralMetadata with numeric base and underscore flag
    Note:   Returns 0 on error (invalid numeric format, malformed scientific notation)
    Note: 
    Note: Algorithm:
    Note: 1. Check for base prefix (0x, 0b, 0o) or assume decimal
    Note: 2. Scan digits appropriate for base (hex: 0-9a-fA-F, binary: 0-1, etc.)
    Note: 3. Allow underscores between digits (not at start/end)
    Note: 4. For decimal, check for decimal point to determine float vs integer
    Note: 5. For floats, check for scientific notation (e or E followed by +/- and digits)
    Note: 6. Validate numeric format (no consecutive underscores, valid digits for base)
    Note: 7. Allocate and populate Token and LiteralMetadata
    Note: 8. Return populated Token
    Note: 
    Note: TODO: Implement using:
    Note: - Character classification for digits in each base
    Note: - Layout.allocate for Token and LiteralMetadata
    Note: - StringCore.string_copy for value storage
    Note: - Validation logic for each numeric format
    
    Return 0  Note: Placeholder
End Process

Process called "validate_numeric_format" takes number_string as Integer, base as Integer, is_float as Integer returns Integer:
    Note: Validate that numeric literal follows proper format rules
    Note: 
    Note: Checks:
    Note: - Digits are valid for the specified base
    Note: - Underscores are not consecutive or at start/end
    Note: - Float has digits before and after decimal point
    Note: - Scientific notation is properly formatted
    Note: 
    Note: Parameters:
    Note:   number_string - Pointer to numeric string to validate
    Note:   base - Numeric base (2, 8, 10, or 16)
    Note:   is_float - Boolean: 1 if floating point, 0 if integer
    Note: 
    Note: Returns:
    Note:   1 if valid format, 0 if invalid
    Note: 
    Note: TODO: Implement format validation for each base and float rules
    
    Return 1  Note: Placeholder - assume valid
End Process

Note: ============================================================================
Note: Boolean and Null Literal Tokenization
Note: ============================================================================

Process called "tokenize_boolean_literal" takes lexer as Integer, start_pos as Integer, start_line as Integer, start_column as Integer, is_true as Integer returns Integer:
    Note: Tokenize a boolean literal (true or false)
    Note: 
    Note: Parameters:
    Note:   lexer - Pointer to lexer state structure
    Note:   start_pos - Starting position in source code
    Note:   start_line - Starting line number
    Note:   start_column - Starting column number
    Note:   is_true - Boolean: 1 for "true", 0 for "false"
    Note: 
    Note: Returns:
    Note:   Pointer to Token structure with:
    Note:     - token_type = TOKEN_BOOLEAN_TRUE (120) or TOKEN_BOOLEAN_FALSE (121)
    Note:     - value = pointer to "true" or "false" string
    Note:     - line/column = starting position
    Note:     - length = 4 ("true") or 5 ("false")
    Note:     - literal_metadata = 0 (no metadata needed for booleans)
    Note: 
    Note: TODO: Implement token creation for boolean literals
    
    Return 0  Note: Placeholder
End Process

Process called "tokenize_null_literal" takes lexer as Integer, start_pos as Integer, start_line as Integer, start_column as Integer, null_variant as Integer returns Integer:
    Note: Tokenize a null literal (null, none, or nil)
    Note: 
    Note: Runa supports three null literal spellings for compatibility:
    Note:   - "null" (most common, C-style)
    Note:   - "none" (Python-style)
    Note:   - "nil" (Ruby/Lua-style)
    Note: All three are semantically equivalent
    Note: 
    Note: Parameters:
    Note:   lexer - Pointer to lexer state structure
    Note:   start_pos - Starting position in source code
    Note:   start_line - Starting line number
    Note:   start_column - Starting column number
    Note:   null_variant - Which variant: 0="null", 1="none", 2="nil"
    Note: 
    Note: Returns:
    Note:   Pointer to Token structure with:
    Note:     - token_type = TOKEN_NULL (130), TOKEN_NONE (131), or TOKEN_NIL (132)
    Note:     - value = pointer to "null", "none", or "nil" string
    Note:     - line/column = starting position
    Note:     - length = 4 ("null"/"none") or 3 ("nil")
    Note:     - literal_metadata = 0 (no metadata needed for null)
    Note: 
    Note: TODO: Implement token creation for null literals
    
    Return 0  Note: Placeholder
End Process

Note: ============================================================================
Note: Character Literal Tokenization
Note: ============================================================================

Process called "tokenize_character_literal" takes lexer as Integer, start_pos as Integer, start_line as Integer, start_column as Integer returns Integer:
    Note: Tokenize a character literal ('c' or '\n')
    Note: 
    Note: Character literals are single characters enclosed in single quotes
    Note: Support escape sequences: '\n', '\t', '\\', '\'', '\u{XX}'
    Note: 
    Note: Parameters:
    Note:   lexer - Pointer to lexer state structure
    Note:   start_pos - Starting position in source code
    Note:   start_line - Starting line number
    Note:   start_column - Starting column number
    Note: 
    Note: Returns:
    Note:   Pointer to Token structure with:
    Note:     - token_type = TOKEN_CHARACTER_LITERAL (140)
    Note:     - value = pointer to single character or escape sequence
    Note:     - line/column = starting position
    Note:     - length = total characters including quotes (e.g., 'a' = 3, '\n' = 4)
    Note:     - literal_metadata = LiteralMetadata with escape info
    Note:   Returns 0 on error (empty character literal, unclosed quote, invalid escape)
    Note: 
    Note: TODO: Implement character literal tokenization with escape sequence support
    
    Return 0  Note: Placeholder
End Process

Note: ============================================================================
Note: Literal Validation and Utility Functions
Note: ============================================================================

Process called "is_digit" takes character as Integer, base as Integer returns Integer:
    Note: Check if character is a valid digit for the given base
    Note: 
    Note: Parameters:
    Note:   character - ASCII character code to check
    Note:   base - Numeric base (2, 8, 10, or 16)
    Note: 
    Note: Returns:
    Note:   1 if character is valid digit for base, 0 otherwise
    Note: 
    Note: Examples:
    Note:   is_digit('5', 10) = 1 (decimal)
    Note:   is_digit('A', 16) = 1 (hex)
    Note:   is_digit('2', 2) = 0 (binary only has 0,1)
    Note: 
    Note: TODO: Implement digit validation for each base
    
    Return 0  Note: Placeholder
End Process

Process called "char_to_digit_value" takes character as Integer, base as Integer returns Integer:
    Note: Convert character digit to its numeric value in given base
    Note: 
    Note: Parameters:
    Note:   character - ASCII character code ('0'-'9', 'a'-'f', 'A'-'F')
    Note:   base - Numeric base (2, 8, 10, or 16)
    Note: 
    Note: Returns:
    Note:   Numeric value (0-15 for hex, 0-9 for decimal, etc.)
    Note:   Returns -1 if character is not valid digit for base
    Note: 
    Note: Examples:
    Note:   char_to_digit_value('5', 10) = 5
    Note:   char_to_digit_value('A', 16) = 10
    Note:   char_to_digit_value('F', 16) = 15
    Note: 
    Note: TODO: Implement character to digit conversion
    
    Return 0  Note: Placeholder
End Process

Process called "create_literal_token" takes token_type as Integer, value as Integer, line as Integer, column as Integer, length as Integer, metadata as Integer returns Integer:
    Note: Create and populate a Token structure for a literal value
    Note: 
    Note: Parameters:
    Note:   token_type - Token type constant (TOKEN_STRING_LITERAL, TOKEN_INTEGER_LITERAL, etc.)
    Note:   value - Pointer to token value string
    Note:   line - Line number where token starts
    Note:   column - Column number where token starts
    Note:   length - Total length of token in source
    Note:   metadata - Pointer to LiteralMetadata structure (can be 0 if not needed)
    Note: 
    Note: Returns:
    Note:   Pointer to newly allocated Token structure
    Note:   Returns 0 on allocation failure
    Note: 
    Note: TODO: Implement using Layout.allocate for Token structure
    
    Return 0  Note: Placeholder
End Process

Process called "create_literal_metadata" takes base as Integer, has_underscores as Integer, quote_style as Integer, is_raw as Integer, is_formatted as Integer, escape_count as Integer returns Integer:
    Note: Create and populate a LiteralMetadata structure
    Note: 
    Note: Parameters:
    Note:   base - Numeric base (2, 8, 10, 16) or 0 for non-numeric
    Note:   has_underscores - Boolean: 1 if literal contains underscores
    Note:   quote_style - Quote character used (34=", 39=') or 0 for non-strings
    Note:   is_raw - Boolean: 1 if raw string
    Note:   is_formatted - Boolean: 1 if formatted string
    Note:   escape_count - Number of escape sequences (0 for raw strings)
    Note: 
    Note: Returns:
    Note:   Pointer to newly allocated LiteralMetadata structure
    Note:   Returns 0 on allocation failure
    Note: 
    Note: TODO: Implement using Layout.allocate for LiteralMetadata structure
    
    Return 0  Note: Placeholder
End Process
