Note: 
Copyright 2025 Sybertnetics Artificial Intelligence Solutions

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
:End Note

Note:
This file provides factory functions for creating and configuring lexers.

This file performs the following tasks:
- Create lexers from various input sources (file, string, stream)
- Configure lexer modes (Canon, Developer, Viewer)
- Set lexer options and flags
- Provide pre-configured lexers for testing
- Manage lexer lifecycle and resource cleanup

This file is essential because of the following reasons:
- Factory pattern simplifies lexer creation with proper initialization
- Configuration helpers ensure consistent lexer behavior
- Testing utilities enable isolated lexer verification
- Resource management prevents memory leaks
- Abstraction layer isolates lexer implementation details

This file consists of the following functions/features/operation types:
- Lexer factory methods for different input sources
- Configuration builders for lexer modes and options
- Test lexer creation with mock inputs
- Lexer cleanup and resource management
- Convenience functions for common lexer operations

Dependencies:
- Imports lexer.runa for main lexer implementation
- Imports token_stream.runa for token stream creation
- Imports core/memory_core.runa for memory management
- Imports io/file.runa for file reading (when implemented)
:End Note

Import "compiler/frontend/lexical/lexer.runa" as Lexer
Import "compiler/frontend/lexical/token_stream.runa" as TokenStream
Import "compiler/frontend/primitives/core/memory_core.runa" as MemoryCore
Import "compiler/frontend/primitives/memory/layout.runa" as Layout

Note: ============================================================================
Note: Lexer Configuration Structure
Note: ============================================================================

Type called "LexerConfig":
    mode as Integer            Note: Lexer mode (CANON, DEVELOPER, VIEWER)
    strict_mode as Integer     Note: Boolean: 1 for strict error handling
    allow_tabs as Integer      Note: Boolean: 1 to allow tab characters for indentation
    indent_size as Integer     Note: Spaces per indentation level (typically 4)
    preserve_comments as Integer Note: Boolean: 1 to keep comment tokens
    preserve_whitespace as Integer Note: Boolean: 1 to keep whitespace tokens
    report_warnings as Integer Note: Boolean: 1 to report non-fatal warnings
    max_errors as Integer      Note: Maximum errors before stopping (0 = unlimited)

Note: ============================================================================
Note: Factory Functions - Create from Source
Note: ============================================================================

Process called "create_lexer_for_file" takes file_path as Integer, mode as Integer returns Integer:
    Note: Create lexer for a source file
    Note: 
    Note: Reads file contents and creates lexer with source code
    Note: 
    Note: Parameters:
    Note:   file_path - Pointer to file path string
    Note:   mode - Lexer mode (LEXER_MODE_CANON, LEXER_MODE_DEVELOPER, etc.)
    Note: 
    Note: Returns:
    Note:   Pointer to initialized LexerState
    Note:   Returns 0 on error (file not found, read error, allocation failure)
    Note: 
    Note: Algorithm:
    Note: 1. Open file at file_path
    Note: 2. Check file exists and is readable
    Note: 3. Read entire file contents into buffer
    Note: 4. Close file
    Note: 5. Create lexer with buffer as source code
    Note: 6. Return lexer
    Note: 
    Note: Error cases:
    Note:   - File does not exist
    Note:   - File is not readable (permissions)
    Note:   - File is too large (exceeds limits)
    Note:   - Memory allocation failure
    Note: 
    Note: TODO: Implement using:
    Note: - File I/O operations (open, read, close)
    Note: - Lexer.lexer_create with file contents
    Note: - Error handling for all cases
    
    Return 0  Note: Placeholder
End Process

Process called "create_lexer_for_string" takes source_code as Integer, source_length as Integer, mode as Integer returns Integer:
    Note: Create lexer for a source code string
    Note: 
    Note: Most direct way to create lexer - pass source directly
    Note: 
    Note: Parameters:
    Note:   source_code - Pointer to source code string
    Note:   source_length - Length of source code
    Note:   mode - Lexer mode
    Note: 
    Note: Returns:
    Note:   Pointer to initialized LexerState
    Note:   Returns 0 on allocation failure
    Note: 
    Note: This is the simplest factory method - directly wraps lexer_create
    Note: 
    Note: TODO: Call Lexer.lexer_create with parameters
    
    Return 0  Note: Placeholder
End Process

Process called "create_lexer_for_stream" takes input_stream as Integer, mode as Integer returns Integer:
    Note: Create lexer for an input stream
    Note: 
    Note: Reads from stream (stdin, pipe, network socket, etc.)
    Note: 
    Note: Parameters:
    Note:   input_stream - Pointer to input stream structure
    Note:   mode - Lexer mode
    Note: 
    Note: Returns:
    Note:   Pointer to initialized LexerState
    Note:   Returns 0 on error
    Note: 
    Note: Algorithm:
    Note: 1. Read all available data from stream
    Note: 2. Buffer data in memory
    Note: 3. Create lexer with buffered data
    Note: 4. Return lexer
    Note: 
    Note: Note: Entire stream is buffered before lexing begins
    Note: For very large streams, consider streaming lexer implementation
    Note: 
    Note: TODO: Implement stream reading and buffering
    
    Return 0  Note: Placeholder
End Process

Note: ============================================================================
Note: Factory Functions - Create with Configuration
Note: ============================================================================

Process called "create_lexer_with_config" takes source_code as Integer, source_length as Integer, config as Integer returns Integer:
    Note: Create lexer with custom configuration
    Note: 
    Note: Provides full control over lexer behavior via configuration object
    Note: 
    Note: Parameters:
    Note:   source_code - Pointer to source code string
    Note:   source_length - Length of source code
    Note:   config - Pointer to LexerConfig structure with settings
    Note: 
    Note: Returns:
    Note:   Pointer to initialized LexerState with applied configuration
    Note:   Returns 0 on error
    Note: 
    Note: Algorithm:
    Note: 1. Create basic lexer using lexer_create
    Note: 2. Apply configuration settings from config:
    Note:    - Set strict_mode flag
    Note:    - Set allow_tabs flag
    Note:    - Set indent_size
    Note:    - Set preserve_comments flag
    Note:    - Set preserve_whitespace flag
    Note:    - Set report_warnings flag
    Note:    - Set max_errors limit
    Note: 3. Return configured lexer
    Note: 
    Note: TODO: Implement configuration application
    
    Return 0  Note: Placeholder
End Process

Process called "create_default_config" returns Integer:
    Note: Create default lexer configuration
    Note: 
    Note: Returns:
    Note:   Pointer to LexerConfig with default settings:
    Note:     - mode = LEXER_MODE_CANON
    Note:     - strict_mode = 1
    Note:     - allow_tabs = 0
    Note:     - indent_size = 4
    Note:     - preserve_comments = 0
    Note:     - preserve_whitespace = 0
    Note:     - report_warnings = 1
    Note:     - max_errors = 0 (unlimited)
    Note: 
    Note: TODO: Implement using Layout.allocate and set defaults
    
    Return 0  Note: Placeholder
End Process

Process called "create_strict_config" returns Integer:
    Note: Create strict lexer configuration
    Note: 
    Note: Strict mode: All warnings are errors, no tolerance for ambiguity
    Note: 
    Note: Returns:
    Note:   Pointer to LexerConfig with strict settings:
    Note:     - strict_mode = 1
    Note:     - allow_tabs = 0 (only spaces)
    Note:     - report_warnings = 1 (all warnings reported)
    Note:     - max_errors = 1 (stop on first error)
    Note: 
    Note: Used for production builds and CI/CD pipelines
    Note: 
    Note: TODO: Implement strict configuration
    
    Return 0  Note: Placeholder
End Process

Process called "create_permissive_config" returns Integer:
    Note: Create permissive lexer configuration
    Note: 
    Note: Permissive mode: Allow tabs, continue on errors, suppress warnings
    Note: 
    Note: Returns:
    Note:   Pointer to LexerConfig with permissive settings:
    Note:     - strict_mode = 0
    Note:     - allow_tabs = 1 (allow mixed spaces/tabs)
    Note:     - report_warnings = 0 (suppress warnings)
    Note:     - max_errors = 0 (continue on all errors)
    Note: 
    Note: Used for development and interactive environments
    Note: 
    Note: TODO: Implement permissive configuration
    
    Return 0  Note: Placeholder
End Process

Note: ============================================================================
Note: Factory Functions - Testing and Mocking
Note: ============================================================================

Process called "create_test_lexer" takes test_source as Integer, mode as Integer returns Integer:
    Note: Create lexer configured for testing
    Note: 
    Note: Test lexers have:
    Note:   - Strict error checking enabled
    Note:   - Comment and whitespace preservation
    Note:   - Detailed error messages
    Note:   - No error count limits
    Note: 
    Note: Parameters:
    Note:   test_source - Pointer to test source code string
    Note:   mode - Lexer mode for test
    Note: 
    Note: Returns:
    Note:   Pointer to initialized test lexer
    Note: 
    Note: Used in unit tests for isolated lexer verification
    Note: 
    Note: TODO: Create lexer with test-specific configuration
    
    Return 0  Note: Placeholder
End Process

Process called "create_mock_lexer_with_tokens" takes mock_tokens as Integer, token_count as Integer returns Integer:
    Note: Create mock lexer with predefined tokens
    Note: 
    Note: For testing parser without running actual lexer
    Note: 
    Note: Parameters:
    Note:   mock_tokens - Array of Token pointers to use
    Note:   token_count - Number of tokens in array
    Note: 
    Note: Returns:
    Note:   Pointer to mock LexerState that returns pre-generated tokens
    Note: 
    Note: The lexer's lexer_next_token will simply iterate through mock_tokens
    Note: 
    Note: TODO: Create minimal LexerState with token array
    
    Return 0  Note: Placeholder
End Process

Note: ============================================================================
Note: Configuration Helpers
Note: ============================================================================

Process called "configure_lexer_mode" takes lexer as Integer, mode as Integer returns Integer:
    Note: Change lexer mode after creation
    Note: 
    Note: Parameters:
    Note:   lexer - Pointer to LexerState
    Note:   mode - New mode (LEXER_MODE_CANON, LEXER_MODE_DEVELOPER, LEXER_MODE_VIEWER)
    Note: 
    Note: Returns:
    Note:   1 on success, 0 if mode is invalid
    Note: 
    Note: Mode determines syntax style:
    Note:   - CANON: Natural language (plus, minus, is equal to)
    Note:   - DEVELOPER: Symbol syntax (+, -, ==)
    Note:   - VIEWER: Display-optimized (underscore displayed as space)
    Note: 
    Note: TODO: Update lexer.mode field with validation
    
    Return 0  Note: Placeholder
End Process

Process called "configure_error_handling" takes lexer as Integer, strict as Integer, max_errors as Integer returns Integer:
    Note: Configure error handling behavior
    Note: 
    Note: Parameters:
    Note:   lexer - Pointer to LexerState
    Note:   strict - Boolean: 1 for strict mode, 0 for permissive
    Note:   max_errors - Maximum errors before stopping (0 = unlimited)
    Note: 
    Note: Returns:
    Note:   1 on success
    Note: 
    Note: Strict mode:
    Note:   - All warnings become errors
    Note:   - No ambiguous constructs allowed
    Note:   - Strict indentation checking
    Note: 
    Note: TODO: Update lexer.strict_mode and lexer.max_errors (in config)
    
    Return 1  Note: Placeholder
End Process

Process called "configure_indentation" takes lexer as Integer, indent_size as Integer, allow_tabs as Integer returns Integer:
    Note: Configure indentation handling
    Note: 
    Note: Parameters:
    Note:   lexer - Pointer to LexerState
    Note:   indent_size - Number of spaces per indentation level
    Note:   allow_tabs - Boolean: 1 to allow tabs, 0 to disallow
    Note: 
    Note: Returns:
    Note:   1 on success
    Note: 
    Note: Standard Runa indentation is 4 spaces, tabs disallowed
    Note: Custom projects may use 2 spaces or allow tabs
    Note: 
    Note: TODO: Update lexer.indent_size and lexer.allow_tabs (in config)
    
    Return 1  Note: Placeholder
End Process

Process called "configure_token_preservation" takes lexer as Integer, preserve_comments as Integer, preserve_whitespace as Integer returns Integer:
    Note: Configure which tokens to preserve vs discard
    Note: 
    Note: Parameters:
    Note:   lexer - Pointer to LexerState
    Note:   preserve_comments - Boolean: 1 to keep comment tokens
    Note:   preserve_whitespace - Boolean: 1 to keep whitespace tokens
    Note: 
    Note: Returns:
    Note:   1 on success
    Note: 
    Note: Preservation use cases:
    Note:   - Comments preserved: Documentation generation, source formatting
    Note:   - Whitespace preserved: Source-to-source transformation, formatters
    Note:   - Both discarded: Normal compilation (fastest)
    Note: 
    Note: TODO: Update preservation flags (in config)
    
    Return 1  Note: Placeholder
End Process

Note: ============================================================================
Note: Lexer Lifecycle Management
Note: ============================================================================

Process called "lexer_factory_cleanup" takes lexer as Integer returns Integer:
    Note: Clean up lexer and all associated resources
    Note: 
    Note: Comprehensive cleanup of all lexer resources:
    Note:   - Tokens and token stream
    Note:   - Error structures
    Note:   - Indentation stack
    Note:   - Keyword table
    Note:   - Delimiter context
    Note:   - Lexer state itself
    Note: 
    Note: Parameters:
    Note:   lexer - Pointer to LexerState to clean up
    Note: 
    Note: Returns:
    Note:   1 on success
    Note: 
    Note: This is the primary cleanup function clients should call
    Note: Wraps lexer_destroy with additional safety checks
    Note: 
    Note: TODO: Call Lexer.lexer_destroy with null checks
    
    Return 1  Note: Placeholder
End Process

Process called "lexer_reset" takes lexer as Integer returns Integer:
    Note: Reset lexer to initial state (for re-lexing)
    Note: 
    Note: Resets lexer position and state without deallocating resources
    Note: Allows re-tokenizing same source code
    Note: 
    Note: Parameters:
    Note:   lexer - Pointer to LexerState to reset
    Note: 
    Note: Returns:
    Note:   1 on success
    Note: 
    Note: Reset actions:
    Note:   - Position = 0, line = 1, column = 1
    Note:   - Clear tokens array
    Note:   - Clear errors array
    Note:   - Reset indentation stack to initial state
    Note:   - Clear context flags
    Note: 
    Note: TODO: Implement state reset without deallocation
    
    Return 1  Note: Placeholder
End Process

Note: ============================================================================
Note: Convenience Functions
Note: ============================================================================

Process called "quick_tokenize_file" takes file_path as Integer returns Integer:
    Note: Convenience function: tokenize file and return token stream
    Note: 
    Note: One-step operation: file -> tokens
    Note: Uses default Canon mode configuration
    Note: 
    Note: Parameters:
    Note:   file_path - Pointer to file path string
    Note: 
    Note: Returns:
    Note:   Pointer to TokenStream with all tokens
    Note:   Returns 0 on error
    Note: 
    Note: Algorithm:
    Note: 1. Create lexer for file (Canon mode)
    Note: 2. Tokenize entire file
    Note: 3. Get token stream
    Note: 4. Clean up lexer (keep tokens)
    Note: 5. Return token stream
    Note: 
    Note: TODO: Implement using create_lexer_for_file and lexer_tokenize_all
    
    Return 0  Note: Placeholder
End Process

Process called "quick_tokenize_string" takes source_code as Integer, source_length as Integer returns Integer:
    Note: Convenience function: tokenize string and return token stream
    Note: 
    Note: One-step operation: string -> tokens
    Note: Uses default Canon mode configuration
    Note: 
    Note: Parameters:
    Note:   source_code - Pointer to source code string
    Note:   source_length - Length of source code
    Note: 
    Note: Returns:
    Note:   Pointer to TokenStream with all tokens
    Note:   Returns 0 on error
    Note: 
    Note: TODO: Implement using create_lexer_for_string and lexer_tokenize_all
    
    Return 0  Note: Placeholder
End Process

Note: ============================================================================
Note: Utility Functions
Note: ============================================================================

Process called "validate_lexer_config" takes config as Integer returns Integer:
    Note: Validate lexer configuration settings
    Note: 
    Note: Checks:
    Note:   - Mode is valid value
    Note:   - indent_size is positive
    Note:   - max_errors is non-negative
    Note:   - Boolean flags are 0 or 1
    Note: 
    Note: Parameters:
    Note:   config - Pointer to LexerConfig to validate
    Note: 
    Note: Returns:
    Note:   1 if configuration is valid, 0 if invalid
    Note: 
    Note: TODO: Implement validation checks for all config fields
    
    Return 1  Note: Placeholder
End Process

Process called "clone_lexer_config" takes config as Integer returns Integer:
    Note: Create a copy of lexer configuration
    Note: 
    Note: Parameters:
    Note:   config - Pointer to LexerConfig to clone
    Note: 
    Note: Returns:
    Note:   Pointer to new LexerConfig with same settings
    Note:   Returns 0 on allocation failure
    Note: 
    Note: Used when creating multiple lexers with same configuration
    Note: 
    Note: TODO: Allocate new config and copy all fields
    
    Return 0  Note: Placeholder
End Process
