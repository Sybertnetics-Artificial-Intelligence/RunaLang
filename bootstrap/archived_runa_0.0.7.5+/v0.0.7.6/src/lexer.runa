# Copyright 2025 Sybertnetics Artificial Intelligence Solutions
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Lexer for Runa v0.0.7.5
# Line-by-line transliteration from v0.0.7.3 lexer.c

# Global variable workaround: Stage 2 memory functions have ABI issues
Let LEXER_POSITION be 0
Let LEXER_CURRENT_CHAR be 0

# Token type constants - matching lexer.h enum
Let TOKEN_EOF be 0
Let TOKEN_PROCESS be 1
Let TOKEN_CALLED be 2
Let TOKEN_RETURNS be 3
Let TOKEN_INTEGER_TYPE be 4
Let TOKEN_STRING_TYPE be 5
Let TOKEN_CHARACTER_TYPE be 6
Let TOKEN_RETURN be 7
Let TOKEN_END be 8
Let TOKEN_COLON be 9
Let TOKEN_STRING_LITERAL be 10
Let TOKEN_INTEGER be 11
Let TOKEN_LET be 12
Let TOKEN_BE be 13
Let TOKEN_SET be 14
Let TOKEN_TO be 15
Let TOKEN_PLUS be 16
Let TOKEN_MINUS be 17
Let TOKEN_IF be 18
Let TOKEN_OTHERWISE be 19
Let TOKEN_WHILE be 20
Let TOKEN_IS be 21
Let TOKEN_EQUAL be 22
Let TOKEN_NOT_EQUAL be 23
Let TOKEN_LESS be 24
Let TOKEN_GREATER be 25
Let TOKEN_GREATER_EQUAL be 26
Let TOKEN_LESS_EQUAL be 27
Let TOKEN_THAN be 28
Let TOKEN_NOT be 29
Let TOKEN_AND be 30
Let TOKEN_OR be 31
Let TOKEN_THAT be 32
Let TOKEN_TAKES be 33
Let TOKEN_AS be 34
Let TOKEN_MULTIPLIED be 35
Let TOKEN_DIVIDED be 36
Let TOKEN_MODULO be 37
Let TOKEN_BY be 38
Let TOKEN_BIT_AND be 39
Let TOKEN_BIT_OR be 40
Let TOKEN_BIT_XOR be 41
Let TOKEN_BIT_SHIFT_LEFT be 42
Let TOKEN_BIT_SHIFT_RIGHT be 43
Let TOKEN_BREAK be 44
Let TOKEN_CONTINUE be 45
Let TOKEN_OTHERWISE_IF be 46
Let TOKEN_PRINT be 47
Let TOKEN_LPAREN be 48
Let TOKEN_RPAREN be 49
Let TOKEN_TYPE be 50
Let TOKEN_DOT be 51
Let TOKEN_COMMA be 52
Let TOKEN_IDENTIFIER be 53
Let TOKEN_READ_FILE be 54
Let TOKEN_WRITE_FILE be 55
Let TOKEN_IMPORT be 56
Let TOKEN_STRING_LENGTH be 57
Let TOKEN_STRING_CHAR_AT be 58
Let TOKEN_STRING_SUBSTRING be 59
Let TOKEN_STRING_EQUALS be 60
Let TOKEN_ASCII_VALUE_OF be 61
Let TOKEN_IS_DIGIT be 62
Let TOKEN_IS_ALPHA be 63
Let TOKEN_IS_WHITESPACE be 64
Let TOKEN_LIST_CREATE be 65
Let TOKEN_LIST_APPEND be 66
Let TOKEN_LIST_GET be 67
Let TOKEN_LIST_GET_INTEGER be 68
Let TOKEN_LIST_LENGTH be 69
Let TOKEN_LIST_DESTROY be 70
Let TOKEN_LIST_SET be 71
Let TOKEN_LIST_INSERT be 72
Let TOKEN_LIST_REMOVE be 73
Let TOKEN_LIST_CLEAR be 74
Let TOKEN_LIST_FIND be 75
Let TOKEN_LIST_SORT be 76
Let TOKEN_LIST_REVERSE be 77
Let TOKEN_LIST_COPY be 78
Let TOKEN_LIST_MERGE be 79
Let TOKEN_STRING_CONCAT be 80
Let TOKEN_STRING_COMPARE be 81
Let TOKEN_STRING_TO_INTEGER be 82
Let TOKEN_INTEGER_TO_STRING be 83
Let TOKEN_STRING_FIND be 84
Let TOKEN_STRING_REPLACE be 85
Let TOKEN_STRING_TRIM be 86
Let TOKEN_STRING_SPLIT be 87
Let TOKEN_FILE_OPEN be 88
Let TOKEN_FILE_CLOSE be 89
Let TOKEN_FILE_READ_LINE be 90
Let TOKEN_FILE_WRITE_LINE be 91
Let TOKEN_FILE_EXISTS be 92
Let TOKEN_FILE_DELETE be 93
Let TOKEN_FILE_SIZE be 94
Let TOKEN_FILE_SEEK be 95
Let TOKEN_FILE_TELL be 96
Let TOKEN_FILE_EOF be 97
Let TOKEN_SIN be 98
Let TOKEN_COS be 99
Let TOKEN_TAN be 100
Let TOKEN_SQRT be 101
Let TOKEN_POW be 102
Let TOKEN_ABS be 103
Let TOKEN_FLOOR be 104
Let TOKEN_CEIL be 105
Let TOKEN_MIN be 106
Let TOKEN_MAX be 107
Let TOKEN_RANDOM be 108
Let TOKEN_LOG be 109
Let TOKEN_EXP be 110
Let TOKEN_PIPE be 111
Let TOKEN_MATCH be 112
Let TOKEN_WHEN be 113
Let TOKEN_WITH be 114
Let TOKEN_GET_COMMAND_LINE_ARGS be 115
Let TOKEN_EXIT_WITH_CODE be 116
Let TOKEN_PANIC be 117
Let TOKEN_ASSERT be 118
Let TOKEN_ALLOCATE be 119
Let TOKEN_DEALLOCATE be 120
Let TOKEN_INLINE be 121
Let TOKEN_ASSEMBLY be 122
Let TOKEN_NOTE be 123
Let TOKEN_POINTER be 124
Let TOKEN_OF be 125
Let TOKEN_ARRAY be 126
Let TOKEN_LBRACKET be 127
Let TOKEN_RBRACKET be 128
Let TOKEN_ERROR be 129
Let TOKEN_MEMORY_GET_BYTE be 130
Let TOKEN_MEMORY_SET_BYTE be 131
Let TOKEN_COUNT be 132
Let TOKEN_NEGATIVE be 133
Let TOKEN_TRUE be 134
Let TOKEN_FALSE be 135
Let TOKEN_GETS be 136
Let TOKEN_INCREASED be 137
Let TOKEN_DECREASED be 138
Let TOKEN_INCREASE be 139
Let TOKEN_DECREASE be 140
Let TOKEN_MULTIPLY be 141
Let TOKEN_DIVIDE be 142
Let TOKEN_FOR be 143
Let TOKEN_FROM be 144
Let TOKEN_EACH be 145
Let TOKEN_LBRACE be 146
Let TOKEN_RBRACE be 147
Let TOKEN_AT be 148
Let TOKEN_INDEX be 149
Let TOKEN_KEY be 150
Let TOKEN_LENGTH be 151
Let TOKEN_IN be 152
Let TOKEN_WHERE be 153
Let TOKEN_AN be 154
Let TOKEN_A be 155
Let TOKEN_CONTAINING be 156
Let TOKEN_DOLLAR be 157

# Additional string helper functions specific to lexer
Process called "string_copy" takes dest as Integer, src as Integer returns Integer:
    # Copy string from src to dest
    Let i be 0
    Let continue_loop be 1
    While continue_loop is equal to 1:
        Let char be memory_get_byte(src, i)
        memory_set_byte(dest, i, char)
        If char is equal to 0:
            Set continue_loop to 0
        Otherwise:
            Set i to i plus 1
        End If
    End While
    Return 0
End Process

Process called "string_copy_n" takes dest as Integer, src as Integer, start as Integer, length as Integer returns Integer:
    # Copy n characters from src starting at position start to dest
    Let i be 0
    While i is less than length:
        Let src_pos be start plus i
        Let char be memory_get_byte(src, src_pos)
        memory_set_byte(dest, i, char)
        Set i to i plus 1
    End While
    Return 0
End Process

Process called "string_set_char" takes str as Integer, index as Integer, char as Integer returns Integer:
    memory_set_byte(str, index, char)
    Return 0
End Process

# print_string and print_integer are provided by codegen as assembly implementations

# Lexer advance - moves to next character
Process called "lexer_advance" takes lexer as Integer returns Integer:
    Let current_char be memory_get_byte(lexer, 20)
    Let newline be 10  # ASCII for '\n'
    If current_char is equal to newline:
        Let line be memory_get_int32(lexer, 12)
        Let new_line be line plus 1
        memory_set_int32(lexer, 12,new_line)
        memory_set_int32(lexer, 16, 0)
    End If

    Let position be memory_get_int32(lexer, 8)  # Get position from struct
    Let new_position be position plus 1
    memory_set_int32(lexer, 8, new_position)     # Update position in struct
    Set LEXER_POSITION to new_position

    Let column be memory_get_int32(lexer, 16)
    Let new_column be column plus 1
    memory_set_int32(lexer, 16, new_column)

    Let source be memory_get_pointer(lexer, 0)
    Let source_len be string_length(source)
    If new_position is greater than or equal to source_len:
        memory_set_byte(lexer, 20, 0)
        Set LEXER_CURRENT_CHAR to 0  # Global workaround
    Otherwise:
        Let char_at_pos be string_char_at(source, new_position)
        memory_set_byte(lexer, 20, char_at_pos)
        Set LEXER_CURRENT_CHAR to char_at_pos  # Global workaround
    End If

    Return 0
End Process

# Skip whitespace
Process called "lexer_skip_whitespace" takes lexer as Integer returns Integer:
    Let continue_loop be 1
    While continue_loop is equal to 1:
        Let current_char be memory_get_byte(lexer, 20)
        If current_char is equal to 0:
            Set continue_loop to 0
        Otherwise:
            Let is_space be is_whitespace(current_char)
            If is_space is equal to 0:
                Set continue_loop to 0
            Otherwise:
                Let dummy be lexer_advance(lexer)
            End If
        End If
    End While
    Return 0
End Process

# Skip comments
Process called "lexer_skip_comment" takes lexer as Integer returns Integer:
    # Skip the '#' character
    Let dummy be lexer_advance(lexer)

    # Skip until end of line or end of file
    Let continue_loop be 1
    While continue_loop is equal to 1:
        Let current_char be memory_get_byte(lexer, 20)
        Let newline be 10  # ASCII for '\n'
        If current_char is equal to 0:
            Set continue_loop to 0
        Otherwise:
            If current_char is equal to newline:
                Set continue_loop to 0
            Otherwise:
                Let dummy2 be lexer_advance(lexer)
            End If
        End If
    End While
    Return 0
End Process

# Skip Note comments - handles both inline and block notes
# Inline: Note: comment text
# Block: Note: (with newline) ... :End Note
Process called "lexer_skip_note_comment" takes lexer as Integer returns Integer:
    # At this point, "Note" has been consumed, current char is next after "Note"
    Let current_char be memory_get_byte(lexer, 20)

    # Skip whitespace after "Note" (but not newlines)
    Let continue_ws be 1
    While continue_ws is equal to 1:
        Set current_char to memory_get_byte(lexer, 20)
        Let space be 32
        Let tab be 9
        If current_char is equal to space:
            Let dummy be lexer_advance(lexer)
        Otherwise:
            If current_char is equal to tab:
                Let dummy1 be lexer_advance(lexer)
            Otherwise:
                Set continue_ws to 0
            End If
        End If
    End While

    # Check what comes after "Note"
    Set current_char to memory_get_byte(lexer, 20)
    Let colon be 58

    If current_char is not equal to colon:
        # No colon - not a comment, this is an error or unusual case
        # Just return and let it be handled as Note token
        Return 0
    End If

    # We have "Note:" - skip the colon
    Let dummy3 be lexer_advance(lexer)

    # Check if this is inline (has content on same line) or block (newline follows)
    Set current_char to memory_get_byte(lexer, 20)
    Let newline be 10
    Let carriage_return be 13
    Let space be 32
    Let tab be 9

    # Skip any spaces/tabs after colon to check what follows
    Let has_content_on_line be 0
    Let check_continue be 1
    While check_continue is equal to 1:
        If current_char is equal to space:
            Let dummy_sp be lexer_advance(lexer)
            Set current_char to memory_get_byte(lexer, 20)
        Otherwise:
            If current_char is equal to tab:
                Let dummy_tb be lexer_advance(lexer)
                Set current_char to memory_get_byte(lexer, 20)
            Otherwise:
                # Not space or tab, check what it is
                If current_char is equal to newline:
                    # Block comment - \n
                    Set has_content_on_line to 0
                Otherwise:
                    If current_char is equal to carriage_return:
                        # Block comment - \r (may be followed by \n)
                        Set has_content_on_line to 0
                    Otherwise:
                        # Has content on same line - inline comment
                        Set has_content_on_line to 1
                    End If
                End If
                Set check_continue to 0
            End If
        End If
    End While

    # Check if we have a block comment or inline comment
    If has_content_on_line is equal to 0:
        # Block comment Note:\n ... :End Note
        # Skip the newline characters (handle both \r and \n)
        Set current_char to memory_get_byte(lexer, 20)
        If current_char is equal to carriage_return:
            Let dummy_cr be lexer_advance(lexer)
            Set current_char to memory_get_byte(lexer, 20)
        End If
        If current_char is equal to newline:
            Let dummy_nl be lexer_advance(lexer)
        End If

        # Scan forward until :End Note
        Let continue_scan be 1
        Let note_depth be 1  # Track nesting in case of nested Note: blocks

        While continue_scan is equal to 1:
            Set current_char to memory_get_byte(lexer, 20)
            If current_char is equal to 0:
                # EOF - unterminated block comment
                Set continue_scan to 0
            Otherwise:
                Let colon be 58
                If current_char is equal to colon:
                    # Might be :End Note - save position in case we need to backtrack
                    Let saved_pos be memory_get_int32(lexer, 8)
                    Let saved_line be memory_get_int32(lexer, 12)
                    Let saved_col be memory_get_int32(lexer, 16)

                    # Advance past colon
                    Let dummy7 be lexer_advance(lexer)

                    # Skip whitespace after colon
                    Let continue_ws3 be 1
                    While continue_ws3 is equal to 1:
                        Set current_char to memory_get_byte(lexer, 20)
                        If current_char is equal to 32:
                            Let dummy8 be lexer_advance(lexer)
                        Otherwise:
                            If current_char is equal to 9:
                                Let dummy9 be lexer_advance(lexer)
                            Otherwise:
                                If current_char is equal to 13:
                                    Let dummy_cr1 be lexer_advance(lexer)
                                Otherwise:
                                    Set continue_ws3 to 0
                                End If
                            End If
                        End If
                    End While

                    # Check for "End Note"
                    Set current_char to memory_get_byte(lexer, 20)
                    If current_char is equal to 69:  # 'E'
                        Let word_e be lexer_read_word(lexer)
                        If string_equals(word_e, "End") is equal to 1:
                            # Skip whitespace
                            Let continue_ws4 be 1
                            While continue_ws4 is equal to 1:
                                Set current_char to memory_get_byte(lexer, 20)
                                If current_char is equal to 32:
                                    Let dummy10 be lexer_advance(lexer)
                                Otherwise:
                                    If current_char is equal to 9:
                                        Let dummy11 be lexer_advance(lexer)
                                    Otherwise:
                                        If current_char is equal to 13:
                                            Let dummy_cr2 be lexer_advance(lexer)
                                        Otherwise:
                                            Set continue_ws4 to 0
                                        End If
                                    End If
                                End If
                            End While

                            # Check for "Note"
                            Set current_char to memory_get_byte(lexer, 20)
                            If current_char is equal to 78:  # 'N'
                                Let word_n be lexer_read_word(lexer)
                                If string_equals(word_n, "Note") is equal to 1:
                                    # Found :End Note! Decrement depth
                                    Set note_depth to note_depth minus 1
                                    If note_depth is equal to 0:
                                        # Matching :End Note found
                                        deallocate(word_e)
                                        deallocate(word_n)
                                        Set continue_scan to 0
                                    Otherwise:
                                        # Nested Note: block ended, continue scanning
                                        deallocate(word_e)
                                        deallocate(word_n)
                                    End If
                                Otherwise:
                                    deallocate(word_n)
                                    deallocate(word_e)
                                End If
                            Otherwise:
                                deallocate(word_e)
                            End If
                        Otherwise:
                            deallocate(word_e)
                        End If
                    End If
                Otherwise:
                    # Check if this is a nested Note: to track depth
                    If current_char is equal to 78:  # 'N'
                        Let saved_n_pos be memory_get_int32(lexer, 8)
                        Let word_note be lexer_read_word(lexer)
                        If string_equals(word_note, "Note") is equal to 1:
                            # Check if followed by colon
                            Set current_char to memory_get_byte(lexer, 20)
                            If current_char is equal to 58:  # ':'
                                Set note_depth to note_depth plus 1
                                Let dummy_n be lexer_advance(lexer)
                            End If
                        End If
                        deallocate(word_note)
                    Otherwise:
                        # Not colon or Note, just advance
                        Let dummy16 be lexer_advance(lexer)
                    End If
                End If
            End If
        End While
    Otherwise:
        # Inline comment Note: comment text
        # Skip to end of line
        Let continue_inline be 1
        While continue_inline is equal to 1:
            Set current_char to memory_get_byte(lexer, 20)
            If current_char is equal to 0:
                Set continue_inline to 0
            Otherwise:
                If current_char is equal to newline:
                    Set continue_inline to 0
                Otherwise:
                    Let dummy_adv be lexer_advance(lexer)
                End If
            End If
        End While
    End If

    Return 0
End Process

# Create token with owned string
Process called "token_create_owned" takes type as Integer, value as Integer, line as Integer, column as Integer returns Integer:
    Let token_size be 24  # sizeof(Token) = 24 bytes (aligned struct)
    Let token be memory_allocate(token_size)
    memory_set_int32(token, 0, type)
    memory_set_pointer(token, 8, value)  # Take ownership - pointer field
    memory_set_int32(token, 16, line)
    memory_set_int32(token, 20, column)
    Return token
End Process

# Create token with duplicated string
Process called "token_create" takes type as Integer, value as Integer, line as Integer, column as Integer returns Integer:
    Let token_size be 24  # sizeof(Token) = 24 bytes (aligned struct)
    Let token be memory_allocate(token_size)
    memory_set_int32(token, 0, type)
    If value is equal to 0:
        memory_set_pointer(token, 8, 0)
    Otherwise:
        Let dup be string_duplicate(value)
        memory_set_pointer(token, 8, dup)  # Pointer field
    End If
    memory_set_int32(token, 16, line)
    memory_set_int32(token, 20, column)
    Return token
End Process

# Read string literal
Process called "lexer_read_string_literal" takes lexer as Integer returns Integer:
    Let dummy be lexer_advance(lexer)  # Skip opening quote
    Let position be memory_get_int32(lexer, 8)  # Get position from struct
    Let start_pos be position

    Let continue_loop be 1
    While continue_loop is equal to 1:
        Let current_char be memory_get_byte(lexer, 20)
        Let quote be 34  # ASCII for '"'
        If current_char is equal to 0:
            Set continue_loop to 0
        Otherwise:
            If current_char is equal to quote:
                Set continue_loop to 0
            Otherwise:
                Let dummy2 be lexer_advance(lexer)
            End If
        End If
    End While

    Let current_char be memory_get_byte(lexer, 20)
    Let quote be 34  # ASCII for '"'
    If current_char is equal to quote:
        Let position be memory_get_int32(lexer, 8)  # Get position from struct
        Let length be position minus start_pos
        Let one be 1
        Let size be length plus one
        Let string be memory_allocate(size)
        Let source be memory_get_pointer(lexer, 0)
        string_copy_n(string, source, start_pos, length)
        string_set_char(string, length, 0)
        Let dummy3 be lexer_advance(lexer)  # Skip closing quote
        Return string
    End If

    Return 0  # Unterminated string
End Process

# Read word (identifier or keyword)
Process called "lexer_read_word" takes lexer as Integer returns Integer:
    Let position be memory_get_int32(lexer, 8)  # Get position from struct
    Let start_pos be position

    Let continue_loop be 1
    While continue_loop is equal to 1:
        # Read from struct instead of global (globals don't work in stage2)
        Let current_char be memory_get_byte(lexer, 20)
        If current_char is equal to 0:
            Set continue_loop to 0
        Otherwise:
            Let is_alnum be is_alnum_char(current_char)
            Let underscore be 95  # ASCII for '_'
            If current_char is equal to underscore:
                Let dummy be lexer_advance(lexer)
            Otherwise:
                If is_alnum is equal to 1:
                    Let dummy2 be lexer_advance(lexer)
                Otherwise:
                    Set continue_loop to 0
                End If
            End If
        End If
    End While

    Let position be memory_get_int32(lexer, 8)  # Get position from struct
    Let length be position minus start_pos
    Let one be 1
    Let size be length plus one
    Let word be memory_allocate(size)
    Let source be memory_get_pointer(lexer, 0)
    string_copy_n(word, source, start_pos, length)
    string_set_char(word, length, 0)

    Return word
End Process

# Read integer
Process called "lexer_read_integer" takes lexer as Integer returns Integer:
    # Read from struct instead of global (globals don't work in stage2)
    Let position be memory_get_int32(lexer, 8)
    Let start_pos be position

    Let continue_loop be 1
    While continue_loop is equal to 1:
        Let current_char be memory_get_byte(lexer, 20)
        If current_char is equal to 0:
            Set continue_loop to 0
        Otherwise:
            Let is_dig be is_digit(current_char)
            If is_dig is equal to 1:
                Let dummy be lexer_advance(lexer)
            Otherwise:
                Set continue_loop to 0
            End If
        End If
    End While

    Let position be memory_get_int32(lexer, 8)  # Get position from struct
    Let length be position minus start_pos
    Let one be 1
    Let size be length plus one
    Let integer be memory_allocate(size)
    Let source be memory_get_pointer(lexer, 0)
    string_copy_n(integer, source, start_pos, length)
    string_set_char(integer, length, 0)

    Return integer
End Process

# Create lexer
Process called "lexer_create" takes source as Integer returns Integer:
    Let lexer_size be 32  # sizeof(Lexer) = 32 bytes with extra space for workaround
    Let lexer be memory_allocate(lexer_size)
    Let dup be string_duplicate(source)
    memory_set_pointer(lexer, 0, dup)      # char *source at offset 0
    memory_set_int32(lexer, 8, 0)          # int position at offset 8
    Set LEXER_POSITION to 0  # Reset position for new lexer
    memory_set_int32(lexer, 12, 1)         # int line at offset 12
    memory_set_int32(lexer, 16, 1)         # int column at offset 16

    Let src_len be string_length(source)
    Let first_char be string_char_at(source, 0)

    memory_set_byte(lexer, 20, first_char)  # char current_char at offset 20
    Set LEXER_CURRENT_CHAR to first_char  # Global workaround
    Return lexer
End Process

# Destroy lexer
Process called "lexer_destroy" takes lexer as Integer returns Integer:
    If lexer is not equal to 0:
        Let source be memory_get_pointer(lexer, 0)
        deallocate(source)
        deallocate(lexer)
    End If
    Return 0
End Process

# Get next token - main lexer function
Process called "lexer_next_token" takes lexer as Integer returns Integer:
    Let continue_main be 1
    While continue_main is equal to 1:
        Let current_char be memory_get_byte(lexer, 20)
        If current_char is equal to 0:
            Set continue_main to 0
        Otherwise:
            Let line be memory_get_int32(lexer, 12)
            Let column be memory_get_int32(lexer, 16)

            # Check for whitespace
            Let is_space be is_whitespace(current_char)
            If is_space is equal to 1:
                Let dummy be lexer_skip_whitespace(lexer)
            Otherwise:
                # Check for comment
                Let hash be 35  # ASCII for '#'
                If current_char is equal to hash:
                    Let dummy2 be lexer_skip_comment(lexer)
                Otherwise:
                    # Check for string literal
                    Let quote be 34  # ASCII for '"'
                    If current_char is equal to quote:
                        Let string be lexer_read_string_literal(lexer)
                        If string is not equal to 0:
                            Let token be token_create_owned(TOKEN_STRING_LITERAL, string, line, column)
                            Return token
                        Otherwise:
                            # Print error for unterminated string
                            Let error_msg be "[LEXER ERROR] Unterminated string literal at line "
                            print_string(error_msg)
                            print_integer(line)
                            Let column_msg be ", column "
                            print_string(column_msg)
                            print_integer(column)
                            print_newline()

                            Let error_str be "Unterminated string"
                            Let token be token_create(TOKEN_ERROR, error_str, line, column)
                            Return token
                        End If
                    Otherwise:
                        # Check for minus sign (could be negative number or minus operator)
                        Let minus_sign be 45  # ASCII for '-'
                        If current_char is equal to minus_sign:
                            # Look ahead to see if this is a negative number literal
                            Let next_pos be memory_get_int32(lexer, 8)
                            Let next_pos be next_pos plus 1
                            Let source be memory_get_pointer(lexer, 0)
                            Let source_len be string_length(source)

                            If next_pos is less than source_len:
                                Let next_char be string_char_at(source, next_pos)
                                Let is_next_digit be is_digit(next_char)

                                If is_next_digit is equal to 1:
                                    # This is a negative number literal like -5
                                    Let dummy_minus be lexer_advance(lexer)
                                    Let integer be lexer_read_integer(lexer)

                                    # Prepend minus sign to integer string
                                    Let int_len be string_length(integer)
                                    Let neg_len be int_len plus 2  # minus + null
                                    Let neg_integer be memory_allocate(neg_len)
                                    memory_set_byte(neg_integer, 0, 45)  # minus sign

                                    # Copy integer digits
                                    Let copy_i be 0
                                    While copy_i is less than int_len:
                                        Let digit_char be memory_get_byte(integer, copy_i)
                                        memory_set_byte(neg_integer, copy_i plus 1, digit_char)
                                        Set copy_i to copy_i plus 1
                                    End While
                                    memory_set_byte(neg_integer, int_len plus 1, 0)  # null terminator

                                    deallocate(integer)
                                    Let token be token_create_owned(TOKEN_INTEGER, neg_integer, line, column)
                                    Return token
                                End If
                            End If
                            # Not a negative number, will be handled as single char token below
                        End If

                        # Check for integer
                        Let is_dig be is_digit(current_char)
                        If is_dig is equal to 1:
                            Let integer be lexer_read_integer(lexer)
                            Let token be token_create_owned(TOKEN_INTEGER, integer, line, column)
                            Return token
                        Otherwise:
                            # Check for word (identifier or keyword)
                            Let is_alph be is_alpha(current_char)
                            If is_alph is equal to 1:
                                Let word be lexer_read_word(lexer)

                                # Special handling for Note comments - check before determining type
                                Let is_note be string_equals(word, "Note")
                                If is_note is equal to 0:
                                    # Not a Note, determine token type and return it
                                    Let type be determine_token_type(word)
                                    Let token be token_create_owned(type, word, line, column)
                                    Return token
                                End If

                                # If we get here, it's a Note comment - skip it
                                Let dummy_note be lexer_skip_note_comment(lexer)
                                deallocate(word)
                                # Loop will continue to next token
                            Otherwise:
                                # Check for single character tokens
                                Let token be check_single_char_token(lexer, current_char, line, column)
                                If token is not equal to 0:
                                    Return token
                                Otherwise:
                                    # Unexpected character error
                                    Let error_msg be "[LEXER ERROR] Unexpected character '"
                                    print_string(error_msg)
                                    print_char(current_char)
                                    Let at_msg be "' at line "
                                    print_string(at_msg)
                                    print_integer(line)
                                    Let column_msg be ", column "
                                    print_string(column_msg)
                                    print_integer(column)
                                    print_newline()

                                    Let dummy3 be lexer_advance(lexer)
                                    Let error_str be "Unexpected character"
                                    Let token be token_create(TOKEN_ERROR, error_str, line, column)
                                    Return token
                                End If
                            End If
                        End If
                    End If
                End If
            End If
        End If
    End While

    Let line be memory_get_int32(lexer, 12)
    Let column be memory_get_int32(lexer, 16)
    Let token be token_create(TOKEN_EOF, 0, line, column)
    Return token
End Process

# Determine token type from word - OPTIMIZED with first-character branching
Process called "determine_token_type" takes word as Integer returns Integer:
    # Get first character to quickly branch
    Let first_char be memory_get_byte(word, 0)

    # Branch on first character - dramatically reduces comparisons
    # P: Process, Print
    If first_char is equal to 80:
        Return check_keywords_P(word)
    End If

    # c: called, containing
    If first_char is equal to 99:
        Return check_keywords_c(word)
    End If

    # r: returns
    If first_char is equal to 114:
        Return check_keywords_r(word)
    End If

    # I: Integer, If, Increase, Inline
    If first_char is equal to 73:
        Return check_keywords_I(word)
    End If

    # A: Assembly
    If first_char is equal to 65:
        Return check_keywords_A(word)
    End If

    # S: String, Set
    If first_char is equal to 83:
        Return check_keywords_S(word)
    End If

    # C: Character, Continue
    If first_char is equal to 67:
        Return check_keywords_C(word)
    End If

    # R: Return
    If first_char is equal to 82:
        Return check_keywords_R(word)
    End If

    # E: End
    If first_char is equal to 69:
        Return check_keywords_E(word)
    End If

    # L: Let
    If first_char is equal to 76:
        Return check_keywords_L(word)
    End If

    # b: be, by
    If first_char is equal to 98:
        Return check_keywords_b(word)
    End If

    # s: set (lowercase - shouldn't happen but be safe)
    If first_char is equal to 115:
        Return check_keywords_s(word)
    End If

    # t: to, takes, than, that, true
    If first_char is equal to 116:
        Return check_keywords_t(word)
    End If

    # p: plus
    If first_char is equal to 112:
        Return check_keywords_p(word)
    End If

    # m: minus, multiplied
    If first_char is equal to 109:
        Return check_keywords_m(word)
    End If

    # i: is, in, index, increased
    If first_char is equal to 105:
        Return check_keywords_i(word)
    End If

    # e: equal, each
    If first_char is equal to 101:
        Return check_keywords_e(word)
    End If

    # l: less, length
    If first_char is equal to 108:
        Return check_keywords_l(word)
    End If

    # g: greater, gets
    If first_char is equal to 103:
        Return check_keywords_g(word)
    End If

    # n: not, negative
    If first_char is equal to 110:
        Return check_keywords_n(word)
    End If

    # N: Note
    If first_char is equal to 78:
        Return check_keywords_N(word)
    End If

    # a: and, as, at, an, a
    If first_char is equal to 97:
        Return check_keywords_a(word)
    End If

    # o: or
    If first_char is equal to 111:
        Return check_keywords_o(word)
    End If

    # O: Otherwise
    If first_char is equal to 79:
        Return check_keywords_O(word)
    End If

    # W: While
    If first_char is equal to 87:
        Return check_keywords_W(word)
    End If

    # T: Type
    If first_char is equal to 84:
        Return check_keywords_T(word)
    End If

    # B: Break
    If first_char is equal to 66:
        Return check_keywords_B(word)
    End If

    # f: false, from, for
    If first_char is equal to 102:
        Return check_keywords_f(word)
    End If

    # d: divided, decreased
    If first_char is equal to 100:
        Return check_keywords_d(word)
    End If

    # D: Display, Decrease, Divide
    If first_char is equal to 68:
        Return check_keywords_D(word)
    End If

    # M: Multiply
    If first_char is equal to 77:
        Return check_keywords_M(word)
    End If

    # F: For
    If first_char is equal to 70:
        Return check_keywords_F(word)
    End If

    # w: where
    If first_char is equal to 119:
        Return check_keywords_w(word)
    End If

    # k: key
    If first_char is equal to 107:
        Return check_keywords_k(word)
    End If

    # Not a keyword - check builtins then return identifier
    Let type be check_builtin_functions(word)
    Return type
End Process

# First-character helper functions for keyword lookup optimization

Process called "check_keywords_P" takes word as Integer returns Integer:
    If string_equals(word, "Process") is equal to 1:
        Return TOKEN_PROCESS
    End If
    If string_equals(word, "Print") is equal to 1:
        Return TOKEN_PRINT
    End If
    Return TOKEN_IDENTIFIER
End Process

Process called "check_keywords_c" takes word as Integer returns Integer:
    If string_equals(word, "called") is equal to 1:
        Return TOKEN_CALLED
    End If
    If string_equals(word, "containing") is equal to 1:
        Return TOKEN_CONTAINING
    End If
    Return TOKEN_IDENTIFIER
End Process

Process called "check_keywords_r" takes word as Integer returns Integer:
    If string_equals(word, "returns") is equal to 1:
        Return TOKEN_RETURNS
    End If
    Return TOKEN_IDENTIFIER
End Process

Process called "check_keywords_I" takes word as Integer returns Integer:
    If string_equals(word, "Integer") is equal to 1:
        Return TOKEN_INTEGER_TYPE
    End If
    If string_equals(word, "If") is equal to 1:
        Return TOKEN_IF
    End If
    If string_equals(word, "Increase") is equal to 1:
        Return TOKEN_INCREASE
    End If
    If string_equals(word, "Inline") is equal to 1:
        Return TOKEN_INLINE
    End If
    If string_equals(word, "Import") is equal to 1:
        Return TOKEN_IMPORT
    End If
    Return TOKEN_IDENTIFIER
End Process

Process called "check_keywords_A" takes word as Integer returns Integer:
    If string_equals(word, "Assembly") is equal to 1:
        Return TOKEN_ASSEMBLY
    End If
    Return TOKEN_IDENTIFIER
End Process

Process called "check_keywords_S" takes word as Integer returns Integer:
    If string_equals(word, "String") is equal to 1:
        Return TOKEN_STRING_TYPE
    End If
    If string_equals(word, "Set") is equal to 1:
        Return TOKEN_SET
    End If
    Return TOKEN_IDENTIFIER
End Process

Process called "check_keywords_C" takes word as Integer returns Integer:
    If string_equals(word, "Character") is equal to 1:
        Return TOKEN_CHARACTER_TYPE
    End If
    If string_equals(word, "Continue") is equal to 1:
        Return TOKEN_CONTINUE
    End If
    Return TOKEN_IDENTIFIER
End Process

Process called "check_keywords_R" takes word as Integer returns Integer:
    If string_equals(word, "Return") is equal to 1:
        Return TOKEN_RETURN
    End If
    Return TOKEN_IDENTIFIER
End Process

Process called "check_keywords_E" takes word as Integer returns Integer:
    If string_equals(word, "End") is equal to 1:
        Return TOKEN_END
    End If
    Return TOKEN_IDENTIFIER
End Process

Process called "check_keywords_L" takes word as Integer returns Integer:
    If string_equals(word, "Let") is equal to 1:
        Return TOKEN_LET
    End If
    Return TOKEN_IDENTIFIER
End Process

Process called "check_keywords_b" takes word as Integer returns Integer:
    If string_equals(word, "be") is equal to 1:
        Return TOKEN_BE
    End If
    If string_equals(word, "by") is equal to 1:
        Return TOKEN_BY
    End If
    If string_equals(word, "bit_and") is equal to 1:
        Return TOKEN_BIT_AND
    End If
    If string_equals(word, "bit_or") is equal to 1:
        Return TOKEN_BIT_OR
    End If
    If string_equals(word, "bit_xor") is equal to 1:
        Return TOKEN_BIT_XOR
    End If
    If string_equals(word, "bit_shift_left") is equal to 1:
        Return TOKEN_BIT_SHIFT_LEFT
    End If
    If string_equals(word, "bit_shift_right") is equal to 1:
        Return TOKEN_BIT_SHIFT_RIGHT
    End If
    Return TOKEN_IDENTIFIER
End Process

Process called "check_keywords_s" takes word as Integer returns Integer:
    Return TOKEN_IDENTIFIER
End Process

Process called "check_keywords_t" takes word as Integer returns Integer:
    If string_equals(word, "to") is equal to 1:
        Return TOKEN_TO
    End If
    If string_equals(word, "takes") is equal to 1:
        Return TOKEN_TAKES
    End If
    If string_equals(word, "than") is equal to 1:
        Return TOKEN_THAN
    End If
    If string_equals(word, "that") is equal to 1:
        Return TOKEN_THAT
    End If
    If string_equals(word, "true") is equal to 1:
        Return TOKEN_TRUE
    End If
    Return TOKEN_IDENTIFIER
End Process

Process called "check_keywords_p" takes word as Integer returns Integer:
    If string_equals(word, "plus") is equal to 1:
        Return TOKEN_PLUS
    End If
    Return TOKEN_IDENTIFIER
End Process

Process called "check_keywords_m" takes word as Integer returns Integer:
    If string_equals(word, "minus") is equal to 1:
        Return TOKEN_MINUS
    End If
    If string_equals(word, "multiplied") is equal to 1:
        Return TOKEN_MULTIPLIED
    End If
    If string_equals(word, "modulo") is equal to 1:
        Return TOKEN_MODULO
    End If
    Return TOKEN_IDENTIFIER
End Process

Process called "check_keywords_i" takes word as Integer returns Integer:
    If string_equals(word, "is") is equal to 1:
        Return TOKEN_IS
    End If
    If string_equals(word, "in") is equal to 1:
        Return TOKEN_IN
    End If
    If string_equals(word, "index") is equal to 1:
        Return TOKEN_INDEX
    End If
    If string_equals(word, "increased") is equal to 1:
        Return TOKEN_INCREASED
    End If
    Return TOKEN_IDENTIFIER
End Process

Process called "check_keywords_e" takes word as Integer returns Integer:
    If string_equals(word, "equal") is equal to 1:
        Return TOKEN_EQUAL
    End If
    If string_equals(word, "each") is equal to 1:
        Return TOKEN_EACH
    End If
    Return TOKEN_IDENTIFIER
End Process

Process called "check_keywords_l" takes word as Integer returns Integer:
    If string_equals(word, "less") is equal to 1:
        Return TOKEN_LESS
    End If
    If string_equals(word, "length") is equal to 1:
        Return TOKEN_LENGTH
    End If
    Return TOKEN_IDENTIFIER
End Process

Process called "check_keywords_g" takes word as Integer returns Integer:
    If string_equals(word, "greater") is equal to 1:
        Return TOKEN_GREATER
    End If
    If string_equals(word, "gets") is equal to 1:
        Return TOKEN_GETS
    End If
    Return TOKEN_IDENTIFIER
End Process

Process called "check_keywords_n" takes word as Integer returns Integer:
    If string_equals(word, "not") is equal to 1:
        Return TOKEN_NOT
    End If
    If string_equals(word, "negative") is equal to 1:
        Return TOKEN_NEGATIVE
    End If
    Return TOKEN_IDENTIFIER
End Process

Process called "check_keywords_N" takes word as Integer returns Integer:
    If string_equals(word, "Note") is equal to 1:
        Return TOKEN_NOTE
    End If
    Return TOKEN_IDENTIFIER
End Process

Process called "check_keywords_a" takes word as Integer returns Integer:
    If string_equals(word, "and") is equal to 1:
        Return TOKEN_AND
    End If
    If string_equals(word, "as") is equal to 1:
        Return TOKEN_AS
    End If
    If string_equals(word, "at") is equal to 1:
        Return TOKEN_AT
    End If
    If string_equals(word, "an") is equal to 1:
        Return TOKEN_AN
    End If
    If string_equals(word, "array") is equal to 1:
        Return TOKEN_ARRAY
    End If
    Return TOKEN_IDENTIFIER
End Process

Process called "check_keywords_o" takes word as Integer returns Integer:
    If string_equals(word, "or") is equal to 1:
        Return TOKEN_OR
    End If
    Return TOKEN_IDENTIFIER
End Process

Process called "check_keywords_O" takes word as Integer returns Integer:
    If string_equals(word, "Otherwise") is equal to 1:
        Return TOKEN_OTHERWISE
    End If
    Return TOKEN_IDENTIFIER
End Process

Process called "check_keywords_W" takes word as Integer returns Integer:
    If string_equals(word, "While") is equal to 1:
        Return TOKEN_WHILE
    End If
    Return TOKEN_IDENTIFIER
End Process

Process called "check_keywords_T" takes word as Integer returns Integer:
    If string_equals(word, "Type") is equal to 1:
        Return TOKEN_TYPE
    End If
    Return TOKEN_IDENTIFIER
End Process

Process called "check_keywords_B" takes word as Integer returns Integer:
    If string_equals(word, "Break") is equal to 1:
        Return TOKEN_BREAK
    End If
    Return TOKEN_IDENTIFIER
End Process

Process called "check_keywords_f" takes word as Integer returns Integer:
    If string_equals(word, "false") is equal to 1:
        Return TOKEN_FALSE
    End If
    If string_equals(word, "from") is equal to 1:
        Return TOKEN_FROM
    End If
    Return TOKEN_IDENTIFIER
End Process

Process called "check_keywords_d" takes word as Integer returns Integer:
    If string_equals(word, "divided") is equal to 1:
        Return TOKEN_DIVIDED
    End If
    If string_equals(word, "decreased") is equal to 1:
        Return TOKEN_DECREASED
    End If
    Return TOKEN_IDENTIFIER
End Process

Process called "check_keywords_D" takes word as Integer returns Integer:
    If string_equals(word, "Display") is equal to 1:
        Return TOKEN_PRINT
    End If
    If string_equals(word, "Decrease") is equal to 1:
        Return TOKEN_DECREASE
    End If
    If string_equals(word, "Divide") is equal to 1:
        Return TOKEN_DIVIDE
    End If
    Return TOKEN_IDENTIFIER
End Process

Process called "check_keywords_M" takes word as Integer returns Integer:
    If string_equals(word, "Multiply") is equal to 1:
        Return TOKEN_MULTIPLY
    End If
    Return TOKEN_IDENTIFIER
End Process

Process called "check_keywords_F" takes word as Integer returns Integer:
    If string_equals(word, "For") is equal to 1:
        Return TOKEN_FOR
    End If
    Return TOKEN_IDENTIFIER
End Process

Process called "check_keywords_w" takes word as Integer returns Integer:
    If string_equals(word, "where") is equal to 1:
        Return TOKEN_WHERE
    End If
    If string_equals(word, "with") is equal to 1:
        Return TOKEN_WITH
    End If
    Return TOKEN_IDENTIFIER
End Process

Process called "check_keywords_k" takes word as Integer returns Integer:
    If string_equals(word, "key") is equal to 1:
        Return TOKEN_KEY
    End If
    Return TOKEN_IDENTIFIER
End Process


# Check built-in function names
Process called "check_builtin_functions" takes word as Integer returns Integer:
    # Check all built-in functions
    Let break_str be "Break"
    Let result be string_equals(word, break_str)
    If result is equal to 1:
        Return TOKEN_BREAK
    End If

    Let continue_str be "Continue"
    Set result to string_equals(word, continue_str)
    If result is equal to 1:
        Return TOKEN_CONTINUE
    End If

    Let print_str be "Print"
    Set result to string_equals(word, print_str)
    If result is equal to 1:
        Return TOKEN_PRINT
    End If

    Let display_str be "Display"
    Set result to string_equals(word, display_str)
    If result is equal to 1:
        Return TOKEN_PRINT  # Display is treated as Print
    End If

    Let type_str be "Type"
    Set result to string_equals(word, type_str)
    If result is equal to 1:
        Return TOKEN_TYPE
    End If

    Let import_str be "Import"
    Set result to string_equals(word, import_str)
    If result is equal to 1:
        Return TOKEN_IMPORT
    End If

    # String functions
    Let string_length_str be "string_length"
    Set result to string_equals(word, string_length_str)
    If result is equal to 1:
        Return TOKEN_STRING_LENGTH
    End If

    # ... (continuing with all other function checks would make this too long)
    # For brevity, using a helper for the rest
    Let type be check_more_builtins(word)
    Return type
End Process

# Additional built-in checks
Process called "check_more_builtins" takes word as Integer returns Integer:
    # File I/O functions
    Let read_file_str be "read_file"
    Let result be string_equals(word, read_file_str)
    If result is equal to 1:
        Return TOKEN_READ_FILE
    End If
    Let write_file_str be "write_file"
    Set result to string_equals(word, write_file_str)
    If result is equal to 1:
        Return TOKEN_WRITE_FILE
    End If

    # Memory access functions
    Let memory_get_byte_str be "memory_get_byte"
    Set result to string_equals(word, memory_get_byte_str)
    If result is equal to 1:
        Return TOKEN_MEMORY_GET_BYTE
    End If

    Let memory_set_byte_str be "memory_set_byte"
    Set result to string_equals(word, memory_set_byte_str)
    If result is equal to 1:
        Return TOKEN_MEMORY_SET_BYTE
    End If

    Let bit_shift_left_str be "bit_shift_left"
    Set result to string_equals(word, bit_shift_left_str)
    If result is equal to 1:
        Return TOKEN_BIT_SHIFT_LEFT
    End If

    Let bit_shift_right_str be "bit_shift_right"
    Set result to string_equals(word, bit_shift_right_str)
    If result is equal to 1:
        Return TOKEN_BIT_SHIFT_RIGHT
    End If

    Let bit_and_str be "bit_and"
    Set result to string_equals(word, bit_and_str)
    If result is equal to 1:
        Return TOKEN_BIT_AND
    End If

    Let bit_or_str be "bit_or"
    Set result to string_equals(word, bit_or_str)
    If result is equal to 1:
        Return TOKEN_BIT_OR
    End If

    Let bit_xor_str be "bit_xor"
    Set result to string_equals(word, bit_xor_str)
    If result is equal to 1:
        Return TOKEN_BIT_XOR
    End If

    # Default to identifier
    Return TOKEN_IDENTIFIER
End Process

# Check single character tokens
Process called "check_single_char_token" takes lexer as Integer, char as Integer, line as Integer, column as Integer returns Integer:
    # Check for minus sign (when not followed by digit)
    Let minus_sign be 45  # ASCII for '-'
    If char is equal to minus_sign:
        Let dummy be lexer_advance(lexer)
        Let minus_str be "-"
        Let token be token_create(TOKEN_MINUS, minus_str, line, column)
        Return token
    End If

    Let colon be 58  # ASCII for ':'
    If char is equal to colon:
        Let dummy be lexer_advance(lexer)
        Let colon_str be ":"
        Let token be token_create(TOKEN_COLON, colon_str, line, column)
        Return token
    End If

    Let lparen be 40  # ASCII for '('
    If char is equal to lparen:
        Let dummy be lexer_advance(lexer)
        Let lparen_str be "("
        Let token be token_create(TOKEN_LPAREN, lparen_str, line, column)
        Return token
    End If

    Let rparen be 41  # ASCII for ')'
    If char is equal to rparen:
        Let dummy be lexer_advance(lexer)
        Let rparen_str be ")"
        Let token be token_create(TOKEN_RPAREN, rparen_str, line, column)
        Return token
    End If

    Let lbracket be 91  # ASCII for '['
    If char is equal to lbracket:
        Let dummy be lexer_advance(lexer)
        Let lbracket_str be "["
        Let token be token_create(TOKEN_LBRACKET, lbracket_str, line, column)
        Return token
    End If

    Let rbracket be 93  # ASCII for ']'
    If char is equal to rbracket:
        Let dummy be lexer_advance(lexer)
        Let rbracket_str be "]"
        Let token be token_create(TOKEN_RBRACKET, rbracket_str, line, column)
        Return token
    End If

    Let dot be 46  # ASCII for '.'
    If char is equal to dot:
        Let dummy be lexer_advance(lexer)
        Let dot_str be "."
        Let token be token_create(TOKEN_DOT, dot_str, line, column)
        Return token
    End If

    Let comma be 44  # ASCII for ','
    If char is equal to comma:
        Let dummy be lexer_advance(lexer)
        Let comma_str be ","
        Let token be token_create(TOKEN_COMMA, comma_str, line, column)
        Return token
    End If

    Let pipe be 124  # ASCII for '|'
    If char is equal to pipe:
        Let dummy be lexer_advance(lexer)
        Let pipe_str be "|"
        Let token be token_create(TOKEN_PIPE, pipe_str, line, column)
        Return token
    End If

    Let dollar be 36  # ASCII for '$'
    If char is equal to dollar:
        Let dummy be lexer_advance(lexer)
        Let dollar_str be "$"
        Let token be token_create(TOKEN_DOLLAR, dollar_str, line, column)
        Return token
    End If

    Let lbrace be 123  # ASCII for '{'
    If char is equal to lbrace:
        Let dummy be lexer_advance(lexer)
        Let lbrace_str be "{"
        Let token be token_create(TOKEN_LBRACE, lbrace_str, line, column)
        Return token
    End If

    Let rbrace be 125  # ASCII for '}'
    If char is equal to rbrace:
        Let dummy be lexer_advance(lexer)
        Let rbrace_str be "}"
        Let token be token_create(TOKEN_RBRACE, rbrace_str, line, column)
        Return token
    End If

    Return 0  # Not a single char token
End Process

# Destroy token
Process called "token_destroy" takes token as Integer returns Integer:
    If token is not equal to 0:
        Let value be memory_get_pointer(token, 8)
        If value is not equal to 0:
            deallocate(value)
        End If
        deallocate(token)
    End If
    Return 0
End Process

# Helper functions for character checking
Process called "is_alnum_char" takes char as Integer returns Integer:
    Let is_alph be is_alpha(char)
    If is_alph is equal to 1:
        Return 1
    End If
    Let is_dig be is_digit(char)
    Return is_dig
End Process

# Print functions for error messages
Process called "print_char" takes char as Integer returns Integer:
    # Create a temporary string with the character
    Let str be memory_allocate(2)
    string_set_char(str, 0, char)
    string_set_char(str, 1, 0)
    print_string(str)
    deallocate(str)
    Return 0
End Process

Process called "print_newline" takes dummy as Integer returns Integer:
    Let newline be 10
    Let result be print_char(newline)
    Return 0
End Process