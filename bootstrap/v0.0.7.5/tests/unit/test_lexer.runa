Process called "test_lexer_keywords" returns Integer:
    Let source be "Process Let Return If While"
    Let lexer be lexer_create(source)

    Let token1 be lexer_next_token(lexer)
    assert(token_get_type(token1) is equal to TOKEN_PROCESS)

    Let token2 be lexer_next_token(lexer)
    assert(token_get_type(token2) is equal to TOKEN_LET)

    Let token3 be lexer_next_token(lexer)
    assert(token_get_type(token3) is equal to TOKEN_RETURN)

    Let token4 be lexer_next_token(lexer)
    assert(token_get_type(token4) is equal to TOKEN_IF)

    Let token5 be lexer_next_token(lexer)
    assert(token_get_type(token5) is equal to TOKEN_WHILE)

    lexer_destroy(lexer)
    Return 0
End Process

Process called "test_lexer_numbers" returns Integer:
    Let source be "42 0 999 123"
    Let lexer be lexer_create(source)

    Let token1 be lexer_next_token(lexer)
    assert(token_get_type(token1) is equal to TOKEN_INTEGER)
    Let value1 be token_get_value(token1)
    assert(string_equals(value1, "42"))

    Let token2 be lexer_next_token(lexer)
    assert(token_get_type(token2) is equal to TOKEN_INTEGER)
    Let value2 be token_get_value(token2)
    assert(string_equals(value2, "0"))

    lexer_destroy(lexer)
    Return 0
End Process

Process called "test_lexer_strings" returns Integer:
    Let source be "\"Hello World\" \"\" \"Escaped \\\"quote\\\"\""
    Let lexer be lexer_create(source)

    Let token1 be lexer_next_token(lexer)
    assert(token_get_type(token1) is equal to TOKEN_STRING_LITERAL)
    Let value1 be token_get_value(token1)
    assert(string_equals(value1, "Hello World"))

    Let token2 be lexer_next_token(lexer)
    assert(token_get_type(token2) is equal to TOKEN_STRING_LITERAL)
    Let value2 be token_get_value(token2)
    assert(string_equals(value2, ""))

    lexer_destroy(lexer)
    Return 0
End Process