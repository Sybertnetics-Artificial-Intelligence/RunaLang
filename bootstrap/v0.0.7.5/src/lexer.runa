Type called "TokenType":
    TOKEN_EOF
    TOKEN_PROCESS
    TOKEN_CALLED
    TOKEN_RETURNS
    TOKEN_INTEGER_TYPE
    TOKEN_RETURN
    TOKEN_END
    TOKEN_COLON
    TOKEN_STRING_LITERAL
    TOKEN_INTEGER
    TOKEN_LET
    TOKEN_BE
    TOKEN_SET
    TOKEN_TO
    TOKEN_PLUS
    TOKEN_MINUS
    TOKEN_IF
    TOKEN_OTHERWISE
    TOKEN_WHILE
    TOKEN_IS
    TOKEN_EQUAL
    TOKEN_LESS
    TOKEN_THAN
    TOKEN_THAT
    TOKEN_TAKES
    TOKEN_AS
    TOKEN_MULTIPLIED
    TOKEN_DIVIDED
    TOKEN_BY
    TOKEN_PRINT
    TOKEN_LPAREN
    TOKEN_RPAREN
    TOKEN_TYPE
    TOKEN_DOT
    TOKEN_COMMA
    TOKEN_IMPORT
    TOKEN_READ_FILE
    TOKEN_WRITE_FILE
    TOKEN_IDENTIFIER
    TOKEN_ERROR
End Type

Type called "Token":
    token_type as Integer
    value as Integer
    line as Integer
    column as Integer
End Type

Type called "Lexer":
    source as Integer
    position as Integer
    line as Integer
    column as Integer
    current_char as Integer
End Type

Process called "string_duplicate" takes str as String returns String:
    If str is equal to null:
        Return null
    End If
    Let len be strlen(str)
    Let dup be malloc(len plus 1)
    strcpy(dup, str)
    Return dup
End Process

Process called "lexer_advance" takes lexer as Lexer returns Integer:
    If current_char of lexer is equal to "\n":
        Set line of lexer to line of lexer plus 1
        Set column of lexer to 0
    End If
    Set position of lexer to position of lexer plus 1
    Set column of lexer to column of lexer plus 1

    If position of lexer is greater than or equal to strlen(source of lexer):
        Set current_char of lexer to "\0"
    Otherwise:
        Let source_ptr be source of lexer
        Set current_char of lexer to source_ptr[position of lexer]
    End If
    Return 0
End Process

Process called "lexer_skip_whitespace" takes lexer as Lexer returns Integer:
    While current_char of lexer is not equal to "\0" and isspace(current_char of lexer) is not equal to 0:
        lexer_advance(lexer)
    End While
    Return 0
End Process

Process called "token_create_owned" takes token_type as TokenType, value as String, line as Integer, column as Integer returns Token:
    Let token be malloc(sizeof_Token())
    Set token_type of token to token_type
    Set value of token to value
    Set line of token to line
    Set column of token to column
    Return token
End Process

Process called "token_create" takes token_type as TokenType, value as String, line as Integer, column as Integer returns Token:
    Let token be malloc(sizeof_Token())
    Set token_type of token to token_type
    If value is not equal to null:
        Set value of token to string_duplicate(value)
    Otherwise:
        Set value of token to null
    End If
    Set line of token to line
    Set column of token to column
    Return token
End Process

Process called "lexer_read_string_literal" takes lexer as Lexer returns String:
    lexer_advance(lexer)
    Let start_pos be position of lexer

    While current_char of lexer is not equal to "\0" and current_char of lexer is not equal to "\"":
        lexer_advance(lexer)
    End While

    If current_char of lexer is equal to "\"":
        Let length be position of lexer minus start_pos
        Let string_result be malloc(length plus 1)
        strncpy(string_result, source of lexer plus start_pos, length)
        string_result[length] = "\0"
        lexer_advance(lexer)
        Return string_result
    End If

    Return null
End Process

Process called "lexer_read_word" takes lexer as Lexer returns String:
    Let start_pos be position of lexer

    While current_char of lexer is not equal to "\0" and (isalnum(current_char of lexer) is not equal to 0 or current_char of lexer is equal to "_"):
        lexer_advance(lexer)
    End While

    Let length be position of lexer minus start_pos
    Let word be malloc(length plus 1)
    strncpy(word, source of lexer plus start_pos, length)
    word[length] = "\0"

    Return word
End Process

Process called "lexer_read_integer" takes lexer as Lexer returns String:
    Let start_pos be position of lexer

    While current_char of lexer is not equal to "\0" and isdigit(current_char of lexer) is not equal to 0:
        lexer_advance(lexer)
    End While

    Let length be position of lexer minus start_pos
    Let integer_str be malloc(length plus 1)
    strncpy(integer_str, source of lexer plus start_pos, length)
    integer_str[length] = "\0"

    Return integer_str
End Process

Process called "lexer_create" takes source as String returns Lexer:
    Let lexer be malloc(sizeof_Lexer())
    Set source of lexer to string_duplicate(source)
    Set position of lexer to 0
    Set line of lexer to 1
    Set column of lexer to 1
    Set current_char of lexer to source[0]
    Return lexer
End Process

Process called "lexer_destroy" takes lexer as Lexer returns Integer:
    If lexer is not equal to null:
        free(source of lexer)
        free(lexer)
    End If
    Return 0
End Process

Process called "lexer_next_token" takes lexer as Lexer returns Token:
    While current_char of lexer is not equal to "\0":
        Let line be line of lexer
        Let column be column of lexer

        If isspace(current_char of lexer) is not equal to 0:
            lexer_skip_whitespace(lexer)
            Continue
        End If

        If current_char of lexer is equal to "\"":
            Let string_value be lexer_read_string_literal(lexer)
            If string_value is not equal to null:
                Return token_create_owned(TOKEN_STRING_LITERAL, string_value, line, column)
            Otherwise:
                Print "[LEXER ERROR] Unterminated string literal at line "
                Print line
                Print ", column "
                Print column
                Return token_create(TOKEN_ERROR, "Unterminated string", line, column)
            End If
        End If

        If isdigit(current_char of lexer) is not equal to 0:
            Let integer_value be lexer_read_integer(lexer)
            Return token_create_owned(TOKEN_INTEGER, integer_value, line, column)
        End If

        If isalpha(current_char of lexer) is not equal to 0:
            Let word be lexer_read_word(lexer)
            Let token_type be TOKEN_ERROR

            If strcmp(word, "Process") is equal to 0:
                Set token_type to TOKEN_PROCESS
            Otherwise If strcmp(word, "called") is equal to 0:
                Set token_type to TOKEN_CALLED
            Otherwise If strcmp(word, "returns") is equal to 0:
                Set token_type to TOKEN_RETURNS
            Otherwise If strcmp(word, "Integer") is equal to 0:
                Set token_type to TOKEN_INTEGER_TYPE
            Otherwise If strcmp(word, "Return") is equal to 0:
                Set token_type to TOKEN_RETURN
            Otherwise If strcmp(word, "End") is equal to 0:
                Set token_type to TOKEN_END
            Otherwise If strcmp(word, "Let") is equal to 0:
                Set token_type to TOKEN_LET
            Otherwise If strcmp(word, "be") is equal to 0:
                Set token_type to TOKEN_BE
            Otherwise If strcmp(word, "Set") is equal to 0:
                Set token_type to TOKEN_SET
            Otherwise If strcmp(word, "to") is equal to 0:
                Set token_type to TOKEN_TO
            Otherwise If strcmp(word, "plus") is equal to 0:
                Set token_type to TOKEN_PLUS
            Otherwise If strcmp(word, "minus") is equal to 0:
                Set token_type to TOKEN_MINUS
            Otherwise If strcmp(word, "If") is equal to 0:
                Set token_type to TOKEN_IF
            Otherwise If strcmp(word, "Otherwise") is equal to 0:
                Set token_type to TOKEN_OTHERWISE
            Otherwise If strcmp(word, "While") is equal to 0:
                Set token_type to TOKEN_WHILE
            Otherwise If strcmp(word, "is") is equal to 0:
                Set token_type to TOKEN_IS
            Otherwise If strcmp(word, "equal") is equal to 0:
                Set token_type to TOKEN_EQUAL
            Otherwise If strcmp(word, "less") is equal to 0:
                Set token_type to TOKEN_LESS
            Otherwise If strcmp(word, "than") is equal to 0:
                Set token_type to TOKEN_THAN
            Otherwise If strcmp(word, "that") is equal to 0:
                Set token_type to TOKEN_THAT
            Otherwise If strcmp(word, "takes") is equal to 0:
                Set token_type to TOKEN_TAKES
            Otherwise If strcmp(word, "as") is equal to 0:
                Set token_type to TOKEN_AS
            Otherwise If strcmp(word, "multiplied") is equal to 0:
                Set token_type to TOKEN_MULTIPLIED
            Otherwise If strcmp(word, "divided") is equal to 0:
                Set token_type to TOKEN_DIVIDED
            Otherwise If strcmp(word, "by") is equal to 0:
                Set token_type to TOKEN_BY
            Otherwise If strcmp(word, "Print") is equal to 0:
                Set token_type to TOKEN_PRINT
            Otherwise If strcmp(word, "Type") is equal to 0:
                Set token_type to TOKEN_TYPE
            Otherwise If strcmp(word, "Import") is equal to 0:
                Set token_type to TOKEN_IMPORT
            Otherwise If strcmp(word, "read_file") is equal to 0:
                Set token_type to TOKEN_READ_FILE
            Otherwise If strcmp(word, "write_file") is equal to 0:
                Set token_type to TOKEN_WRITE_FILE
            Otherwise:
                Set token_type to TOKEN_IDENTIFIER
            End If

            Return token_create_owned(token_type, word, line, column)
        End If

        If current_char of lexer is equal to ":":
            lexer_advance(lexer)
            Return token_create(TOKEN_COLON, ":", line, column)
        End If

        If current_char of lexer is equal to "(":
            lexer_advance(lexer)
            Return token_create(TOKEN_LPAREN, "(", line, column)
        End If

        If current_char of lexer is equal to ")":
            lexer_advance(lexer)
            Return token_create(TOKEN_RPAREN, ")", line, column)
        End If

        If current_char of lexer is equal to ".":
            lexer_advance(lexer)
            Return token_create(TOKEN_DOT, ".", line, column)
        End If

        If current_char of lexer is equal to ",":
            lexer_advance(lexer)
            Return token_create(TOKEN_COMMA, ",", line, column)
        End If

        Print "[LEXER ERROR] Unexpected character '"
        Print current_char of lexer
        Print "' at line "
        Print line of lexer
        Print ", column "
        Print column of lexer
        lexer_advance(lexer)
        Return token_create(TOKEN_ERROR, "Unexpected character", line, column)
    End While

    Return token_create(TOKEN_EOF, null, line of lexer, column of lexer)
End Process

Process called "token_destroy" takes token as Token returns String:
    If token is not equal to null:
        free(value of token)
        free(token)
    End If
    Return 0
End Process