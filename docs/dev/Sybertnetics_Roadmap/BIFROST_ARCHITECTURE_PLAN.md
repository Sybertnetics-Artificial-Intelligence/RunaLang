# **BifrÃ¶st: The Runa Universal Compute IR**

**Vision:** To create a single, unified, high-level Intermediate Representation (IR) that allows Runa code to be compiled and optimally executed on any specialized, massively parallel hardware, from GPUs and FPGAs to DSPs and future AI accelerators.

**Status:** Planning Phase (Target: v0.9.0+)

---

## ðŸŽ¯ The Vision: A Bridge to Infinite Power

In the age of heterogeneous computing, the CPU is no longer the sole arbiter of performance. True computational power lies in a diverse ecosystem of specialized silicon. The greatest challenge facing modern software is the fragmentation of this ecosystem. Each hardware vendor has its own proprietary language (CUDA, Metal), its own tools, and its own internal IRs (PTX, AIR).

**BifrÃ¶st** is Runa's answer to this fragmentation.

Named after the mythical rainbow bridge connecting the mortal realm to the realm of the gods, BifrÃ¶st is a **next-generation, graph-based, formally verifiable IR** designed from first principles for the world of massively parallel computing. It is the single, unified bridge that allows high-level Runa code to be translated into the raw power of any specialized hardware.

BifrÃ¶st is not just a "SPIR-V alternative." It is a conceptual leap forward, designed to be a true "full-spectrum" compute IR, targeting everything from the most powerful NVIDIA GPUs to custom FPGAs and DSPs with a single, unified, and verifiable representation.

---

## ðŸš« Why Existing IRs Are Not The Answer

Current solutions like LLVM IR and SPIR-V are powerful but were not designed for the full breadth of the heterogeneous world we now live in.

### LLVM IR's Limitations

1.  **CPU-Centric Design:** LLVM was born as a CPU compiler infrastructure. Its models for parallelism, memory, and execution are fundamentally based on CPU architecture. GPU support is an add-on, not a native concept.
2.  **Loss of Parallel Semantics:** LLVM IR represents a linear sequence of low-level instructions. It loses the high-level structure of a parallel computation (e.g., "apply this function to all 1 million elements"). This makes it incredibly difficult for a backend to reconstruct the original parallel intent and map it optimally to hardware.
3.  **Impoverished Type System:** It lacks first-class types for hardware concepts like `Vectors`, `Matrices`, `Textures`, or `FixedPoint` numbers, which are critical for graphics and DSPs.
4.  **Single, Flat Memory Model:** LLVM IR assumes a single, unified memory space. It has no native understanding of the complex memory hierarchies of GPUs (`global`, `shared`, `local` memory), which are the most critical factor for performance.

### SPIR-V's Limitations

1.  **Graphics-First Heritage:** SPIR-V is an excellent standard for graphics shaders and general-purpose GPU compute (GPGPU). However, its execution model is tightly coupled to the GPU model of workgroups and subgroups.
2.  **Limited Target Scope:** It is not designed to effectively represent the unique computational models of other accelerators, such as the reconfigurable dataflow pipelines of an **FPGA** or the fixed-function hardware of a **DSP**.
3.  **Not High-Level Enough:** While higher-level than machine code, it still loses significant semantic information, making high-level, cross-platform optimizations difficult.

---

## âœ¨ Why BifrÃ¶st is a Revolutionary Approach

BifrÃ¶st is designed from the ground up to overcome these limitations by adhering to a different set of core principles.

| Feature | LLVM IR | SPIR-V | BifrÃ¶st (Runa) |
| :--- | :--- | :--- | :--- |
| **Primary Target** | CPUs | GPUs | **All Accelerators** (GPU, FPGA, DSP, etc.) |
| **Representation** | Linear Instructions | Linear Instructions | **Computational Graph (DAG)** |
| **Abstraction Level** | Low (add, load, store) | Mid (GPU-centric ops) | **High** (`MatrixMultiply`, `Convolve2D`, `FFT`) |
| **Parallelism Model** | Implicit (libraries) | Explicit (GPU model) | **Explicit & Abstract** (`DataParallel`, `Pipeline`) |
| **Memory Model** | Flat Address Space | GPU Memory Spaces | **Explicit & Hierarchical** (`global`, `shared`, etc.) |
| **Verifiability** | Difficult | Limited | **Formally Verifiable** (by design) |

### Core Design Principles

1.  **Graph-Based Representation:** BifrÃ¶st represents computations as a Directed Acyclic Graph (DAG). Nodes are high-level operations (`MatrixMultiply`, `Convolve2D`), and edges represent the flow of data. This structure is ideal for high-level optimization and mapping to parallel architectures.

2.  **Explicit & Abstract Parallelism:** BifrÃ¶st has first-class concepts for different modes of parallelism (`DataParallel`, `TaskGraph`, `Pipeline`), which can be mapped efficiently to any target hardware.

3.  **Hardware-Aware Type System:** It includes a rich type system with native support for `Vector`, `Matrix`, `Texture`, and `FixedPoint` numbers, essential for targeting diverse hardware.

4.  **Explicit Memory Hierarchy:** BifrÃ¶st understands the complex memory hierarchies of modern accelerators. It has native concepts for `global`, `shared`, `local`, and `constant` memory, enabling precise control over data placement.

5.  **Formal Verifiability:** The high-level, graph-based nature of BifrÃ¶st allows for static analysis to prove critical properties like memory safety, data-race freedom, and resource bounds *before* the code ever touches the hardware.

---

## ðŸ—ï¸ Architecture Overview

The BifrÃ¶st pipeline runs in parallel to the Gungnir (CPU) pipeline, branching off from the Mid-Level IR (MIR).

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Runa Source Code (or translated from C, Python...)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AST â†’ HIR â†’ MIR (Platform-Agnostic Optimizations) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚ (CPU & General Purpose Path)  â”‚ (Heterogeneous / Accelerator Path)
     â–¼                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Gungnir (LIR)     â”‚   â”‚  BifrÃ¶st (Universal    â”‚
â”‚  â€¢ For CPU targets â”‚   â”‚     Compute IR)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                         â”‚
         â–¼                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CPU Backends       â”‚   â”‚ Accelerator Backends   â”‚
â”‚ â€¢ x86-64 Assembly  â”‚   â”‚ â€¢ CUDA (for NVIDIA)    â”‚
â”‚ â€¢ ARM64 Assembly   â”‚   â”‚ â€¢ Metal (for Apple)    â”‚
â”‚ â€¢ RISC-V Assembly  â”‚   â”‚ â€¢ Verilog/VHDL (FPGAs) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Architectural Components (`runa/compiler/middle/bifrost/`)

```
runa/compiler/middle/bifrost/
â”œâ”€â”€ graph/
â”‚   â”œâ”€â”€ node.runa          // Defines the core `BifrostNode` (operations) and `BifrostType`.
â”‚   â”œâ”€â”€ edge.runa          // Defines data flow edges and dependencies.
â”‚   â””â”€â”€ graph.runa         // The main `BifrostGraph` data structure.
â”‚
â”œâ”€â”€ builder.runa           // Translates Runa MIR into a BifrÃ¶st compute graph.
â”‚
â”œâ”€â”€ analysis/
â”‚   â”œâ”€â”€ parallelism.runa   // Detects and classifies parallelism patterns in the graph.
â”‚   â”œâ”€â”€ memory_access.runa // Analyzes memory access patterns for optimization.
â”‚   â””â”€â”€ verifier.runa        // Formally verifies the graph for safety and correctness.
â”‚
â”œâ”€â”€ optimizations/
â”‚   â”œâ”€â”€ kernel_fusion.runa // Merges multiple small kernels into one to reduce overhead.
â”‚   â”œâ”€â”€ layout_opt.runa    // Optimizes data layout in memory for better access patterns.
â”‚   â””â”€â”€ op_reordering.runa // Reorders operations to improve instruction-level parallelism.
â”‚
â””â”€â”€ backends/
    â”œâ”€â”€ cuda/
    â”‚   â””â”€â”€ cuda_gen.runa    // Generates PTX or CUDA C++ from a BifrÃ¶st graph.
    â”œâ”€â”€ metal/
    â”‚   â””â”€â”€ metal_gen.runa   // Generates Metal Shading Language (MSL).
    â”œâ”€â”€ opencl/
    â”‚   â””â”€â”€ opencl_gen.runa  // Generates OpenCL C.
    â””â”€â”€ fpga/
        â””â”€â”€ hdl_gen.runa     // Generates synthesizable Verilog or VHDL.
```

---

## ðŸš€ The Developer Experience: Seamless Acceleration

A Runa developer does not need to be a CUDA or Metal expert. They simply write idiomatic, high-level Runa code, and the compiler handles the rest.

```runa
Note: A simple vector addition in Runa.

Process called "vector_add" that takes a as List of Float, b as List of Float returns List of Float:
    Let result be a new List of Float with capacity as length of a

    Note: The compiler identifies this loop as a massively data-parallel operation.
    Note: It will be automatically offloaded to the GPU via the BifrÃ¶st pipeline.
    For i from 0 to (length of a) minus 1:
        Set result at index i to (a at index i) plus (b at index i)
    End For

    Return result
End Process
```

For expert users, Runa provides explicit directives for fine-grained control.

```runa
@Execution_Model:
    target: "gpu"
    backend: "cuda"  // Request a specific backend, or "auto"
    block_size: 256  // Provide a hint for the CUDA block size
@End_Execution_Model
Process called "matrix_multiply" that takes A as Matrix, B as Matrix returns Matrix:
    // ... implementation ...
End Process
```

---

## ðŸ“‹ Implementation Roadmap

The development of BifrÃ¶st is a major post-v0.8 initiative, planned to be executed in parallel with the AOTT and Cross-Compilation efforts.

### Phase 1: Graph Foundation (Target: v0.9.0)

*   **Goal:** Implement the core BifrÃ¶st graph data structures and the `MIR -> BifrÃ¶st` builder.
*   **Deliverables:**
    *   `runa/compiler/middle/bifrost/graph/` module is complete and unit-tested.
    *   `runa/compiler/middle/bifrost/builder.runa` is implemented.
*   **Success Criteria:**
    *   âœ… The compiler can successfully translate Runa MIR into a valid, in-memory BifrÃ¶st graph.
    *   âœ… The graph structure correctly represents data dependencies and high-level operations.
    *   âœ… No code generation is implemented in this phase.

### Phase 2: First Backend - CUDA (Target: v0.9.1)

*   **Goal:** Implement the first end-to-end backend for NVIDIA GPUs.
*   **Deliverables:**
    *   `runa/compiler/middle/bifrost/backends/cuda/cuda_gen.runa` is implemented.
    *   The compiler can take a BifrÃ¶st graph and generate working CUDA C++ or PTX.
*   **Success Criteria:**
    *   âœ… Simple, data-parallel Runa loops can be successfully compiled and executed on NVIDIA GPUs.
    *   âœ… Performance is at least 5x faster than the equivalent single-threaded CPU version for suitable workloads.
    *   âœ… End-to-end integration tests pass.

### Phase 3: Optimization & Analysis (Target: v0.9.2)

*   **Goal:** Implement the core optimization passes and the formal verifier.
*   **Deliverables:**
    *   `runa/compiler/middle/bifrost/optimizations/` library is built out.
    *   `runa/compiler/middle/bifrost/analysis/verifier.runa` is implemented.
*   **Success Criteria:**
    *   âœ… Kernel fusion provides a measurable performance increase (e.g., >30%) on relevant benchmarks.
    *   âœ… Memory layout optimizations improve memory-bound kernel performance.
    *   âœ… The verifier can statically prove memory safety and data-race freedom for simple kernels.

### Phase 4: Additional Backends - Metal & OpenCL (Target: v0.9.3)

*   **Goal:** Add support for Apple and AMD/Intel GPUs, proving the portability of the BifrÃ¶st design.
*   **Deliverables:**
    *   `metal_gen.runa` and `opencl_gen.runa` modules are implemented.
*   **Success Criteria:**
    *   âœ… The exact same Runa source code can be compiled to run on NVIDIA, Apple, and AMD GPUs.
    *   âœ… Performance on each platform is within 80% of hand-written, platform-specific code (e.g., MSL for Metal).

### Phase 5: The Final Frontier - FPGAs (Target: v1.0+)

*   **Goal:** Target reconfigurable hardware, the ultimate test of BifrÃ¶st's flexibility.
*   **Deliverables:**
    *   `runa/compiler/middle/bifrost/backends/fpga/hdl_gen.runa` is implemented.
*   **Success Criteria:**
    *   âœ… The compiler can generate synthesizable Verilog or VHDL from a BifrÃ¶st graph representing a dataflow pipeline.
    *   âœ… Simple Runa algorithms can be compiled and run on a target FPGA development board.

---

## ðŸŽ¯ Conclusion

BifrÃ¶st is the architectural key that unlocks Runa's "full-spectrum" promise. It elevates the compiler from a CPU-centric tool to a true universal translator for computation. By providing a single, high-level, verifiable representation for all forms of parallel hardware, BifrÃ¶st eliminates the fragmentation and complexity that plague modern high-performance computing, making the power of accelerators accessible to all Runa developers.

