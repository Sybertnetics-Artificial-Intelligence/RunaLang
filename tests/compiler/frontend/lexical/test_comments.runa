Note:
tests/compiler/frontend/lexical/test_comments.runa
Comprehensive tests for comment handling in the lexer
:End Note

Import Module "compiler/frontend/lexical/lexer" as Lexer
Import Module "compiler/frontend/lexical/token_stream" as TokenStream
Import Module "testing/assert" as Assert

@Reasoning
    Comments are essential for code documentation. Runa supports single-line
    comments with "Note:" and multi-line comment blocks with "Note:" ... ":End Note".
    These tests ensure comments are properly skipped and don't interfere with tokenization.
@End Reasoning

Note: =====================================================================
Note: SINGLE-LINE COMMENT TESTS
Note: =====================================================================

Process called "test_single_line_comments" returns Nothing:
    Note: Test single-line comment
    Let source be "Let x be 5  Note: This is a comment"
    Let tokens be Lexer.tokenize(source, "developer")
    
    Note: Should only have Let, x, be, 5 tokens
    Assert.equals(TokenStream.get_token_count(tokens), 4)
    Assert.equals(TokenStream.get_token_at(tokens, 0).token_type, "KEYWORD")
    Assert.equals(TokenStream.get_token_at(tokens, 0).value, "Let")
    Assert.equals(TokenStream.get_token_at(tokens, 1).value, "x")
    Assert.equals(TokenStream.get_token_at(tokens, 2).value, "be")
    Assert.equals(TokenStream.get_token_at(tokens, 3).value, "5")
    
    Note: Test comment at beginning of line
    Let source2 be "Note: Start with comment\nLet y be 10"
    Let tokens2 be Lexer.tokenize(source2, "developer")
    Assert.equals(TokenStream.get_token_at(tokens2, 0).value, "Let")
    Assert.equals(TokenStream.get_token_at(tokens2, 1).value, "y")
    
    Note: Test comment with special characters
    Let source3 be "Let z be 3  Note: Special chars !@#$%^&*()"
    Let tokens3 be Lexer.tokenize(source3, "developer")
    Assert.equals(TokenStream.get_token_count(tokens3), 4)
End Process

Note: =====================================================================
Note: MULTI-LINE COMMENT BLOCK TESTS
Note: =====================================================================

Process called "test_multi_line_comment_blocks" returns Nothing:
    Note: Test multi-line comment block
    Let source be "Let x be 5\nNote:\nThis is a multi-line\ncomment block\n:End Note\nLet y be 10"
    Let tokens be Lexer.tokenize(source, "developer")
    
    Note: Should only have Let x be 5 Let y be 10 tokens
    Assert.equals(TokenStream.get_token_count(tokens), 8)
    Assert.equals(TokenStream.get_token_at(tokens, 0).value, "Let")
    Assert.equals(TokenStream.get_token_at(tokens, 1).value, "x")
    Assert.equals(TokenStream.get_token_at(tokens, 4).value, "Let")
    Assert.equals(TokenStream.get_token_at(tokens, 5).value, "y")
    
    Note: Test nested content in comment block
    Let source2 be "Note:\nLine 1\nLine 2\nLine 3\n:End Note\nLet z be 15"
    Let tokens2 be Lexer.tokenize(source2, "developer")
    Assert.equals(TokenStream.get_token_at(tokens2, 0).value, "Let")
    Assert.equals(TokenStream.get_token_at(tokens2, 1).value, "z")
    
    Note: Test comment block with code-like content
    Let source3 be "Note:\nLet fake be 123\nIf this then that\n:End Note\nLet real be 456"
    Let tokens3 be Lexer.tokenize(source3, "developer")
    Assert.equals(TokenStream.get_token_at(tokens3, 0).value, "Let")
    Assert.equals(TokenStream.get_token_at(tokens3, 1).value, "real")
    Assert.equals(TokenStream.get_token_at(tokens3, 3).value, "456")
End Process

Note: =====================================================================
Note: COMMENT BLOCK EDGE CASES
Note: =====================================================================

Process called "test_comment_block_edge_cases" returns Nothing:
    Note: Test :End Note must be on its own line
    Let source be "Note: This should be single line :End Note"
    Let tokens be Lexer.tokenize(source, "developer")
    Assert.equals(TokenStream.get_token_count(tokens), 0)  Note: All consumed as comment
    
    Note: Test multiple Note: before :End Note
    Let source2 be "Note:\nNote: Another note\nNote: Yet another\n:End Note\nLet x be 1"
    Let tokens2 be Lexer.tokenize(source2, "developer")
    Assert.equals(TokenStream.get_token_at(tokens2, 0).value, "Let")
    Assert.equals(TokenStream.get_token_at(tokens2, 1).value, "x")
    
    Note: Test empty comment block
    Let source3 be "Note:\n:End Note\nLet y be 2"
    Let tokens3 be Lexer.tokenize(source3, "developer")
    Assert.equals(TokenStream.get_token_at(tokens3, 0).value, "Let")
    Assert.equals(TokenStream.get_token_at(tokens3, 1).value, "y")
    
    Note: Test unclosed comment block (should treat as single-line comments)
    Let source4 be "Note:\nThis has no end\nLet z be 3"
    Let tokens4 be Lexer.tokenize(source4, "developer")
    Assert.equals(TokenStream.get_token_at(tokens4, 0).value, "Let")
    Assert.equals(TokenStream.get_token_at(tokens4, 1).value, "z")
End Process

Note: =====================================================================
Note: COMMENT POSITIONING TESTS
Note: =====================================================================

Process called "test_comment_positioning" returns Nothing:
    Note: Test inline comment after statement
    Let source be "Let x be 5  Note: Initialize x\nLet y be 10"
    Let tokens be Lexer.tokenize(source, "developer")
    Assert.equals(TokenStream.get_token_count(tokens), 8)
    
    Note: Test comment between tokens
    Let source2 be "Let Note: variable name\nx be 5"
    Let tokens2 be Lexer.tokenize(source2, "developer")
    Assert.equals(TokenStream.get_token_at(tokens2, 0).value, "Let")
    Assert.equals(TokenStream.get_token_at(tokens2, 1).value, "x")
    
    Note: Test multiple comments on same line
    Let source3 be "Let x Note: var Note: another\nbe 5"
    Let tokens3 be Lexer.tokenize(source3, "developer")
    Assert.equals(TokenStream.get_token_at(tokens3, 0).value, "Let")
    Assert.equals(TokenStream.get_token_at(tokens3, 1).value, "x")
    Assert.equals(TokenStream.get_token_at(tokens3, 2).value, "be")
End Process

Note: =====================================================================
Note: ANNOTATION BLOCK TESTS
Note: =====================================================================

Process called "test_annotation_blocks" returns Nothing:
    Note: Test @Reasoning annotation block
    Let source be "@Reasoning\nThis explains the logic\n@End Reasoning\nLet x be 5"
    Let tokens be Lexer.tokenize(source, "developer")
    
    Note: Annotations should be tokenized, not skipped like comments
    Assert.contains_token(tokens, "@Reasoning")
    Assert.contains_token(tokens, "@End")
    Assert.contains_token(tokens, "Reasoning")
    
    Note: Test other annotation types
    Let source2 be "@Implementation\nDetails here\n@End Implementation\nLet y be 10"
    Let tokens2 be Lexer.tokenize(source2, "developer")
    Assert.contains_token(tokens2, "@Implementation")
    Assert.contains_token(tokens2, "@End")
    
    Note: Ensure annotations are not confused with comments
    Let source3 be "Note: This is a comment\n@TestCases\nTest data\n@End TestCases"
    Let tokens3 be Lexer.tokenize(source3, "developer")
    Assert.not_contains_token(tokens3, "This")  Note: Comment content skipped
    Assert.contains_token(tokens3, "@TestCases")  Note: Annotation tokenized
End Process

Note: =====================================================================
Note: COMMENT CONTENT PRESERVATION TESTS
Note: =====================================================================

Process called "test_comment_content_preservation" returns Nothing:
    Note: Test that comment content doesn't affect tokenization
    Let source be "Let x be 5\nNote: Let y be 10\nLet z be 15"
    Let tokens be Lexer.tokenize(source, "developer")
    
    Note: Should not tokenize the commented "Let y be 10"
    Assert.equals(TokenStream.get_token_count(tokens), 8)
    Assert.not_contains_token(tokens, "y")
    Assert.contains_token(tokens, "x")
    Assert.contains_token(tokens, "z")
    
    Note: Test keywords in comments don't affect parsing
    Let source2 be "Note: If While For Process Type\nLet a be 1"
    Let tokens2 be Lexer.tokenize(source2, "developer")
    Assert.equals(TokenStream.get_token_at(tokens2, 0).value, "Let")
    Assert.equals(TokenStream.get_token_at(tokens2, 1).value, "a")
    
    Note: Test operators in comments
    Let source3 be "Note: + - * / = == != < >\nLet b be 2"
    Let tokens3 be Lexer.tokenize(source3, "developer")
    Assert.not_contains_token(tokens3, "+")
    Assert.not_contains_token(tokens3, "==")
End Process

Note: =====================================================================
Note: COMMENT INTERACTION WITH STRINGS
Note: =====================================================================

Process called "test_comments_with_strings" returns Nothing:
    Note: Test "Note:" inside a string is not a comment
    Let source be "Let msg be \"Note: This is in a string\""
    Let tokens be Lexer.tokenize(source, "developer")
    Assert.contains_token(tokens, "\"Note: This is in a string\"")
    
    Note: Test comment after string
    Let source2 be "Let text be \"Hello\"  Note: A greeting"
    Let tokens2 be Lexer.tokenize(source2, "developer")
    Assert.contains_token(tokens2, "\"Hello\"")
    Assert.not_contains_token(tokens2, "greeting")
    
    Note: Test string containing :End Note
    Let source3 be "Let s be \"Use :End Note to close blocks\""
    Let tokens3 be Lexer.tokenize(source3, "developer")
    Assert.contains_token(tokens3, "\"Use :End Note to close blocks\"")
    
    Note: Test comment containing quotes
    Let source4 be "Note: Use \"quotes\" for strings\nLet x be 1"
    Let tokens4 be Lexer.tokenize(source4, "developer")
    Assert.not_contains_token(tokens4, "quotes")
    Assert.contains_token(tokens4, "x")
End Process

Note: =====================================================================
Note: LINE AND COLUMN TRACKING WITH COMMENTS
Note: =====================================================================

Process called "test_line_column_tracking_with_comments" returns Nothing:
    Note: Test line numbers are correct after comments
    Let source be "Note: Comment\nLet x be 5\nNote: Another\nLet y be 10"
    Let tokens be Lexer.tokenize(source, "developer")
    
    Let let_token1 be TokenStream.find_first_token(tokens, "Let")
    Assert.equals(let_token1.line, 2)  Note: After first comment
    
    Let let_token2 be TokenStream.find_nth_token(tokens, "Let", 2)
    Assert.equals(let_token2.line, 4)  Note: After second comment
    
    Note: Test column positions after inline comments
    Let source2 be "Let x Note: comment\nbe 5"
    Let tokens2 be Lexer.tokenize(source2, "developer")
    
    Let be_token be TokenStream.find_first_token(tokens2, "be")
    Assert.equals(be_token.line, 2)
    Assert.equals(be_token.column, 1)
    
    Note: Test multi-line comment block line tracking
    Let source3 be "Note:\nLine 1\nLine 2\nLine 3\n:End Note\nLet z be 1"
    Let tokens3 be Lexer.tokenize(source3, "developer")
    
    Let let_token be TokenStream.find_first_token(tokens3, "Let")
    Assert.equals(let_token.line, 6)  Note: After 5-line comment block
End Process

Note: =====================================================================
Note: SPECIAL COMMENT PATTERNS
Note: =====================================================================

Process called "test_special_comment_patterns" returns Nothing:
    Note: Test annotation-style comments
    Let source be "Note: @Implementation This handles the calculation\nLet x be 5"
    Let tokens be Lexer.tokenize(source, "developer")
    Assert.not_contains_token(tokens, "@Implementation")
    Assert.contains_token(tokens, "x")
    
    Note: Test directive comments
    Let source2 be "Note: This code handles edge cases\nLet y be 10"
    Let tokens2 be Lexer.tokenize(source2, "developer")
    Assert.not_contains_token(tokens2, "edge")
    Assert.contains_token(tokens2, "y")
    
    Note: Test documentation-style comments
    Let source3 be "Note: @param x The input value\nNote: @returns The result\nProcess foo"
    Let tokens3 be Lexer.tokenize(source3, "developer")
    Assert.not_contains_token(tokens3, "@param")
    Assert.not_contains_token(tokens3, "@returns")
    Assert.contains_token(tokens3, "Process")
    Assert.contains_token(tokens3, "foo")
End Process

Note: =====================================================================
Note: TEST RUNNER
Note: =====================================================================

Process called "run_all_comment_tests" returns Nothing:
    @TestCases
        - Single-line comments with "Note:"
        - Multi-line comment blocks with "Note:" ... ":End Note"
        - Comment block edge cases (unclosed, empty, nested Note:)
        - Comment positioning (inline, between tokens)
        - Annotation blocks (not treated as comments)
        - Comment content preservation
        - Interaction with string literals
        - Line and column tracking with comments
        - Special comment patterns (annotations, documentation)
    @End TestCases
    
    test_single_line_comments()
    test_multi_line_comment_blocks()
    test_comment_block_edge_cases()
    test_comment_positioning()
    test_annotation_blocks()
    test_comment_content_preservation()
    test_comments_with_strings()
    test_line_column_tracking_with_comments()
    test_special_comment_patterns()
    
    Print("All comment tests passed!")
End Process