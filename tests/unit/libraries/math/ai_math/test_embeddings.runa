Note: Comprehensive Unit Tests for Embedding Operations Module
Note: Tests word embeddings (Word2Vec, GloVe, FastText), sentence embeddings,
Note: positional embeddings, and various embedding manipulation techniques.
Note: Validates lookup operations, similarity computations, and embedding properties.

Import "math/ai_math/embeddings" as Embeddings
Import "math/core/operations" as MathOps
Import "math/engine/linalg/core" as LinAlg
Import "dev/debug/errors/core" as Errors
Import "data/collections/core/map" as MapOps

Note: ===== Test Framework =====

Type called "TestResult":
    test_name as String
    passed as Boolean
    error_message as String
    execution_time as String
    expected_value as String
    actual_value as String

Type called "TestSuite":
    suite_name as String
    total_tests as Integer
    passed_tests as Integer
    failed_tests as Integer
    results as List[TestResult]

Note: ===== Test Helper Functions =====

Process called "assert_equals_float" that takes actual as String, expected as String, tolerance as String, test_name as String returns TestResult:
    Note: Assert that two floating point values are equal within tolerance
    
    Let diff_result be MathOps.subtract(actual, expected, 15)
    If diff_result.overflow_occurred:
        Return TestResult with test_name: test_name, passed: false, error_message: "Overflow in difference calculation", execution_time: "0", expected_value: expected, actual_value: actual
    
    Let abs_diff be MathOps.absolute_value(diff_result.result_value)
    Let comparison be MathOps.compare(abs_diff.result_value, tolerance)
    
    If comparison <= 0:
        Return TestResult with test_name: test_name, passed: true, error_message: "", execution_time: "0", expected_value: expected, actual_value: actual
    Otherwise:
        Return TestResult with test_name: test_name, passed: false, error_message: "Values differ by more than tolerance", execution_time: "0", expected_value: expected, actual_value: actual

Process called "assert_equals_int" that takes actual as Integer, expected as Integer, test_name as String returns TestResult:
    Note: Assert that two integers are equal
    
    If actual == expected:
        Return TestResult with test_name: test_name, passed: true, error_message: "", execution_time: "0", expected_value: expected.to_string(), actual_value: actual.to_string()
    Otherwise:
        Return TestResult with test_name: test_name, passed: false, error_message: "Integer values do not match", execution_time: "0", expected_value: expected.to_string(), actual_value: actual.to_string()

Process called "assert_matrix_equals" that takes actual as Matrix[Float], expected as Matrix[Float], tolerance as String, test_name as String returns TestResult:
    Note: Assert that two matrices are equal within tolerance
    
    If actual.rows != expected.rows or actual.columns != expected.columns:
        Return TestResult with test_name: test_name, passed: false, error_message: "Matrix dimensions do not match", execution_time: "0", expected_value: "Matrix dimensions mismatch", actual_value: "Matrix dimensions mismatch"
    
    Let i be 0
    While i < actual.rows:
        Let j be 0
        While j < actual.columns:
            Let actual_val be actual.entries.get(i).get(j)
            Let expected_val be expected.entries.get(i).get(j)
            
            Let element_test be assert_equals_float(actual_val, expected_val, tolerance, test_name + " element check")
            If not element_test.passed:
                Return element_test
            Set j to j + 1
        Set i to i + 1
    
    Return TestResult with test_name: test_name, passed: true, error_message: "", execution_time: "0", expected_value: "Matrix match", actual_value: "Matrix match"

Process called "assert_vector_equals" that takes actual as Vector[Float], expected as Vector[Float], tolerance as String, test_name as String returns TestResult:
    Note: Assert that two vectors are equal within tolerance
    
    If actual.dimension != expected.dimension:
        Return TestResult with test_name: test_name, passed: false, error_message: "Vector dimensions do not match", execution_time: "0", expected_value: "Vector dimensions mismatch", actual_value: "Vector dimensions mismatch"
    
    Let i be 0
    While i < actual.dimension:
        Let actual_val be actual.components.get(i)
        Let expected_val be expected.components.get(i)
        
        Let element_test be assert_equals_float(actual_val, expected_val, tolerance, test_name + " element check")
        If not element_test.passed:
            Return element_test
        Set i to i + 1
    
    Return TestResult with test_name: test_name, passed: true, error_message: "", execution_time: "0", expected_value: "Vector match", actual_value: "Vector match"

Process called "create_test_vector_int" that takes values as List[Integer] returns Vector[Integer]:
    Note: Create integer vector from list
    Return LinAlg.create_vector_int(values)

Process called "create_test_vector_float" that takes values as List[String] returns Vector[Float]:
    Note: Create float vector from string list
    Return LinAlg.create_vector(values, "float")

Process called "create_test_matrix" that takes rows as Integer, cols as Integer, pattern as String returns Matrix[Float]:
    Note: Create test matrix with specified pattern
    
    Let entries be List[List[String]]()
    
    If pattern == "identity":
        Let i be 0
        While i < rows:
            Let row be List[String]()
            Let j be 0
            While j < cols:
                If i == j:
                    Call row.add("1.0")
                Otherwise:
                    Call row.add("0.0")
                Set j to j + 1
            Call entries.add(row)
            Set i to i + 1
    Otherwise If pattern == "ones":
        Let i be 0
        While i < rows:
            Let row be List[String]()
            Let j be 0
            While j < cols:
                Call row.add("1.0")
                Set j to j + 1
            Call entries.add(row)
            Set i to i + 1
    Otherwise If pattern == "sequential":
        Let value be 1
        Let i be 0
        While i < rows:
            Let row be List[String]()
            Let j be 0
            While j < cols:
                Call row.add(value.to_string())
                Set value to value + 1
                Set j to j + 1
            Call entries.add(row)
            Set i to i + 1
    Otherwise If pattern == "small_values":
        Let value be 0.1
        Let i be 0
        While i < rows:
            Let row be List[String]()
            Let j be 0
            While j < cols:
                Call row.add(value.to_string())
                Set value to value + 0.1
                Set j to j + 1
            Call entries.add(row)
            Set i to i + 1
    Otherwise:
        Note: Default to zeros
        Let i be 0
        While i < rows:
            Let row be List[String]()
            Let j be 0
            While j < cols:
                Call row.add("0.0")
                Set j to j + 1
            Call entries.add(row)
            Set i to i + 1
    
    Return LinAlg.create_matrix(entries, "float")

Note: ===== Embedding Matrix Tests =====

Process called "test_create_embedding_matrix" that takes no parameters returns TestResult:
    Note: Test creation of embedding matrix
    
    Try:
        Let vocab_size be 100
        Let embedding_dim be 50
        
        Let config be Embeddings.EmbeddingConfig with vocab_size: vocab_size, embedding_dim: embedding_dim, padding_idx: None, max_norm: None, norm_type: 2.0, scale_grad_by_freq: false, sparse: false
        
        Let embedding_matrix be Embeddings.create_embedding_matrix(vocab_size, embedding_dim, config)
        
        Note: Check matrix dimensions
        If embedding_matrix.embeddings.rows != vocab_size:
            Return TestResult with test_name: "test_create_embedding_matrix", passed: false, error_message: "Embedding matrix rows incorrect", execution_time: "0", expected_value: vocab_size.to_string(), actual_value: embedding_matrix.embeddings.rows.to_string()
        
        If embedding_matrix.embeddings.columns != embedding_dim:
            Return TestResult with test_name: "test_create_embedding_matrix", passed: false, error_message: "Embedding matrix columns incorrect", execution_time: "0", expected_value: embedding_dim.to_string(), actual_value: embedding_matrix.embeddings.columns.to_string()
        
        Note: Check that vocabulary mappings were created
        If embedding_matrix.vocab.size() != vocab_size:
            Return TestResult with test_name: "test_create_embedding_matrix", passed: false, error_message: "Vocabulary size incorrect", execution_time: "0", expected_value: vocab_size.to_string(), actual_value: embedding_matrix.vocab.size().to_string()
        
        Note: Check that embeddings are not frozen by default
        If embedding_matrix.frozen:
            Return TestResult with test_name: "test_create_embedding_matrix", passed: false, error_message: "Embeddings should not be frozen by default", execution_time: "0", expected_value: "false", actual_value: "true"
        
        Return TestResult with test_name: "test_create_embedding_matrix", passed: true, error_message: "", execution_time: "0", expected_value: "Valid embedding matrix", actual_value: "Valid embedding matrix"
    
    Catch error:
        Return TestResult with test_name: "test_create_embedding_matrix", passed: false, error_message: "Exception: " + error.message, execution_time: "0", expected_value: "No exception", actual_value: "Exception thrown"

Process called "test_embedding_lookup" that takes no parameters returns TestResult:
    Note: Test embedding lookup functionality
    
    Try:
        Let vocab_size be 10
        Let embedding_dim be 5
        
        Let config be Embeddings.EmbeddingConfig with vocab_size: vocab_size, embedding_dim: embedding_dim, padding_idx: None, max_norm: None, norm_type: 2.0, scale_grad_by_freq: false, sparse: false
        
        Let embedding_matrix be Embeddings.create_embedding_matrix(vocab_size, embedding_dim, config)
        
        Note: Create indices to lookup
        Let index_values be List[Integer]()
        Call index_values.add(0)
        Call index_values.add(2)
        Call index_values.add(5)
        Let indices be create_test_vector_int(index_values)
        
        Let lookup_result be Embeddings.embedding_lookup(embedding_matrix, indices)
        
        Note: Check result dimensions
        If lookup_result.rows != 3:
            Return TestResult with test_name: "test_embedding_lookup", passed: false, error_message: "Lookup result rows incorrect", execution_time: "0", expected_value: "3", actual_value: lookup_result.rows.to_string()
        
        If lookup_result.columns != embedding_dim:
            Return TestResult with test_name: "test_embedding_lookup", passed: false, error_message: "Lookup result columns incorrect", execution_time: "0", expected_value: embedding_dim.to_string(), actual_value: lookup_result.columns.to_string()
        
        Note: Check that lookup returns correct embeddings
        Let first_embedding be lookup_result.entries.get(0)
        Let original_first be embedding_matrix.embeddings.entries.get(0)
        
        Let i be 0
        While i < embedding_dim:
            Let lookup_val be first_embedding.get(i)
            Let original_val be original_first.get(i)
            If lookup_val != original_val:
                Return TestResult with test_name: "test_embedding_lookup", passed: false, error_message: "Lookup values do not match original", execution_time: "0", expected_value: "Matching values", actual_value: "Mismatched values"
            Set i to i + 1
        
        Return TestResult with test_name: "test_embedding_lookup", passed: true, error_message: "", execution_time: "0", expected_value: "Valid embedding lookup", actual_value: "Valid embedding lookup"
    
    Catch error:
        Return TestResult with test_name: "test_embedding_lookup", passed: false, error_message: "Exception: " + error.message, execution_time: "0", expected_value: "No exception", actual_value: "Exception thrown"

Process called "test_embedding_lookup_out_of_bounds" that takes no parameters returns TestResult:
    Note: Test embedding lookup with invalid indices
    
    Try:
        Let vocab_size be 5
        Let embedding_dim be 3
        
        Let config be Embeddings.EmbeddingConfig with vocab_size: vocab_size, embedding_dim: embedding_dim, padding_idx: None, max_norm: None, norm_type: 2.0, scale_grad_by_freq: false, sparse: false
        
        Let embedding_matrix be Embeddings.create_embedding_matrix(vocab_size, embedding_dim, config)
        
        Note: Create indices with out-of-bounds value
        Let invalid_index_values be List[Integer]()
        Call invalid_index_values.add(0)
        Call invalid_index_values.add(10)  Note: Out of bounds
        Let invalid_indices be create_test_vector_int(invalid_index_values)
        
        Try:
            Let lookup_result be Embeddings.embedding_lookup(embedding_matrix, invalid_indices)
            Return TestResult with test_name: "test_embedding_lookup_out_of_bounds", passed: false, error_message: "Should have thrown error for out-of-bounds index", execution_time: "0", expected_value: "Error", actual_value: "No error"
        Catch bounds_error:
            Note: Expected behavior
            Return TestResult with test_name: "test_embedding_lookup_out_of_bounds", passed: true, error_message: "", execution_time: "0", expected_value: "Bounds error thrown", actual_value: "Bounds error thrown"
    
    Catch error:
        Return TestResult with test_name: "test_embedding_lookup_out_of_bounds", passed: false, error_message: "Exception: " + error.message, execution_time: "0", expected_value: "Controlled bounds error", actual_value: "Unexpected exception"

Note: ===== Word2Vec Tests =====

Process called "test_skip_gram_loss" that takes no parameters returns TestResult:
    Note: Test skip-gram loss computation
    
    Try:
        Let vocab_size be 10
        Let embedding_dim be 5
        
        Let config be Embeddings.EmbeddingConfig with vocab_size: vocab_size, embedding_dim: embedding_dim, padding_idx: None, max_norm: None, norm_type: 2.0, scale_grad_by_freq: false, sparse: false
        
        Let embedding_matrix be Embeddings.create_embedding_matrix(vocab_size, embedding_dim, config)
        
        Let center_word be 3
        
        Let context_values be List[Integer]()
        Call context_values.add(1)
        Call context_values.add(2)
        Call context_values.add(4)
        Let context_words be create_test_vector_int(context_values)
        
        Let negative_values be List[Integer]()
        Call negative_values.add(6)
        Call negative_values.add(7)
        Let negative_samples be create_test_vector_int(negative_values)
        
        Let loss be Embeddings.skip_gram_loss(center_word, context_words, negative_samples, embedding_matrix)
        
        Note: Loss should be a positive finite value
        Let loss_float be Parse loss.to_string() as Float
        If loss_float <= 0.0:
            Return TestResult with test_name: "test_skip_gram_loss", passed: false, error_message: "Skip-gram loss should be positive", execution_time: "0", expected_value: "Positive value", actual_value: loss.to_string()
        
        If loss_float != loss_float:  Note: Check for NaN
            Return TestResult with test_name: "test_skip_gram_loss", passed: false, error_message: "Skip-gram loss is NaN", execution_time: "0", expected_value: "Finite value", actual_value: "NaN"
        
        Return TestResult with test_name: "test_skip_gram_loss", passed: true, error_message: "", execution_time: "0", expected_value: "Valid skip-gram loss", actual_value: "Valid skip-gram loss"
    
    Catch error:
        Return TestResult with test_name: "test_skip_gram_loss", passed: false, error_message: "Exception: " + error.message, execution_time: "0", expected_value: "No exception", actual_value: "Exception thrown"

Process called "test_cbow_loss" that takes no parameters returns TestResult:
    Note: Test continuous bag-of-words loss computation
    
    Try:
        Let vocab_size be 8
        Let embedding_dim be 4
        
        Let config be Embeddings.EmbeddingConfig with vocab_size: vocab_size, embedding_dim: embedding_dim, padding_idx: None, max_norm: None, norm_type: 2.0, scale_grad_by_freq: false, sparse: false
        
        Let embedding_matrix be Embeddings.create_embedding_matrix(vocab_size, embedding_dim, config)
        
        Let center_word be 2
        
        Let context_values be List[Integer]()
        Call context_values.add(0)
        Call context_values.add(1)
        Call context_values.add(3)
        Call context_values.add(4)
        Let context_words be create_test_vector_int(context_values)
        
        Let loss be Embeddings.cbow_loss(center_word, context_words, embedding_matrix)
        
        Note: Loss should be positive and finite
        Let loss_float be Parse loss.to_string() as Float
        If loss_float <= 0.0:
            Return TestResult with test_name: "test_cbow_loss", passed: false, error_message: "CBOW loss should be positive", execution_time: "0", expected_value: "Positive value", actual_value: loss.to_string()
        
        If loss_float != loss_float:
            Return TestResult with test_name: "test_cbow_loss", passed: false, error_message: "CBOW loss is NaN", execution_time: "0", expected_value: "Finite value", actual_value: "NaN"
        
        Return TestResult with test_name: "test_cbow_loss", passed: true, error_message: "", execution_time: "0", expected_value: "Valid CBOW loss", actual_value: "Valid CBOW loss"
    
    Catch error:
        Return TestResult with test_name: "test_cbow_loss", passed: false, error_message: "Exception: " + error.message, execution_time: "0", expected_value: "No exception", actual_value: "Exception thrown"

Process called "test_negative_sampling" that takes no parameters returns TestResult:
    Note: Test negative sampling for Word2Vec
    
    Try:
        Let positive_values be List[Integer]()
        Call positive_values.add(1)
        Call positive_values.add(3)
        Call positive_values.add(5)
        Let positive_samples be create_test_vector_int(positive_values)
        
        Let vocab_size be 20
        Let num_negative be 5
        
        Let negative_samples be Embeddings.negative_sampling(positive_samples, vocab_size, num_negative)
        
        Note: Check that correct number of negative samples returned
        If negative_samples.dimension != num_negative:
            Return TestResult with test_name: "test_negative_sampling", passed: false, error_message: "Wrong number of negative samples", execution_time: "0", expected_value: num_negative.to_string(), actual_value: negative_samples.dimension.to_string()
        
        Note: Check that all samples are within vocabulary bounds
        Let i be 0
        While i < negative_samples.dimension:
            Let sample_str be negative_samples.components.get(i)
            Let sample_idx be Parse sample_str as Integer
            
            If sample_idx < 0 or sample_idx >= vocab_size:
                Return TestResult with test_name: "test_negative_sampling", passed: false, error_message: "Negative sample out of bounds", execution_time: "0", expected_value: "[0, " + vocab_size.to_string() + ")", actual_value: sample_idx.to_string()
            Set i to i + 1
        
        Return TestResult with test_name: "test_negative_sampling", passed: true, error_message: "", execution_time: "0", expected_value: "Valid negative sampling", actual_value: "Valid negative sampling"
    
    Catch error:
        Return TestResult with test_name: "test_negative_sampling", passed: false, error_message: "Exception: " + error.message, execution_time: "0", expected_value: "No exception", actual_value: "Exception thrown"

Note: ===== GloVe Tests =====

Process called "test_glove_weighting_function" that takes no parameters returns TestResult:
    Note: Test GloVe weighting function
    
    Try:
        Let x_max be 100.0
        Let alpha be 0.75
        
        Note: Test with count below x_max
        Let low_count be 10.0
        Let low_weight be Embeddings.glove_weighting_function(low_count, x_max, alpha)
        
        Note: Weight should be (count/x_max)^alpha for count < x_max
        Let expected_low be MathOps.power("0.1", "0.75", 15)  Note: (10/100)^0.75
        If expected_low.overflow_occurred:
            Return TestResult with test_name: "test_glove_weighting_function", passed: false, error_message: "Overflow in expected weight calculation", execution_time: "0", expected_value: "No overflow", actual_value: "Overflow"
        
        Let low_weight_check be assert_equals_float(low_weight.to_string(), expected_low.result_value, "0.01", "low count weight")
        If not low_weight_check.passed:
            Return low_weight_check
        
        Note: Test with count above x_max (should be capped at 1.0)
        Let high_count be 200.0
        Let high_weight be Embeddings.glove_weighting_function(high_count, x_max, alpha)
        
        Let high_weight_check be assert_equals_float(high_weight.to_string(), "1.0", "0.01", "high count weight")
        If not high_weight_check.passed:
            Return high_weight_check
        
        Return TestResult with test_name: "test_glove_weighting_function", passed: true, error_message: "", execution_time: "0", expected_value: "Valid GloVe weighting", actual_value: "Valid GloVe weighting"
    
    Catch error:
        Return TestResult with test_name: "test_glove_weighting_function", passed: false, error_message: "Exception: " + error.message, execution_time: "0", expected_value: "No exception", actual_value: "Exception thrown"

Process called "test_build_cooccurrence_matrix" that takes no parameters returns TestResult:
    Note: Test co-occurrence matrix building
    
    Try:
        Note: Simple corpus: ["hello", "world"] ["hello", "there"]
        Let corpus be List[List[String]]()
        
        Let doc1 be List[String]()
        Call doc1.add("hello")
        Call doc1.add("world")
        Call corpus.add(doc1)
        
        Let doc2 be List[String]()
        Call doc2.add("hello")
        Call doc2.add("there")
        Call corpus.add(doc2)
        
        Let window_size be 2
        
        Note: Create vocabulary mapping
        Let vocab be MapOps.create_map()
        Call vocab.put("hello", 0)
        Call vocab.put("world", 1)
        Call vocab.put("there", 2)
        
        Let cooccurrence_matrix be Embeddings.build_cooccurrence_matrix(corpus, window_size, vocab)
        
        Note: Check matrix dimensions (should be vocab_size x vocab_size)
        If cooccurrence_matrix.rows != 3 or cooccurrence_matrix.columns != 3:
            Return TestResult with test_name: "test_build_cooccurrence_matrix", passed: false, error_message: "Co-occurrence matrix dimensions incorrect", execution_time: "0", expected_value: "3x3", actual_value: cooccurrence_matrix.rows.to_string() + "x" + cooccurrence_matrix.columns.to_string()
        
        Note: "hello" should co-occur with both "world" and "there"
        Let hello_world_count be cooccurrence_matrix.entries.get(0).get(1)
        Let hello_there_count be cooccurrence_matrix.entries.get(0).get(2)
        
        Let hello_world_float be Parse hello_world_count as Float
        Let hello_there_float be Parse hello_there_count as Float
        
        If hello_world_float <= 0.0 or hello_there_float <= 0.0:
            Return TestResult with test_name: "test_build_cooccurrence_matrix", passed: false, error_message: "Expected co-occurrences not found", execution_time: "0", expected_value: "Positive counts", actual_value: "Zero or negative counts"
        
        Return TestResult with test_name: "test_build_cooccurrence_matrix", passed: true, error_message: "", execution_time: "0", expected_value: "Valid co-occurrence matrix", actual_value: "Valid co-occurrence matrix"
    
    Catch error:
        Return TestResult with test_name: "test_build_cooccurrence_matrix", passed: false, error_message: "Exception: " + error.message, execution_time: "0", expected_value: "No exception", actual_value: "Exception thrown"

Note: ===== FastText Tests =====

Process called "test_character_ngrams" that takes no parameters returns TestResult:
    Note: Test character n-gram generation for FastText
    
    Try:
        Let word be "hello"
        Let min_n be 2
        Let max_n be 3
        
        Let ngrams be Embeddings.character_ngrams(word, min_n, max_n)
        
        Note: Should generate n-grams of length 2 and 3
        Note: Expected: "he", "el", "ll", "lo", "hel", "ell", "llo"
        Let expected_count be 7
        
        If ngrams.dimension != expected_count:
            Return TestResult with test_name: "test_character_ngrams", passed: false, error_message: "Wrong number of n-grams generated", execution_time: "0", expected_value: expected_count.to_string(), actual_value: ngrams.dimension.to_string()
        
        Note: Check that first n-gram is correct
        Let first_ngram be ngrams.components.get(0)
        If first_ngram != "he":
            Return TestResult with test_name: "test_character_ngrams", passed: false, error_message: "First n-gram incorrect", execution_time: "0", expected_value: "he", actual_value: first_ngram
        
        Return TestResult with test_name: "test_character_ngrams", passed: true, error_message: "", execution_time: "0", expected_value: "Valid character n-grams", actual_value: "Valid character n-grams"
    
    Catch error:
        Return TestResult with test_name: "test_character_ngrams", passed: false, error_message: "Exception: " + error.message, execution_time: "0", expected_value: "No exception", actual_value: "Exception thrown"

Process called "test_hash_ngrams" that takes no parameters returns TestResult:
    Note: Test n-gram hashing for FastText
    
    Try:
        Let ngram_strings be List[String]()
        Call ngram_strings.add("he")
        Call ngram_strings.add("el")
        Call ngram_strings.add("ll")
        Let ngrams be LinAlg.create_vector_string(ngram_strings)
        
        Let bucket_size be 1000
        
        Let hashed_ngrams be Embeddings.hash_ngrams(ngrams, bucket_size)
        
        Note: Check that correct number of hashes returned
        If hashed_ngrams.dimension != ngrams.dimension:
            Return TestResult with test_name: "test_hash_ngrams", passed: false, error_message: "Wrong number of hashed n-grams", execution_time: "0", expected_value: ngrams.dimension.to_string(), actual_value: hashed_ngrams.dimension.to_string()
        
        Note: Check that all hash values are within bucket range
        Let i be 0
        While i < hashed_ngrams.dimension:
            Let hash_str be hashed_ngrams.components.get(i)
            Let hash_val be Parse hash_str as Integer
            
            If hash_val < 0 or hash_val >= bucket_size:
                Return TestResult with test_name: "test_hash_ngrams", passed: false, error_message: "Hash value out of bucket range", execution_time: "0", expected_value: "[0, " + bucket_size.to_string() + ")", actual_value: hash_val.to_string()
            Set i to i + 1
        
        Return TestResult with test_name: "test_hash_ngrams", passed: true, error_message: "", execution_time: "0", expected_value: "Valid n-gram hashing", actual_value: "Valid n-gram hashing"
    
    Catch error:
        Return TestResult with test_name: "test_hash_ngrams", passed: false, error_message: "Exception: " + error.message, execution_time: "0", expected_value: "No exception", actual_value: "Exception thrown"

Note: ===== Sentence Embedding Tests =====

Process called "test_mean_pooling" that takes no parameters returns TestResult:
    Note: Test mean pooling for sentence embeddings
    
    Try:
        Note: Create matrix of word embeddings: 3 words x 4 dimensions
        Let word_embeddings_entries be List[List[String]]()
        
        Let word1 be List[String]()
        Call word1.add("1.0")
        Call word1.add("2.0")
        Call word1.add("3.0")
        Call word1.add("4.0")
        Call word_embeddings_entries.add(word1)
        
        Let word2 be List[String]()
        Call word2.add("2.0")
        Call word2.add("4.0")
        Call word2.add("6.0")
        Call word2.add("8.0")
        Call word_embeddings_entries.add(word2)
        
        Let word3 be List[String]()
        Call word3.add("3.0")
        Call word3.add("6.0")
        Call word3.add("9.0")
        Call word3.add("12.0")
        Call word_embeddings_entries.add(word3)
        
        Let word_embeddings be LinAlg.create_matrix(word_embeddings_entries, "float")
        
        Let pooled_embedding be Embeddings.mean_pooling(word_embeddings, None)
        
        Note: Check output dimension
        If pooled_embedding.dimension != 4:
            Return TestResult with test_name: "test_mean_pooling", passed: false, error_message: "Pooled embedding dimension incorrect", execution_time: "0", expected_value: "4", actual_value: pooled_embedding.dimension.to_string()
        
        Note: Check mean calculation: first dimension should be (1+2+3)/3 = 2.0
        Let first_dim_mean be pooled_embedding.components.get(0)
        Let expected_mean be "2.0"
        
        Let mean_check be assert_equals_float(first_dim_mean, expected_mean, "0.01", "mean pooling first dimension")
        If not mean_check.passed:
            Return mean_check
        
        Return TestResult with test_name: "test_mean_pooling", passed: true, error_message: "", execution_time: "0", expected_value: "Valid mean pooling", actual_value: "Valid mean pooling"
    
    Catch error:
        Return TestResult with test_name: "test_mean_pooling", passed: false, error_message: "Exception: " + error.message, execution_time: "0", expected_value: "No exception", actual_value: "Exception thrown"

Process called "test_max_pooling" that takes no parameters returns TestResult:
    Note: Test max pooling for sentence embeddings
    
    Try:
        Note: Same test matrix as mean pooling
        Let word_embeddings_entries be List[List[String]]()
        
        Let word1 be List[String]()
        Call word1.add("1.0")
        Call word1.add("2.0")
        Call word1.add("3.0")
        Call word1.add("4.0")
        Call word_embeddings_entries.add(word1)
        
        Let word2 be List[String]()
        Call word2.add("2.0")
        Call word2.add("4.0")
        Call word2.add("6.0")
        Call word2.add("8.0")
        Call word_embeddings_entries.add(word2)
        
        Let word3 be List[String]()
        Call word3.add("3.0")  Note: Max for first dimension
        Call word3.add("6.0")  Note: Max for second dimension
        Call word3.add("9.0")  Note: Max for third dimension
        Call word3.add("12.0") Note: Max for fourth dimension
        Call word_embeddings_entries.add(word3)
        
        Let word_embeddings be LinAlg.create_matrix(word_embeddings_entries, "float")
        
        Let pooled_embedding be Embeddings.max_pooling(word_embeddings, None)
        
        Note: Check output dimension
        If pooled_embedding.dimension != 4:
            Return TestResult with test_name: "test_max_pooling", passed: false, error_message: "Pooled embedding dimension incorrect", execution_time: "0", expected_value: "4", actual_value: pooled_embedding.dimension.to_string()
        
        Note: Check max calculation: first dimension should be max(1, 2, 3) = 3.0
        Let first_dim_max be pooled_embedding.components.get(0)
        Let expected_max be "3.0"
        
        Let max_check be assert_equals_float(first_dim_max, expected_max, "0.01", "max pooling first dimension")
        If not max_check.passed:
            Return max_check
        
        Note: Check fourth dimension: max(4, 8, 12) = 12.0
        Let fourth_dim_max be pooled_embedding.components.get(3)
        Let expected_fourth_max be "12.0"
        
        Let fourth_check be assert_equals_float(fourth_dim_max, expected_fourth_max, "0.01", "max pooling fourth dimension")
        If not fourth_check.passed:
            Return fourth_check
        
        Return TestResult with test_name: "test_max_pooling", passed: true, error_message: "", execution_time: "0", expected_value: "Valid max pooling", actual_value: "Valid max pooling"
    
    Catch error:
        Return TestResult with test_name: "test_max_pooling", passed: false, error_message: "Exception: " + error.message, execution_time: "0", expected_value: "No exception", actual_value: "Exception thrown"

Note: ===== Positional Embedding Tests =====

Process called "test_sinusoidal_position_embeddings" that takes no parameters returns TestResult:
    Note: Test sinusoidal positional embeddings
    
    Try:
        Let max_length be 10
        Let d_model be 6
        Let base be 10000.0
        
        Let pos_embeddings be Embeddings.sinusoidal_position_embeddings(max_length, d_model, base)
        
        Note: Check output dimensions
        If pos_embeddings.rows != max_length:
            Return TestResult with test_name: "test_sinusoidal_position_embeddings", passed: false, error_message: "Position embeddings rows incorrect", execution_time: "0", expected_value: max_length.to_string(), actual_value: pos_embeddings.rows.to_string()
        
        If pos_embeddings.columns != d_model:
            Return TestResult with test_name: "test_sinusoidal_position_embeddings", passed: false, error_message: "Position embeddings columns incorrect", execution_time: "0", expected_value: d_model.to_string(), actual_value: pos_embeddings.columns.to_string()
        
        Note: Check that different positions have different embeddings
        Let pos0_first_dim be pos_embeddings.entries.get(0).get(0)
        Let pos1_first_dim be pos_embeddings.entries.get(1).get(0)
        
        If pos0_first_dim == pos1_first_dim:
            Return TestResult with test_name: "test_sinusoidal_position_embeddings", passed: false, error_message: "Position embeddings should be different", execution_time: "0", expected_value: "Different values", actual_value: "Same values"
        
        Note: Check that values are within reasonable range for sin/cos
        Let sample_val be pos_embeddings.entries.get(0).get(0)
        Let sample_float be Parse sample_val as Float
        
        If sample_float < -1.1 or sample_float > 1.1:
            Return TestResult with test_name: "test_sinusoidal_position_embeddings", passed: false, error_message: "Position embedding values out of expected range", execution_time: "0", expected_value: "[-1, 1]", actual_value: sample_val
        
        Return TestResult with test_name: "test_sinusoidal_position_embeddings", passed: true, error_message: "", execution_time: "0", expected_value: "Valid sinusoidal position embeddings", actual_value: "Valid sinusoidal position embeddings"
    
    Catch error:
        Return TestResult with test_name: "test_sinusoidal_position_embeddings", passed: false, error_message: "Exception: " + error.message, execution_time: "0", expected_value: "No exception", actual_value: "Exception thrown"

Process called "test_learned_position_embeddings" that takes no parameters returns TestResult:
    Note: Test learned positional embeddings
    
    Try:
        Let max_length be 5
        Let d_model be 4
        
        Let pos_embeddings be Embeddings.learned_position_embeddings(max_length, d_model)
        
        Note: Check output dimensions
        If pos_embeddings.rows != max_length:
            Return TestResult with test_name: "test_learned_position_embeddings", passed: false, error_message: "Learned embeddings rows incorrect", execution_time: "0", expected_value: max_length.to_string(), actual_value: pos_embeddings.rows.to_string()
        
        If pos_embeddings.columns != d_model:
            Return TestResult with test_name: "test_learned_position_embeddings", passed: false, error_message: "Learned embeddings columns incorrect", execution_time: "0", expected_value: d_model.to_string(), actual_value: pos_embeddings.columns.to_string()
        
        Note: Check that embeddings are properly initialized (not all zeros)
        Let has_nonzero be false
        Let i be 0
        While i < max_length and not has_nonzero:
            Let j be 0
            While j < d_model and not has_nonzero:
                Let val be pos_embeddings.entries.get(i).get(j)
                Let val_float be Parse val as Float
                If val_float != 0.0:
                    Set has_nonzero to true
                Set j to j + 1
            Set i to i + 1
        
        If not has_nonzero:
            Return TestResult with test_name: "test_learned_position_embeddings", passed: false, error_message: "Learned embeddings should not be all zeros", execution_time: "0", expected_value: "Non-zero values", actual_value: "All zeros"
        
        Return TestResult with test_name: "test_learned_position_embeddings", passed: true, error_message: "", execution_time: "0", expected_value: "Valid learned position embeddings", actual_value: "Valid learned position embeddings"
    
    Catch error:
        Return TestResult with test_name: "test_learned_position_embeddings", passed: false, error_message: "Exception: " + error.message, execution_time: "0", expected_value: "No exception", actual_value: "Exception thrown"

Note: ===== Error Handling Tests =====

Process called "test_invalid_embedding_dimensions" that takes no parameters returns TestResult:
    Note: Test error handling for invalid dimensions
    
    Try:
        Let config be Embeddings.EmbeddingConfig with vocab_size: 0, embedding_dim: 10, padding_idx: None, max_norm: None, norm_type: 2.0, scale_grad_by_freq: false, sparse: false
        
        Try:
            Let embedding_matrix be Embeddings.create_embedding_matrix(0, 10, config)
            Return TestResult with test_name: "test_invalid_embedding_dimensions", passed: false, error_message: "Should have thrown error for zero vocab size", execution_time: "0", expected_value: "Error", actual_value: "No error"
        Catch dimension_error:
            Note: Expected behavior
            Pass
        
        Try:
            Let config2 be Embeddings.EmbeddingConfig with vocab_size: 10, embedding_dim: -5, padding_idx: None, max_norm: None, norm_type: 2.0, scale_grad_by_freq: false, sparse: false
            Let embedding_matrix be Embeddings.create_embedding_matrix(10, -5, config2)
            Return TestResult with test_name: "test_invalid_embedding_dimensions", passed: false, error_message: "Should have thrown error for negative embedding dim", execution_time: "0", expected_value: "Error", actual_value: "No error"
        Catch dimension_error2:
            Note: Expected behavior
            Pass
        
        Return TestResult with test_name: "test_invalid_embedding_dimensions", passed: true, error_message: "", execution_time: "0", expected_value: "Proper error handling", actual_value: "Proper error handling"
    
    Catch error:
        Return TestResult with test_name: "test_invalid_embedding_dimensions", passed: false, error_message: "Exception: " + error.message, execution_time: "0", expected_value: "Controlled errors only", actual_value: "Unexpected exception"

Note: ===== Test Suite Management =====

Process called "create_test_suite" that takes suite_name as String returns TestSuite:
    Note: Create a new test suite for organizing test results
    Return TestSuite with suite_name: suite_name, total_tests: 0, passed_tests: 0, failed_tests: 0, results: List[TestResult]()

Process called "add_test_result" that takes suite as TestSuite, result as TestResult returns TestSuite:
    Note: Add a test result to the test suite
    
    Call suite.results.add(result)
    Set suite.total_tests to suite.total_tests + 1
    
    If result.passed:
        Set suite.passed_tests to suite.passed_tests + 1
    Otherwise:
        Set suite.failed_tests to suite.failed_tests + 1
    
    Return suite

Process called "run_all_embedding_tests" that takes no parameters returns TestSuite:
    Note: Run all embedding tests and return comprehensive results
    
    Let suite be create_test_suite("Embedding Operations Test Suite")
    
    Note: Embedding matrix tests
    Set suite to add_test_result(suite, test_create_embedding_matrix())
    Set suite to add_test_result(suite, test_embedding_lookup())
    Set suite to add_test_result(suite, test_embedding_lookup_out_of_bounds())
    
    Note: Word2Vec tests
    Set suite to add_test_result(suite, test_skip_gram_loss())
    Set suite to add_test_result(suite, test_cbow_loss())
    Set suite to add_test_result(suite, test_negative_sampling())
    
    Note: GloVe tests
    Set suite to add_test_result(suite, test_glove_weighting_function())
    Set suite to add_test_result(suite, test_build_cooccurrence_matrix())
    
    Note: FastText tests
    Set suite to add_test_result(suite, test_character_ngrams())
    Set suite to add_test_result(suite, test_hash_ngrams())
    
    Note: Sentence embedding tests
    Set suite to add_test_result(suite, test_mean_pooling())
    Set suite to add_test_result(suite, test_max_pooling())
    
    Note: Positional embedding tests
    Set suite to add_test_result(suite, test_sinusoidal_position_embeddings())
    Set suite to add_test_result(suite, test_learned_position_embeddings())
    
    Note: Error handling tests
    Set suite to add_test_result(suite, test_invalid_embedding_dimensions())
    
    Return suite

Process called "print_test_results" that takes suite as TestSuite returns String:
    Note: Format test results for display
    
    Let output be "=== " + suite.suite_name + " ===" + "\n"
    Set output to output + "Total tests: " + suite.total_tests.to_string() + "\n"
    Set output to output + "Passed: " + suite.passed_tests.to_string() + "\n"
    Set output to output + "Failed: " + suite.failed_tests.to_string() + "\n\n"
    
    If suite.failed_tests > 0:
        Set output to output + "Failed tests:" + "\n"
        Let i be 0
        While i < suite.results.length:
            Let result be suite.results.get(i)
            If not result.passed:
                Set output to output + "- " + result.test_name + ": " + result.error_message + "\n"
            Set i to i + 1
    
    Let success_rate_num be suite.passed_tests * 100
    Let success_rate be success_rate_num / suite.total_tests
    Set output to output + "\nSuccess rate: " + success_rate.to_string() + "%"
    
    Return output

Note: ===== Main Test Runner =====

Process called "main" that takes no parameters returns Integer:
    Note: Main test runner for embedding operations module
    
    Display "Running comprehensive tests for embedding operations..."
    Display ""
    
    Let test_suite be run_all_embedding_tests()
    Let results_output be print_test_results(test_suite)
    
    Display results_output
    
    If test_suite.failed_tests == 0:
        Display ""
        Display "All embedding operation tests passed successfully!"
        Return 0
    Otherwise:
        Display ""
        Display "Some embedding operation tests failed. Please review the failures above."
        Return 1