Note:
Unit tests for math/discrete/automata.runa module
Testing finite automata, regular expressions, grammars, parsing algorithms,
and Turing machines with comprehensive coverage of all automata theory operations.
:End Note

Import "dev/test" as UnitTest
Import "collections" as Collections
Import "stdlib/math/discrete/automata" as Automata

Note: =====================================================================
Note: TEST DATA GENERATORS
Note: =====================================================================

Process called "create_test_dfa_even_zeros":
    Note: DFA accepting strings with even number of zeros
    Let states be List.from_array(["q0", "q1"])
    Let alphabet be List.from_array(["0", "1"])
    Let transitions be Dictionary.create()
    
    Let q0_trans be Dictionary.create()
    Dictionary.set(q0_trans, "0", "q1")
    Dictionary.set(q0_trans, "1", "q0")
    Dictionary.set(transitions, "q0", q0_trans)
    
    Let q1_trans be Dictionary.create()
    Dictionary.set(q1_trans, "0", "q0")
    Dictionary.set(q1_trans, "1", "q1")
    Dictionary.set(transitions, "q1", q1_trans)
    
    Let accept_states be List.from_array(["q0"])
    Return Automata.create_dfa(states, alphabet, transitions, "q0", accept_states)

Process called "create_test_nfa_ends_with_01":
    Note: NFA accepting strings ending with "01"
    Let states be List.from_array(["q0", "q1", "q2"])
    Let alphabet be List.from_array(["0", "1"])
    Let transitions be Dictionary.create()
    
    Let q0_trans be Dictionary.create()
    Dictionary.set(q0_trans, "0", List.from_array(["q0", "q1"]))
    Dictionary.set(q0_trans, "1", List.from_array(["q0"]))
    Dictionary.set(transitions, "q0", q0_trans)
    
    Let q1_trans be Dictionary.create()
    Dictionary.set(q1_trans, "0", List.create())
    Dictionary.set(q1_trans, "1", List.from_array(["q2"]))
    Dictionary.set(transitions, "q1", q1_trans)
    
    Let q2_trans be Dictionary.create()
    Dictionary.set(q2_trans, "0", List.create())
    Dictionary.set(q2_trans, "1", List.create())
    Dictionary.set(transitions, "q2", q2_trans)
    
    Let accept_states be List.from_array(["q2"])
    Return Automata.create_nfa(states, alphabet, transitions, "q0", accept_states)

Process called "create_test_epsilon_nfa":
    Note: ε-NFA with epsilon transitions
    Let states be List.from_array(["q0", "q1", "q2"])
    Let alphabet be List.from_array(["a", "b"])
    Let transitions be Dictionary.create()
    
    Let q0_trans be Dictionary.create()
    Dictionary.set(q0_trans, "a", List.from_array(["q1"]))
    Dictionary.set(q0_trans, "b", List.create())
    Dictionary.set(q0_trans, "ε", List.from_array(["q2"]))
    Dictionary.set(transitions, "q0", q0_trans)
    
    Let q1_trans be Dictionary.create()
    Dictionary.set(q1_trans, "a", List.create())
    Dictionary.set(q1_trans, "b", List.from_array(["q2"]))
    Dictionary.set(q1_trans, "ε", List.create())
    Dictionary.set(transitions, "q1", q1_trans)
    
    Let q2_trans be Dictionary.create()
    Dictionary.set(q2_trans, "a", List.create())
    Dictionary.set(q2_trans, "b", List.create())
    Dictionary.set(q2_trans, "ε", List.create())
    Dictionary.set(transitions, "q2", q2_trans)
    
    Let accept_states be List.from_array(["q2"])
    Return Automata.create_epsilon_nfa(states, alphabet, transitions, "q0", accept_states)

Process called "create_test_context_free_grammar":
    Note: Context-free grammar for balanced parentheses
    Let non_terminals be List.from_array(["S"])
    Let terminals be List.from_array(["(", ")"])
    Let productions be Dictionary.create()
    
    Let s_productions be List.create()
    List.push(s_productions, List.from_array(["(", "S", ")"]))
    List.push(s_productions, List.from_array(["S", "S"]))
    List.push(s_productions, List.from_array([]))
    Dictionary.set(productions, "S", s_productions)
    
    Return Automata.create_context_free_grammar(non_terminals, terminals, productions, "S")

Process called "create_test_strings":
    Let strings be List.create()
    List.push(strings, "")
    List.push(strings, "0")
    List.push(strings, "1")
    List.push(strings, "01")
    List.push(strings, "10")
    List.push(strings, "00")
    List.push(strings, "11")
    List.push(strings, "001")
    List.push(strings, "101")
    List.push(strings, "0011")
    List.push(strings, "1010")
    Return strings

Note: =====================================================================
Note: ASSERTION HELPERS
Note: =====================================================================

Process called "assert_automaton_equals" that takes actual as FiniteAutomaton, expected as FiniteAutomaton, message as String:
    UnitTest.assert_equals(actual.states, expected.states, message + " - states mismatch")
    UnitTest.assert_equals(actual.alphabet, expected.alphabet, message + " - alphabet mismatch")
    UnitTest.assert_equals(actual.start_state, expected.start_state, message + " - start state mismatch")
    UnitTest.assert_equals(actual.accept_states, expected.accept_states, message + " - accept states mismatch")
    UnitTest.assert_equals(actual.automaton_type, expected.automaton_type, message + " - type mismatch")
    UnitTest.assert_equals(actual.is_deterministic, expected.is_deterministic, message + " - determinism mismatch")

Process called "assert_grammar_equals" that takes actual as Grammar, expected as Grammar, message as String:
    UnitTest.assert_equals(actual.non_terminals, expected.non_terminals, message + " - non-terminals mismatch")
    UnitTest.assert_equals(actual.terminals, expected.terminals, message + " - terminals mismatch")
    UnitTest.assert_equals(actual.start_symbol, expected.start_symbol, message + " - start symbol mismatch")
    UnitTest.assert_equals(actual.grammar_type, expected.grammar_type, message + " - grammar type mismatch")
    UnitTest.assert_equals(actual.is_context_free, expected.is_context_free, message + " - context-free flag mismatch")

Process called "assert_regex_equals" that takes actual as RegularExpression, expected as RegularExpression, message as String:
    UnitTest.assert_equals(actual.pattern, expected.pattern, message + " - pattern mismatch")
    UnitTest.assert_equals(actual.alphabet, expected.alphabet, message + " - alphabet mismatch")
    UnitTest.assert_equals(actual.is_valid, expected.is_valid, message + " - validity mismatch")

Process called "assert_parse_tree_valid" that takes tree as ParseTree, message as String:
    UnitTest.assert_true(tree.is_valid_derivation, message + " - parse tree should be valid")
    UnitTest.assert_false(String.is_empty(tree.root_symbol), message + " - root symbol should not be empty")
    UnitTest.assert_false(List.is_empty(tree.leaf_symbols), message + " - should have leaf symbols")

Note: =====================================================================
Note: DFA CREATION AND BASIC OPERATIONS TESTS
Note: =====================================================================

Process called "test_create_dfa_basic":
    Let dfa be create_test_dfa_even_zeros()
    UnitTest.assert_equals(dfa.automaton_type, "DFA", "Should be DFA type")
    UnitTest.assert_true(dfa.is_deterministic, "DFA should be deterministic")
    UnitTest.assert_equals(List.size(dfa.states), 2, "Should have 2 states")
    UnitTest.assert_equals(List.size(dfa.alphabet), 2, "Should have 2 symbols")

Process called "test_create_dfa_invalid_inputs":
    Let empty_states be List.create()
    Let alphabet be List.from_array(["0", "1"])
    Let transitions be Dictionary.create()
    
    Try:
        Let invalid_dfa be Automata.create_dfa(empty_states, alphabet, transitions, "q0", List.create())
        UnitTest.fail("Should throw error for empty states")
    Catch error:
        UnitTest.assert_true(True, "Correctly rejected empty states")

Process called "test_simulate_dfa_acceptance":
    Let dfa be create_test_dfa_even_zeros()
    
    UnitTest.assert_true(Automata.simulate_dfa(dfa, ""), "Empty string has even zeros")
    UnitTest.assert_false(Automata.simulate_dfa(dfa, "0"), "Single zero is odd")
    UnitTest.assert_true(Automata.simulate_dfa(dfa, "00"), "Two zeros is even")
    UnitTest.assert_false(Automata.simulate_dfa(dfa, "000"), "Three zeros is odd")
    UnitTest.assert_true(Automata.simulate_dfa(dfa, "1010"), "Two zeros with ones is even")
    UnitTest.assert_false(Automata.simulate_dfa(dfa, "1001"), "Three zeros with ones is odd")

Process called "test_simulate_dfa_long_strings":
    Let dfa be create_test_dfa_even_zeros()
    Let long_even_string be "0011000011001100"
    Let long_odd_string be "001100001100110"
    
    UnitTest.assert_true(Automata.simulate_dfa(dfa, long_even_string), "Long string with even zeros should accept")
    UnitTest.assert_false(Automata.simulate_dfa(dfa, long_odd_string), "Long string with odd zeros should reject")

Note: =====================================================================
Note: NFA CREATION AND SIMULATION TESTS
Note: =====================================================================

Process called "test_create_nfa_basic":
    Let nfa be create_test_nfa_ends_with_01()
    UnitTest.assert_equals(nfa.automaton_type, "NFA", "Should be NFA type")
    UnitTest.assert_false(nfa.is_deterministic, "NFA should not be deterministic")
    UnitTest.assert_equals(List.size(nfa.states), 3, "Should have 3 states")

Process called "test_simulate_nfa_acceptance":
    Let nfa be create_test_nfa_ends_with_01()
    
    UnitTest.assert_true(Automata.simulate_nfa(nfa, "01"), "Should accept '01'")
    UnitTest.assert_true(Automata.simulate_nfa(nfa, "001"), "Should accept '001'")
    UnitTest.assert_true(Automata.simulate_nfa(nfa, "101"), "Should accept '101'")
    UnitTest.assert_true(Automata.simulate_nfa(nfa, "1101"), "Should accept '1101'")
    UnitTest.assert_false(Automata.simulate_nfa(nfa, ""), "Should reject empty string")
    UnitTest.assert_false(Automata.simulate_nfa(nfa, "0"), "Should reject '0'")
    UnitTest.assert_false(Automata.simulate_nfa(nfa, "1"), "Should reject '1'")
    UnitTest.assert_false(Automata.simulate_nfa(nfa, "00"), "Should reject '00'")
    UnitTest.assert_false(Automata.simulate_nfa(nfa, "11"), "Should reject '11'")

Process called "test_nfa_nondeterminism":
    Let nfa be create_test_nfa_ends_with_01()
    Let test_strings be create_test_strings()
    
    For each string in test_strings:
        Let result1 be Automata.simulate_nfa(nfa, string)
        Let result2 be Automata.simulate_nfa(nfa, string)
        UnitTest.assert_equals(result1, result2, "NFA simulation should be deterministic in result")

Note: =====================================================================
Note: EPSILON-NFA TESTS
Note: =====================================================================

Process called "test_create_epsilon_nfa":
    Let epsilon_nfa be create_test_epsilon_nfa()
    UnitTest.assert_equals(epsilon_nfa.automaton_type, "ε-NFA", "Should be ε-NFA type")
    UnitTest.assert_false(epsilon_nfa.is_deterministic, "ε-NFA should not be deterministic")

Process called "test_eliminate_epsilon_transitions":
    Let epsilon_nfa be create_test_epsilon_nfa()
    Let nfa be Automata.eliminate_epsilon_transitions(epsilon_nfa)
    
    UnitTest.assert_equals(nfa.automaton_type, "NFA", "Should convert to NFA")
    UnitTest.assert_false(nfa.is_deterministic, "Result should still be non-deterministic")

Process called "test_epsilon_closure_reachability":
    Let epsilon_nfa be create_test_epsilon_nfa()
    Let test_strings be List.from_array(["", "a", "b", "ab"])
    
    For each string in test_strings:
        Let result_with_epsilon be Automata.simulate_nfa(epsilon_nfa, string)
        Let nfa_no_epsilon be Automata.eliminate_epsilon_transitions(epsilon_nfa)
        Let result_without_epsilon be Automata.simulate_nfa(nfa_no_epsilon, string)
        UnitTest.assert_equals(result_with_epsilon, result_without_epsilon, "Epsilon elimination should preserve language")

Note: =====================================================================
Note: NFA TO DFA CONVERSION TESTS
Note: =====================================================================

Process called "test_nfa_to_dfa_subset_construction":
    Let nfa be create_test_nfa_ends_with_01()
    Let dfa be Automata.nfa_to_dfa_subset_construction(nfa)
    
    UnitTest.assert_equals(dfa.automaton_type, "DFA", "Should convert to DFA")
    UnitTest.assert_true(dfa.is_deterministic, "Result should be deterministic")
    UnitTest.assert_true(List.size(dfa.states) >= 3, "DFA should have at least original state count")

Process called "test_conversion_preserves_language":
    Let nfa be create_test_nfa_ends_with_01()
    Let dfa be Automata.nfa_to_dfa_subset_construction(nfa)
    Let test_strings be List.from_array(["", "0", "1", "01", "10", "001", "101", "1101", "0110"])
    
    For each string in test_strings:
        Let nfa_result be Automata.simulate_nfa(nfa, string)
        Let dfa_result be Automata.simulate_dfa(dfa, string)
        UnitTest.assert_equals(nfa_result, dfa_result, "NFA and DFA should accept same strings: " + string)

Process called "test_conversion_edge_cases":
    Let single_state_nfa be create_single_state_nfa()
    Let converted_dfa be Automata.nfa_to_dfa_subset_construction(single_state_nfa)
    UnitTest.assert_equals(List.size(converted_dfa.states), 1, "Single state NFA should convert to single state DFA")

Process called "create_single_state_nfa":
    Let states be List.from_array(["q0"])
    Let alphabet be List.from_array(["a"])
    Let transitions be Dictionary.create()
    
    Let q0_trans be Dictionary.create()
    Dictionary.set(q0_trans, "a", List.from_array(["q0"]))
    Dictionary.set(transitions, "q0", q0_trans)
    
    Let accept_states be List.from_array(["q0"])
    Return Automata.create_nfa(states, alphabet, transitions, "q0", accept_states)

Note: =====================================================================
Note: DFA MINIMIZATION TESTS
Note: =====================================================================

Process called "test_minimize_dfa_hopcroft":
    Let redundant_dfa be create_redundant_dfa()
    Let minimized be Automata.minimize_dfa_hopcroft(redundant_dfa)
    
    UnitTest.assert_true(List.size(minimized.states) <= List.size(redundant_dfa.states), "Minimized DFA should have fewer or equal states")
    UnitTest.assert_equals(minimized.automaton_type, "DFA", "Should remain DFA")
    UnitTest.assert_true(minimized.is_deterministic, "Should remain deterministic")

Process called "test_minimize_dfa_table_filling":
    Let redundant_dfa be create_redundant_dfa()
    Let minimized be Automata.minimize_dfa_table_filling(redundant_dfa)
    
    UnitTest.assert_true(List.size(minimized.states) <= List.size(redundant_dfa.states), "Table filling minimization should reduce states")
    UnitTest.assert_equals(minimized.automaton_type, "DFA", "Should remain DFA")

Process called "test_minimization_preserves_language":
    Let dfa be create_test_dfa_even_zeros()
    Let minimized_hopcroft be Automata.minimize_dfa_hopcroft(dfa)
    Let minimized_table be Automata.minimize_dfa_table_filling(dfa)
    Let test_strings be create_test_strings()
    
    For each string in test_strings:
        Let original_result be Automata.simulate_dfa(dfa, string)
        Let hopcroft_result be Automata.simulate_dfa(minimized_hopcroft, string)
        Let table_result be Automata.simulate_dfa(minimized_table, string)
        
        UnitTest.assert_equals(original_result, hopcroft_result, "Hopcroft minimization should preserve language for: " + string)
        UnitTest.assert_equals(original_result, table_result, "Table filling minimization should preserve language for: " + string)

Process called "create_redundant_dfa":
    Note: DFA with redundant states that can be minimized
    Let states be List.from_array(["q0", "q1", "q2", "q3"])
    Let alphabet be List.from_array(["a", "b"])
    Let transitions be Dictionary.create()
    
    Let q0_trans be Dictionary.create()
    Dictionary.set(q0_trans, "a", "q1")
    Dictionary.set(q0_trans, "b", "q2")
    Dictionary.set(transitions, "q0", q0_trans)
    
    Let q1_trans be Dictionary.create()
    Dictionary.set(q1_trans, "a", "q1")
    Dictionary.set(q1_trans, "b", "q2")
    Dictionary.set(transitions, "q1", q1_trans)
    
    Let q2_trans be Dictionary.create()
    Dictionary.set(q2_trans, "a", "q3")
    Dictionary.set(q2_trans, "b", "q2")
    Dictionary.set(transitions, "q2", q2_trans)
    
    Let q3_trans be Dictionary.create()
    Dictionary.set(q3_trans, "a", "q3")
    Dictionary.set(q3_trans, "b", "q2")
    Dictionary.set(transitions, "q3", q3_trans)
    
    Let accept_states be List.from_array(["q1", "q3"])
    Return Automata.create_dfa(states, alphabet, transitions, "q0", accept_states)

Note: =====================================================================
Note: REGULAR EXPRESSION TESTS
Note: =====================================================================

Process called "test_parse_regular_expression":
    Let pattern be "a*b+"
    Let regex be Automata.parse_regular_expression(pattern)
    
    UnitTest.assert_equals(regex.pattern, pattern, "Pattern should be preserved")
    UnitTest.assert_true(regex.is_valid, "Simple regex should be valid")
    UnitTest.assert_true(List.size(regex.alphabet) > 0, "Should have detected alphabet symbols")

Process called "test_regex_complex_patterns":
    Let patterns be List.from_array(["a*", "a+", "a?", "(a|b)*", "a*b*c*", "(ab)+", "a{2,5}", "[abc]*"])
    
    For each pattern in patterns:
        Let regex be Automata.parse_regular_expression(pattern)
        UnitTest.assert_true(regex.is_valid, "Pattern should be valid: " + pattern)
        UnitTest.assert_false(String.is_empty(regex.pattern), "Pattern should be preserved: " + pattern)

Process called "test_regex_to_nfa_thompson":
    Let regex be Automata.parse_regular_expression("a*b+")
    Let nfa be Automata.regex_to_nfa_thompson(regex)
    
    UnitTest.assert_equals(nfa.automaton_type, "ε-NFA", "Thompson construction produces ε-NFA")
    UnitTest.assert_false(nfa.is_deterministic, "Thompson NFA should be non-deterministic")
    UnitTest.assert_true(List.size(nfa.states) > 0, "Should have created states")

Process called "test_regex_to_dfa_direct":
    Let regex be Automata.parse_regular_expression("ab*")
    Let dfa be Automata.regex_to_dfa_direct(regex)
    
    UnitTest.assert_equals(dfa.automaton_type, "DFA", "Direct construction should produce DFA")
    UnitTest.assert_true(dfa.is_deterministic, "Direct DFA should be deterministic")

Process called "test_dfa_to_regex_conversion":
    Let dfa be create_test_dfa_even_zeros()
    Let regex be Automata.dfa_to_regex_state_elimination(dfa)
    
    UnitTest.assert_true(regex.is_valid, "Generated regex should be valid")
    UnitTest.assert_false(String.is_empty(regex.pattern), "Should generate non-empty pattern")

Note: =====================================================================
Note: LANGUAGE OPERATIONS TESTS
Note: =====================================================================

Process called "test_language_emptiness":
    Let empty_dfa be create_empty_language_dfa()
    Let non_empty_dfa be create_test_dfa_even_zeros()
    
    UnitTest.assert_true(Automata.check_language_emptiness(empty_dfa), "Empty language DFA should be detected")
    UnitTest.assert_false(Automata.check_language_emptiness(non_empty_dfa), "Non-empty language DFA should be detected")

Process called "test_generate_strings_in_language":
    Let dfa be create_test_dfa_even_zeros()
    Let generated_strings be Automata.generate_strings_in_language(dfa, 4)
    
    UnitTest.assert_true(List.size(generated_strings) > 0, "Should generate some strings")
    
    For each string in generated_strings:
        UnitTest.assert_true(Automata.simulate_dfa(dfa, string), "Generated string should be accepted: " + string)

Process called "test_automaton_union":
    Let dfa1 be create_test_dfa_even_zeros()
    Let dfa2 be create_dfa_odd_ones()
    Let union_dfa be Automata.compute_automaton_union(dfa1, dfa2)
    
    UnitTest.assert_equals(union_dfa.automaton_type, "DFA", "Union should produce DFA")
    UnitTest.assert_true(union_dfa.is_deterministic, "Union DFA should be deterministic")
    
    UnitTest.assert_true(Automata.simulate_dfa(union_dfa, "00"), "Union should accept even zeros")
    UnitTest.assert_true(Automata.simulate_dfa(union_dfa, "1"), "Union should accept odd ones")

Process called "test_automaton_intersection":
    Let dfa1 be create_universal_dfa()
    Let dfa2 be create_test_dfa_even_zeros()
    Let intersection_dfa be Automata.compute_automaton_intersection(dfa1, dfa2)
    
    Let test_strings be create_test_strings()
    For each string in test_strings:
        Let result1 be Automata.simulate_dfa(dfa1, string)
        Let result2 be Automata.simulate_dfa(dfa2, string)
        Let intersection_result be Automata.simulate_dfa(intersection_dfa, string)
        Let expected be result1 and result2
        UnitTest.assert_equals(intersection_result, expected, "Intersection should match logical AND for: " + string)

Process called "test_automaton_complement":
    Let dfa be create_test_dfa_even_zeros()
    Let complement_dfa be Automata.compute_automaton_complement(dfa)
    Let test_strings be create_test_strings()
    
    For each string in test_strings:
        Let original_result be Automata.simulate_dfa(dfa, string)
        Let complement_result be Automata.simulate_dfa(complement_dfa, string)
        UnitTest.assert_equals(original_result, not complement_result, "Complement should invert acceptance for: " + string)

Process called "create_empty_language_dfa":
    Let states be List.from_array(["q0"])
    Let alphabet be List.from_array(["a", "b"])
    Let transitions be Dictionary.create()
    
    Let q0_trans be Dictionary.create()
    Dictionary.set(q0_trans, "a", "q0")
    Dictionary.set(q0_trans, "b", "q0")
    Dictionary.set(transitions, "q0", q0_trans)
    
    Return Automata.create_dfa(states, alphabet, transitions, "q0", List.create())

Process called "create_dfa_odd_ones":
    Note: DFA accepting strings with odd number of ones
    Let states be List.from_array(["q0", "q1"])
    Let alphabet be List.from_array(["0", "1"])
    Let transitions be Dictionary.create()
    
    Let q0_trans be Dictionary.create()
    Dictionary.set(q0_trans, "0", "q0")
    Dictionary.set(q0_trans, "1", "q1")
    Dictionary.set(transitions, "q0", q0_trans)
    
    Let q1_trans be Dictionary.create()
    Dictionary.set(q1_trans, "0", "q1")
    Dictionary.set(q1_trans, "1", "q0")
    Dictionary.set(transitions, "q1", q1_trans)
    
    Let accept_states be List.from_array(["q1"])
    Return Automata.create_dfa(states, alphabet, transitions, "q0", accept_states)

Process called "create_universal_dfa":
    Note: DFA accepting all strings
    Let states be List.from_array(["q0"])
    Let alphabet be List.from_array(["0", "1"])
    Let transitions be Dictionary.create()
    
    Let q0_trans be Dictionary.create()
    Dictionary.set(q0_trans, "0", "q0")
    Dictionary.set(q0_trans, "1", "q0")
    Dictionary.set(transitions, "q0", q0_trans)
    
    Let accept_states be List.from_array(["q0"])
    Return Automata.create_dfa(states, alphabet, transitions, "q0", accept_states)

Note: =====================================================================
Note: CONTEXT-FREE GRAMMAR TESTS
Note: =====================================================================

Process called "test_create_context_free_grammar":
    Let grammar be create_test_context_free_grammar()
    UnitTest.assert_equals(grammar.grammar_type, "Context-Free", "Should be context-free")
    UnitTest.assert_true(grammar.is_context_free, "Should be marked as context-free")
    UnitTest.assert_equals(grammar.start_symbol, "S", "Start symbol should be S")

Process called "test_eliminate_left_recursion":
    Let recursive_grammar be create_left_recursive_grammar()
    Let eliminated_grammar be Automata.eliminate_left_recursion(recursive_grammar)
    
    UnitTest.assert_true(eliminated_grammar.is_context_free, "Should remain context-free")
    UnitTest.assert_false(has_left_recursion(eliminated_grammar), "Should eliminate left recursion")

Process called "test_compute_first_sets":
    Let grammar be create_test_context_free_grammar()
    Let first_sets be Automata.compute_first_sets(grammar)
    
    UnitTest.assert_true(Dictionary.has_key(first_sets, "S"), "Should compute FIRST for start symbol")
    Let s_first be Dictionary.get(first_sets, "S")
    UnitTest.assert_true(List.contains(s_first, "("), "FIRST(S) should contain '('")

Process called "test_compute_follow_sets":
    Let grammar be create_test_context_free_grammar()
    Let follow_sets be Automata.compute_follow_sets(grammar)
    
    UnitTest.assert_true(Dictionary.has_key(follow_sets, "S"), "Should compute FOLLOW for start symbol")
    Let s_follow be Dictionary.get(follow_sets, "S")
    UnitTest.assert_true(List.contains(s_follow, ")") or List.contains(s_follow, "$"), "FOLLOW(S) should contain ')' or end marker")

Process called "create_left_recursive_grammar":
    Let non_terminals be List.from_array(["A"])
    Let terminals be List.from_array(["a", "b"])
    Let productions be Dictionary.create()
    
    Let a_productions be List.create()
    List.push(a_productions, List.from_array(["A", "a"]))
    List.push(a_productions, List.from_array(["b"]))
    Dictionary.set(productions, "A", a_productions)
    
    Return Automata.create_context_free_grammar(non_terminals, terminals, productions, "A")

Process called "has_left_recursion" that takes grammar as Grammar returns Boolean:
    For each nt in grammar.non_terminals:
        If Dictionary.has_key(grammar.productions, nt):
            Let productions be Dictionary.get(grammar.productions, nt)
            For each production in productions:
                If not List.is_empty(production):
                    Let first_symbol be List.get(production, 0)
                    If String.equals(first_symbol, nt):
                        Return True
    Return False

Note: =====================================================================
Note: PARSING ALGORITHM TESTS
Note: =====================================================================

Process called "test_parse_cky_algorithm":
    Let grammar be create_cnf_grammar()
    Let input_string be "(())"
    Let parse_tree be Automata.parse_cky_algorithm(grammar, input_string)
    
    assert_parse_tree_valid(parse_tree, "CYK parsing should produce valid tree")
    UnitTest.assert_equals(parse_tree.root_symbol, "S", "Parse tree should have correct root")

Process called "test_parse_earley_algorithm":
    Let grammar be create_test_context_free_grammar()
    Let input_string be "()"
    Let parse_tree be Automata.parse_earley_algorithm(grammar, input_string)
    
    assert_parse_tree_valid(parse_tree, "Earley parsing should produce valid tree")
    UnitTest.assert_true(List.contains(parse_tree.leaf_symbols, "("), "Should contain opening parenthesis")
    UnitTest.assert_true(List.contains(parse_tree.leaf_symbols, ")"), "Should contain closing parenthesis")

Process called "test_parse_ll_recursive_descent":
    Let ll_grammar be create_ll_grammar()
    Let input_string be "a+b"
    Let parse_tree be Automata.parse_ll_recursive_descent(ll_grammar, input_string)
    
    assert_parse_tree_valid(parse_tree, "LL parsing should produce valid tree")
    UnitTest.assert_true(parse_tree.parse_complexity > 0, "Should have recorded complexity")

Process called "test_parse_lr_shift_reduce":
    Let lr_grammar be create_lr_grammar()
    Let input_string be "a*b"
    Let parse_tree be Automata.parse_lr_shift_reduce(lr_grammar, input_string)
    
    assert_parse_tree_valid(parse_tree, "LR parsing should produce valid tree")
    UnitTest.assert_false(List.is_empty(parse_tree.derivation_sequence), "Should have derivation sequence")

Process called "create_cnf_grammar":
    Note: Grammar in Chomsky Normal Form for CYK parsing
    Let non_terminals be List.from_array(["S", "A", "B"])
    Let terminals be List.from_array(["(", ")"])
    Let productions be Dictionary.create()
    
    Let s_productions be List.create()
    List.push(s_productions, List.from_array(["A", "B"]))
    List.push(s_productions, List.from_array(["S", "S"]))
    Dictionary.set(productions, "S", s_productions)
    
    Let a_productions be List.create()
    List.push(a_productions, List.from_array(["("]))
    Dictionary.set(productions, "A", a_productions)
    
    Let b_productions be List.create()
    List.push(b_productions, List.from_array([")"]))
    Dictionary.set(productions, "B", b_productions)
    
    Return Automata.create_context_free_grammar(non_terminals, terminals, productions, "S")

Process called "create_ll_grammar":
    Let non_terminals be List.from_array(["E", "T", "F"])
    Let terminals be List.from_array(["a", "b", "+", "*", "(", ")"])
    Let productions be Dictionary.create()
    
    Let e_productions be List.create()
    List.push(e_productions, List.from_array(["T", "+", "E"]))
    List.push(e_productions, List.from_array(["T"]))
    Dictionary.set(productions, "E", e_productions)
    
    Let t_productions be List.create()
    List.push(t_productions, List.from_array(["F"]))
    Dictionary.set(productions, "T", t_productions)
    
    Let f_productions be List.create()
    List.push(f_productions, List.from_array(["a"]))
    List.push(f_productions, List.from_array(["b"]))
    Dictionary.set(productions, "F", f_productions)
    
    Return Automata.create_context_free_grammar(non_terminals, terminals, productions, "E")

Process called "create_lr_grammar":
    Let non_terminals be List.from_array(["E", "T", "F"])
    Let terminals be List.from_array(["a", "b", "+", "*"])
    Let productions be Dictionary.create()
    
    Let e_productions be List.create()
    List.push(e_productions, List.from_array(["E", "+", "T"]))
    List.push(e_productions, List.from_array(["T"]))
    Dictionary.set(productions, "E", e_productions)
    
    Let t_productions be List.create()
    List.push(t_productions, List.from_array(["T", "*", "F"]))
    List.push(t_productions, List.from_array(["F"]))
    Dictionary.set(productions, "T", t_productions)
    
    Let f_productions be List.create()
    List.push(f_productions, List.from_array(["a"]))
    List.push(f_productions, List.from_array(["b"]))
    Dictionary.set(productions, "F", f_productions)
    
    Return Automata.create_context_free_grammar(non_terminals, terminals, productions, "E")

Note: =====================================================================
Note: TURING MACHINE TESTS
Note: =====================================================================

Process called "test_create_turing_machine":
    Let states be List.from_array(["q0", "q1", "qaccept", "qreject"])
    Let tape_alphabet be List.from_array(["0", "1", "B"])
    Let transitions be create_tm_transitions()
    Let tm be Automata.create_turing_machine(states, tape_alphabet, transitions, "q0", List.from_array(["qaccept"]), List.from_array(["qreject"]))
    
    UnitTest.assert_true(Dictionary.has_key(tm, "states"), "TM should have states")
    UnitTest.assert_true(Dictionary.has_key(tm, "tape_alphabet"), "TM should have tape alphabet")

Process called "test_simulate_turing_machine":
    Let tm be create_test_turing_machine()
    Let result be Automata.simulate_turing_machine(tm, "01", 100)
    
    UnitTest.assert_true(Dictionary.has_key(result, "final_state"), "Should have final state")
    UnitTest.assert_true(Dictionary.has_key(result, "steps_taken"), "Should count steps")
    UnitTest.assert_true(Dictionary.has_key(result, "halted"), "Should indicate if halted")

Process called "test_turing_machine_complexity":
    Let tm be create_test_turing_machine()
    Let input_classes be List.from_array(["unary_numbers", "binary_strings", "palindromes"])
    Let complexity be Automata.analyze_turing_machine_complexity(tm, input_classes)
    
    UnitTest.assert_true(Dictionary.has_key(complexity, "time_complexity"), "Should analyze time complexity")
    UnitTest.assert_true(Dictionary.has_key(complexity, "space_complexity"), "Should analyze space complexity")

Process called "create_tm_transitions":
    Let transitions be Dictionary.create()
    Note: Simple TM that accepts palindromes
    
    Let q0_transitions be Dictionary.create()
    Dictionary.set(q0_transitions, "0", Dictionary.from_entries([["next_state", "q1"], ["write_symbol", "B"], ["head_direction", "R"]]))
    Dictionary.set(q0_transitions, "1", Dictionary.from_entries([["next_state", "q1"], ["write_symbol", "B"], ["head_direction", "R"]]))
    Dictionary.set(transitions, "q0", q0_transitions)
    
    Return transitions

Process called "create_test_turing_machine":
    Let states be List.from_array(["q0", "q1", "qaccept", "qreject"])
    Let tape_alphabet be List.from_array(["0", "1", "B"])
    Let transitions be create_tm_transitions()
    Return Automata.create_turing_machine(states, tape_alphabet, transitions, "q0", List.from_array(["qaccept"]), List.from_array(["qreject"]))

Note: =====================================================================
Note: LANGUAGE THEORY AND CLASSIFICATION TESTS
Note: =====================================================================

Process called "test_classify_language_type":
    Let regular_grammar be create_regular_grammar()
    Let cf_grammar be create_test_context_free_grammar()
    
    Let regular_type be Automata.classify_language_type(regular_grammar)
    Let cf_type be Automata.classify_language_type(cf_grammar)
    
    UnitTest.assert_equals(regular_type, "Regular", "Should classify as regular")
    UnitTest.assert_equals(cf_type, "Context-Free", "Should classify as context-free")

Process called "test_language_regularity":
    Let regular_examples be List.from_array(["", "a", "aa", "aaa"])
    Let non_regular_examples be List.from_array(["ab", "aabb", "aaabbb"])
    Let result be Automata.test_language_regularity(regular_examples, non_regular_examples)
    
    UnitTest.assert_true(Dictionary.has_key(result, "is_regular"), "Should test regularity")
    UnitTest.assert_true(Dictionary.has_key(result, "evidence"), "Should provide evidence")

Process called "test_context_free_property":
    Let cf_examples be List.from_array(["", "()", "(())", "((()))", "()(())"])
    Let result be Automata.test_context_free_property(cf_examples)
    
    UnitTest.assert_true(Dictionary.has_key(result, "is_context_free"), "Should test context-free property")
    UnitTest.assert_true(Dictionary.has_key(result, "pumping_lemma_result"), "Should apply pumping lemma")

Process called "test_closure_properties":
    Let languages be List.from_array(["regular1", "regular2"])
    Let union_closed be Automata.verify_regular_closure_properties("union", languages)
    Let intersection_closed be Automata.verify_regular_closure_properties("intersection", languages)
    
    UnitTest.assert_true(union_closed, "Regular languages should be closed under union")
    UnitTest.assert_true(intersection_closed, "Regular languages should be closed under intersection")

Process called "create_regular_grammar":
    Let non_terminals be List.from_array(["S", "A"])
    Let terminals be List.from_array(["a", "b"])
    Let productions be Dictionary.create()
    
    Let s_productions be List.create()
    List.push(s_productions, List.from_array(["a", "A"]))
    List.push(s_productions, List.from_array(["b"]))
    Dictionary.set(productions, "S", s_productions)
    
    Let a_productions be List.create()
    List.push(a_productions, List.from_array(["a", "A"]))
    List.push(a_productions, List.from_array(["b"]))
    Dictionary.set(productions, "A", a_productions)
    
    Return Automata.create_context_free_grammar(non_terminals, terminals, productions, "S")

Note: =====================================================================
Note: EQUIVALENCE AND ANALYSIS TESTS
Note: =====================================================================

Process called "test_check_automaton_equivalence":
    Let dfa1 be create_test_dfa_even_zeros()
    Let dfa2 be create_equivalent_dfa_even_zeros()
    Let dfa3 be create_dfa_odd_ones()
    
    UnitTest.assert_true(Automata.check_automaton_equivalence(dfa1, dfa2), "Equivalent automata should be detected")
    UnitTest.assert_false(Automata.check_automaton_equivalence(dfa1, dfa3), "Non-equivalent automata should be detected")

Process called "test_check_grammar_ambiguity":
    Let ambiguous_grammar be create_ambiguous_grammar()
    Let unambiguous_grammar be create_test_context_free_grammar()
    
    Let ambiguous_result be Automata.check_grammar_ambiguity(ambiguous_grammar)
    Let unambiguous_result be Automata.check_grammar_ambiguity(unambiguous_grammar)
    
    UnitTest.assert_true(Dictionary.get_boolean(ambiguous_result, "is_ambiguous"), "Should detect ambiguous grammar")
    UnitTest.assert_false(Dictionary.get_boolean(unambiguous_result, "is_ambiguous"), "Should detect unambiguous grammar")

Process called "test_post_correspondence_problem":
    Let tiles be create_pcp_tiles()
    Let result be Automata.solve_post_correspondence_problem(tiles)
    
    UnitTest.assert_true(Dictionary.has_key(result, "has_solution"), "Should determine if PCP has solution")
    UnitTest.assert_true(Dictionary.has_key(result, "solution_sequence"), "Should provide solution if exists")

Process called "create_equivalent_dfa_even_zeros":
    Note: Different structure but same language as even zeros DFA
    Let states be List.from_array(["s0", "s1"])
    Let alphabet be List.from_array(["0", "1"])
    Let transitions be Dictionary.create()
    
    Let s0_trans be Dictionary.create()
    Dictionary.set(s0_trans, "0", "s1")
    Dictionary.set(s0_trans, "1", "s0")
    Dictionary.set(transitions, "s0", s0_trans)
    
    Let s1_trans be Dictionary.create()
    Dictionary.set(s1_trans, "0", "s0")
    Dictionary.set(s1_trans, "1", "s1")
    Dictionary.set(transitions, "s1", s1_trans)
    
    Let accept_states be List.from_array(["s0"])
    Return Automata.create_dfa(states, alphabet, transitions, "s0", accept_states)

Process called "create_ambiguous_grammar":
    Let non_terminals be List.from_array(["E"])
    Let terminals be List.from_array(["a", "+", "*"])
    Let productions be Dictionary.create()
    
    Let e_productions be List.create()
    List.push(e_productions, List.from_array(["E", "+", "E"]))
    List.push(e_productions, List.from_array(["E", "*", "E"]))
    List.push(e_productions, List.from_array(["a"]))
    Dictionary.set(productions, "E", e_productions)
    
    Return Automata.create_context_free_grammar(non_terminals, terminals, productions, "E")

Process called "create_pcp_tiles":
    Let tiles be List.create()
    List.push(tiles, Dictionary.from_entries([["top", "1"], ["bottom", "101"]]))
    List.push(tiles, Dictionary.from_entries([["top", "10"], ["bottom", "00"]]))
    List.push(tiles, Dictionary.from_entries([["top", "011"], ["bottom", "11"]]))
    Return tiles

Note: =====================================================================
Note: TWO-WAY AUTOMATA TESTS
Note: =====================================================================

Process called "test_create_two_way_automaton":
    Let states be List.from_array(["q0", "q1", "q2"])
    Let alphabet be List.from_array(["a", "b"])
    Let transitions be create_2dfa_transitions()
    Let two_way_dfa be Automata.create_two_way_automaton(states, alphabet, transitions, "q0", List.from_array(["q2"]))
    
    UnitTest.assert_equals(two_way_dfa.automaton_type, "2DFA", "Should be two-way DFA")
    UnitTest.assert_true(two_way_dfa.is_deterministic, "2DFA should be deterministic")

Process called "create_2dfa_transitions":
    Let transitions be Dictionary.create()
    
    Let q0_trans be Dictionary.create()
    Dictionary.set(q0_trans, "a", List.from_array(["q1", "R"]))
    Dictionary.set(q0_trans, "b", List.from_array(["q0", "R"]))
    Dictionary.set(transitions, "q0", q0_trans)
    
    Let q1_trans be Dictionary.create()
    Dictionary.set(q1_trans, "a", List.from_array(["q1", "R"]))
    Dictionary.set(q1_trans, "b", List.from_array(["q2", "L"]))
    Dictionary.set(transitions, "q1", q1_trans)
    
    Let q2_trans be Dictionary.create()
    Dictionary.set(q2_trans, "a", List.from_array(["q2", "S"]))
    Dictionary.set(q2_trans, "b", List.from_array(["q2", "S"]))
    Dictionary.set(transitions, "q2", q2_trans)
    
    Return transitions

Note: =====================================================================
Note: OPTIMIZATION AND PERFORMANCE TESTS
Note: =====================================================================

Process called "test_optimize_automaton_size":
    Let large_dfa be create_large_test_dfa()
    Let optimized be Automata.optimize_automaton_size(large_dfa, "minimize_states")
    
    UnitTest.assert_true(List.size(optimized.states) <= List.size(large_dfa.states), "Optimization should reduce or maintain state count")
    UnitTest.assert_equals(optimized.automaton_type, "DFA", "Should remain DFA after optimization")

Process called "test_benchmark_automaton_operations":
    Let operations be List.from_array(["simulation", "minimization", "conversion"])
    Let test_automata be List.from_array([create_test_dfa_even_zeros(), create_test_nfa_ends_with_01()])
    Let benchmarks be Automata.benchmark_automaton_operations(operations, test_automata)
    
    UnitTest.assert_true(Dictionary.has_key(benchmarks, "simulation"), "Should benchmark simulation")
    UnitTest.assert_true(Dictionary.has_key(benchmarks, "minimization"), "Should benchmark minimization")

Process called "test_validate_automaton_structure":
    Let valid_dfa be create_test_dfa_even_zeros()
    Let invalid_dfa be create_invalid_dfa()
    
    Let valid_result be Automata.validate_automaton_structure(valid_dfa, List.from_array(["completeness", "consistency"]))
    Let invalid_result be Automata.validate_automaton_structure(invalid_dfa, List.from_array(["completeness", "consistency"]))
    
    UnitTest.assert_true(Dictionary.get_boolean(valid_result, "is_valid"), "Valid DFA should pass validation")
    UnitTest.assert_false(Dictionary.get_boolean(invalid_result, "is_valid"), "Invalid DFA should fail validation")

Process called "create_large_test_dfa":
    Let states be List.create()
    For i from 0 to 10:
        List.push(states, "q" + Integer.to_string(i))
    
    Let alphabet be List.from_array(["a", "b"])
    Let transitions be Dictionary.create()
    
    For each state in states:
        Let state_trans be Dictionary.create()
        Dictionary.set(state_trans, "a", "q0")
        Dictionary.set(state_trans, "b", "q0")
        Dictionary.set(transitions, state, state_trans)
    
    Return Automata.create_dfa(states, alphabet, transitions, "q0", List.from_array(["q0"]))

Process called "create_invalid_dfa":
    Note: DFA with missing transitions
    Let states be List.from_array(["q0", "q1"])
    Let alphabet be List.from_array(["a", "b"])
    Let incomplete_transitions be Dictionary.create()
    
    Let q0_trans be Dictionary.create()
    Dictionary.set(q0_trans, "a", "q1")
    Note: Missing 'b' transition for q0
    Dictionary.set(incomplete_transitions, "q0", q0_trans)
    
    Return Automata.create_dfa(states, alphabet, incomplete_transitions, "q0", List.from_array(["q1"]))

Note: =====================================================================
Note: ADVANCED LANGUAGE OPERATIONS TESTS
Note: =====================================================================

Process called "test_language_separation":
    Let regular_examples be List.from_array(["a*", "b*", "(a|b)*"])
    Let cf_examples be List.from_array(["a^n b^n", "(^n )^n"])
    Let separation be Automata.demonstrate_language_separation(regular_examples, cf_examples, "regular_vs_context_free")
    
    UnitTest.assert_true(Dictionary.has_key(separation, "separating_example"), "Should provide separating example")
    UnitTest.assert_true(Dictionary.has_key(separation, "proof_technique"), "Should specify proof technique")

Process called "test_language_operations":
    Let languages be List.from_array(["L1", "L2"])
    Let operations be List.from_array(["union", "intersection", "complement", "concatenation"])
    Let results be Automata.compute_language_operations(languages, operations)
    
    UnitTest.assert_equals(List.size(results), List.size(operations), "Should compute all operations")
    For each result in results:
        UnitTest.assert_true(Dictionary.has_key(result, "operation"), "Should specify operation")
        UnitTest.assert_true(Dictionary.has_key(result, "result_language"), "Should provide result language")

Process called "test_non_closure_demonstration":
    Let context_free_class be "context_free"
    Let intersection_op be "intersection"
    Let demo be Automata.demonstrate_non_closure(context_free_class, intersection_op)
    
    UnitTest.assert_true(Dictionary.has_key(demo, "counterexample"), "Should provide counterexample")
    UnitTest.assert_true(Dictionary.has_key(demo, "explanation"), "Should explain why not closed")

Note: =====================================================================
Note: CONVERSION AND TRANSFORMATION TESTS
Note: =====================================================================

Process called "test_cfg_to_pda_conversion":
    Let grammar be create_test_context_free_grammar()
    Let pda be Automata.cfg_to_pda_conversion(grammar)
    
    UnitTest.assert_true(Dictionary.has_key(pda, "states"), "PDA should have states")
    UnitTest.assert_true(Dictionary.has_key(pda, "stack_alphabet"), "PDA should have stack alphabet")

Process called "test_pda_to_cfg_conversion":
    Let pda be create_test_pda()
    Let grammar be Automata.pda_to_cfg_conversion(pda)
    
    UnitTest.assert_true(grammar.is_context_free, "Converted grammar should be context-free")
    UnitTest.assert_false(List.is_empty(grammar.non_terminals), "Should have non-terminals")

Process called "test_pushdown_automaton_simulation":
    Let pda be create_test_pda()
    Let balanced_string be "(())"
    Let unbalanced_string be "(()"
    
    UnitTest.assert_true(Automata.simulate_pushdown_automaton(pda, balanced_string), "Should accept balanced parentheses")
    UnitTest.assert_false(Automata.simulate_pushdown_automaton(pda, unbalanced_string), "Should reject unbalanced parentheses")

Process called "create_test_pda":
    Let states be List.from_array(["q0", "q1", "q2"])
    Let input_alphabet be List.from_array(["(", ")"])
    Let stack_alphabet be List.from_array(["Z", "X"])
    Let transitions be create_pda_transitions()
    Return Automata.create_pushdown_automaton(states, input_alphabet, stack_alphabet, transitions, "q0", "Z", List.from_array(["q2"]))

Process called "create_pda_transitions":
    Let transitions be Dictionary.create()
    
    Note: Push X for each opening parenthesis
    Dictionary.set(transitions, "q0,(,Z", Dictionary.from_entries([["next_state", "q1"], ["stack_operation", "push"], ["stack_symbol", "X"]]))
    Dictionary.set(transitions, "q1,(,X", Dictionary.from_entries([["next_state", "q1"], ["stack_operation", "push"], ["stack_symbol", "X"]]))
    
    Note: Pop X for each closing parenthesis
    Dictionary.set(transitions, "q1,),X", Dictionary.from_entries([["next_state", "q1"], ["stack_operation", "pop"], ["stack_symbol", "ε"]]))
    Dictionary.set(transitions, "q1,ε,Z", Dictionary.from_entries([["next_state", "q2"], ["stack_operation", "stay"], ["stack_symbol", "Z"]]))
    
    Return transitions

Note: =====================================================================
Note: COMPLEXITY ANALYSIS TESTS
Note: =====================================================================

Process called "test_analyze_automaton_complexity":
    Let dfa be create_test_dfa_even_zeros()
    Let measures be List.from_array(["state_complexity", "time_complexity", "space_complexity"])
    Let analysis be Automata.analyze_automaton_complexity(dfa, measures)
    
    UnitTest.assert_true(Dictionary.has_key(analysis, "state_complexity"), "Should analyze state complexity")
    UnitTest.assert_true(Dictionary.has_key(analysis, "time_complexity"), "Should analyze time complexity")

Process called "test_analyze_parsing_complexity":
    Let grammar be create_test_context_free_grammar()
    Let algorithm be "CYK"
    Let analysis be Automata.analyze_parsing_complexity(grammar, algorithm)
    
    UnitTest.assert_true(Dictionary.has_key(analysis, "time_complexity"), "Should analyze parsing time complexity")
    UnitTest.assert_true(Dictionary.has_key(analysis, "space_complexity"), "Should analyze parsing space complexity")

Note: =====================================================================
Note: UTILITY AND DEBUGGING TESTS
Note: =====================================================================

Process called "test_visualize_automaton_structure":
    Let dfa be create_test_dfa_even_zeros()
    Let layout_options be Dictionary.from_entries([["format", "dot"], ["layout", "hierarchical"]])
    Let visualization be Automata.visualize_automaton_structure(dfa, layout_options)
    
    UnitTest.assert_true(Dictionary.has_key(visualization, "dot_output"), "Should generate DOT visualization")
    UnitTest.assert_true(Dictionary.has_key(visualization, "layout_info"), "Should provide layout information")

Process called "test_convert_automaton_formats":
    Let dfa be create_test_dfa_even_zeros()
    Let json_output be Automata.convert_automaton_formats(dfa, "JSON")
    Let xml_output be Automata.convert_automaton_formats(dfa, "XML")
    
    UnitTest.assert_false(String.is_empty(json_output), "Should generate JSON format")
    UnitTest.assert_false(String.is_empty(xml_output), "Should generate XML format")

Process called "test_troubleshoot_automaton_issues":
    Let issue_description be "DFA not accepting expected strings"
    Let suggestions be Automata.troubleshoot_automaton_issues(issue_description)
    
    UnitTest.assert_false(List.is_empty(suggestions), "Should provide troubleshooting suggestions")
    UnitTest.assert_true(List.size(suggestions) > 0, "Should have at least one suggestion")

Note: =====================================================================
Note: COMPREHENSIVE INTEGRATION TESTS
Note: =====================================================================

Process called "test_regex_to_automaton_pipeline":
    Let regex_pattern be "(a|b)*abb"
    Let regex be Automata.parse_regular_expression(regex_pattern)
    Let nfa be Automata.regex_to_nfa_thompson(regex)
    Let dfa be Automata.nfa_to_dfa_subset_construction(nfa)
    Let minimized be Automata.minimize_dfa_hopcroft(dfa)
    
    Let test_strings be List.from_array(["abb", "aabb", "babb", "ababb", "abbabb"])
    For each string in test_strings:
        UnitTest.assert_true(Automata.simulate_dfa(minimized, string), "Pipeline should accept strings ending with 'abb': " + string)
    
    Let reject_strings be List.from_array(["", "a", "ab", "ba", "abba"])
    For each string in reject_strings:
        UnitTest.assert_false(Automata.simulate_dfa(minimized, string), "Pipeline should reject strings not ending with 'abb': " + string)

Process called "test_grammar_parsing_pipeline":
    Let grammar be create_test_context_free_grammar()
    Let test_string be "(())"
    
    Let cky_tree be Automata.parse_cky_algorithm(grammar, test_string)
    Let earley_tree be Automata.parse_earley_algorithm(grammar, test_string)
    
    assert_parse_tree_valid(cky_tree, "CYK should produce valid parse")
    assert_parse_tree_valid(earley_tree, "Earley should produce valid parse")
    
    UnitTest.assert_equals(cky_tree.root_symbol, earley_tree.root_symbol, "Different parsers should agree on root")

Process called "test_complete_automata_workflow":
    Note: Test complete workflow from regex to optimized DFA
    Let pattern be "a*b*"
    Let regex be Automata.parse_regular_expression(pattern)
    Let nfa be Automata.regex_to_nfa_thompson(regex)
    Let epsilon_free_nfa be Automata.eliminate_epsilon_transitions(nfa)
    Let dfa be Automata.nfa_to_dfa_subset_construction(epsilon_free_nfa)
    Let minimized_dfa be Automata.minimize_dfa_hopcroft(dfa)
    
    UnitTest.assert_true(regex.is_valid, "Starting regex should be valid")
    UnitTest.assert_equals(nfa.automaton_type, "ε-NFA", "Thompson should produce ε-NFA")
    UnitTest.assert_equals(epsilon_free_nfa.automaton_type, "NFA", "Should eliminate epsilons")
    UnitTest.assert_equals(dfa.automaton_type, "DFA", "Should convert to DFA")
    UnitTest.assert_true(dfa.is_deterministic, "DFA should be deterministic")
    
    Let test_cases be List.from_array(["", "a", "b", "ab", "aab", "abb", "aabb", "aaabbb"])
    For each test_case in test_cases:
        Let original_result be Automata.simulate_nfa(nfa, test_case)
        Let final_result be Automata.simulate_dfa(minimized_dfa, test_case)
        UnitTest.assert_equals(original_result, final_result, "Complete workflow should preserve language for: " + test_case)

Note: =====================================================================
Note: ERROR HANDLING AND EDGE CASE TESTS
Note: =====================================================================

Process called "test_error_handling_invalid_states":
    Let invalid_states be List.from_array([])
    Let alphabet be List.from_array(["a"])
    Let transitions be Dictionary.create()
    
    Try:
        Let dfa be Automata.create_dfa(invalid_states, alphabet, transitions, "q0", List.create())
        UnitTest.fail("Should reject empty states list")
    Catch error:
        UnitTest.assert_true(True, "Correctly handled empty states")

Process called "test_error_handling_invalid_alphabet":
    Let states be List.from_array(["q0"])
    Let empty_alphabet be List.create()
    Let transitions be Dictionary.create()
    
    Try:
        Let dfa be Automata.create_dfa(states, empty_alphabet, transitions, "q0", List.create())
        UnitTest.fail("Should reject empty alphabet")
    Catch error:
        UnitTest.assert_true(True, "Correctly handled empty alphabet")

Process called "test_error_handling_missing_start_state":
    Let states be List.from_array(["q0", "q1"])
    Let alphabet be List.from_array(["a"])
    Let transitions be Dictionary.create()
    
    Try:
        Let dfa be Automata.create_dfa(states, alphabet, transitions, "q2", List.create())
        UnitTest.fail("Should reject missing start state")
    Catch error:
        UnitTest.assert_true(True, "Correctly handled missing start state")

Process called "test_edge_case_single_symbol_alphabet":
    Let states be List.from_array(["q0", "q1"])
    Let single_symbol be List.from_array(["a"])
    Let transitions be Dictionary.create()
    
    Let q0_trans be Dictionary.create()
    Dictionary.set(q0_trans, "a", "q1")
    Dictionary.set(transitions, "q0", q0_trans)
    
    Let q1_trans be Dictionary.create()
    Dictionary.set(q1_trans, "a", "q0")
    Dictionary.set(transitions, "q1", q1_trans)
    
    Let dfa be Automata.create_dfa(states, single_symbol, transitions, "q0", List.from_array(["q1"]))
    UnitTest.assert_true(Automata.simulate_dfa(dfa, "a"), "Should accept single symbol")
    UnitTest.assert_false(Automata.simulate_dfa(dfa, "aa"), "Should reject even length string")

Process called "test_edge_case_large_alphabet":
    Let states be List.from_array(["q0"])
    Let large_alphabet be create_large_alphabet()
    Let transitions be Dictionary.create()
    
    Let q0_trans be Dictionary.create()
    For each symbol in large_alphabet:
        Dictionary.set(q0_trans, symbol, "q0")
    Dictionary.set(transitions, "q0", q0_trans)
    
    Let dfa be Automata.create_dfa(states, large_alphabet, transitions, "q0", List.from_array(["q0"]))
    UnitTest.assert_equals(List.size(dfa.alphabet), List.size(large_alphabet), "Should handle large alphabet")

Process called "create_large_alphabet":
    Let alphabet be List.create()
    For i from 97 to 122:  Note: ASCII 'a' to 'z'
        List.push(alphabet, Character.from_ascii(i))
    Return alphabet

Note: =====================================================================
Note: PERFORMANCE AND STRESS TESTS
Note: =====================================================================

Process called "test_large_string_simulation":
    Let dfa be create_test_dfa_even_zeros()
    Let large_string be create_large_test_string(1000)
    
    Let start_time be Time.get_current_milliseconds()
    Let result be Automata.simulate_dfa(dfa, large_string)
    Let end_time be Time.get_current_milliseconds()
    Let duration be end_time - start_time
    
    UnitTest.assert_true(duration < 1000, "Large string simulation should complete within 1 second")
    UnitTest.assert_true(result == True or result == False, "Should produce valid boolean result")

Process called "test_complex_nfa_to_dfa_performance":
    Let complex_nfa be create_complex_nfa()
    
    Let start_time be Time.get_current_milliseconds()
    Let dfa be Automata.nfa_to_dfa_subset_construction(complex_nfa)
    Let end_time be Time.get_current_milliseconds()
    Let duration be end_time - start_time
    
    UnitTest.assert_true(duration < 5000, "Complex NFA conversion should complete within 5 seconds")
    UnitTest.assert_true(dfa.is_deterministic, "Result should be deterministic")

Process called "create_large_test_string" that takes length as Integer returns String:
    Let result be String.create("")
    For i from 0 to length:
        If Integer.modulo(i, 2) == 0:
            result be String.append(result, "0")
        Otherwise:
            result be String.append(result, "1")
    Return result

Process called "create_complex_nfa":
    Note: NFA with many non-deterministic transitions
    Let states be List.create()
    For i from 0 to 8:
        List.push(states, "q" + Integer.to_string(i))
    
    Let alphabet be List.from_array(["a", "b", "c"])
    Let transitions be Dictionary.create()
    
    For i from 0 to 7:
        Let state_name be "q" + Integer.to_string(i)
        Let state_trans be Dictionary.create()
        
        For each symbol in alphabet:
            Let targets be List.create()
            For j from i to Integer.min(i + 2, 7):
                List.push(targets, "q" + Integer.to_string(j))
            Dictionary.set(state_trans, symbol, targets)
        
        Dictionary.set(transitions, state_name, state_trans)
    
    Return Automata.create_nfa(states, alphabet, transitions, "q0", List.from_array(["q7"]))

Note: =====================================================================
Note: TEST SUITE COORDINATION
Note: =====================================================================

Process called "run_all_automata_tests":
    UnitTest.start_test_suite("Automata Theory Module Tests")
    
    Note: DFA Tests
    UnitTest.run_test("test_create_dfa_basic", test_create_dfa_basic)
    UnitTest.run_test("test_create_dfa_invalid_inputs", test_create_dfa_invalid_inputs)
    UnitTest.run_test("test_simulate_dfa_acceptance", test_simulate_dfa_acceptance)
    UnitTest.run_test("test_simulate_dfa_long_strings", test_simulate_dfa_long_strings)
    
    Note: NFA Tests
    UnitTest.run_test("test_create_nfa_basic", test_create_nfa_basic)
    UnitTest.run_test("test_simulate_nfa_acceptance", test_simulate_nfa_acceptance)
    UnitTest.run_test("test_nfa_nondeterminism", test_nfa_nondeterminism)
    
    Note: Epsilon-NFA Tests
    UnitTest.run_test("test_create_epsilon_nfa", test_create_epsilon_nfa)
    UnitTest.run_test("test_eliminate_epsilon_transitions", test_eliminate_epsilon_transitions)
    UnitTest.run_test("test_epsilon_closure_reachability", test_epsilon_closure_reachability)
    
    Note: Conversion Tests
    UnitTest.run_test("test_nfa_to_dfa_subset_construction", test_nfa_to_dfa_subset_construction)
    UnitTest.run_test("test_conversion_preserves_language", test_conversion_preserves_language)
    UnitTest.run_test("test_conversion_edge_cases", test_conversion_edge_cases)
    
    Note: Minimization Tests
    UnitTest.run_test("test_minimize_dfa_hopcroft", test_minimize_dfa_hopcroft)
    UnitTest.run_test("test_minimize_dfa_table_filling", test_minimize_dfa_table_filling)
    UnitTest.run_test("test_minimization_preserves_language", test_minimization_preserves_language)
    
    Note: Regular Expression Tests
    UnitTest.run_test("test_parse_regular_expression", test_parse_regular_expression)
    UnitTest.run_test("test_regex_complex_patterns", test_regex_complex_patterns)
    UnitTest.run_test("test_regex_to_nfa_thompson", test_regex_to_nfa_thompson)
    UnitTest.run_test("test_regex_to_dfa_direct", test_regex_to_dfa_direct)
    UnitTest.run_test("test_dfa_to_regex_conversion", test_dfa_to_regex_conversion)
    
    Note: Language Operations Tests
    UnitTest.run_test("test_language_emptiness", test_language_emptiness)
    UnitTest.run_test("test_generate_strings_in_language", test_generate_strings_in_language)
    UnitTest.run_test("test_automaton_union", test_automaton_union)
    UnitTest.run_test("test_automaton_intersection", test_automaton_intersection)
    UnitTest.run_test("test_automaton_complement", test_automaton_complement)
    
    Note: Context-Free Grammar Tests
    UnitTest.run_test("test_create_context_free_grammar", test_create_context_free_grammar)
    UnitTest.run_test("test_eliminate_left_recursion", test_eliminate_left_recursion)
    UnitTest.run_test("test_compute_first_sets", test_compute_first_sets)
    UnitTest.run_test("test_compute_follow_sets", test_compute_follow_sets)
    UnitTest.run_test("test_cfg_to_pda_conversion", test_cfg_to_pda_conversion)
    UnitTest.run_test("test_pda_to_cfg_conversion", test_pda_to_cfg_conversion)
    
    Note: Parsing Algorithm Tests
    UnitTest.run_test("test_parse_cky_algorithm", test_parse_cky_algorithm)
    UnitTest.run_test("test_parse_earley_algorithm", test_parse_earley_algorithm)
    UnitTest.run_test("test_parse_ll_recursive_descent", test_parse_ll_recursive_descent)
    UnitTest.run_test("test_parse_lr_shift_reduce", test_parse_lr_shift_reduce)
    
    Note: Turing Machine Tests
    UnitTest.run_test("test_create_turing_machine", test_create_turing_machine)
    UnitTest.run_test("test_simulate_turing_machine", test_simulate_turing_machine)
    UnitTest.run_test("test_turing_machine_complexity", test_turing_machine_complexity)
    
    Note: Language Theory Tests
    UnitTest.run_test("test_classify_language_type", test_classify_language_type)
    UnitTest.run_test("test_language_regularity", test_language_regularity)
    UnitTest.run_test("test_context_free_property", test_context_free_property)
    UnitTest.run_test("test_closure_properties", test_closure_properties)
    UnitTest.run_test("test_language_separation", test_language_separation)
    UnitTest.run_test("test_language_operations", test_language_operations)
    
    Note: Equivalence and Analysis Tests
    UnitTest.run_test("test_check_automaton_equivalence", test_check_automaton_equivalence)
    UnitTest.run_test("test_check_grammar_ambiguity", test_check_grammar_ambiguity)
    UnitTest.run_test("test_post_correspondence_problem", test_post_correspondence_problem)
    
    Note: Two-Way Automata Tests
    UnitTest.run_test("test_create_two_way_automaton", test_create_two_way_automaton)
    
    Note: Optimization Tests
    UnitTest.run_test("test_optimize_automaton_size", test_optimize_automaton_size)
    UnitTest.run_test("test_benchmark_automaton_operations", test_benchmark_automaton_operations)
    UnitTest.run_test("test_validate_automaton_structure", test_validate_automaton_structure)
    
    Note: Complexity Analysis Tests
    UnitTest.run_test("test_analyze_automaton_complexity", test_analyze_automaton_complexity)
    UnitTest.run_test("test_analyze_parsing_complexity", test_analyze_parsing_complexity)
    
    Note: Utility Tests
    UnitTest.run_test("test_visualize_automaton_structure", test_visualize_automaton_structure)
    UnitTest.run_test("test_convert_automaton_formats", test_convert_automaton_formats)
    UnitTest.run_test("test_troubleshoot_automaton_issues", test_troubleshoot_automaton_issues)
    
    Note: Integration Tests
    UnitTest.run_test("test_regex_to_automaton_pipeline", test_regex_to_automaton_pipeline)
    UnitTest.run_test("test_grammar_parsing_pipeline", test_grammar_parsing_pipeline)
    UnitTest.run_test("test_complete_automata_workflow", test_complete_automata_workflow)
    
    Note: Error Handling Tests
    UnitTest.run_test("test_error_handling_invalid_states", test_error_handling_invalid_states)
    UnitTest.run_test("test_error_handling_invalid_alphabet", test_error_handling_invalid_alphabet)
    UnitTest.run_test("test_error_handling_missing_start_state", test_error_handling_missing_start_state)
    
    Note: Edge Case Tests
    UnitTest.run_test("test_edge_case_single_symbol_alphabet", test_edge_case_single_symbol_alphabet)
    UnitTest.run_test("test_edge_case_large_alphabet", test_edge_case_large_alphabet)
    
    Note: Performance Tests
    UnitTest.run_test("test_large_string_simulation", test_large_string_simulation)
    UnitTest.run_test("test_complex_nfa_to_dfa_performance", test_complex_nfa_to_dfa_performance)
    
    UnitTest.end_test_suite()