Note:
tests/unit/libraries/math/engine/optimization/evolutionary_test.runa
Unit Tests for Math Engine Optimization Evolutionary Module

This test suite provides comprehensive testing for the math engine optimization evolutionary module including:
- Genetic Algorithm (GA) variants and implementations
- Particle Swarm Optimization (PSO) algorithms
- Differential Evolution (DE) strategies
- Evolution Strategies (ES) and CMA-ES
- Multi-objective evolutionary algorithms (NSGA-II, SPEA2)
- Genetic programming and symbolic regression
- Island models and parallel evolutionary computation
- Hybrid evolutionary algorithms
- Constraint handling in evolutionary optimization
- Diversity preservation mechanisms
- Selection strategies and replacement policies
- Crossover and mutation operators
:End Note

Import "stdlib/math/engine/optimization/evolutionary" as EvoOpt
Import "dev/debug/test_framework/assertions" as Assert
Import "dev/debug/test_framework/test_runner" as TestRunner
Import "dev/debug/test_framework/data_generators" as DataGen
Import "math.core" as MathCore
Import "collections" as Collections

Note: =====================================================================
Note: HELPER FUNCTIONS AND TEST UTILITIES
Note: =====================================================================

Process called "create_simple_test_function" that takes function_type as String returns EvolutionaryObjective:
    Note: Create simple test function for evolutionary algorithms
    If function_type == "sphere":
        Return EvoOpt.EvolutionaryObjective{
            function: "lambda x: sum(xi*xi for xi in x)",
            dimension: 2,
            bounds_lower: ["-5.0", "-5.0"],
            bounds_upper: ["5.0", "5.0"],
            optimal_value: "0.0",
            optimal_point: ["0.0", "0.0"],
            function_type: "unimodal"
        }
    Otherwise if function_type == "rosenbrock":
        Return EvoOpt.EvolutionaryObjective{
            function: "lambda x: 100*(x[1] - x[0]*x[0])**2 + (1 - x[0])**2",
            dimension: 2,
            bounds_lower: ["-2.0", "-2.0"],
            bounds_upper: ["2.0", "2.0"],
            optimal_value: "0.0",
            optimal_point: ["1.0", "1.0"],
            function_type: "multimodal"
        }
    Otherwise if function_type == "rastrigin":
        Return EvoOpt.EvolutionaryObjective{
            function: "lambda x: 10*len(x) + sum(xi*xi - 10*cos(2*pi*xi) for xi in x)",
            dimension: 2,
            bounds_lower: ["-5.12", "-5.12"],
            bounds_upper: ["5.12", "5.12"],
            optimal_value: "0.0",
            optimal_point: ["0.0", "0.0"],
            function_type: "highly_multimodal"
        }
    Otherwise:
        Return EvoOpt.EvolutionaryObjective{
            function: "lambda x: x[0]*x[0] + x[1]*x[1]",
            dimension: 2,
            bounds_lower: ["-10.0", "-10.0"],
            bounds_upper: ["10.0", "10.0"],
            optimal_value: "0.0",
            optimal_point: ["0.0", "0.0"],
            function_type: "quadratic"
        }

Process called "create_multiobjective_test_function" returns MultiObjectiveFunction:
    Note: Create multi-objective test function (ZDT1)
    Return EvoOpt.MultiObjectiveFunction{
        objectives: [
            "lambda x: x[0]",
            "lambda x: (1 + 9*sum(x[1:])/len(x[1:])) * (1 - sqrt(x[0]/(1 + 9*sum(x[1:])/len(x[1:]))))"
        ],
        dimension: 10,
        bounds_lower: ["0.0"] * 10,
        bounds_upper: ["1.0"] * 10,
        pareto_front_known: True,
        function_name: "ZDT1"
    }

Process called "create_genetic_algorithm_config" returns GeneticConfig:
    Note: Create default genetic algorithm configuration
    Return EvoOpt.GeneticConfig{
        population_size: 50,
        max_generations: 100,
        crossover_rate: "0.8",
        mutation_rate: "0.1",
        selection_method: "tournament",
        tournament_size: 3,
        crossover_method: "single_point",
        mutation_method: "gaussian",
        replacement_strategy: "generational",
        elitism_count: 2
    }

Process called "create_pso_config" returns PSO_Config:
    Note: Create default PSO configuration
    Return EvoOpt.PSO_Config{
        swarm_size: 30,
        max_iterations: 100,
        inertia_weight: "0.9",
        cognitive_coefficient: "2.0",
        social_coefficient: "2.0",
        inertia_decay: "0.99",
        velocity_clamping: True,
        max_velocity_factor: "0.5",
        topology: "global_best"
    }

Process called "create_differential_evolution_config" returns DE_Config:
    Note: Create default differential evolution configuration
    Return EvoOpt.DE_Config{
        population_size: 40,
        max_generations: 150,
        differential_weight: "0.8",
        crossover_probability: "0.9",
        strategy: "DE/rand/1/bin",
        bounds_handling: "reflect",
        adaptive_parameters: False
    }

Process called "assert_evolutionary_result_valid" that takes result as EvolutionaryResult returns Boolean:
    Note: Assert that evolutionary optimization result is valid
    Assert.IsNotNull(result)
    Assert.IsTrue(result.converged == "true" or result.converged == "false")
    Assert.IsTrue(result.generations >= 0)
    Assert.IsTrue(result.function_evaluations >= 0)
    Assert.IsNotEmpty(result.best_solution)
    Assert.IsNotEmpty(result.best_fitness)
    Assert.IsNotNull(result.population_history)
    Return True

Process called "assert_multiobjective_result_valid" that takes result as MultiObjectiveResult returns Boolean:
    Note: Assert that multi-objective result is valid
    Assert.IsNotNull(result)
    Assert.IsTrue(result.generations >= 0)
    Assert.IsNotEmpty(result.pareto_front)
    Assert.IsTrue(result.pareto_front.length > 0)
    For solution in result.pareto_front:
        Assert.IsNotEmpty(solution.variables)
        Assert.IsNotEmpty(solution.objectives)
    Return True

Note: =====================================================================
Note: GENETIC ALGORITHM TESTS
Note: =====================================================================

Process called "test_genetic_algorithm_basic" that takes no parameters returns Boolean:
    Note: Test basic genetic algorithm functionality
    Let objective be create_simple_test_function("sphere")
    Let config be create_genetic_algorithm_config()
    
    Let result be EvoOpt.genetic_algorithm(objective, config)
    
    Assert.IsTrue(assert_evolutionary_result_valid(result))
    Assert.IsTrue(result.generations > 0)
    
    Note: Check convergence towards optimum
    Let best_fitness be MathCore.parse_float(result.best_fitness)
    Assert.IsTrue(best_fitness < 1.0)
    Return True

Process called "test_genetic_algorithm_selection_methods" that takes no parameters returns Boolean:
    Note: Test different selection methods
    Let objective be create_simple_test_function("sphere")
    Let base_config be create_genetic_algorithm_config()
    Set base_config.max_generations to 50
    
    Let selection_methods be ["tournament", "roulette", "rank", "sus"]
    
    For method in selection_methods:
        Let config be base_config
        Set config.selection_method to method
        
        Let result be EvoOpt.genetic_algorithm(objective, config)
        Assert.IsTrue(assert_evolutionary_result_valid(result))
        
        Let best_fitness be MathCore.parse_float(result.best_fitness)
        Assert.IsTrue(best_fitness < 10.0)
    
    Return True

Process called "test_genetic_algorithm_crossover_methods" that takes no parameters returns Boolean:
    Note: Test different crossover methods
    Let objective be create_simple_test_function("rosenbrock")
    Let base_config be create_genetic_algorithm_config()
    Set base_config.max_generations to 75
    
    Let crossover_methods be ["single_point", "two_point", "uniform", "arithmetic", "blx_alpha"]
    
    For method in crossover_methods:
        Let config be base_config
        Set config.crossover_method to method
        
        Let result be EvoOpt.genetic_algorithm(objective, config)
        Assert.IsTrue(assert_evolutionary_result_valid(result))
    
    Return True

Process called "test_genetic_algorithm_mutation_methods" that takes no parameters returns Boolean:
    Note: Test different mutation methods
    Let objective be create_simple_test_function("sphere")
    Let base_config be create_genetic_algorithm_config()
    Set base_config.max_generations to 60
    
    Let mutation_methods be ["gaussian", "uniform", "polynomial", "cauchy"]
    
    For method in mutation_methods:
        Let config be base_config
        Set config.mutation_method to method
        
        Let result be EvoOpt.genetic_algorithm(objective, config)
        Assert.IsTrue(assert_evolutionary_result_valid(result))
    
    Return True

Process called "test_genetic_algorithm_elitism" that takes no parameters returns Boolean:
    Note: Test elitism in genetic algorithms
    Let objective be create_simple_test_function("rastrigin")
    
    Note: Test without elitism
    Let config_no_elitism be create_genetic_algorithm_config()
    Set config_no_elitism.elitism_count to 0
    Set config_no_elitism.max_generations to 50
    
    Let result_no_elitism be EvoOpt.genetic_algorithm(objective, config_no_elitism)
    Assert.IsTrue(assert_evolutionary_result_valid(result_no_elitism))
    
    Note: Test with elitism
    Let config_with_elitism be create_genetic_algorithm_config()
    Set config_with_elitism.elitism_count to 3
    Set config_with_elitism.max_generations to 50
    
    Let result_with_elitism be EvoOpt.genetic_algorithm(objective, config_with_elitism)
    Assert.IsTrue(assert_evolutionary_result_valid(result_with_elitism))
    
    Note: Elitism should generally improve performance
    Let fitness_no_elitism be MathCore.parse_float(result_no_elitism.best_fitness)
    Let fitness_with_elitism be MathCore.parse_float(result_with_elitism.best_fitness)
    Assert.IsTrue(fitness_with_elitism <= fitness_no_elitism * 1.5)
    
    Return True

Note: =====================================================================
Note: PARTICLE SWARM OPTIMIZATION TESTS
Note: =====================================================================

Process called "test_particle_swarm_optimization_basic" that takes no parameters returns Boolean:
    Note: Test basic particle swarm optimization
    Let objective be create_simple_test_function("sphere")
    Let config be create_pso_config()
    
    Let result be EvoOpt.particle_swarm_optimization(objective, config)
    
    Assert.IsTrue(assert_evolutionary_result_valid(result))
    Assert.IsTrue(result.iterations > 0)
    
    Note: PSO should converge well on sphere function
    Let best_fitness be MathCore.parse_float(result.best_fitness)
    Assert.IsTrue(best_fitness < 0.1)
    Return True

Process called "test_pso_inertia_weight_strategies" that takes no parameters returns Boolean:
    Note: Test different inertia weight strategies
    Let objective be create_simple_test_function("rosenbrock")
    Let base_config be create_pso_config()
    Set base_config.max_iterations to 80
    
    Let inertia_strategies be [
        ["constant", "0.7"],
        ["linear_decrease", "0.9"],
        ["nonlinear_decrease", "0.9"],
        ["adaptive", "0.8"]
    ]
    
    For strategy_info in inertia_strategies:
        Let config be base_config
        Set config.inertia_strategy to strategy_info[0]
        Set config.initial_inertia to strategy_info[1]
        
        Let result be EvoOpt.particle_swarm_optimization(objective, config)
        Assert.IsTrue(assert_evolutionary_result_valid(result))
    
    Return True

Process called "test_pso_topology_variants" that takes no parameters returns Boolean:
    Note: Test different PSO topology variants
    Let objective be create_simple_test_function("rastrigin")
    Let base_config be create_pso_config()
    Set base_config.max_iterations to 100
    
    Let topologies be ["global_best", "local_best", "von_neumann", "random"]
    
    For topology in topologies:
        Let config be base_config
        Set config.topology to topology
        
        Let result be EvoOpt.particle_swarm_optimization(objective, config)
        Assert.IsTrue(assert_evolutionary_result_valid(result))
    
    Return True

Process called "test_pso_velocity_clamping" that takes no parameters returns Boolean:
    Note: Test PSO velocity clamping mechanisms
    Let objective be create_simple_test_function("sphere")
    Let config be create_pso_config()
    Set config.velocity_clamping to True
    Set config.max_velocity_factor to "0.2"
    Set config.max_iterations to 60
    
    Let result be EvoOpt.particle_swarm_optimization_with_diagnostics(objective, config)
    
    Assert.IsTrue(assert_evolutionary_result_valid(result))
    Assert.IsNotNull(result.velocity_statistics)
    
    Note: Check that velocities were clamped
    Let max_velocities be result.velocity_statistics.max_velocities_per_iteration
    For max_vel in max_velocities:
        Assert.IsTrue(MathCore.parse_float(max_vel) <= 2.0)  # 0.2 * (5.0 - (-5.0))
    
    Return True

Process called "test_pso_with_constriction_factor" that takes no parameters returns Boolean:
    Note: Test PSO with constriction factor
    Let objective be create_simple_test_function("rosenbrock")
    Let config be create_pso_config()
    Set config.use_constriction_factor to True
    Set config.phi1 to "2.05"
    Set config.phi2 to "2.05"
    Set config.max_iterations to 100
    
    Let result be EvoOpt.pso_with_constriction(objective, config)
    
    Assert.IsTrue(assert_evolutionary_result_valid(result))
    Assert.IsTrue(result.converged == "true")
    Return True

Note: =====================================================================
Note: DIFFERENTIAL EVOLUTION TESTS
Note: =====================================================================

Process called "test_differential_evolution_basic" that takes no parameters returns Boolean:
    Note: Test basic differential evolution
    Let objective be create_simple_test_function("sphere")
    Let config be create_differential_evolution_config()
    
    Let result be EvoOpt.differential_evolution(objective, config)
    
    Assert.IsTrue(assert_evolutionary_result_valid(result))
    Assert.IsTrue(result.generations > 0)
    
    Note: DE should perform well on sphere function
    Let best_fitness be MathCore.parse_float(result.best_fitness)
    Assert.IsTrue(best_fitness < 0.01)
    Return True

Process called "test_differential_evolution_strategies" that takes no parameters returns Boolean:
    Note: Test different DE strategies
    Let objective be create_simple_test_function("rosenbrock")
    Let base_config be create_differential_evolution_config()
    Set base_config.max_generations to 100
    
    Let strategies be [
        "DE/rand/1/bin",
        "DE/best/1/bin",
        "DE/current-to-best/1/bin",
        "DE/rand/2/bin",
        "DE/best/2/bin"
    ]
    
    For strategy in strategies:
        Let config be base_config
        Set config.strategy to strategy
        
        Let result be EvoOpt.differential_evolution(objective, config)
        Assert.IsTrue(assert_evolutionary_result_valid(result))
    
    Return True

Process called "test_differential_evolution_parameter_adaptation" that takes no parameters returns Boolean:
    Note: Test adaptive parameter control in DE
    Let objective be create_simple_test_function("rastrigin")
    Let config be create_differential_evolution_config()
    Set config.adaptive_parameters to True
    Set config.adaptation_strategy to "jade"
    Set config.max_generations to 120
    
    Let result be EvoOpt.adaptive_differential_evolution(objective, config)
    
    Assert.IsTrue(assert_evolutionary_result_valid(result))
    Assert.IsNotNull(result.parameter_history)
    
    Note: Check that parameters were adapted
    Let initial_f be MathCore.parse_float(result.parameter_history.f_values[0])
    Let final_f be MathCore.parse_float(result.parameter_history.f_values[-1])
    Assert.IsTrue(initial_f != final_f or result.parameter_history.f_values.length > 10)
    
    Return True

Process called "test_differential_evolution_bounds_handling" that takes no parameters returns Boolean:
    Note: Test bounds handling strategies in DE
    Let objective be create_simple_test_function("sphere")
    Let base_config be create_differential_evolution_config()
    Set base_config.max_generations to 50
    
    Let bounds_strategies be ["reflect", "random", "clip", "wrap_around"]
    
    For strategy in bounds_strategies:
        Let config be base_config
        Set config.bounds_handling to strategy
        
        Let result be EvoOpt.differential_evolution(objective, config)
        Assert.IsTrue(assert_evolutionary_result_valid(result))
        
        Note: Check that all solutions are within bounds
        For variable in result.best_solution:
            Let value be MathCore.parse_float(variable)
            Assert.IsTrue(value >= -5.0 and value <= 5.0)
    
    Return True

Note: =====================================================================
Note: EVOLUTION STRATEGIES TESTS
Note: =====================================================================

Process called "test_evolution_strategies_basic" that takes no parameters returns Boolean:
    Note: Test basic (Œº+Œª) evolution strategy
    Let objective be create_simple_test_function("sphere")
    Let config be EvoOpt.EvolutionStrategiesConfig{
        mu: 10,
        lambda: 30,
        strategy_type: "plus",
        self_adaptation: True,
        individual_step_sizes: True,
        max_generations: 100
    }
    
    Let result be EvoOpt.evolution_strategies(objective, config)
    
    Assert.IsTrue(assert_evolutionary_result_valid(result))
    
    Note: ES should converge well on sphere function
    Let best_fitness be MathCore.parse_float(result.best_fitness)
    Assert.IsTrue(best_fitness < 0.001)
    Return True

Process called "test_cma_es_basic" that takes no parameters returns Boolean:
    Note: Test Covariance Matrix Adaptation Evolution Strategy
    Let objective be create_simple_test_function("rosenbrock")
    Let config be EvoOpt.CMA_ES_Config{
        population_size: 20,
        initial_step_size: "0.5",
        max_generations: 150,
        adaptation_strategy: "cma",
        bounds_handling: "penalty"
    }
    
    Let result be EvoOpt.cma_evolution_strategy(objective, config)
    
    Assert.IsTrue(assert_evolutionary_result_valid(result))
    Assert.IsNotNull(result.covariance_matrices)
    
    Note: CMA-ES should handle Rosenbrock function well
    Let best_fitness be MathCore.parse_float(result.best_fitness)
    Assert.IsTrue(best_fitness < 1.0)
    Return True

Process called "test_evolution_strategies_variants" that takes no parameters returns Boolean:
    Note: Test different ES variants
    Let objective be create_simple_test_function("sphere")
    
    Let variants be [
        ["plus", 10, 30],
        ["comma", 15, 45],
        ["plus", 5, 20]
    ]
    
    For variant_info in variants:
        Let config be EvoOpt.EvolutionStrategiesConfig{
            strategy_type: variant_info[0],
            mu: variant_info[1],
            lambda: variant_info[2],
            self_adaptation: True,
            max_generations: 60
        }
        
        Let result be EvoOpt.evolution_strategies(objective, config)
        Assert.IsTrue(assert_evolutionary_result_valid(result))
    
    Return True

Note: =====================================================================
Note: MULTI-OBJECTIVE OPTIMIZATION TESTS
Note: =====================================================================

Process called "test_nsga_ii_basic" that takes no parameters returns Boolean:
    Note: Test NSGA-II multi-objective optimization
    Let objective be create_multiobjective_test_function()
    Let config be EvoOpt.NSGA_II_Config{
        population_size: 100,
        max_generations: 150,
        crossover_rate: "0.9",
        mutation_rate: "0.1",
        tournament_size: 2,
        crowding_distance_assignment: True
    }
    
    Let result be EvoOpt.nsga_ii(objective, config)
    
    Assert.IsTrue(assert_multiobjective_result_valid(result))
    Assert.IsTrue(result.pareto_front.length > 10)
    
    Note: Check Pareto front diversity
    Let diversity be EvoOpt.calculate_pareto_front_diversity(result.pareto_front)
    Assert.IsTrue(diversity > 0.1)
    Return True

Process called "test_spea2_algorithm" that takes no parameters returns Boolean:
    Note: Test SPEA2 multi-objective optimization
    Let objective be create_multiobjective_test_function()
    Let config be EvoOpt.SPEA2_Config{
        population_size: 80,
        archive_size: 40,
        max_generations: 120,
        crossover_rate: "0.8",
        mutation_rate: "0.2",
        k_nearest_neighbors: 3
    }
    
    Let result be EvoOpt.spea2(objective, config)
    
    Assert.IsTrue(assert_multiobjective_result_valid(result))
    Assert.IsTrue(result.archive.length <= 40)
    Return True

Process called "test_multi_objective_metrics" that takes no parameters returns Boolean:
    Note: Test multi-objective performance metrics
    Let objective be create_multiobjective_test_function()
    Let config be EvoOpt.NSGA_II_Config{
        population_size: 50,
        max_generations: 80
    }
    
    Let result be EvoOpt.nsga_ii(objective, config)
    
    Assert.IsTrue(assert_multiobjective_result_valid(result))
    
    Note: Calculate performance metrics
    Let hypervolume be EvoOpt.calculate_hypervolume(result.pareto_front, ["2.0", "2.0"])
    Let igd be EvoOpt.calculate_inverted_generational_distance(result.pareto_front, objective.true_pareto_front)
    Let spread be EvoOpt.calculate_spread_metric(result.pareto_front)
    
    Assert.IsTrue(hypervolume > 0.0)
    Assert.IsTrue(igd >= 0.0)
    Assert.IsTrue(spread >= 0.0)
    Return True

Process called "test_pareto_dominance_relationships" that takes no parameters returns Boolean:
    Note: Test Pareto dominance relationship computations
    Let solution1 be EvoOpt.MultiObjectiveSolution{
        variables: ["0.5", "0.3"],
        objectives: ["0.5", "1.2"]
    }
    
    Let solution2 be EvoOpt.MultiObjectiveSolution{
        variables: ["0.3", "0.4"],
        objectives: ["0.3", "1.8"]
    }
    
    Let solution3 be EvoOpt.MultiObjectiveSolution{
        variables: ["0.7", "0.2"],
        objectives: ["0.7", "0.9"]
    }
    
    Note: Test dominance relationships
    Let dom_1_2 be EvoOpt.dominates(solution1, solution2)
    Let dom_2_1 be EvoOpt.dominates(solution2, solution1)
    Let dom_3_1 be EvoOpt.dominates(solution3, solution1)
    
    Assert.IsTrue(dom_1_2)    # solution1 dominates solution2
    Assert.IsFalse(dom_2_1)   # solution2 does not dominate solution1
    Assert.IsTrue(dom_3_1)    # solution3 dominates solution1
    Return True

Note: =====================================================================
Note: CONSTRAINT HANDLING TESTS
Note: =====================================================================

Process called "test_penalty_method_constraints" that takes no parameters returns Boolean:
    Note: Test penalty method for constraint handling
    Let objective be EvoOpt.ConstrainedObjective{
        function: "lambda x: x[0]*x[0] + x[1]*x[1]",
        constraints: [
            "lambda x: x[0] + x[1] - 1",  # equality constraint
            "lambda x: x[0] - 0.5"        # inequality constraint (x[0] <= 0.5)
        ],
        constraint_types: ["eq", "ineq"],
        penalty_method: "quadratic"
    }
    
    Let config be create_genetic_algorithm_config()
    Set config.constraint_handling to "penalty_method"
    Set config.penalty_factor to "100.0"
    
    Let result be EvoOpt.constrained_genetic_algorithm(objective, config)
    
    Assert.IsTrue(assert_evolutionary_result_valid(result))
    
    Note: Check constraint satisfaction
    Let x0 be MathCore.parse_float(result.best_solution[0])
    Let x1 be MathCore.parse_float(result.best_solution[1])
    Assert.IsTrue(AbsoluteValue(x0 + x1 - 1.0) < 0.1)  # equality constraint
    Assert.IsTrue(x0 <= 0.6)  # inequality constraint with tolerance
    Return True

Process called "test_feasibility_preservation" that takes no parameters returns Boolean:
    Note: Test feasibility preservation in constrained optimization
    Let objective be EvoOpt.ConstrainedObjective{
        function: "lambda x: x[0]*x[0] + x[1]*x[1]",
        constraints: [
            "lambda x: x[0]*x[0] + x[1]*x[1] - 1"  # circle constraint
        ],
        constraint_types: ["ineq"],
        handling_method: "feasibility_preservation"
    }
    
    Let config be create_genetic_algorithm_config()
    Set config.constraint_handling to "feasibility_preservation"
    Set config.repair_mechanism to "projection"
    
    Let result be EvoOpt.constrained_genetic_algorithm(objective, config)
    
    Assert.IsTrue(assert_evolutionary_result_valid(result))
    
    Note: All solutions should be feasible
    For individual in result.final_population:
        Let x0 be MathCore.parse_float(individual[0])
        Let x1 be MathCore.parse_float(individual[1])
        Assert.IsTrue(x0*x0 + x1*x1 <= 1.1)  # within constraint with tolerance
    
    Return True

Process called "test_multi_objective_constraints" that takes no parameters returns Boolean:
    Note: Test multi-objective optimization with constraints
    Let objective be EvoOpt.ConstrainedMultiObjectiveFunction{
        objectives: [
            "lambda x: x[0]*x[0]",
            "lambda x: (x[0] - 2)*(x[0] - 2)"
        ],
        constraints: [
            "lambda x: x[0] - 3"  # x[0] <= 3
        ],
        constraint_types: ["ineq"]
    }
    
    Let config be EvoOpt.ConstrainedNSGA_II_Config{
        population_size: 60,
        max_generations: 100,
        constraint_handling: "constraint_domination"
    }
    
    Let result be EvoOpt.constrained_nsga_ii(objective, config)
    
    Assert.IsTrue(assert_multiobjective_result_valid(result))
    
    Note: Check constraint satisfaction in Pareto front
    For solution in result.pareto_front:
        Let x0 be MathCore.parse_float(solution.variables[0])
        Assert.IsTrue(x0 <= 3.1)  # constraint satisfaction with tolerance
    
    Return True

Note: =====================================================================
Note: DIVERSITY AND NICHING TESTS
Note: =====================================================================

Process called "test_fitness_sharing" that takes no parameters returns Boolean:
    Note: Test fitness sharing for diversity preservation
    Let objective be create_simple_test_function("rastrigin")  # multimodal function
    Let config = create_genetic_algorithm_config()
    Set config.diversity_mechanism to "fitness_sharing"
    Set config.sharing_radius to "0.5"
    Set config.alpha_share to "2.0"
    Set config.max_generations to 100
    
    Let result be EvoOpt.genetic_algorithm_with_sharing(objective, config)
    
    Assert.IsTrue(assert_evolutionary_result_valid(result))
    
    Note: Check population diversity
    Let diversity be EvoOpt.calculate_population_diversity(result.final_population)
    Assert.IsTrue(diversity > 0.1)
    Return True

Process called "test_crowding_distance" that takes no parameters returns Boolean:
    Note: Test crowding distance for diversity maintenance
    Let objective be create_multiobjective_test_function()
    Let config be EvoOpt.NSGA_II_Config{
        population_size: 80,
        max_generations: 60,
        diversity_mechanism: "crowding_distance"
    }
    
    Let result be EvoOpt.nsga_ii(objective, config)
    
    Assert.IsTrue(assert_multiobjective_result_valid(result))
    
    Note: Check that crowding distances were computed
    Assert.IsNotNull(result.crowding_distances)
    Assert.IsTrue(result.crowding_distances.length == result.pareto_front.length)
    Return True

Process called "test_speciation_algorithms" that takes no parameters returns Boolean:
    Note: Test speciation-based algorithms
    Let objective be EvoOpt.MultimodalObjective{
        function: "lambda x: -exp(-(x[0]-2)*(x[0]-2) - (x[1]-2)*(x[1]-2)) - exp(-(x[0]+2)*(x[0]+2) - (x[1]+2)*(x[1]+2))",
        num_peaks: 2,
        peak_locations: [["2.0", "2.0"], ["-2.0", "-2.0"]]
    }
    
    Let config be EvoOpt.SpeciationConfig{
        num_species: 2,
        species_radius: "1.0",
        population_size: 60,
        max_generations: 120,
        speciation_method: "k_means"
    }
    
    Let result be EvoOpt.speciation_genetic_algorithm(objective, config)
    
    Assert.IsTrue(assert_evolutionary_result_valid(result))
    Assert.IsTrue(result.species.length == 2)
    
    Note: Check that both peaks were found
    Let peaks_found be 0
    For species in result.species:
        Let best_individual be species.best_individual
        Let x0 be MathCore.parse_float(best_individual[0])
        Let x1 be MathCore.parse_float(best_individual[1])
        If (AbsoluteValue(x0 - 2.0) < 0.5 and AbsoluteValue(x1 - 2.0) < 0.5) or
           (AbsoluteValue(x0 + 2.0) < 0.5 and AbsoluteValue(x1 + 2.0) < 0.5):
            Set peaks_found to peaks_found + 1
    
    Assert.IsTrue(peaks_found >= 1)  # At least one peak should be found
    Return True

Note: =====================================================================
Note: HYBRID AND PARALLEL ALGORITHMS TESTS
Note: =====================================================================

Process called "test_hybrid_ga_local_search" that takes no parameters returns Boolean:
    Note: Test hybrid GA with local search
    Let objective be create_simple_test_function("rosenbrock")
    Let config be EvoOpt.HybridGAConfig{
        ga_config: create_genetic_algorithm_config(),
        local_search_method: "nelder_mead",
        local_search_probability: "0.2",
        local_search_iterations: 20,
        max_generations: 80
    }
    
    Let result be EvoOpt.hybrid_genetic_algorithm(objective, config)
    
    Assert.IsTrue(assert_evolutionary_result_valid(result))
    
    Note: Hybrid should outperform pure GA on this problem
    Let best_fitness be MathCore.parse_float(result.best_fitness)
    Assert.IsTrue(best_fitness < 1.0)
    Return True

Process called "test_memetic_algorithm" that takes no parameters returns Boolean:
    Note: Test memetic algorithm (GA + local search for all individuals)
    Let objective be create_simple_test_function("sphere")
    Let config be EvoOpt.MemeticAlgorithmConfig{
        population_size: 30,
        max_generations: 50,
        local_search_method: "gradient_descent",
        local_search_iterations: 10,
        crossover_rate: "0.8",
        mutation_rate: "0.1"
    }
    
    Let result be EvoOpt.memetic_algorithm(objective, config)
    
    Assert.IsTrue(assert_evolutionary_result_valid(result))
    
    Note: Memetic algorithm should converge very well
    Let best_fitness be MathCore.parse_float(result.best_fitness)
    Assert.IsTrue(best_fitness < 0.001)
    Return True

Process called "test_island_model_parallel_ga" that takes no parameters returns Boolean:
    Note: Test island model for parallel genetic algorithms
    Let objective be create_simple_test_function("rastrigin")
    Let config be EvoOpt.IslandModelConfig{
        num_islands: 4,
        population_per_island: 25,
        migration_interval: 10,
        migration_rate: "0.1",
        topology: "ring",
        max_generations: 100
    }
    
    Let result be EvoOpt.island_model_ga(objective, config)
    
    Assert.IsTrue(assert_evolutionary_result_valid(result))
    Assert.IsTrue(result.islands.length == 4)
    
    Note: Check migration statistics
    Assert.IsNotNull(result.migration_statistics)
    Assert.IsTrue(result.migration_statistics.total_migrations > 0)
    Return True

Process called "test_cooperative_coevolution" that takes no parameters returns Boolean:
    Note: Test cooperative coevolutionary algorithms
    Let objective be EvoOpt.DecomposableObjective{
        function: "lambda x: sum(x[i]*x[i] for i in range(0, 5)) + sum((x[i] - 1)*(x[i] - 1) for i in range(5, 10))",
        subproblems: [
            EvoOpt.Subproblem{variables: [0, 1, 2, 3, 4], bounds: ["-5.0"] * 5},
            EvoOpt.Subproblem{variables: [5, 6, 7, 8, 9], bounds: ["-5.0"] * 5}
        ]
    }
    
    Let config be EvoOpt.CooperativeCoevolutionConfig{
        num_subpopulations: 2,
        subpopulation_size: 30,
        collaboration_method: "random_representatives",
        max_generations: 80
    }
    
    Let result be EvoOpt.cooperative_coevolution(objective, config)
    
    Assert.IsTrue(assert_evolutionary_result_valid(result))
    Assert.IsTrue(result.subpopulations.length == 2)
    Return True

Note: =====================================================================
Note: COMPREHENSIVE TEST RUNNER FUNCTIONS
Note: =====================================================================

Process called "run_genetic_algorithm_tests" that takes no parameters returns Boolean:
    Note: Run all genetic algorithm tests
    Let tests be [
        "test_genetic_algorithm_basic",
        "test_genetic_algorithm_selection_methods",
        "test_genetic_algorithm_crossover_methods",
        "test_genetic_algorithm_mutation_methods",
        "test_genetic_algorithm_elitism"
    ]
    
    Let all_passed be True
    For test_name in tests:
        Try:
            Print "Running " + test_name + "..."
            Let result be Call(test_name)
            If result:
                Print "  ‚úì " + test_name + " PASSED"
            Else:
                Print "  ‚úó " + test_name + " FAILED"
                Set all_passed to False
        Catch error:
            Print "  ‚úó " + test_name + " ERROR: " + ToString(error)
            Set all_passed to False
    
    Return all_passed

Process called "run_particle_swarm_tests" that takes no parameters returns Boolean:
    Note: Run all particle swarm optimization tests
    Let tests be [
        "test_particle_swarm_optimization_basic",
        "test_pso_inertia_weight_strategies",
        "test_pso_topology_variants",
        "test_pso_velocity_clamping",
        "test_pso_with_constriction_factor"
    ]
    
    Let all_passed be True
    For test_name in tests:
        Try:
            Print "Running " + test_name + "..."
            Let result be Call(test_name)
            If result:
                Print "  ‚úì " + test_name + " PASSED"
            Else:
                Print "  ‚úó " + test_name + " FAILED"
                Set all_passed to False
        Catch error:
            Print "  ‚úó " + test_name + " ERROR: " + ToString(error)
            Set all_passed to False
    
    Return all_passed

Process called "run_differential_evolution_tests" that takes no parameters returns Boolean:
    Note: Run all differential evolution tests
    Let tests be [
        "test_differential_evolution_basic",
        "test_differential_evolution_strategies",
        "test_differential_evolution_parameter_adaptation",
        "test_differential_evolution_bounds_handling"
    ]
    
    Let all_passed be True
    For test_name in tests:
        Try:
            Print "Running " + test_name + "..."
            Let result be Call(test_name)
            If result:
                Print "  ‚úì " + test_name + " PASSED"
            Else:
                Print "  ‚úó " + test_name + " FAILED"
                Set all_passed to False
        Catch error:
            Print "  ‚úó " + test_name + " ERROR: " + ToString(error)
            Set all_passed to False
    
    Return all_passed

Process called "run_evolution_strategies_tests" that takes no parameters returns Boolean:
    Note: Run all evolution strategies tests
    Let tests be [
        "test_evolution_strategies_basic",
        "test_cma_es_basic",
        "test_evolution_strategies_variants"
    ]
    
    Let all_passed be True
    For test_name in tests:
        Try:
            Print "Running " + test_name + "..."
            Let result be Call(test_name)
            If result:
                Print "  ‚úì " + test_name + " PASSED"
            Else:
                Print "  ‚úó " + test_name + " FAILED"
                Set all_passed to False
        Catch error:
            Print "  ‚úó " + test_name + " ERROR: " + ToString(error)
            Set all_passed to False
    
    Return all_passed

Process called "run_multi_objective_tests" that takes no parameters returns Boolean:
    Note: Run all multi-objective optimization tests
    Let tests be [
        "test_nsga_ii_basic",
        "test_spea2_algorithm",
        "test_multi_objective_metrics",
        "test_pareto_dominance_relationships"
    ]
    
    Let all_passed be True
    For test_name in tests:
        Try:
            Print "Running " + test_name + "..."
            Let result be Call(test_name)
            If result:
                Print "  ‚úì " + test_name + " PASSED"
            Else:
                Print "  ‚úó " + test_name + " FAILED"
                Set all_passed to False
        Catch error:
            Print "  ‚úó " + test_name + " ERROR: " + ToString(error)
            Set all_passed to False
    
    Return all_passed

Process called "run_constraint_handling_tests" that takes no parameters returns Boolean:
    Note: Run all constraint handling tests
    Let tests be [
        "test_penalty_method_constraints",
        "test_feasibility_preservation",
        "test_multi_objective_constraints"
    ]
    
    Let all_passed be True
    For test_name in tests:
        Try:
            Print "Running " + test_name + "..."
            Let result be Call(test_name)
            If result:
                Print "  ‚úì " + test_name + " PASSED"
            Else:
                Print "  ‚úó " + test_name + " FAILED"
                Set all_passed to False
        Catch error:
            Print "  ‚úó " + test_name + " ERROR: " + ToString(error)
            Set all_passed to False
    
    Return all_passed

Process called "run_diversity_niching_tests" that takes no parameters returns Boolean:
    Note: Run all diversity and niching tests
    Let tests be [
        "test_fitness_sharing",
        "test_crowding_distance",
        "test_speciation_algorithms"
    ]
    
    Let all_passed be True
    For test_name in tests:
        Try:
            Print "Running " + test_name + "..."
            Let result be Call(test_name)
            If result:
                Print "  ‚úì " + test_name + " PASSED"
            Else:
                Print "  ‚úó " + test_name + " FAILED"
                Set all_passed to False
        Catch error:
            Print "  ‚úó " + test_name + " ERROR: " + ToString(error)
            Set all_passed to False
    
    Return all_passed

Process called "run_hybrid_parallel_tests" that takes no parameters returns Boolean:
    Note: Run all hybrid and parallel algorithm tests
    Let tests be [
        "test_hybrid_ga_local_search",
        "test_memetic_algorithm",
        "test_island_model_parallel_ga",
        "test_cooperative_coevolution"
    ]
    
    Let all_passed be True
    For test_name in tests:
        Try:
            Print "Running " + test_name + "..."
            Let result be Call(test_name)
            If result:
                Print "  ‚úì " + test_name + " PASSED"
            Else:
                Print "  ‚úó " + test_name + " FAILED"
                Set all_passed to False
        Catch error:
            Print "  ‚úó " + test_name + " ERROR: " + ToString(error)
            Set all_passed to False
    
    Return all_passed

Process called "run_all_tests" that takes no parameters returns Boolean:
    Note: Run all evolutionary optimization module tests
    Print "=" * 80
    Print "EVOLUTIONARY OPTIMIZATION MODULE COMPREHENSIVE TEST SUITE"
    Print "=" * 80
    Print ""
    
    Let test_categories be [
        ["Genetic Algorithms", "run_genetic_algorithm_tests"],
        ["Particle Swarm Optimization", "run_particle_swarm_tests"],
        ["Differential Evolution", "run_differential_evolution_tests"],
        ["Evolution Strategies", "run_evolution_strategies_tests"],
        ["Multi-Objective Optimization", "run_multi_objective_tests"],
        ["Constraint Handling", "run_constraint_handling_tests"],
        ["Diversity and Niching", "run_diversity_niching_tests"],
        ["Hybrid and Parallel Algorithms", "run_hybrid_parallel_tests"]
    ]
    
    Let overall_success be True
    Let passed_categories be 0
    Let total_categories be test_categories.length
    
    For category_info in test_categories:
        Let category_name be category_info[0]
        Let test_runner be category_info[1]
        
        Print "Testing " + category_name + "..."
        Print "-" * (9 + Length(category_name))
        
        Let category_result be Call(test_runner)
        If category_result:
            Print "‚úì " + category_name + ": ALL TESTS PASSED"
            Set passed_categories to passed_categories + 1
        Else:
            Print "‚úó " + category_name + ": SOME TESTS FAILED"
            Set overall_success to False
        Print ""
    
    Print "=" * 80
    Print "EVOLUTIONARY OPTIMIZATION TEST SUMMARY"
    Print "=" * 80
    Print "Categories tested: " + ToString(total_categories)
    Print "Categories passed: " + ToString(passed_categories)
    Print "Categories failed: " + ToString(total_categories - passed_categories)
    
    Let success_rate be (passed_categories * 100.0) / total_categories
    Print "Success rate: " + ToString(success_rate) + "%"
    
    If overall_success:
        Print "\nüéâ ALL EVOLUTIONARY OPTIMIZATION TESTS PASSED! üéâ"
        Print "The evolutionary optimization module is ready for production use."
    Else:
        Print "\n‚ùå SOME EVOLUTIONARY OPTIMIZATION TESTS FAILED ‚ùå"
        Print "Please review and fix failing tests before deployment."
    
    Print "=" * 80
    
    Return overall_success