Import module "core_libs" as Core

Note: =====================================================================
Note: TOKEN DATA STRUCTURES
Note: =====================================================================

Type called "Token":
    kind as String                       Note: Token type (keyword, identifier, etc.)
    value as String                      Note: Actual token text
    line as Integer                      Note: Line number in source
    column as Integer                    Note: Column position in line
    length as Integer                    Note: Token length in characters
End Type

Type called "TokenStream":
    tokens as Array                      Note: Array of Token objects
    current_index as Integer             Note: Current position in stream
    source_file as String                Note: Source file path
End Type

Note: =====================================================================
Note: AST DATA STRUCTURES
Note: =====================================================================

Type called "ASTNode":
    node_type as String                  Note: Type of AST node
    children as Array                    Note: Child nodes
    value as String                      Note: Node-specific value
    start_token as Token                 Note: First token of this node
    end_token as Token                   Note: Last token of this node
End Type

Type called "ParseContext":
    tokens as TokenStream                Note: Token stream being parsed
    errors as Array                      Note: Accumulated parse errors
    current_scope as String              Note: Current parsing scope
    precedence_level as Integer          Note: Current operator precedence
End Type

Note: =====================================================================
Note: TOKENIZATION OPERATIONS
Note: =====================================================================

Process called "tokenize" that takes source as String returns TokenStream:
    Note: Tokenize Runa source code into token stream
    Note: Handles all Runa keywords, operators, and literals
    Note: Time complexity: O(n), Space complexity: O(n)
    Note: Preserves position information for error reporting
    
    Let tokens be Core.empty_list()
    Let current_line be 1
    Let current_column be 1
    Let position be 0
    Let source_length be Core.string_length(source)
    
    While position is less than source_length:
        Let char be Core.string_substring(source, position, position plus 1)
        
        Note: Skip whitespace
        If char is equal to " " or char is equal to "	":
            Set current_column to current_column plus 1
            Set position to position plus 1
        Otherwise If char is equal to "\n" or char is equal to "\r":
            Set current_line to current_line plus 1
            Set current_column to 1
            Set position to position plus 1
        Otherwise:
            Note: Scan for token starting at current position
            Let token be scan_next_token(source, position, current_line, current_column)
            Core.array_push(tokens, token)
            Set position to position plus token.length
            Set current_column to current_column plus token.length
        End If
    End While
    
    Note: Add EOF token
    Let eof_token be Token with kind as "EOF", value as "", line as current_line, column as current_column, length as 0
    Core.array_push(tokens, eof_token)
    
    Let token_stream be TokenStream with tokens as tokens, current_index as 0, source_file as "<source>"
    Return token_stream
End Process

Process called "scan_identifier" that takes source as String, position as Integer returns Token:
    Note: Scan identifier or keyword from source
    Note: Distinguishes between keywords and user identifiers
    Note: Handles Unicode identifiers
    
    Let start_position be position
    Let source_length be Core.string_length(source)
    Let end_position be position
    
    Note: Scan while character is letter, digit, or underscore
    While end_position is less than source_length:
        Let char be Core.string_substring(source, end_position, end_position plus 1)
        If is_identifier_char(char) is equal to true:
            Set end_position to end_position plus 1
        Otherwise:
            Break
        End If
    End While
    
    Let value be Core.string_substring(source, start_position, end_position)
    Let length be end_position minus start_position
    
    Note: Check if this is a keyword
    Let kind be "identifier"
    If is_keyword(value) is equal to true:
        Set kind to "keyword"
    End If
    
    Let token be Token with kind as kind, value as value, line as 0, column as 0, length as length
    Return token
End Process

Process called "scan_number" that takes source as String, position as Integer returns Token:
    Note: Scan numeric literal from source
    Note: Supports integers, floats, scientific notation
    Note: Handles different number bases (hex, binary, octal)
    
    Let start_position be position
    Let source_length be Core.string_length(source)
    Let end_position be position
    Let has_decimal_point be false
    
    Note: Scan digits
    While end_position is less than source_length:
        Let char be Core.string_substring(source, end_position, end_position plus 1)
        If is_digit(char) is equal to true:
            Set end_position to end_position plus 1
        Otherwise If char is equal to "." and has_decimal_point is equal to false:
            Set has_decimal_point to true
            Set end_position to end_position plus 1
        Otherwise:
            Break
        End If
    End While
    
    Let value be Core.string_substring(source, start_position, end_position)
    Let length be end_position minus start_position
    Let kind be "integer"
    If has_decimal_point is equal to true:
        Set kind to "float"
    End If
    
    Let token be Token with kind as kind, value as value, line as 0, column as 0, length as length
    Return token
End Process

Note: =====================================================================
Note: PARSING OPERATIONS
Note: =====================================================================

Process called "parse" that takes tokens as TokenStream returns ASTNode:
    Note: Parse token stream into abstract syntax tree
    Note: Uses recursive descent parsing
    Note: Implements error recovery for robustness
    
    Let context be ParseContext with tokens as tokens, errors as Core.empty_list(), current_scope as "global", precedence_level as 0
    Let statements be Core.empty_list()
    
    Note: Parse all top-level statements
    While peek_token(context).kind is not equal to "EOF":
        Let statement be parse_statement(context)
        Core.array_push(statements, statement)
    End While
    
    Note: Create root AST node
    Let start_token be Token with kind as "SOF", value as "", line as 1, column as 1, length as 0
    Let end_token be peek_token(context)
    Let root be ASTNode with node_type as "Program", children as statements, value as null, start_token as start_token, end_token as end_token
    
    Return root
End Process

Process called "parse_expression" that takes context as ParseContext returns ASTNode:
    Note: Parse expression with operator precedence
    Note: Handles binary, unary, and ternary operators
    Note: Implements Pratt parsing algorithm
    
    Return parse_binary_expression(context, 0)
End Process

Process called "parse_statement" that takes context as ParseContext returns ASTNode:
    Note: Parse single statement
    Note: Handles all Runa statement types
    Note: Includes error recovery points
    
    Let current_token be peek_token(context)
    
    Note: Dispatch based on statement type
    If current_token.kind is equal to "keyword" and current_token.value is equal to "Let":
        Return parse_variable_declaration(context)
    Otherwise If current_token.kind is equal to "keyword" and current_token.value is equal to "Set":
        Return parse_assignment_statement(context)
    Otherwise If current_token.kind is equal to "keyword" and current_token.value is equal to "If":
        Return parse_if_statement(context)
    Otherwise If current_token.kind is equal to "keyword" and current_token.value is equal to "While":
        Return parse_while_statement(context)
    Otherwise If current_token.kind is equal to "keyword" and current_token.value is equal to "Assembly":
        Return parse_assembly_statement(context)
    Otherwise If current_token.kind is equal to "keyword" and current_token.value is equal to "For":
        Return parse_for_statement(context)
    Otherwise If current_token.kind is equal to "keyword" and current_token.value is equal to "Return":
        Return parse_return_statement(context)
    Otherwise If current_token.kind is equal to "keyword" and current_token.value is equal to "Process":
        Return parse_function(context)
    Otherwise If current_token.kind is equal to "keyword" and current_token.value is equal to "Type":
        Return parse_type(context)
    Otherwise If current_token.kind is equal to "keyword" and current_token.value is equal to "Import":
        Return parse_import_statement(context)
    Otherwise:
        Note: Expression statement
        Let expr be parse_expression(context)
        Let stmt be ASTNode with node_type as "ExpressionStatement", children as Core.empty_list(), value as expr, start_token as current_token, end_token as peek_token(context)
        Return stmt
    End If
End Process

Process called "parse_function" that takes context as ParseContext returns ASTNode:
    Note: Parse Process definition
    Note: Handles parameters, return types, and body
    Note: Validates function signature
    
    Let start_token be consume_token(context)  Note: Process keyword
    expect_keyword(context, "called")
    
    Let name_token be expect_token(context, "string")
    Let name be name_token.value
    
    Note: Parse parameter list
    Let parameters be Core.empty_list()
    If peek_token(context).value is equal to "that":
        consume_token(context)  Note: that
        expect_keyword(context, "takes")
        
        Note: Parse parameters
        While peek_token(context).kind is not equal to "keyword" or peek_token(context).value is not equal to "returns":
            Let param_name be expect_token(context, "identifier")
            expect_keyword(context, "as")
            Let param_type be expect_token(context, "identifier")
            
            Let param be ASTNode with node_type as "Parameter", children as Core.empty_list(), value as param_name.value, start_token as param_name, end_token as param_type
            Core.array_push(parameters, param)
            
            Note: Check for more parameters
            If peek_token(context).value is equal to ",":
                consume_token(context)
            End If
        End While
    End If
    
    Note: Parse return type
    Let return_type be null
    If peek_token(context).value is equal to "returns":
        consume_token(context)
        Let return_type_token be expect_token(context, "identifier")
        Set return_type to return_type_token.value
    End If
    
    expect_token(context, "colon")
    
    Note: Parse function body
    Let body be Core.empty_list()
    While peek_token(context).value is not equal to "End":
        Let stmt be parse_statement(context)
        Core.array_push(body, stmt)
    End While
    
    expect_keyword(context, "End")
    expect_keyword(context, "Process")
    
    Let function_node be ASTNode with node_type as "FunctionDeclaration", children as body, value as name, start_token as start_token, end_token as peek_token(context)
    Return function_node
End Process

Process called "parse_type" that takes context as ParseContext returns ASTNode:
    Note: Parse Type definition
    Note: Handles structured types and enums
    Note: Supports generic type parameters
    
    Let start_token be consume_token(context)  Note: Type keyword
    expect_keyword(context, "called")
    
    Let name_token be expect_token(context, "string")
    Let name be name_token.value
    
    expect_token(context, "colon")
    
    Note: Parse type body (fields)
    Let fields be Core.empty_list()
    While peek_token(context).value is not equal to "End":
        Let field_name be expect_token(context, "identifier")
        expect_keyword(context, "as")
        Let field_type be expect_token(context, "identifier")
        
        Let field be ASTNode with node_type as "Field", children as Core.empty_list(), value as field_name.value, start_token as field_name, end_token as field_type
        Core.array_push(fields, field)
    End While
    
    expect_keyword(context, "End")
    expect_keyword(context, "Type")
    
    Let type_node be ASTNode with node_type as "TypeDeclaration", children as fields, value as name, start_token as start_token, end_token as peek_token(context)
    Return type_node
End Process

Process called "parse_assembly_statement" that takes context as ParseContext returns ASTNode:
    Note: Parse inline Assembly statement
    Note: Format: Assembly "instruction string"
    
    Let start_token be consume_token(context)  Note: Assembly keyword
    
    Note: Expect a string literal containing the assembly instructions
    Let asm_token be peek_token(context)
    If asm_token.kind is not equal to "string":
        add_error(context, "Expected string literal after Assembly keyword")
        Let error_node be ASTNode with node_type as "Error", children as Core.empty_list(), value as "Invalid assembly statement", start_token as start_token, end_token as asm_token
        Return error_node
    End If
    
    Let asm_string be consume_token(context)
    Let end_token be asm_string
    
    Note: Create AST node for inline assembly
    Let asm_node be ASTNode with node_type as "AssemblyStatement", children as Core.empty_list(), value as asm_string.value, start_token as start_token, end_token as end_token
    Return asm_node
End Process

Note: =====================================================================
Note: ERROR RECOVERY OPERATIONS
Note: =====================================================================

Process called "recover_from_error" that takes context as ParseContext, expected as String returns Nothing:
    Note: Recover parser state after syntax error
    Note: Synchronizes to next valid parse point
    Note: Minimizes cascading errors
    
    Note: Skip tokens until we find a synchronization point
    While context.tokens.current_index is less than Core.array_length(context.tokens.tokens):
        Let current_token be peek_token(context)
        
        Note: Look for statement boundaries and block endings  
        If current_token.kind is equal to "keyword" and current_token.value is equal to "End":
            Break
        End If
        If current_token.kind is equal to "keyword" and current_token.value is equal to "Let":
            Break
        End If
        If current_token.kind is equal to "keyword" and current_token.value is equal to "Set":
            Break
        End If
        If current_token.kind is equal to "keyword" and current_token.value is equal to "Process":
            Break
        End If
        If current_token.kind is equal to "keyword" and current_token.value is equal to "Type":
            Break
        End If
        
        Note: Stop at EOF
        If current_token.kind is equal to "EOF":
            Break
        End If
        
        consume_token(context)
    End While
End Process

Process called "add_parse_error" that takes context as ParseContext, message as String, token as Token returns Nothing:
    Note: Record parse error with context
    Note: Includes source position and expected tokens
    Note: Maintains error list for reporting
    
    Note: Create error information with position and message
    Let error_info be Core.string_concat("Parse error at line ", Core.integer_to_string(token.line))
    Set error_info to Core.string_concat(error_info, ", column ")
    Set error_info to Core.string_concat(error_info, Core.integer_to_string(token.column))
    Set error_info to Core.string_concat(error_info, ": ")
    Set error_info to Core.string_concat(error_info, message)
    
    Note: Add to error list
    Core.array_push(context.errors, error_info)
End Process

Note: =====================================================================
Note: HELPER OPERATIONS
Note: =====================================================================

Process called "scan_next_token" that takes source as String, position as Integer, line as Integer, column as Integer returns Token:
    Note: Scan the next token from the current position
    Let char be Core.string_substring(source, position, position plus 1)
    
    Note: Check for different token types
    If is_letter(char) is equal to true:
        Return scan_identifier(source, position)
    Otherwise If is_digit(char) is equal to true:
        Return scan_number(source, position)
    Otherwise If char is equal to "\"":
        Return scan_string(source, position)
    Otherwise If char is equal to ":":
        Let token be Token with kind as "colon", value as ":", line as line, column as column, length as 1
        Return token
    Otherwise If char is equal to ",":
        Let token be Token with kind as "comma", value as ",", line as line, column as column, length as 1
        Return token
    Otherwise:
        Note: Unknown character, treat as single character token
        Let token be Token with kind as "unknown", value as char, line as line, column as column, length as 1
        Return token
    End If
End Process

Process called "scan_string" that takes source as String, position as Integer returns Token:
    Note: Scan string literal from source
    Let start_position be position
    Let end_position be position plus 1  Note: Skip opening quote
    Let source_length be Core.string_length(source)
    
    Note: Scan until closing quote
    While end_position is less than source_length:
        Let char be Core.string_substring(source, end_position, end_position plus 1)
        If char is equal to "\"":
            Set end_position to end_position plus 1  Note: Include closing quote
            Break
        End If
        Set end_position to end_position plus 1
    End While
    
    Let value be Core.string_substring(source, start_position plus 1, end_position minus 1)  Note: Remove quotes
    Let length be end_position minus start_position
    Let token be Token with kind as "string", value as value, line as 0, column as 0, length as length
    Return token
End Process

Process called "is_letter" that takes char as String returns Boolean:
    Note: Check if character is a letter  
    Return char is equal to "a" or char is equal to "b" or char is equal to "c" or char is equal to "d" or char is equal to "e" or char is equal to "f" or char is equal to "g" or char is equal to "h" or char is equal to "i" or char is equal to "j" or char is equal to "k" or char is equal to "l" or char is equal to "m" or char is equal to "n" or char is equal to "o" or char is equal to "p" or char is equal to "q" or char is equal to "r" or char is equal to "s" or char is equal to "t" or char is equal to "u" or char is equal to "v" or char is equal to "w" or char is equal to "x" or char is equal to "y" or char is equal to "z" or char is equal to "A" or char is equal to "B" or char is equal to "C" or char is equal to "D" or char is equal to "E" or char is equal to "F" or char is equal to "G" or char is equal to "H" or char is equal to "I" or char is equal to "J" or char is equal to "K" or char is equal to "L" or char is equal to "M" or char is equal to "N" or char is equal to "O" or char is equal to "P" or char is equal to "Q" or char is equal to "R" or char is equal to "S" or char is equal to "T" or char is equal to "U" or char is equal to "V" or char is equal to "W" or char is equal to "X" or char is equal to "Y" or char is equal to "Z"
End Process

Process called "is_digit" that takes char as String returns Boolean:
    Note: Check if character is a digit
    Return char is equal to "0" or char is equal to "1" or char is equal to "2" or char is equal to "3" or char is equal to "4" or char is equal to "5" or char is equal to "6" or char is equal to "7" or char is equal to "8" or char is equal to "9"
End Process

Process called "is_identifier_char" that takes char as String returns Boolean:
    Note: Check if character is valid in identifier
    Return is_letter(char) or is_digit(char) or char is equal to "_"
End Process

Process called "is_keyword" that takes word as String returns Boolean:
    Note: Check if word is a Runa keyword
    Return word is equal to "Let" or word is equal to "Set" or word is equal to "If" or word is equal to "Otherwise" or word is equal to "While" or word is equal to "For" or word is equal to "Return" or word is equal to "Process" or word is equal to "Type" or word is equal to "Import" or word is equal to "Assembly" or word is equal to "External" or word is equal to "End" or word is equal to "called" or word is equal to "that" or word is equal to "takes" or word is equal to "as" or word is equal to "returns"
End Process

Process called "peek_token" that takes context as ParseContext returns Token:
    Note: Look at current token without consuming it
    Let index be context.tokens.current_index
    If index is greater than or equal to Core.array_length(context.tokens.tokens):
        Let eof_token be Token with kind as "EOF", value as "", line as 0, column as 0, length as 0
        Return eof_token
    End If
    
    Let token be Core.array_get(context.tokens.tokens, index)
    Return token
End Process

Process called "consume_token" that takes context as ParseContext returns Token:
    Note: Consume and return current token
    Let token be peek_token(context)
    Set context.tokens.current_index to context.tokens.current_index plus 1
    Return token
End Process

Process called "expect_token" that takes context as ParseContext, expected_kind as String returns Token:
    Note: Consume token and verify it matches expected kind
    Let token be consume_token(context)
    If token.kind is not equal to expected_kind:
        add_parse_error(context, Core.string_concat("Expected ", expected_kind), token)
        recover_from_error(context, expected_kind)
    End If
    Return token
End Process

Process called "expect_keyword" that takes context as ParseContext, expected_value as String returns Token:
    Note: Consume token and verify it matches expected keyword
    Let token be consume_token(context)
    If token.kind is not equal to "keyword" or token.value is not equal to expected_value:
        add_parse_error(context, Core.string_concat("Expected keyword '", expected_value), token)
        recover_from_error(context, expected_value)
    End If
    Return token
End Process

Process called "parse_binary_expression" that takes context as ParseContext, min_precedence as Integer returns ASTNode:
    Note: Parse binary expression with precedence climbing
    Let left be parse_primary_expression(context)
    
    While true:
        Let op_token be peek_token(context)
        Let precedence be get_operator_precedence(op_token.value)
        
        If precedence is less than min_precedence:
            Break
        End If
        
        consume_token(context)  Note: Consume operator
        Let right be parse_binary_expression(context, precedence plus 1)
        
        Let children be Core.empty_list()
        Core.array_push(children, left)
        Core.array_push(children, right)
        
        Set left to ASTNode with node_type as "BinaryExpression", children as children, value as op_token.value, start_token as left.start_token, end_token as right.end_token
    End While
    
    Return left
End Process

Process called "parse_primary_expression" that takes context as ParseContext returns ASTNode:
    Note: Parse primary expressions (literals, identifiers, parenthesized)
    Let token be peek_token(context)
    
    If token.kind is equal to "integer" or token.kind is equal to "float" or token.kind is equal to "string":
        consume_token(context)
        Let literal be ASTNode with node_type as "Literal", children as Core.empty_list(), value as token.value, start_token as token, end_token as token
        Return literal
    Otherwise If token.kind is equal to "identifier":
        consume_token(context)
        Let identifier be ASTNode with node_type as "Identifier", children as Core.empty_list(), value as token.value, start_token as token, end_token as token
        Return identifier
    Otherwise:
        add_parse_error(context, "Expected expression", token)
        recover_from_error(context, "expression")
        Let error_node be ASTNode with node_type as "Error", children as Core.empty_list(), value as null, start_token as token, end_token as token
        Return error_node
    End If
End Process

Process called "get_operator_precedence" that takes operator as String returns Integer:
    Note: Get precedence for binary operators
    If operator is equal to "plus" or operator is equal to "minus":
        Return 1
    Otherwise If operator is equal to "multiplied" or operator is equal to "divided":
        Return 2
    Otherwise:
        Return 0
    End If
End Process

Process called "parse_variable_declaration" that takes context as ParseContext returns ASTNode:
    Note: Parse Let statement
    Let start_token be consume_token(context)  Note: Let keyword
    Let name_token be expect_token(context, "identifier")
    expect_keyword(context, "be")
    Let value be parse_expression(context)
    
    Let children be Core.empty_list()
    Core.array_push(children, value)
    
    Let declaration be ASTNode with node_type as "VariableDeclaration", children as children, value as name_token.value, start_token as start_token, end_token as peek_token(context)
    Return declaration
End Process

Process called "parse_assignment_statement" that takes context as ParseContext returns ASTNode:
    Note: Parse Set statement
    Let start_token be consume_token(context)  Note: Set keyword
    Let name_token be expect_token(context, "identifier")
    expect_keyword(context, "to")
    Let value be parse_expression(context)
    
    Let children be Core.empty_list()
    Core.array_push(children, value)
    
    Let assignment be ASTNode with node_type as "Assignment", children as children, value as name_token.value, start_token as start_token, end_token as peek_token(context)
    Return assignment
End Process

Process called "parse_if_statement" that takes context as ParseContext returns ASTNode:
    Note: Parse If statement
    Let start_token be consume_token(context)  Note: If keyword
    Let condition be parse_expression(context)
    expect_token(context, "colon")
    
    Let then_body be Core.empty_list()
    While peek_token(context).value is not equal to "End" and peek_token(context).value is not equal to "Otherwise":
        Let stmt be parse_statement(context)
        Core.array_push(then_body, stmt)
    End While
    
    Let else_body be Core.empty_list()
    If peek_token(context).value is equal to "Otherwise":
        consume_token(context)  Note: Otherwise keyword
        While peek_token(context).value is not equal to "End":
            Let stmt be parse_statement(context)
            Core.array_push(else_body, stmt)
        End While
    End If
    
    expect_keyword(context, "End")
    expect_keyword(context, "If")
    
    Let children be Core.empty_list()
    Core.array_push(children, condition)
    Core.array_push(children, then_body)
    Core.array_push(children, else_body)
    
    Let if_stmt be ASTNode with node_type as "IfStatement", children as children, value as null, start_token as start_token, end_token as peek_token(context)
    Return if_stmt
End Process

Process called "parse_while_statement" that takes context as ParseContext returns ASTNode:
    Note: Parse While statement
    Let start_token be consume_token(context)  Note: While keyword
    Let condition be parse_expression(context)
    expect_token(context, "colon")
    
    Let body be Core.empty_list()
    While peek_token(context).value is not equal to "End":
        Let stmt be parse_statement(context)
        Core.array_push(body, stmt)
    End While
    
    expect_keyword(context, "End")
    expect_keyword(context, "While")
    
    Let children be Core.empty_list()
    Core.array_push(children, condition)
    Core.array_push(children, body)
    
    Let while_stmt be ASTNode with node_type as "WhileStatement", children as children, value as null, start_token as start_token, end_token as peek_token(context)
    Return while_stmt
End Process

Process called "parse_for_statement" that takes context as ParseContext returns ASTNode:
    Note: Parse For Each statement
    Let start_token be consume_token(context)  Note: For keyword
    expect_keyword(context, "Each")
    Let var_token be expect_token(context, "identifier")
    expect_keyword(context, "in")
    Let iterable be parse_expression(context)
    expect_token(context, "colon")
    
    Let body be Core.empty_list()
    While peek_token(context).value is not equal to "End":
        Let stmt be parse_statement(context)
        Core.array_push(body, stmt)
    End While
    
    expect_keyword(context, "End")
    expect_keyword(context, "For")
    
    Let children be Core.empty_list()
    Core.array_push(children, iterable)
    Core.array_push(children, body)
    
    Let for_stmt be ASTNode with node_type as "ForStatement", children as children, value as var_token.value, start_token as start_token, end_token as peek_token(context)
    Return for_stmt
End Process

Process called "parse_return_statement" that takes context as ParseContext returns ASTNode:
    Note: Parse Return statement
    Let start_token be consume_token(context)  Note: Return keyword
    
    Let value be null
    If peek_token(context).kind is not equal to "EOF" and peek_token(context).value is not equal to "End":
        Set value to parse_expression(context)
    End If
    
    Let children be Core.empty_list()
    If value is not null:
        Core.array_push(children, value)
    End If
    
    Let return_stmt be ASTNode with node_type as "ReturnStatement", children as children, value as null, start_token as start_token, end_token as peek_token(context)
    Return return_stmt
End Process

Process called "parse_import_statement" that takes context as ParseContext returns ASTNode:
    Note: Parse Import statement
    Let start_token be consume_token(context)  Note: Import keyword
    expect_keyword(context, "module")
    Let module_name be expect_token(context, "string")
    
    Let alias be null
    If peek_token(context).value is equal to "as":
        consume_token(context)  Note: as keyword
        Let alias_token be expect_token(context, "identifier")
        Set alias to alias_token.value
    End If
    
    Let import_stmt be ASTNode with node_type as "ImportStatement", children as Core.empty_list(), value as module_name.value, start_token as start_token, end_token as peek_token(context)
    Return import_stmt
End Process

Note: =====================================================================
Note: AST MANIPULATION OPERATIONS  
Note: =====================================================================

Process called "optimize_ast" that takes root as ASTNode returns ASTNode:
    Note: Perform AST-level optimizations
    Note: Constant folding, dead code elimination
    Note: Preserves semantic equivalence
    
    Note: For bootstrap phase, implement basic constant folding
    If root.node_type is equal to "BinaryExpression":
        Let left be Core.array_get(root.children, 0)
        Let right be Core.array_get(root.children, 1)
        
        Note: Recursively optimize children first
        Let optimized_left be optimize_ast(left)
        Let optimized_right be optimize_ast(right)
        
        Note: Constant folding for numeric operations
        If optimized_left.node_type is equal to "Literal" and optimized_right.node_type is equal to "Literal" and root.value is equal to "plus":
            Let left_val be Core.string_to_integer(optimized_left.value)
            Let right_val be Core.string_to_integer(optimized_right.value)
            Let result be left_val plus right_val
            Let folded_node be ASTNode with node_type as "Literal", children as Core.empty_list(), value as Core.integer_to_string(result), start_token as root.start_token, end_token as root.end_token
            Return folded_node
        End If
    End If
    
    Note: Optimize children recursively
    Let optimized_children be Core.empty_list()
    Let child_index be 0
    While child_index is less than Core.array_length(root.children):
        Let child be Core.array_get(root.children, child_index)
        Let optimized_child be optimize_ast(child)
        Core.array_push(optimized_children, optimized_child)
        Set child_index to child_index plus 1
    End While
    
    Note: Return optimized node
    Let optimized_root be ASTNode with node_type as root.node_type, children as optimized_children, value as root.value, start_token as root.start_token, end_token as root.end_token
    Return optimized_root
End Process

Process called "validate_ast" that takes root as ASTNode returns Core.Result:
    Note: Validate AST structure and consistency
    Note: Checks for semantic errors
    Note: Ensures all nodes are properly formed
    
    Note: Check if node type is valid
    If root.node_type is null or Core.string_length(root.node_type) is equal to 0:
        Let error_result be Core.Result with success as false, value as null, error_message as "Invalid node type"
        Return error_result
    End If
    
    Note: Check children array exists
    If root.children is null:
        Let error_result be Core.Result with success as false, value as null, error_message as "Missing children array"
        Return error_result
    End If
    
    Note: Validate all child nodes recursively
    Let child_index be 0
    While child_index is less than Core.array_length(root.children):
        Let child be Core.array_get(root.children, child_index)
        Let child_result be validate_ast(child)
        
        If child_result.success is equal to false:
            Return child_result
        End If
        
        Set child_index to child_index plus 1
    End While
    
    Note: Node-specific validation
    If root.node_type is equal to "FunctionDeclaration":
        If root.value is null or Core.string_length(root.value) is equal to 0:
            Let error_result be Core.Result with success as false, value as null, error_message as "Function declaration missing name"
            Return error_result
        End If
    End If
    
    If root.node_type is equal to "TypeDeclaration":
        If root.value is null or Core.string_length(root.value) is equal to 0:
            Let error_result be Core.Result with success as false, value as null, error_message as "Type declaration missing name"
            Return error_result
        End If
    End If
    
    Let success_result be Core.Result with success as true, value as root, error_message as null
    Return success_result
End Process